{"timestamp": "2025-10-22T03:28:51.234564", "feed": "arxiv_cslg", "title": "Learning Task-Agnostic Representations through Multi-Teacher Distillation", "link": "https://papers.cool/arxiv/2510.18680", "analysis": {"summary": "The paper proposes a task-agnostic distillation framework that uses a majority-vote objective to combine diverse teacher embeddings across modalities, deriving a loss bounded by mutual information between student and teachers. Experiments on text, vision, and molecular data show that the resulting student representations improve performance on various downstream tasks such as classification, clustering, and regression without requiring task-specific labels.", "summary_cn": "本文提出一种任务无关的多教师蒸馏框架，采用“多数投票”目标函数，将文本、视觉和分子等不同模态的教师嵌入进行融合，并证明该目标函数被学生与教师嵌入之间的互信息所界定。实验表明，得到的学生表示能够在无需任务标签的情况下提升分类、聚类和回归等多种下游任务的性能。", "keywords": "multi-teacher distillation, task-agnostic representation, embedding, mutual information, knowledge distillation, modality-agnostic, representation learning, downstream tasks, classification, clustering", "scoring": {"interpretability": 3, "understanding": 6, "safety": 1, "technicality": 8, "surprisal": 6}, "category": {"failure_mode_addressed": "non-applicable", "primary_focus": "other"}, "authors": ["Philippe Formont", "Maxime Darrin", "Banafsheh Karimian", "Jackie CK Cheung", "Eric Granger", "Ismail Ben Ayed", "Mohammadhadi Shateri", "Pablo Piantanida"]}, "usage": {"completion_tokens": 681, "prompt_tokens": 3375, "total_tokens": 4056, "completion_tokens_details": {"accepted_prediction_tokens": null, "audio_tokens": null, "reasoning_tokens": 464, "rejected_prediction_tokens": null, "image_tokens": 0}, "prompt_tokens_details": {"audio_tokens": 0, "cached_tokens": 3136}, "cost": 0.00091485, "is_byok": false, "cost_details": {"upstream_inference_cost": null, "upstream_inference_prompt_cost": 0.00050625, "upstream_inference_completions_cost": 0.0004086}}, "model": "openai/gpt-oss-120b"}
{"timestamp": "2025-10-22T03:28:51.379323", "feed": "arxiv_cslg", "title": "Benchmarking Fairness-aware Graph Neural Networks in Knowledge Graphs", "link": "https://papers.cool/arxiv/2510.18473", "analysis": {"summary": "The paper presents a benchmark for fairness-aware graph neural networks (GNNs) applied to large-scale knowledge graphs (YAGO, DBpedia, Wikidata). It evaluates both in‑processing and preprocessing mitigation methods across various GNN backbones and early‑stopping settings, revealing distinct trade‑offs between prediction accuracy and fairness metrics compared to previous graph datasets. Key findings include the strong influence of backbone choice and early stopping on performance, preprocessing methods boosting fairness, and in‑processing methods improving accuracy.", "summary_cn": "本文针对大规模知识图谱（YAGO、DBpedia、Wikidata）开展了公平感知图神经网络（GNN）的基准评估，比较了不同的在训练中处理和预处理方法在多种GNN骨干网络和提前停止条件下的表现。结果显示，与以往图数据集相比，知识图谱在预测准确率与公平度量之间呈现更明显的权衡，且骨干网络和提前停止策略显著影响性能；预处理方法通常提升公平性，而在训练中处理的方法则更有利于预测准确度。", "keywords": "fairness-aware GNN, knowledge graph, bias mitigation, graph neural network, benchmarking, fairness metrics", "scoring": {"interpretability": 2, "understanding": 5, "safety": 5, "technicality": 6, "surprisal": 6}, "category": {"failure_mode_addressed": "societal-disruption", "primary_focus": "other"}, "authors": ["Yuya Sasaki"]}, "usage": {"completion_tokens": 680, "prompt_tokens": 3414, "total_tokens": 4094, "completion_tokens_details": {"accepted_prediction_tokens": null, "audio_tokens": null, "reasoning_tokens": 410, "rejected_prediction_tokens": null, "image_tokens": 0}, "prompt_tokens_details": {"audio_tokens": 0, "cached_tokens": 0}, "cost": 0.0009201, "is_byok": false, "cost_details": {"upstream_inference_cost": null, "upstream_inference_prompt_cost": 0.0005121, "upstream_inference_completions_cost": 0.000408}}, "model": "openai/gpt-oss-120b"}
{"timestamp": "2025-10-22T03:28:51.488802", "feed": "arxiv_cslg", "title": "HeFS: Helper-Enhanced Feature Selection via Pareto-Optimized Genetic Search", "link": "https://papers.cool/arxiv/2510.18575", "analysis": {"summary": "HeFS (Helper-Enhanced Feature Selection) is a framework that refines feature subsets generated by existing algorithms by searching the residual feature space for a Helper Set of complementary features. It uses a biased initialization, ratio‑guided mutation within a genetic algorithm, and Pareto‑based multi‑objective optimization to jointly maximize predictive accuracy and feature complementarity. Experiments on 18 benchmark datasets, including gastric cancer classification and drug toxicity prediction, show consistent performance gains over state‑of‑the‑art methods.", "summary_cn": "HeFS（Helper‑Enhanced Feature Selection）框架通过在剩余特征空间中寻找可补充原有子集的“Helper Set”，对现有特征选择算法的结果进行优化。该方法在遗传算法中引入偏置初始化和比例引导的变异，并采用基于 Pareto 的多目标优化，同时最大化预测精度和特征互补性。实验证明，在包括胃癌分类、药物毒性预测等18 个基准数据集上，HeFS 能持续发现被忽视的有价值特征并提升性能。", "keywords": "feature selection, genetic algorithm, Pareto optimization, helper set, combinatorial optimization, high-dimensional data", "scoring": {"interpretability": 3, "understanding": 6, "safety": 1, "technicality": 8, "surprisal": 6}, "category": {"failure_mode_addressed": "non-applicable", "primary_focus": "other"}, "authors": ["Yusi Fan", "Tian Wang", "Zhiying Yan", "Chang Liu", "Qiong Zhou", "Qi Lu", "Zhehao Guo", "Ziqi Deng", "Wenyu Zhu", "Ruochi Zhang", "Fengfeng Zhou"]}, "usage": {"completion_tokens": 530, "prompt_tokens": 3399, "total_tokens": 3929, "completion_tokens_details": {"accepted_prediction_tokens": null, "audio_tokens": null, "reasoning_tokens": 263, "rejected_prediction_tokens": null, "image_tokens": 0}, "prompt_tokens_details": {"audio_tokens": 0, "cached_tokens": 0}, "cost": 0.00034796, "is_byok": false, "cost_details": {"upstream_inference_cost": null, "upstream_inference_prompt_cost": 0.00013596, "upstream_inference_completions_cost": 0.000212}}, "model": "openai/gpt-oss-120b"}
{"timestamp": "2025-10-22T03:28:52.018712", "feed": "arxiv_cslg", "title": "Learning Boltzmann Generators via Constrained Mass Transport", "link": "https://papers.cool/arxiv/2510.18460", "analysis": {"summary": "Learning Boltzmann Generators via Constrained Mass Transport proposes a variational framework that generates intermediate distributions while constraining KL divergence and entropy decay between steps, reducing mode collapse and mass teleportation. The method achieves over 2.5× higher effective sample size than prior variational baselines on standard benchmarks and a new ELIL tetrapeptide system without using molecular dynamics samples. Experiments demonstrate improved distributional overlap and stability across multimodal high‑dimensional targets.", "summary_cn": "本文提出了受约束质量传输（Constrained Mass Transport）框架，用于在生成玻尔兹曼生成器（Boltzmann Generators）时通过约束相邻步骤之间的 KL 散度和熵衰减来生成中间分布，从而缓解模式崩溃和质量瞬移问题。该方法在标准基准以及首次引入的 ELIL 四肽系统上实现了超过 2.5 倍的有效样本量提升，且无需使用分子动力学采样。实验表明该方法能够提升分布重叠度并在高维多模态目标上保持更好的采样稳定性。", "keywords": "Boltzmann generators, constrained mass transport, variational inference, KL divergence constraint, entropy decay, mode collapse, effective sample size, molecular sampling, ELIL tetrapeptide", "scoring": {"interpretability": 2, "understanding": 6, "safety": 2, "technicality": 8, "surprisal": 6}, "category": {"failure_mode_addressed": "non-applicable", "primary_focus": "other"}, "authors": ["Christopher von Klitzing", "Denis Blessing", "Henrik Schopmans", "Pascal Friederich", "Gerhard Neumann"]}, "usage": {"completion_tokens": 793, "prompt_tokens": 3403, "total_tokens": 4196, "completion_tokens_details": {"accepted_prediction_tokens": null, "audio_tokens": null, "reasoning_tokens": 533, "rejected_prediction_tokens": null, "image_tokens": 0}, "prompt_tokens_details": {"audio_tokens": 0, "cached_tokens": 0}, "cost": 0.00098625, "is_byok": false, "cost_details": {"upstream_inference_cost": null, "upstream_inference_prompt_cost": 0.00051045, "upstream_inference_completions_cost": 0.0004758}}, "model": "openai/gpt-oss-120b"}
{"timestamp": "2025-10-22T03:28:52.117171", "feed": "arxiv_cslg", "title": "BO4Mob: Bayesian Optimization Benchmarks for High-Dimensional Urban Mobility Problem", "link": "https://papers.cool/arxiv/2510.18824", "analysis": {"summary": "BO4Mob is a benchmark suite for high-dimensional Bayesian Optimization applied to origin-destination travel demand estimation in large urban road networks, featuring up to 10,100 continuous variables and realistic stochastic traffic simulations based on San Jose, CA. The benchmark includes five real-world scenarios and evaluates three state-of-the-art BO algorithms against two non-BO baselines, highlighting challenges of expensive, non-differentiable objective evaluations. It aims to foster scalable optimization methods for data-driven urban mobility models and digital twins.", "summary_cn": "BO4Mob 是一个针对大规模城市道路网络中起点‑终点（OD）出行需求估计的高维贝叶斯优化基准套件，涵盖最高 10,100 维连续变量，并使用基于加州圣何塞的真实交通仿真，捕捉非线性、随机的交通动态。该基准提供五种实际场景，比较了三种最新的 BO 算法与两种非 BO 基线，以展示昂贵、不可微目标评估的挑战。旨在推动可扩展的优化方法在数据驱动的城市出行模型和数字孪生中的应用。", "keywords": "Bayesian optimization, high-dimensional optimization, urban mobility, origin-destination demand estimation, traffic simulation, benchmark, digital twin", "scoring": {"interpretability": 2, "understanding": 6, "safety": 2, "technicality": 8, "surprisal": 5}, "category": {"failure_mode_addressed": "non-applicable", "primary_focus": "other"}, "authors": ["Seunghee Ryu", "Donghoon Kwon", "Seongjin Choi", "Aryan Deshwal", "Seungmo Kang", "Carolina Osorio"]}, "usage": {"completion_tokens": 611, "prompt_tokens": 3421, "total_tokens": 4032, "completion_tokens_details": {"accepted_prediction_tokens": null, "audio_tokens": null, "reasoning_tokens": 319, "rejected_prediction_tokens": null, "image_tokens": 0}, "prompt_tokens_details": {"audio_tokens": 0, "cached_tokens": 0}, "cost": 0.00038124, "is_byok": false, "cost_details": {"upstream_inference_cost": null, "upstream_inference_prompt_cost": 0.00013684, "upstream_inference_completions_cost": 0.0002444}}, "model": "openai/gpt-oss-120b"}
{"timestamp": "2025-10-22T03:28:52.781137", "feed": "arxiv_cslg", "title": "Computable universal online learning", "link": "https://papers.cool/arxiv/2510.18352", "analysis": {"summary": "The paper investigates when universal online learning can be realized by an actual computer program, distinguishing computable from non‑computable learning strategies and providing exact characterizations for classes that are learnable under computable‑universal and agnostic settings. It also analyses proper universal online learning variants, highlighting limits of computability in online binary classification theory.", "summary_cn": "本文探讨了通用在线学习能否由实际计算机程序实现，区分可计算与不可计算的学习策略，并对在可计算‑通用和容错（agnostic）设置下可学习的类别给出精确刻画。同时分析了正则通用在线学习的变体，凸显了在线二元分类理论中计算能力的局限。", "keywords": "online learning, universal learning, computable learning, binary classification, agnostic learning, inductive inference", "scoring": {"interpretability": 2, "understanding": 6, "safety": 2, "technicality": 8, "surprisal": 5}, "category": {"failure_mode_addressed": "non-applicable", "primary_focus": "other"}, "authors": ["Dariusz Kalociński", "Tomasz Steifer"]}, "usage": {"completion_tokens": 226, "prompt_tokens": 3437, "total_tokens": 3663, "completion_tokens_details": {"accepted_prediction_tokens": null, "audio_tokens": null, "reasoning_tokens": 0, "rejected_prediction_tokens": null, "image_tokens": 0}, "prompt_tokens_details": {"audio_tokens": 0, "cached_tokens": 0}, "cost": 0.00027355, "is_byok": false, "cost_details": {"upstream_inference_cost": null, "upstream_inference_prompt_cost": 0.00017185, "upstream_inference_completions_cost": 0.0001017}}, "model": "openai/gpt-oss-120b"}
{"timestamp": "2025-10-22T03:28:52.990061", "feed": "arxiv_cslg", "title": "Actor-Free Continuous Control via Structurally Maximizable Q-Functions", "link": "https://papers.cool/arxiv/2510.18828", "analysis": {"summary": "This paper proposes an actor‑free, purely value‑based framework for continuous‑control reinforcement learning by introducing structurally maximizable Q‑functions, enabling efficient maximization of Q‑values without a separate actor. The approach achieves performance and sample efficiency comparable to state‑of‑the‑art actor‑critic baselines, especially in environments with constrained, non‑smooth action spaces. Code is released publicly.", "summary_cn": "本文提出一种无演员、纯价值的连续控制强化学习框架，通过结构化可最大化的 Q 函数实现对 Q 值的高效最大化，无需单独的演员网络。该方法在性能和样本效率上与最先进的演员‑评论家基线相当，特别在约束且非光滑的动作空间环境中表现更佳。已公开代码。", "keywords": "value-based RL, continuous control, Q-function maximization, actor-free, off-policy learning, structural maximization, sample efficiency, constrained action spaces, reinforcement learning, Q-learning", "scoring": {"interpretability": 2, "understanding": 6, "safety": 2, "technicality": 7, "surprisal": 6}, "category": {"failure_mode_addressed": "non-applicable", "primary_focus": "other"}, "authors": ["Yigit Korkmaz", "Urvi Bhuwania", "Ayush Jain", "Erdem Bıyık"]}, "usage": {"completion_tokens": 622, "prompt_tokens": 3447, "total_tokens": 4069, "completion_tokens_details": {"accepted_prediction_tokens": null, "audio_tokens": null, "reasoning_tokens": 441, "rejected_prediction_tokens": null, "image_tokens": 0}, "prompt_tokens_details": {"audio_tokens": 0, "cached_tokens": 0}, "cost": 0.00038668, "is_byok": false, "cost_details": {"upstream_inference_cost": null, "upstream_inference_prompt_cost": 0.00013788, "upstream_inference_completions_cost": 0.0002488}}, "model": "openai/gpt-oss-120b"}
{"timestamp": "2025-10-22T03:28:53.335651", "feed": "arxiv_cslg", "title": "A Hybrid Enumeration Framework for Optimal Counterfactual Generation in Post-Acute COVID-19 Heart Failure", "link": "https://papers.cool/arxiv/2510.18841", "analysis": {"summary": "The paper introduces a hybrid enumeration and optimization framework for generating optimal counterfactual explanations in a clinical setting, applied to post‑acute sequelae of COVID‑19 in patients with pre‑existing heart failure. By integrating regularized predictive models with the NICE and Multi‑Objective Counterfactual algorithms, the method efficiently explores high‑dimensional intervention spaces and produces patient‑specific, interpretable counterfactuals that indicate how changes in comorbidities or treatments could affect predicted heart‑failure admissions. Experiments on over 2700 patients achieve high discriminative performance (AUROC 0.88) and demonstrate the approach’s utility for personalized risk estimation and intervention analysis.", "summary_cn": "本文提出一种混合枚举与优化框架，用于在临床环境中生成最优反事实解释，聚焦于新冠后遗症患者中已有心衰的病例。通过将正则化预测模型与 NICE 与多目标反事实（MOC）算法相结合，能够高效搜索高维干预空间，生成患者特定的可解释反事实，量化改变共病模式或治疗因素对心衰住院风险的影响。对2700余名患者的实验显示模型具有较高的判别能力（AUROC 0.88），验证了该方法在个性化风险评估和干预分析中的价值。", "keywords": "counterfactual explanations, causal inference, personalized medicine, heart failure, COVID-19, optimization, enumeration, predictive modeling, interpretable AI, healthcare", "scoring": {"interpretability": 7, "understanding": 6, "safety": 2, "technicality": 8, "surprisal": 6}, "category": {"failure_mode_addressed": "non-applicable", "primary_focus": "interpretability"}, "authors": ["Jingya Cheng", "Alaleh Azhir", "Jiazi Tian", "Hossein Estiri"]}, "usage": {"completion_tokens": 780, "prompt_tokens": 3470, "total_tokens": 4250, "completion_tokens_details": {"accepted_prediction_tokens": null, "audio_tokens": null, "reasoning_tokens": 469, "rejected_prediction_tokens": null, "image_tokens": 0}, "prompt_tokens_details": {"audio_tokens": 0, "cached_tokens": 0}, "cost": 0.0004508, "is_byok": false, "cost_details": {"upstream_inference_cost": null, "upstream_inference_prompt_cost": 0.0001388, "upstream_inference_completions_cost": 0.000312}}, "model": "openai/gpt-oss-120b"}
{"timestamp": "2025-10-22T03:28:54.284689", "feed": "arxiv_cslg", "title": "Reasoning Language Model Inference Serving Unveiled: An Empirical Study", "link": "https://papers.cool/arxiv/2510.18672", "analysis": {"summary": "This paper empirically investigates the inference serving performance of reasoning large language models (RLLMs), revealing distinct serving behaviors such as high memory usage, request stragglers, adaptive runtime, and domain preference compared to traditional LLMs. It evaluates the applicability of common inference optimizations, finding that model quantization and speculative decoding improve efficiency with minor accuracy loss, while prefix caching and KV‑cache quantization can hurt performance for smaller RLLMs. The study validates these findings under realistic workloads modeled by a Gamma distribution, providing practical insights for deploying RLLMs.", "summary_cn": "本文对推理大语言模型（RLLM）的推理服务性能进行实证研究，指出其相较于传统 LLM 存在显著的内存占用波动、请求延迟、运行时间自适应和领域偏好等特征。评估常用的推理优化技术后发现，模型量化和投机解码可提升效率且对准确率影响有限，而前缀缓存和 KV 缓存量化在小规模 RLLM 上可能导致性能或准确率下降。通过 Gamma 分布模拟的真实工作负载实验验证了这些结论，为 RLLM 部署提供了实用参考。", "keywords": "reasoning language model, inference serving, model quantization, speculative decoding, KV cache, memory usage, straggler requests, real-world workload", "scoring": {"interpretability": 2, "understanding": 6, "safety": 3, "technicality": 7, "surprisal": 6}, "category": {"failure_mode_addressed": "non-applicable", "primary_focus": "robustness"}, "authors": ["Qi Li", "Junpan Wu", "Xiang Liu", "Yuxin Wang", "Zeyu Li", "Zhenheng Tang", "Yuhan Chen", "Shaohuai Shi", "Xiaowen Chu"]}, "usage": {"completion_tokens": 751, "prompt_tokens": 4079, "total_tokens": 4830, "completion_tokens_details": {"accepted_prediction_tokens": null, "audio_tokens": null, "reasoning_tokens": 359, "rejected_prediction_tokens": null, "image_tokens": 0}, "prompt_tokens_details": {"audio_tokens": 0, "cached_tokens": 0}, "cost": 0.0003917, "is_byok": false, "cost_details": {"upstream_inference_cost": null, "upstream_inference_prompt_cost": 0.00020395, "upstream_inference_completions_cost": 0.00018775}}, "model": "openai/gpt-oss-120b"}
{"timestamp": "2025-10-22T03:28:54.689922", "feed": "arxiv_cslg", "title": "Higher Embedding Dimension Creates a Stronger World Model for a Simple Sorting Task", "link": "https://papers.cool/arxiv/2510.18315", "analysis": {"summary": "The paper studies how the embedding dimension influences the emergence of an internal world model in a transformer trained via reinforcement learning to perform bubble-sort-style adjacent swaps. While high accuracy is achieved even with very small embeddings, larger dimensions produce more faithful, consistent, and robust internal representations, revealed through two mechanisms: the last row of the attention matrix encodes global token order, and the chosen transposition aligns with the largest adjacent difference of these encoded values. These findings provide quantitative evidence that larger embedding dimensions strengthen structured internal representations and improve interpretability.", "summary_cn": "本文研究了嵌入维度如何影响通过强化学习训练的 transformer 在冒泡排序式相邻交换任务中内部 world model 的形成。即使在极小的嵌入维度下模型也能达到高准确率，但更高的维度会产生更忠实、一致且鲁棒的内部表示，具体表现为两条机制：注意力权重矩阵的最后一行单调编码全局 token 顺序，选择的置换对齐于这些编码值的最大相邻差异。这些结果提供了量化证据，表明更高的嵌入维度能强化结构化内部表示并提升 interpretability。", "keywords": "embedding dimension, transformer, world model, bubble sort, internal representation, attention matrix, algorithmic task, reinforcement learning", "scoring": {"interpretability": 7, "understanding": 7, "safety": 2, "technicality": 7, "surprisal": 6}, "category": {"failure_mode_addressed": "non-applicable", "primary_focus": "interpretability"}, "authors": ["Brady Bhalla", "Honglu Fan", "Nancy Chen", "Tony Yue YU"]}, "usage": {"completion_tokens": 561, "prompt_tokens": 3979, "total_tokens": 4540, "completion_tokens_details": {"accepted_prediction_tokens": null, "audio_tokens": null, "reasoning_tokens": 185, "rejected_prediction_tokens": null, "image_tokens": 0}, "prompt_tokens_details": {"audio_tokens": 0, "cached_tokens": 0}, "cost": 0.0003392, "is_byok": false, "cost_details": {"upstream_inference_cost": null, "upstream_inference_prompt_cost": 0.00019895, "upstream_inference_completions_cost": 0.00014025}}, "model": "openai/gpt-oss-120b"}
{"timestamp": "2025-10-22T03:28:55.557636", "feed": "arxiv_cslg", "title": "Partial VOROS: A Cost-aware Performance Metric for Binary Classifiers with Precision and Capacity Constraints", "link": "https://papers.cool/arxiv/2510.18520", "analysis": {"summary": "The paper introduces Partial VOROS, a cost-aware performance metric for binary classifiers that incorporates precision and capacity constraints into ROC analysis. It defines a feasible region in ROC space for classifiers meeting these constraints and proposes the partial area of lesser classifiers, which is averaged over cost parameters to obtain the partial volume over the ROC surface. Experiments on mortality risk prediction using the MIMIC-IV dataset demonstrate that this metric better ranks classifiers for hospital alert systems than existing alternatives.", "summary_cn": "本文提出了 Partial VOROS，一种考虑精确率和容量约束的成本感知二分类性能指标，将这些约束映射到 ROC 空间的可行区域，并定义了较差分类器的部分面积，然后在成本参数范围内平均得到 ROC 曲面的部分体积。通过在 MIMIC-IV 数据集上预测死亡风险的实验，展示该指标在医院警报系统中比传统指标更能有效排序分类器。", "keywords": "binary classification, ROC, Partial VOROS, cost-aware metric, precision constraint, capacity constraint, healthcare alerts, MIMIC-IV", "scoring": {"interpretability": 2, "understanding": 6, "safety": 5, "technicality": 7, "surprisal": 5}, "category": {"failure_mode_addressed": "non-applicable", "primary_focus": "other"}, "authors": ["Christopher Ratigan", "Kyle Heuton", "Carissa Wang", "Lenore Cowen", "Michael C. Hughes"]}, "usage": {"completion_tokens": 653, "prompt_tokens": 4040, "total_tokens": 4693, "completion_tokens_details": {"accepted_prediction_tokens": null, "audio_tokens": null, "reasoning_tokens": 331, "rejected_prediction_tokens": null, "image_tokens": 0}, "prompt_tokens_details": {"audio_tokens": 0, "cached_tokens": 0}, "cost": 0.00036525, "is_byok": false, "cost_details": {"upstream_inference_cost": null, "upstream_inference_prompt_cost": 0.000202, "upstream_inference_completions_cost": 0.00016325}}, "model": "openai/gpt-oss-120b"}
{"timestamp": "2025-10-22T03:28:56.453041", "feed": "arxiv_cslg", "title": "Improving the Generation and Evaluation of Synthetic Data for Downstream Medical Causal Inference", "link": "https://papers.cool/arxiv/2510.18768", "analysis": {"summary": "The paper identifies key desiderata for synthetic medical datasets used in treatment effect analysis—preserving covariate distribution, treatment assignment, and outcome generation—and introduces evaluation metrics for these criteria. Based on this, it proposes STEAM, a generative method that explicitly models the data-generating process to satisfy the desiderata, achieving state-of-the-art performance on the proposed metrics, especially as the underlying causal complexity grows.", "summary_cn": "本文确定了用于医学治疗效应分析的合成数据的关键需求：保持协变量分布、治疗分配机制和结果生成机制，并提出了相应的评估指标。在此基础上，作者提出了 STEAM 方法，该生成模型显式模拟数据生成过程以满足这些需求，在所设指标上实现了最新水平的表现，尤其在真实数据生成过程复杂度提升时表现突出。", "keywords": "synthetic data, causal inference, treatment effect, generative models, STEAM, medical data, evaluation metrics, covariate distribution, treatment assignment, outcome generation", "scoring": {"interpretability": 2, "understanding": 6, "safety": 4, "technicality": 7, "surprisal": 6}, "category": {"failure_mode_addressed": "non-applicable", "primary_focus": "other"}, "authors": ["Harry Amad", "Zhaozhi Qian", "Dennis Frauen", "Julianna Piskorz", "Stefan Feuerriegel", "Mihaela van der Schaar"]}, "usage": {"completion_tokens": 843, "prompt_tokens": 4043, "total_tokens": 4886, "completion_tokens_details": {"accepted_prediction_tokens": null, "audio_tokens": null, "reasoning_tokens": 533, "rejected_prediction_tokens": null, "image_tokens": 0}, "prompt_tokens_details": {"audio_tokens": 0, "cached_tokens": 0}, "cost": 0.0004129, "is_byok": false, "cost_details": {"upstream_inference_cost": null, "upstream_inference_prompt_cost": 0.00020215, "upstream_inference_completions_cost": 0.00021075}}, "model": "openai/gpt-oss-120b"}
{"timestamp": "2025-10-22T03:28:56.767114", "feed": "arxiv_cslg", "title": "Learning from N-Tuple Data with M Positive Instances: Unbiased Risk Estimation and Theoretical Guarantees", "link": "https://papers.cool/arxiv/2510.18406", "analysis": {"summary": "The paper proposes a method for learning from N‑tuple data where only the total number of positive instances (M) per tuple is known, deriving an unbiased risk estimator and providing theoretical generalization and consistency guarantees, along with practical ReLU‑based corrections for stability.", "summary_cn": "本文提出一种在仅观察到每个 N‑tuple 中正例数量 (M) 的情况下进行学习的方法，推导出无偏风险估计器并给出理论上的泛化与一致性保证，同时引入基于 ReLU 的修正以提升有限样本的稳定性。", "keywords": "weak supervision, N-tuple learning, unbiased risk estimator, multi-instance learning, Rademacher complexity, statistical consistency", "scoring": {"interpretability": 2, "understanding": 6, "safety": 2, "technicality": 7, "surprisal": 5}, "category": {"failure_mode_addressed": "non-applicable", "primary_focus": "other"}, "authors": ["Miao Zhang", "Junpeng Li", "ChangChun HUa", "Yana Yang"]}, "usage": {"completion_tokens": 196, "prompt_tokens": 3453, "total_tokens": 3649, "completion_tokens_details": {"accepted_prediction_tokens": null, "audio_tokens": null, "reasoning_tokens": 0, "rejected_prediction_tokens": null, "image_tokens": 0}, "prompt_tokens_details": {"audio_tokens": 0, "cached_tokens": 0}, "cost": 0.00026085, "is_byok": false, "cost_details": {"upstream_inference_cost": null, "upstream_inference_prompt_cost": 0.00017265, "upstream_inference_completions_cost": 8.82e-05}}, "model": "openai/gpt-oss-120b"}
{"timestamp": "2025-10-22T03:28:57.311989", "feed": "arxiv_cslg", "title": "Physics-Informed Parametric Bandits for Beam Alignment in mmWave Communications", "link": "https://papers.cool/arxiv/2510.18299", "analysis": {"summary": "The paper introduces two physics-informed bandit algorithms, pretc and prgreedy, that exploit the sparse multipath structure of millimeter-wave channels to efficiently identify optimal beam directions. pretc performs an initial random exploration followed by exploitation based on estimated rewards, while prgreedy continuously updates estimates online. Experiments on synthetic DeepMIMO and real-world DeepSense6G datasets show both methods outperform existing beam-alignment approaches across diverse scenarios.", "summary_cn": "本文提出两种物理信息驱动的 Bandit 算法 pretc 和 prgreedy，利用毫米波信道的稀疏多路径特性高效寻找最优波束方向。pretc 先进行随机探索，再基于估计的奖励函数进行利用；prgreedy 则在在线过程中持续更新估计并选择当前最佳波束。实验在合成 DeepMIMO 数据集和真实 DeepSense6G 数据集上均显示两种方法在多种场景下优于现有波束对准方案，表现出良好的通用性和鲁棒性。", "keywords": "mmWave communications, beam alignment, bandit algorithms, physics-informed, sparse multipath, phase retrieval, DeepMIMO, DeepSense6G, online estimation", "scoring": {"interpretability": 2, "understanding": 6, "safety": 1, "technicality": 8, "surprisal": 6}, "category": {"failure_mode_addressed": "non-applicable", "primary_focus": "robustness"}, "authors": ["Hao Qin", "Thang Duong", "Ming Li", "Chicheng Zhang"]}, "usage": {"completion_tokens": 880, "prompt_tokens": 4124, "total_tokens": 5004, "completion_tokens_details": {"accepted_prediction_tokens": null, "audio_tokens": null, "reasoning_tokens": 522, "rejected_prediction_tokens": null, "image_tokens": 0}, "prompt_tokens_details": {"audio_tokens": 0, "cached_tokens": 0}, "cost": 0.0004262, "is_byok": false, "cost_details": {"upstream_inference_cost": null, "upstream_inference_prompt_cost": 0.0002062, "upstream_inference_completions_cost": 0.00022}}, "model": "openai/gpt-oss-120b"}
{"timestamp": "2025-10-22T03:28:57.332115", "feed": "arxiv_cslg", "title": "RAISE: A Unified Framework for Responsible AI Scoring and Evaluation", "link": "https://papers.cool/arxiv/2510.18559", "analysis": {"summary": "The paper presents RAISE, a unified framework that scores AI models across explainability, fairness, robustness, and sustainability, aggregating them into a single Responsibility Score. It evaluates three deep learning models on structured datasets from finance, healthcare, and socioeconomics, revealing trade-offs such as high explainability and fairness for a Transformer at high environmental cost. The work highlights the need for multi-dimensional evaluation for responsible model selection.", "summary_cn": "本文提出 RAISE 框架，用于在可解释性、公平性、鲁棒性和可持续性四个维度上对 AI 模型进行评分，并汇总为一个整体责任分数。作者在金融、医疗和社会经济结构化数据上评估了多层感知机、表格 ResNet 和特征分词 Transformer，揭示了如 Transformer 在可解释性和公平性上表现突出但环境成本高的权衡。该研究强调在负责任的模型选择中进行多维度评估的必要性。", "keywords": "responsible AI, evaluation framework, explainability, fairness, robustness, sustainability, responsibility score, model assessment, multi-dimensional evaluation", "scoring": {"interpretability": 6, "understanding": 7, "safety": 5, "technicality": 6, "surprisal": 5}, "category": {"failure_mode_addressed": "other", "primary_focus": "interpretability"}, "authors": ["Loc Phuc Truong Nguyen", "Hung Thanh Do"]}, "usage": {"completion_tokens": 888, "prompt_tokens": 4001, "total_tokens": 4889, "completion_tokens_details": {"accepted_prediction_tokens": null, "audio_tokens": null, "reasoning_tokens": 553, "rejected_prediction_tokens": null, "image_tokens": 0}, "prompt_tokens_details": {"audio_tokens": 0, "cached_tokens": 0}, "cost": 0.00042205, "is_byok": false, "cost_details": {"upstream_inference_cost": null, "upstream_inference_prompt_cost": 0.00020005, "upstream_inference_completions_cost": 0.000222}}, "model": "openai/gpt-oss-120b"}
{"timestamp": "2025-10-22T03:28:57.425564", "feed": "arxiv_cslg", "title": "ACTG-ARL: Differentially Private Conditional Text Generation with RL-Boosted Control", "link": "https://papers.cool/arxiv/2510.18232", "analysis": {"summary": "The paper introduces ACTG-ARL, a hierarchical framework for differentially private synthetic text generation that separates feature learning from conditional generation, and enhances control via Anchored Reinforcement Learning (ARL) to improve instruction-following while preventing reward hacking. ACTG combines a DP tabular synthesizer with a DP fine-tuned conditional generator, achieving a 20% MAUVE improvement over prior methods. The approach delivers higher quality DP text and finer-grained conditional control under strong privacy guarantees.", "summary_cn": "本文提出 ACTG-ARL，一种层次化的差分隐私（DP）合成文本生成框架，将特征学习与条件文本生成分离，并通过锚定强化学习（ARL）提升指令遵循能力且防止奖励黑客行为。ACTG 将 DP 表格合成器与 DP 微调的条件生成器结合，在保持强隐私保证的前提下，使合成文本质量提升约 20%（MAUVE），并实现更细粒度的控制。", "keywords": "differential privacy, conditional text generation, anchored reinforcement learning, synthetic data, privacy-preserving generation, DP tabular synthesizer, MAUVE", "scoring": {"interpretability": 2, "understanding": 6, "safety": 6, "technicality": 8, "surprisal": 6}, "category": {"failure_mode_addressed": "other", "primary_focus": "control"}, "authors": ["Yuzheng Hu", "Ryan McKenna", "Da Yu", "Shanshan Wu", "Han Zhao", "Zheng Xu", "Peter Kairouz"]}, "usage": {"completion_tokens": 724, "prompt_tokens": 3458, "total_tokens": 4182, "completion_tokens_details": {"accepted_prediction_tokens": null, "audio_tokens": null, "reasoning_tokens": 465, "rejected_prediction_tokens": null, "image_tokens": 0}, "prompt_tokens_details": {"audio_tokens": 0, "cached_tokens": 0}, "cost": 0.00042792, "is_byok": false, "cost_details": {"upstream_inference_cost": null, "upstream_inference_prompt_cost": 0.00013832, "upstream_inference_completions_cost": 0.0002896}}, "model": "openai/gpt-oss-120b"}
{"timestamp": "2025-10-22T03:28:58.235292", "feed": "arxiv_cslg", "title": "Ensemble based Closed-Loop Optimal Control using Physics-Informed Neural Networks", "link": "https://papers.cool/arxiv/2510.18195", "analysis": {"summary": "The paper introduces a multistage ensemble framework that uses physics-informed neural networks (PINNs) to learn the optimal cost-to-go and corresponding control signals by solving the Hamilton-Jacobi-Bellman equation without stabilizer terms. It demonstrates closed-loop control of a continuous nonlinear two-state system under noisy conditions using either a singular learned control signal or an ensemble policy.", "summary_cn": "本文提出一种多阶段集成框架，利用物理信息神经网络（PINNs）在不使用稳定子项的情况下学习最优代价函数并求解相应的控制信号，通过求解Hamilton-Jacobi-Bellman方程实现。实验在噪声扰动和不同初始条件下，对一个两状态连续非线性系统展示了单一控制信号和集成控制策略的闭环控制效果。", "keywords": "physics-informed neural networks, Hamilton-Jacobi-Bellman, optimal control, ensemble learning, closed-loop control, nonlinear systems", "scoring": {"interpretability": 2, "understanding": 6, "safety": 3, "technicality": 8, "surprisal": 6}, "category": {"failure_mode_addressed": "non-applicable", "primary_focus": "control"}, "authors": ["Jostein Barry-Straume", "Adwait D. Verulkar", "Arash Sarshar", "Andrey A. Popov", "Adrian Sandu"]}, "usage": {"completion_tokens": 568, "prompt_tokens": 3422, "total_tokens": 3990, "completion_tokens_details": {"accepted_prediction_tokens": null, "audio_tokens": null, "reasoning_tokens": 314, "rejected_prediction_tokens": null, "image_tokens": 0}, "prompt_tokens_details": {"audio_tokens": 0, "cached_tokens": 3136}, "cost": 0.0008541, "is_byok": false, "cost_details": {"upstream_inference_cost": null, "upstream_inference_prompt_cost": 0.0005133, "upstream_inference_completions_cost": 0.0003408}}, "model": "openai/gpt-oss-120b"}
{"timestamp": "2025-10-22T03:28:58.892453", "feed": "arxiv_cslg", "title": "Prototyping an End-to-End Multi-Modal Tiny-CNN for Cardiovascular Sensor Patches", "link": "https://papers.cool/arxiv/2510.18668", "analysis": {"summary": "This paper presents a tiny convolutional neural network that fuses ECG and PCG signals early to classify cardiovascular health conditions on resource‑constrained edge devices, achieving a three‑fold reduction in memory and computational cost while keeping accuracy competitive with state‑of‑the‑art models. The authors evaluate the model on the PhysioNet 2016 Challenge dataset and demonstrate its low‑energy inference on a microcontroller‑based sensor patch – showing feasibility for on‑device monitoring.", "summary_cn": "本文 : 在 ECG 和 PCG 信号上构建 tiny CNN 进行二元分类，旨 在 资源受限的 边缘设备上实现 低功耗、低内存的心血管监测。作者使用 PhysioNet 2016 数据集进行训练验证，并在微控制器 传感器补丁上展示 能耗优势，证明 可在设备端进行实时监测。", "keywords": "cardiovascular monitoring, ECG, PCG, multi-modal CNN, edge AI, low-power inference", "scoring": {"interpretability": 4, "understanding": 5, "safety": 5, "technicality": 7, "surprisal": 6}, "category": {"failure_mode_addressed": "non-applicable", "primary_focus": "other"}, "authors": ["Mustafa Fuad Rifet Ibrahim", "Tunc Alkanat", "Maurice Meijer", "Felix Manthey", "Alexander Schlaefer", "Peer Stelldinger"]}, "usage": {"completion_tokens": 276, "prompt_tokens": 3434, "total_tokens": 3710, "completion_tokens_details": {"accepted_prediction_tokens": null, "audio_tokens": null, "reasoning_tokens": 0, "rejected_prediction_tokens": null, "image_tokens": 0}, "prompt_tokens_details": {"audio_tokens": 0, "cached_tokens": 0}, "cost": 0.0002959, "is_byok": false, "cost_details": {"upstream_inference_cost": null, "upstream_inference_prompt_cost": 0.0001717, "upstream_inference_completions_cost": 0.0001242}}, "model": "openai/gpt-oss-120b"}
{"timestamp": "2025-10-22T03:28:59.066590", "feed": "arxiv_cslg", "title": "Joint Optimization of Cooperation Efficiency and Communication Covertness for Target Detection with AUVs", "link": "https://papers.cool/arxiv/2510.18225", "analysis": {"summary": "The paper studies cooperative underwater target detection with multiple AUVs, focusing on the trade‑off between cooperation efficiency and communication covertness. It formulates a joint trajectory‑and‑power optimization problem and solves it via a hierarchical action‑management framework that uses macro‑level PPO for agent selection and micro‑level multi‑agent PPO for decentralized trajectory and power decisions under a centralized‑training/decentralized‑execution paradigm. The approach enables adaptive, covert cooperation while respecting energy and mobility constraints, offering theoretical and practical insights for secure underwater operations.", "summary_cn": "本文研究了多 AUV 在水下协同目标检测中的合作效率与通信隐蔽性之间的权衡。通过将轨迹与功率控制的联合优化问题建模为层次化行动管理框架，在宏观层使用 PPO 进行任务分配的马尔可夫决策过程建模，在微观层采用多智能体 PPO 依据局部观测动态调整轨迹和发射功率，实现集中训练、分散执行的隐蔽协作。该方法在满足能量和运动约束的前提下提供了高效安全的水下作业理论与实践方案。", "keywords": "underwater autonomous vehicles, cooperative target detection, communication covertness, trajectory optimization, power control, hierarchical reinforcement learning, proximal policy optimization, multi-agent RL, covert communication", "scoring": {"interpretability": 2, "understanding": 5, "safety": 5, "technicality": 8, "surprisal": 5}, "category": {"failure_mode_addressed": "human-misuse", "primary_focus": "control"}, "authors": ["Xueyao Zhang", "Bo Yang", "Zhiwen Yu", "Xuelin Cao", "Wei Xiang", "Bin Guo", "Liang Wang", "Billy Pik Lik Lau", "George C. Alexandropoulos", "Jun Luo", "Mérouane Debbah", "Zhu Han", "Chau Yuen"]}, "usage": {"completion_tokens": 774, "prompt_tokens": 3419, "total_tokens": 4193, "completion_tokens_details": {"accepted_prediction_tokens": null, "audio_tokens": null, "reasoning_tokens": 483, "rejected_prediction_tokens": null, "image_tokens": 0}, "prompt_tokens_details": {"audio_tokens": 0, "cached_tokens": 64}, "cost": 0.00097725, "is_byok": false, "cost_details": {"upstream_inference_cost": null, "upstream_inference_prompt_cost": 0.00051285, "upstream_inference_completions_cost": 0.0004644}}, "model": "openai/gpt-oss-120b"}
{"timestamp": "2025-10-22T03:28:59.311184", "feed": "arxiv_cslg", "title": "Why Policy Gradient Algorithms Work for Undiscounted Total-Reward MDPs", "link": "https://papers.cool/arxiv/2510.18340", "analysis": {"summary": "The paper analyzes the classical policy gradient method for infinite-horizon MDPs with undiscounted total reward (gamma = 1). It shows that the classification of states into recurrent and transient remains invariant for policies that assign strictly positive probability to every action, and introduces a new transient visitation measure to replace the ill-defined state visitation measure used with discounts. These insights provide convergence guarantees for policy gradient algorithms in the undiscounted setting, which is relevant for large language model training.", "summary_cn": "本文研究了在无限时域、累计总回报（gamma = 1）下的策略梯度方法。作者证明，对于对每个动作都给出正概率的策略（如软最大输出），状态的循环/瞬时划分保持不变，并提出了“瞬时访问度量”（transient visitation measure）来取代在折扣为1时不适用的传统访问度量，从而为无折扣环境中的策略梯度收敛提供了理论保障。", "keywords": "policy gradient, undiscounted MDP, transient visitation measure, recurrent states, reinforcement learning theory, infinite-horizon, softmax policies", "scoring": {"interpretability": 2, "understanding": 7, "safety": 2, "technicality": 8, "surprisal": 7}, "category": {"failure_mode_addressed": "non-applicable", "primary_focus": "other"}, "authors": ["Jongmin Lee", "Ernest K. Ryu"]}, "usage": {"completion_tokens": 593, "prompt_tokens": 4015, "total_tokens": 4608, "completion_tokens_details": {"accepted_prediction_tokens": null, "audio_tokens": null, "reasoning_tokens": 260, "rejected_prediction_tokens": null, "image_tokens": 0}, "prompt_tokens_details": {"audio_tokens": 0, "cached_tokens": 0}, "cost": 0.000349, "is_byok": false, "cost_details": {"upstream_inference_cost": null, "upstream_inference_prompt_cost": 0.00020075, "upstream_inference_completions_cost": 0.00014825}}, "model": "openai/gpt-oss-120b"}
{"timestamp": "2025-10-22T03:28:59.738049", "feed": "arxiv_cslg", "title": "A Rectification-Based Approach for Distilling Boosted Trees into Decision Trees", "link": "https://papers.cool/arxiv/2510.18615", "analysis": {"summary": "The paper proposes a rectification-based method for distilling boosted-ensemble models into single decision trees, aiming to balance predictive performance with interpretability. By iteratively correcting the decision tree using the residuals of the boosted model, the approach yields compact trees that retain much of the original accuracy. Empirical evaluations demonstrate that this rectification distillation outperforms naïve retraining baselines.", "summary_cn": "本文提出一种基于校正（rectification）的蒸馏方法，将提升树（boosted trees）转化为单棵决策树，以在预测性能和可解释性之间取得平衡。该方法通过利用提升模型的残差对决策树进行迭代校正，生成既紧凑又保持原模型大部分准确性的树结构。实验结果显示，该校正蒸馏在效果上优于传统的重新训练蒸馏基线。", "keywords": "boosted trees, decision trees, model distillation, rectification, interpretability, tree ensembles, machine learning", "scoring": {"interpretability": 7, "understanding": 6, "safety": 1, "technicality": 7, "surprisal": 5}, "category": {"failure_mode_addressed": "non-applicable", "primary_focus": "interpretability"}, "authors": ["Gilles Audemard", "Sylvie Coste-Marquis", "Pierre Marquis", "Mehdi Sabiri", "Nicolas Szczepanski"]}, "usage": {"completion_tokens": 576, "prompt_tokens": 3272, "total_tokens": 3848, "completion_tokens_details": {"accepted_prediction_tokens": null, "audio_tokens": null, "reasoning_tokens": 323, "rejected_prediction_tokens": null, "image_tokens": 0}, "prompt_tokens_details": {"audio_tokens": 0, "cached_tokens": 3152}, "cost": 0.00055816, "is_byok": false, "cost_details": {"upstream_inference_cost": null, "upstream_inference_prompt_cost": 0.00027016, "upstream_inference_completions_cost": 0.000288}}, "model": "openai/gpt-oss-120b"}
{"timestamp": "2025-10-22T03:28:59.789327", "feed": "arxiv_cslg", "title": "Robustness Verification of Graph Neural Networks Via Lightweight Satisfiability Testing", "link": "https://papers.cool/arxiv/2510.18591", "analysis": {"summary": "The paper proposes RobLight, a verification tool for graph neural networks that improves structural robustness certification by replacing heavyweight mixed‑integer solvers with efficient polynomial‑time partial SAT solvers, which may be incomplete but run much faster. Experiments on multiple GNN variants and datasets show that this lightweight approach can match or exceed state‑of‑the‑art robustness detection while reducing computational cost.", "summary_cn": "本文提出了 RobLight，一种用于图神经网络结构鲁棒性验证的工具，通过用高效的多项式时间部分 SAT 求解器替代传统的混合整数求解器，从而在可能不完整的情况下显著提升验证速度。对多种 GNN 变体和数据集的实验表明，该轻量化方法在计算成本降低的同时，能够匹配或超越现有最先进的鲁棒性检测效果。", "keywords": "graph neural networks, adversarial robustness, verification, satisfiability testing, partial solvers, robustness certification, structural attacks", "scoring": {"interpretability": 3, "understanding": 6, "safety": 6, "technicality": 8, "surprisal": 6}, "category": {"failure_mode_addressed": "human-misuse", "primary_focus": "robustness"}, "authors": ["Chia-Hsuan Lu", "Tony Tan", "Michael Benedikt"]}, "usage": {"completion_tokens": 578, "prompt_tokens": 3400, "total_tokens": 3978, "completion_tokens_details": {"accepted_prediction_tokens": null, "audio_tokens": null, "reasoning_tokens": 336, "rejected_prediction_tokens": null, "image_tokens": 0}, "prompt_tokens_details": {"audio_tokens": 0, "cached_tokens": 3152}, "cost": 0.00057836, "is_byok": false, "cost_details": {"upstream_inference_cost": null, "upstream_inference_prompt_cost": 0.00028936, "upstream_inference_completions_cost": 0.000289}}, "model": "openai/gpt-oss-120b"}
{"timestamp": "2025-10-22T03:29:00.563667", "feed": "arxiv_cslg", "title": "Informed Learning for Estimating Drought Stress at Fine-Scale Resolution Enables Accurate Yield Prediction", "link": "https://papers.cool/arxiv/2510.18648", "analysis": {"summary": "The paper proposes a physics-informed deep learning framework that estimates fine-scale crop drought stress and sensitivity to water scarcity, and uses these estimates to predict crop yields. By integrating multispectral satellite imagery, meteorological data, and a novel physics-based loss with a deep ensemble approach, it achieves up to 0.82 R2, outperforming LSTM and Transformer baselines while providing explainable insights into the water-yield relationship.", "summary_cn": "本文提出一种融合物理约束的深度学习框架，用于在细尺度上估计作物干旱胁迫及对缺水的敏感性，并基于此预测作物产量。通过结合多光谱卫星影像、气象数据以及新颖的 physics-informed loss 与深度集成方法，模型实现了最高 0.82 的 R2，超越 LSTM 与 Transformer 基线，同时提供了关于水分与产量关系的可解释性洞察。", "keywords": "drought stress, physics-informed learning, crop yield prediction, satellite imagery, deep ensembles, explainable AI, water scarcity, agricultural AI", "scoring": {"interpretability": 6, "understanding": 7, "safety": 3, "technicality": 7, "surprisal": 6}, "category": {"failure_mode_addressed": "non-applicable", "primary_focus": "interpretability"}, "authors": ["Miro Miranda", "Marcela Charfuelan", "Matias Valdenegro Toro", "Andreas Dengel"]}, "usage": {"completion_tokens": 984, "prompt_tokens": 4087, "total_tokens": 5071, "completion_tokens_details": {"accepted_prediction_tokens": null, "audio_tokens": null, "reasoning_tokens": 656, "rejected_prediction_tokens": null, "image_tokens": 0}, "prompt_tokens_details": {"audio_tokens": 0, "cached_tokens": 0}, "cost": 0.00045035, "is_byok": false, "cost_details": {"upstream_inference_cost": null, "upstream_inference_prompt_cost": 0.00020435, "upstream_inference_completions_cost": 0.000246}}, "model": "openai/gpt-oss-120b"}
{"timestamp": "2025-10-22T03:29:01.215945", "feed": "arxiv_cslg", "title": "ActivationReasoning: Logical Reasoning in Latent Activation Spaces", "link": "https://papers.cool/arxiv/2510.18184", "analysis": {"summary": "The paper proposes ActivationReasoning (AR), a framework that embeds explicit logical reasoning into the latent activation space of large language models by using sparse autoencoders to identify concepts, mapping activating concepts to logical propositions, and applying logical rules to infer higher‑order structures and steer model behavior. Experiments on multi‑hop reasoning, abstraction, and context‑sensitive safety tasks show that AR improves transparency, robustness, and controllability while scaling with reasoning complexity. The approach aims to make internal reasoning more interpretable and aligned with desired outcomes.", "summary_cn": "本文提出了 ActivationReasoning（AR）框架，通过稀疏自编码器识别潜在概念，将激活概念映射为逻辑命题，并在潜在激活空间中应用逻辑规则推导更高层结构，从而引导模型行为。实验在多跳推理、抽象化以及上下文敏感安全任务上展示了 AR 能提升透明度、鲁棒性和可控性，并随推理复杂度良好扩展。该方法旨在让模型内部推理更具可解释性并与期望行为对齐。", "keywords": "latent activation reasoning, sparse autoencoders, mechanistic interpretability, logical reasoning, model control, AI alignment, safety, concept activation, multi-hop reasoning, probing", "scoring": {"interpretability": 8, "understanding": 8, "safety": 6, "technicality": 7, "surprisal": 8}, "category": {"failure_mode_addressed": "misalignment", "primary_focus": "interpretability"}, "authors": ["Lukas Helff", "Ruben Härle", "Wolfgang Stammer", "Felix Friedrich", "Manuel Brack", "Antonia Wüst", "Hikaru Shindo", "Patrick Schramowski", "Kristian Kersting"]}, "usage": {"completion_tokens": 814, "prompt_tokens": 3484, "total_tokens": 4298, "completion_tokens_details": {"accepted_prediction_tokens": null, "audio_tokens": null, "reasoning_tokens": 577, "rejected_prediction_tokens": null, "image_tokens": 0}, "prompt_tokens_details": {"audio_tokens": 0, "cached_tokens": 0}, "cost": 0.00046496, "is_byok": false, "cost_details": {"upstream_inference_cost": null, "upstream_inference_prompt_cost": 0.00013936, "upstream_inference_completions_cost": 0.0003256}}, "model": "openai/gpt-oss-120b"}
{"timestamp": "2025-10-22T03:29:01.514692", "feed": "arxiv_cslg", "title": "Enhancing Fractional Gradient Descent with Learned Optimizers", "link": "https://papers.cool/arxiv/2510.18783", "analysis": {"summary": "The paper introduces L2O-CFGD, a meta-learned optimizer that dynamically tunes the hyperparameters of Caputo fractional gradient descent, addressing convergence and scheduling challenges in non-convex settings. Experiments show that the learned schedule outperforms static hyperparameter choices and can rival fully black-box meta-learned optimizers on several tasks. The approach also provides insights into leveraging the history-dependent nature of fractional differentials for optimization.", "summary_cn": "本文提出 L2O-CFGD，一种元学习优化器，用于动态调节 Caputo 分数梯度下降（Caputo Fractional Gradient Descent, CFGD）的超参数，以解决非凸情境下的收敛性和调度难题。实验表明，该学习得到的调度方案优于通过广泛搜索得到的静态超参数，并在部分任务上可与全黑盒元学习优化器相媲美。该方法还帮助理解如何利用分数微分的历史依赖性来提升优化性能。", "keywords": "fractional gradient descent, learned optimizer, meta-learning, Caputo derivative, hyperparameter scheduling, optimization, neural network training", "scoring": {"interpretability": 2, "understanding": 5, "safety": 1, "technicality": 7, "surprisal": 6}, "category": {"failure_mode_addressed": "non-applicable", "primary_focus": "other"}, "authors": ["Jan Sobotka", "Petr Šimánek", "Pavel Kordík"]}, "usage": {"completion_tokens": 567, "prompt_tokens": 3401, "total_tokens": 3968, "completion_tokens_details": {"accepted_prediction_tokens": null, "audio_tokens": null, "reasoning_tokens": 286, "rejected_prediction_tokens": null, "image_tokens": 0}, "prompt_tokens_details": {"audio_tokens": 0, "cached_tokens": 3152}, "cost": 0.00057301, "is_byok": false, "cost_details": {"upstream_inference_cost": null, "upstream_inference_prompt_cost": 0.00028951, "upstream_inference_completions_cost": 0.0002835}}, "model": "openai/gpt-oss-120b"}
{"timestamp": "2025-10-22T03:29:01.600210", "feed": "arxiv_cslg", "title": "Rethinking PCA Through Duality", "link": "https://papers.cool/arxiv/2510.18130", "analysis": {"summary": "The paper revisits principal component analysis (PCA) by applying the difference‑of‑convex (DC) framework, introducing novel dual formulations that are kernelizable and support out‑of‑sample extensions. It shows that simultaneous iteration is an instance of the difference‑of‑convex algorithm, proposes new PCA algorithms, and presents a kernelizable robust PCA variant minimizing an \\(l_1\\) reconstruction error. Empirical comparisons with state‑of‑the‑art methods are also provided.", "summary_cn": "本文通过差分凸（DC）框架重新审视主成分分析（PCA），提出可核化并支持样本外扩展的全新对偶形式。作者证明同步迭代是差分凸算法（DCA）的一个实例，进而设计了新的 PCA 算法，并引入一种最小化 \\(l_1\\) 重构误差的核化鲁棒 PCA 变体。最后给出与最新方法的实验对比。", "keywords": "PCA, dual formulation, difference-of-convex algorithm, kernel PCA, robust PCA, optimization, QR algorithm, out-of-sample extension", "scoring": {"interpretability": 4, "understanding": 6, "safety": 2, "technicality": 8, "surprisal": 6}, "category": {"failure_mode_addressed": "non-applicable", "primary_focus": "other"}, "authors": ["Jan Quan", "Johan Suykens", "Panagiotis Patrinos"]}, "usage": {"completion_tokens": 720, "prompt_tokens": 3351, "total_tokens": 4071, "completion_tokens_details": {"accepted_prediction_tokens": null, "audio_tokens": null, "reasoning_tokens": 468, "rejected_prediction_tokens": null, "image_tokens": 0}, "prompt_tokens_details": {"audio_tokens": 0, "cached_tokens": 0}, "cost": 0.00042204, "is_byok": false, "cost_details": {"upstream_inference_cost": null, "upstream_inference_prompt_cost": 0.00013404, "upstream_inference_completions_cost": 0.000288}}, "model": "openai/gpt-oss-120b"}
{"timestamp": "2025-10-22T03:29:02.659133", "feed": "arxiv_cslg", "title": "A Unified Perspective on Optimization in Machine Learning and Neuroscience: From Gradient Descent to Neural Adaptation", "link": "https://papers.cool/arxiv/2510.18812", "analysis": {"summary": "The review unifies optimization theory across machine learning and neuroscience, contrasting gradient-based methods that rely on backpropagation with derivative‑free (zeroth‑order) approaches that use only function evaluations and randomness. It surveys how zeroth‑order techniques can approximate gradients for neural network training and draws parallels between these methods and biological learning mechanisms such as random exploration and feedback‑guided adaptation, emphasizing implications for neuromorphic hardware.", "summary_cn": "本文综述了机器学习与神经科学中的优化方法，比较了依赖反向传播的梯度基方法与仅需函数评估的零阶（zeroth‑order）优化。文章阐述了零阶技巧如何在神经网络训练中近似梯度，并将其与生物学习中的随机探索和反馈引导的适应机制相类比，探讨了对神经形态硬件的潜在意义。", "keywords": "optimization, gradient descent, backpropagation, zeroth-order optimization, neural adaptation, biological learning, neuromorphic hardware, stochastic optimization, derivative-free methods", "scoring": {"interpretability": 2, "understanding": 7, "safety": 3, "technicality": 6, "surprisal": 4}, "category": {"failure_mode_addressed": "non-applicable", "primary_focus": "other"}, "authors": ["Jesús García Fernández", "Nasir Ahmad", "Marcel van Gerven"]}, "usage": {"completion_tokens": 613, "prompt_tokens": 3512, "total_tokens": 4125, "completion_tokens_details": {"accepted_prediction_tokens": null, "audio_tokens": null, "reasoning_tokens": 384, "rejected_prediction_tokens": null, "image_tokens": 0}, "prompt_tokens_details": {"audio_tokens": 0, "cached_tokens": 3152}, "cost": 0.00061266, "is_byok": false, "cost_details": {"upstream_inference_cost": null, "upstream_inference_prompt_cost": 0.00030616, "upstream_inference_completions_cost": 0.0003065}}, "model": "openai/gpt-oss-120b"}
{"timestamp": "2025-10-22T03:29:02.766075", "feed": "arxiv_cslg", "title": "When LRP Diverges from Leave-One-Out in Transformers", "link": "https://papers.cool/arxiv/2510.18810", "analysis": {"summary": "The paper investigates why Layer‑Wise Relevance Propagation (LRP) often fails to match the intuitive feature‑importance scores produced by Leave‑One‑Out (LOO) in modern Transformer models. It shows analytically and empirically that bilinear propagation rules used in recent AttnLRP violate the implementation invariance axiom, and demonstrates that ignoring relevance flow through the softmax (propagating only through value matrices) markedly improves alignment with LOO, especially in middle‑to‑late layers.", "summary_cn": "本文研究了在现代 Transformer 中，层级相关传播 (LRP) 为什么常常与直观的留一法 (LOO) 特征重要性得分不一致。研究表明，近期 AttnLRP 中使用的双线性传播规则违背实现不变性公理；此外，实验发现如果在软最大层不传播相关性，仅通过值矩阵进行反向传播，可显著提升 LRP 与 LOO 的对齐，尤其在中后层表现更佳。", "keywords": "LRP, leave-one-out, transformers, feature importance, implementation invariance, softmax propagation, interpretability, attention mechanisms", "scoring": {"interpretability": 7, "understanding": 7, "safety": 3, "technicality": 7, "surprisal": 6}, "category": {"failure_mode_addressed": "non-applicable", "primary_focus": "interpretability"}, "authors": ["Weiqiu You", "Siqi Zeng", "Yao-Hung Hubert Tsai", "Makoto Yamada", "Han Zhao"]}, "usage": {"completion_tokens": 617, "prompt_tokens": 3375, "total_tokens": 3992, "completion_tokens_details": {"accepted_prediction_tokens": null, "audio_tokens": null, "reasoning_tokens": 348, "rejected_prediction_tokens": null, "image_tokens": 0}, "prompt_tokens_details": {"audio_tokens": 0, "cached_tokens": 3152}, "cost": 0.00059411, "is_byok": false, "cost_details": {"upstream_inference_cost": null, "upstream_inference_prompt_cost": 0.00028561, "upstream_inference_completions_cost": 0.0003085}}, "model": "openai/gpt-oss-120b"}
{"timestamp": "2025-10-22T03:29:02.855138", "feed": "arxiv_cslg", "title": "Simple and Efficient Heterogeneous Temporal Graph Neural Network", "link": "https://papers.cool/arxiv/2510.18467", "analysis": {"summary": "The paper introduces SE-HTGNN, a simple and efficient heterogeneous temporal graph neural network that integrates temporal modeling directly into spatial attention via a dynamic attention mechanism, retaining historical attention information to improve representation learning. It also leverages large language models to prompt the network, capturing implicit node-type properties as prior knowledge. Experiments show up to a 10× speed‑up over state‑of‑the‑art baselines while achieving superior forecasting accuracy.", "summary_cn": "本文提出了 SE-HTGNN，一种简洁高效的异构时序图神经网络，通过动态注意力机制将时序建模直接融合到空间注意力中，保留历史快照的注意力信息以提升表示学习效果。并利用大语言模型对 SE-HTGNN 进行提示，捕获节点类型的隐含属性作为先验知识。实验表明该方法在保持最佳预测精度的同时，实现了相较于最先进基线高达 10 倍的加速。", "keywords": "heterogeneous temporal graph, dynamic attention, graph neural network, temporal modeling, LLM prompting, efficiency, representation learning", "scoring": {"interpretability": 3, "understanding": 5, "safety": 2, "technicality": 7, "surprisal": 6}, "category": {"failure_mode_addressed": "non-applicable", "primary_focus": "other"}, "authors": ["Yili Wang", "Tairan Huang", "Changlong He", "Qiutong Li", "Jianliang Gao"]}, "usage": {"completion_tokens": 592, "prompt_tokens": 3412, "total_tokens": 4004, "completion_tokens_details": {"accepted_prediction_tokens": null, "audio_tokens": null, "reasoning_tokens": 318, "rejected_prediction_tokens": null, "image_tokens": 0}, "prompt_tokens_details": {"audio_tokens": 0, "cached_tokens": 3152}, "cost": 0.00058716, "is_byok": false, "cost_details": {"upstream_inference_cost": null, "upstream_inference_prompt_cost": 0.00029116, "upstream_inference_completions_cost": 0.000296}}, "model": "openai/gpt-oss-120b"}
{"timestamp": "2025-10-22T03:29:02.905145", "feed": "arxiv_cslg", "title": "Approximation Rates of Shallow Neural Networks: Barron Spaces, Activation Functions and Optimality Analysis", "link": "https://papers.cool/arxiv/2510.18388", "analysis": {"summary": "The paper studies the approximation capabilities of shallow neural networks whose activation functions are powers of exponential functions, focusing on how the rates depend on input dimension and target function smoothness within Barron spaces. It proves that optimal rates cannot be achieved with \\ell^{1}-bounded coefficients or insufficient smoothness, and establishes optimal rates in various norms for functions in Barron and Sobolev spaces, highlighting the inherent curse of dimensionality.", "summary_cn": "本文研究了使用指数函数幂次作为激活函数的浅层神经网络的近似能力，重点考察在 Barron 空间中维度和目标函数光滑度对近似速率的影响。研究表明在 \\ell^{1} 系数受限或光滑度不足的情况下无法实现最优速率，并为 Barron 空间和 Sobolev 空间中的函数在多种范数下给出最优近似速率，确认了维度诅咒的存在。", "keywords": "shallow neural networks, Barron space, approximation rates, activation functions, ReLU^k, curse of dimensionality, Sobolev spaces, theoretical analysis", "scoring": {"interpretability": 2, "understanding": 6, "safety": 2, "technicality": 8, "surprisal": 5}, "category": {"failure_mode_addressed": "non-applicable", "primary_focus": "other"}, "authors": ["Jian Lu", "Xiaohuang Huang"]}, "usage": {"completion_tokens": 698, "prompt_tokens": 3336, "total_tokens": 4034, "completion_tokens_details": {"accepted_prediction_tokens": null, "audio_tokens": null, "reasoning_tokens": 434, "rejected_prediction_tokens": null, "image_tokens": 0}, "prompt_tokens_details": {"audio_tokens": 0, "cached_tokens": 3152}, "cost": 0.00062876, "is_byok": false, "cost_details": {"upstream_inference_cost": null, "upstream_inference_prompt_cost": 0.00027976, "upstream_inference_completions_cost": 0.000349}}, "model": "openai/gpt-oss-120b"}
{"timestamp": "2025-10-22T03:29:03.233630", "feed": "arxiv_cslg", "title": "Nash Policy Gradient: A Policy Gradient Method with Iteratively Refined Regularization for Finding Nash Equilibria", "link": "https://papers.cool/arxiv/2510.18183", "analysis": {"summary": "The paper introduces Nash Policy Gradient (NashPG), a policy‑gradient algorithm that keeps regularization strength fixed and iteratively refines a reference policy, guaranteeing strictly monotonic improvement and convergence to an exact Nash equilibrium in two‑player zero‑sum games without requiring a uniqueness assumption. Theoretical analysis shows convergence, and experiments on classic benchmark games as well as large‑scale domains such as Battleship and No‑Limit Texas Hold'em demonstrate comparable or lower exploitability and higher Elo ratings than prior model‑free methods.", "summary_cn": "本文提出了 Nash Policy Gradient (NashPG) 方法，在固定正则化强度的情况下通过迭代改进参考策略，实现严格单调改进并在二人零和游戏中收敛到精确的纳什均衡，且不依赖唯一性假设。理论分析证明了收敛性，实验证明在传统基准游戏以及 Battleship 和无限注德州扑克等大规模领域中，NashPG 的可利用性更低且 Elo 评分更高，优于以往的无模型方法。", "keywords": "Nash equilibrium, policy gradient, multi-agent reinforcement learning, regularization, imperfect-information games, convergence, exploitability, zero-sum games, algorithmic robustness, reinforcement learning", "scoring": {"interpretability": 1, "understanding": 5, "safety": 2, "technicality": 8, "surprisal": 7}, "category": {"failure_mode_addressed": "non-applicable", "primary_focus": "robustness"}, "authors": ["Eason Yu", "Tzu Hao Liu", "Yunke Wang", "Clément L. Canonne", "Nguyen H. Tran", "Chang Xu"]}, "usage": {"completion_tokens": 1042, "prompt_tokens": 3405, "total_tokens": 4447, "completion_tokens_details": {"accepted_prediction_tokens": null, "audio_tokens": null, "reasoning_tokens": 848, "rejected_prediction_tokens": null, "image_tokens": 0}, "prompt_tokens_details": {"audio_tokens": 0, "cached_tokens": 0}, "cost": 0.000553, "is_byok": false, "cost_details": {"upstream_inference_cost": null, "upstream_inference_prompt_cost": 0.0001362, "upstream_inference_completions_cost": 0.0004168}}, "model": "openai/gpt-oss-120b"}
{"timestamp": "2025-10-22T03:29:03.558830", "feed": "arxiv_cslg", "title": "Pay Attention to the Triggers: Constructing Backdoors That Survive Distillation", "link": "https://papers.cool/arxiv/2510.18541", "analysis": {"summary": "The paper introduces T-MTB, a backdoor technique for large language models that constructs composite triggers composed of common tokens, enabling the backdoor to survive knowledge distillation into student models. By leveraging triggers that appear frequently in distillation datasets, the poisoned teacher remains stealthy while the backdoor reliably transfers during compression, exposing severe security risks in scenarios such as jailbreaking and content manipulation across multiple model families.", "summary_cn": "本文提出了 T-MTB，这是一种针对大型语言模型的后门技术，通过使用由常见词组成的复合触发词，使后门能够在知识蒸馏过程中成功转移到学生模型。由于这些触发词在蒸馏数据集中经常出现，受污染的教师模型保持隐蔽，而后门在压缩过程中仍能被有效传递，揭示了在越狱和内容调制等情境下的严重安全风险，实验覆盖了多个模型系列。", "keywords": "backdoor, knowledge distillation, large language model, trigger, transferability, jailbreak, content modulation, security, model compression", "scoring": {"interpretability": 2, "understanding": 7, "safety": 8, "technicality": 7, "surprisal": 7}, "category": {"failure_mode_addressed": "misalignment", "primary_focus": "robustness"}, "authors": ["Giovanni De Muri", "Mark Vero", "Robin Staab", "Martin Vechev"]}, "usage": {"completion_tokens": 757, "prompt_tokens": 3436, "total_tokens": 4193, "completion_tokens_details": {"accepted_prediction_tokens": null, "audio_tokens": null, "reasoning_tokens": 515, "rejected_prediction_tokens": null, "image_tokens": 0}, "prompt_tokens_details": {"audio_tokens": 0, "cached_tokens": 3152}, "cost": 0.00067326, "is_byok": false, "cost_details": {"upstream_inference_cost": null, "upstream_inference_prompt_cost": 0.00029476, "upstream_inference_completions_cost": 0.0003785}}, "model": "openai/gpt-oss-120b"}
{"timestamp": "2025-10-22T03:29:03.564506", "feed": "arxiv_cslg", "title": "Towards Unsupervised Open-Set Graph Domain Adaptation via Dual Reprogramming", "link": "https://papers.cool/arxiv/2510.18363", "analysis": {"summary": "The paper introduces GraphRTA, a framework for unsupervised open-set graph domain adaptation that reprograms both the target graph structure and the model by pruning domain-specific parameters, and adds an extra classifier dimension for unknown classes to eliminate threshold tuning. Experiments on multiple datasets show competitive performance against recent baselines.", "summary_cn": "本文提出了 GraphRTA 框架，用于无监督开放集合图域适应，通过修改目标图的结构和节点特征以及剪枝模型的域特定参数来实现图和模型的双重重编程，并在分类器中加入未知类别维度，以免除手动阈值设置。实验在多个公开数据集上表明该方法相较于最新基线取得了满意的性能。", "keywords": "open-set graph domain adaptation, graph reprogramming, model pruning, unknown class detection, unsupervised learning", "scoring": {"interpretability": 3, "understanding": 5, "safety": 3, "technicality": 7, "surprisal": 6}, "category": {"failure_mode_addressed": "non-applicable", "primary_focus": "robustness"}, "authors": ["Zhen Zhang", "Bingsheng He"]}, "usage": {"completion_tokens": 568, "prompt_tokens": 4101, "total_tokens": 4669, "completion_tokens_details": {"accepted_prediction_tokens": null, "audio_tokens": null, "reasoning_tokens": 285, "rejected_prediction_tokens": null, "image_tokens": 0}, "prompt_tokens_details": {"audio_tokens": 0, "cached_tokens": 0}, "cost": 0.00034705, "is_byok": false, "cost_details": {"upstream_inference_cost": null, "upstream_inference_prompt_cost": 0.00020505, "upstream_inference_completions_cost": 0.000142}}, "model": "openai/gpt-oss-120b"}
{"timestamp": "2025-10-22T03:29:03.748079", "feed": "arxiv_cslg", "title": "OmniCast: A Masked Latent Diffusion Model for Weather Forecasting Across Time Scales", "link": "https://papers.cool/arxiv/2510.18707", "analysis": {"summary": "OmniCast introduces a masked latent diffusion model that combines a VAE encoder with a diffusion‑based transformer to produce probabilistic weather forecasts across medium‑range to subseasonal‑to‑seasonal horizons. By masking future latent tokens during training and jointly sampling space‑time tokens during inference, the approach reduces error accumulation and achieves state‑of‑the‑art performance while being orders of magnitude faster than autoregressive baselines. The model also demonstrates stable rollouts up to a century ahead, highlighting its scalability for long‑term climate prediction.", "summary_cn": "OmniCast 提出了一种掩码潜在扩散模型，将 VAE 编码器与基于扩散的 Transformer 相结合，以生成跨中期到亚季节‑季节时间尺度的概率天气预报。通过在训练期间掩码未来潜在标记并在推理时联合采样时空标记，该方法降低了自回归模型的误差累积，并在保持预测精度的同时实现了数十倍的速度提升。实验表明，该模型能够稳定生成最长达 100 年的天气演化序列，展现了在长期气候预测中的可扩展性。", "keywords": "masked diffusion, latent diffusion model, weather forecasting, subseasonal-to-seasonal, transformer, VAE, probabilistic forecasting", "scoring": {"interpretability": 2, "understanding": 3, "safety": 3, "technicality": 8, "surprisal": 7}, "category": {"failure_mode_addressed": "non-applicable", "primary_focus": "other"}, "authors": ["Tung Nguyen", "Tuan Pham", "Troy Arcomano", "Veerabhadra Kotamarthi", "Ian Foster", "Sandeep Madireddy", "Aditya Grover"]}, "usage": {"completion_tokens": 665, "prompt_tokens": 3517, "total_tokens": 4182, "completion_tokens_details": {"accepted_prediction_tokens": null, "audio_tokens": null, "reasoning_tokens": 349, "rejected_prediction_tokens": null, "image_tokens": 0}, "prompt_tokens_details": {"audio_tokens": 0, "cached_tokens": 3152}, "cost": 0.00063941, "is_byok": false, "cost_details": {"upstream_inference_cost": null, "upstream_inference_prompt_cost": 0.00030691, "upstream_inference_completions_cost": 0.0003325}}, "model": "openai/gpt-oss-120b"}
{"timestamp": "2025-10-22T03:29:04.103113", "feed": "arxiv_cslg", "title": "Alibaba International E-commerce Product Search Competition DILAB Team Technical Report", "link": "https://papers.cool/arxiv/2510.18499", "analysis": {"summary": "The report describes the multilingual e‑commerce product search system built by the DILAB team for the Alibaba International Search competition, which achieved 5th place with an overall score of 0.8819. The system uses a multi‑stage pipeline that combines data refinement, lightweight preprocessing, language tagging, and adaptive modeling with multiple architectures and fine‑tuning strategies to handle query‑category and query‑item tasks across many languages. The authors emphasize the importance of systematic data curation and iterative validation for robust multilingual search performance.", "summary_cn": "本文介绍了 DILAB 团队为阿里巴巴国际电商搜索大赛构建的多语言商品搜索系统，该系统在最终排行榜上获得第 5 名，整体得分 0.8819。系统采用多阶段流水线，融合数据精炼、轻量预处理、语言标签和自适应建模，使用多种架构和微调策略来同时处理查询‑类别（QC）和查询‑商品（QI）任务，支持多语言和多领域。作者强调系统化的数据策划和迭代验证对实现稳健的多语言搜索性能至关重要。", "keywords": "multilingual search, e-commerce product search, data refinement, language tagging, adaptive modeling", "scoring": {"interpretability": 2, "understanding": 5, "safety": 2, "technicality": 7, "surprisal": 5}, "category": {"failure_mode_addressed": "non-applicable", "primary_focus": "other"}, "authors": ["Hyewon Lee", "Junghyun Oh", "Minkyung Song", "Soyoung Park", "Seunghoon Han"]}, "usage": {"completion_tokens": 659, "prompt_tokens": 3379, "total_tokens": 4038, "completion_tokens_details": {"accepted_prediction_tokens": null, "audio_tokens": null, "reasoning_tokens": 402, "rejected_prediction_tokens": null, "image_tokens": 0}, "prompt_tokens_details": {"audio_tokens": 0, "cached_tokens": 3152}, "cost": 0.00061571, "is_byok": false, "cost_details": {"upstream_inference_cost": null, "upstream_inference_prompt_cost": 0.00028621, "upstream_inference_completions_cost": 0.0003295}}, "model": "openai/gpt-oss-120b"}
{"timestamp": "2025-10-22T03:29:04.353040", "feed": "arxiv_cslg", "title": "Preference-based Reinforcement Learning beyond Pairwise Comparisons: Benefits of Multiple Options", "link": "https://papers.cool/arxiv/2510.18713", "analysis": {"summary": "The paper studies online preference-based reinforcement learning with ranking feedback, introducing the M-AUPO algorithm that selects multiple actions to maximize average uncertainty under a Plackett-Luce model. It provides the first theoretical guarantees showing that larger feedback subsets improve sample efficiency, achieving a suboptimality bound that scales with the inverse square root of subset size and a matching lower bound. These results advance the understanding of how richer preference information can accelerate alignment of large language models.", "summary_cn": "本文研究了在线基于偏好的强化学习（PbRL）在使用排名反馈时的样本效率提升，提出了在 Plackett-Luce 模型下通过最大化子集平均不确定性来选择多动作的 M-AUPO 算法。论文给出了首次理论保证，证明更大的反馈子集能够直接提升样本效率，提供了随子集大小的平方根倒数缩放的次优差距上界以及相匹配的下界。该工作深化了我们对利用更丰富偏好信息加速大语言模型对齐的理解。", "keywords": "preference-based reinforcement learning, Plackett-Luce, ranking feedback, sample efficiency, online learning, LLM alignment, subset selection, M-AUPO", "scoring": {"interpretability": 3, "understanding": 7, "safety": 6, "technicality": 8, "surprisal": 7}, "category": {"failure_mode_addressed": "misalignment", "primary_focus": "alignment"}, "authors": ["Joongkyu Lee", "Seouh-won Yi", "Min-hwan Oh"]}, "usage": {"completion_tokens": 781, "prompt_tokens": 3572, "total_tokens": 4353, "completion_tokens_details": {"accepted_prediction_tokens": null, "audio_tokens": null, "reasoning_tokens": 500, "rejected_prediction_tokens": null, "image_tokens": 0}, "prompt_tokens_details": {"audio_tokens": 0, "cached_tokens": 3152}, "cost": 0.00070566, "is_byok": false, "cost_details": {"upstream_inference_cost": null, "upstream_inference_prompt_cost": 0.00031516, "upstream_inference_completions_cost": 0.0003905}}, "model": "openai/gpt-oss-120b"}
{"timestamp": "2025-10-22T03:29:04.706337", "feed": "arxiv_cslg", "title": "Training Diverse Graph Experts for Ensembles: A Systematic Empirical Study", "link": "https://papers.cool/arxiv/2510.18370", "analysis": {"summary": "The paper presents the first systematic empirical study of diversification techniques for training multiple graph neural network experts within a mixture‑of‑experts ensemble. By evaluating 20 strategies—including random re‑initialization, hyperparameter variation, architectural changes, directionality modeling, and data partitioning—across 14 node‑classification benchmarks, the authors analyze expert diversity, complementarity, and overall ensemble performance, offering practical guidance for building effective GNN MoE systems.", "summary_cn": "本文首次系统性地研究了在图神经网络（GNN）混合专家（Mixture‑of‑Experts）框架中训练多样化专家的技术。通过在 14 个节点分类基准上评估 20 种多样化策略（包括随机重新初始化、超参数调节、架构变化、方向建模和数据划分），分析了专家的多样性、互补性以及整体集成性能，并提供了构建高效 GNN MoE 系统的实用指导。", "keywords": "graph neural networks, mixture of experts, ensemble learning, expert diversification, node classification, graph heterogeneity, systematic study, performance improvement", "scoring": {"interpretability": 2, "understanding": 5, "safety": 1, "technicality": 7, "surprisal": 5}, "category": {"failure_mode_addressed": "non-applicable", "primary_focus": "other"}, "authors": ["Gangda Deng", "Yuxin Yang", "Ömer Faruk Akgül", "Hanqing Zeng", "Yinglong Xia", "Rajgopal Kannan", "Viktor Prasanna"]}, "usage": {"completion_tokens": 648, "prompt_tokens": 3407, "total_tokens": 4055, "completion_tokens_details": {"accepted_prediction_tokens": null, "audio_tokens": null, "reasoning_tokens": 397, "rejected_prediction_tokens": null, "image_tokens": 0}, "prompt_tokens_details": {"audio_tokens": 0, "cached_tokens": 3152}, "cost": 0.00061441, "is_byok": false, "cost_details": {"upstream_inference_cost": null, "upstream_inference_prompt_cost": 0.00029041, "upstream_inference_completions_cost": 0.000324}}, "model": "openai/gpt-oss-120b"}
{"timestamp": "2025-10-22T03:29:04.851513", "feed": "arxiv_cslg", "title": "Uncertainty Estimation by Flexible Evidential Deep Learning", "link": "https://papers.cool/arxiv/2510.18322", "analysis": {"summary": "The paper introduces Flexible Evidential Deep Learning (F-EDL), which generalizes standard evidential deep learning by predicting a flexible Dirichlet distribution over class probabilities, offering a more expressive representation of uncertainty. The authors provide theoretical advantages of F-EDL and demonstrate state-of-the-art performance on uncertainty quantification across classical, long-tailed, and noisy in-distribution scenarios.", "summary_cn": "本文提出了灵活证据深度学习（F-EDL），通过对类别概率预测灵活的 Dirichlet 分布，扩展了传统证据深度学习的不确定性表达能力。作者给出了理论优势，并在经典、长尾和噪声分布等场景中展示了其在不确定性量化方面的最先进性能。", "keywords": "uncertainty quantification, evidential deep learning, flexible Dirichlet distribution, classification, out-of-distribution, long-tailed, noisy labels", "scoring": {"interpretability": 2, "understanding": 5, "safety": 7, "technicality": 7, "surprisal": 6}, "category": {"failure_mode_addressed": "misalignment", "primary_focus": "robustness"}, "authors": ["Taeseong Yoon", "Heeyoung Kim"]}, "usage": {"completion_tokens": 697, "prompt_tokens": 3415, "total_tokens": 4112, "completion_tokens_details": {"accepted_prediction_tokens": null, "audio_tokens": null, "reasoning_tokens": 507, "rejected_prediction_tokens": null, "image_tokens": 0}, "prompt_tokens_details": {"audio_tokens": 0, "cached_tokens": 3152}, "cost": 0.00064011, "is_byok": false, "cost_details": {"upstream_inference_cost": null, "upstream_inference_prompt_cost": 0.00029161, "upstream_inference_completions_cost": 0.0003485}}, "model": "openai/gpt-oss-120b"}
{"timestamp": "2025-10-22T03:29:05.023700", "feed": "arxiv_cslg", "title": "Provable Generalization Bounds for Deep Neural Networks with Adaptive Regularization", "link": "https://papers.cool/arxiv/2510.18410", "analysis": {"summary": "The paper proposes Momentum-Adaptive Gradient Dropout (MAGDrop), a regularization technique that modulates dropout rates on activations using current gradients and accumulated momentum, and provides a tightened PAC-Bayes generalization bound reflecting this adaptivity. Empirical results on MNIST and CIFAR-10 show MAGDrop improves test accuracy and reduces generalization gaps compared to standard dropout and other adaptive regularizers. The work bridges theoretical analysis with practical regularization, offering a framework aimed at improving deep network generalization for high‑stakes applications.", "summary_cn": "本文提出动量自适应梯度 Dropout（MAGDrop），一种依据当前梯度和累计动量动态调整激活层 dropout 率的正则化方法，并推导了反映该自适应性的紧致 PAC‑Bayes 泛化上界。实验在 MNIST 与 CIFAR‑10 上显示，MAGDrop 相较于标准 dropout 与其他自适应正则化器提升了测试准确率并显著缩小了泛化差距。该工作将理论分析与实用正则化相结合，为提升深度网络在高风险应用场景下的泛化能力提供了框架。", "keywords": "generalization, deep neural networks, adaptive regularization, dropout, momentum, PAC-Bayes, overfitting, theoretical bounds, empirical evaluation", "scoring": {"interpretability": 2, "understanding": 6, "safety": 4, "technicality": 7, "surprisal": 6}, "category": {"failure_mode_addressed": "non-applicable", "primary_focus": "robustness"}, "authors": ["Adeel Safder"]}, "usage": {"completion_tokens": 823, "prompt_tokens": 3399, "total_tokens": 4222, "completion_tokens_details": {"accepted_prediction_tokens": null, "audio_tokens": null, "reasoning_tokens": 556, "rejected_prediction_tokens": null, "image_tokens": 0}, "prompt_tokens_details": {"audio_tokens": 0, "cached_tokens": 3152}, "cost": 0.00070071, "is_byok": false, "cost_details": {"upstream_inference_cost": null, "upstream_inference_prompt_cost": 0.00028921, "upstream_inference_completions_cost": 0.0004115}}, "model": "openai/gpt-oss-120b"}
{"timestamp": "2025-10-22T03:29:05.315956", "feed": "arxiv_cslg", "title": "Search Self-play: Pushing the Frontier of Agent Capability without Supervision", "link": "https://papers.cool/arxiv/2510.18821", "analysis": {"summary": "The paper introduces Search Self‑Play (SSP), a framework where a large language model simultaneously generates deep search queries (task proposer) and solves them (problem solver), using the proposer’s retrieved documents as ground‑truth for verifiable rewards. By iteratively co‑evolving both roles through competition and cooperation, SSP achieves substantial performance gains on various search benchmarks without any human‑provided supervision. Experiments show the method works both from scratch and with continuous reinforcement‑learning updates.", "summary_cn": "本文提出搜索自博弈（Search Self‑Play, SSP）框架，让大型语言模型同时担任任务提议者和问题求解者，通过提议者的检索文档生成可靠的真实答案，以实现可验证奖励的强化学习。提议者与求解者在竞争与合作中共同进化，显著提升搜索代理在多项基准上的表现，无需任何人工监督。实验表明该方法在从零训练和持续 RL 训练两种设置下均有效。", "keywords": "search self-play, RL with verifiable rewards, LLM agents, task synthesis, retrieval-augmented generation, unsupervised RL training", "scoring": {"interpretability": 2, "understanding": 6, "safety": 5, "technicality": 8, "surprisal": 7}, "category": {"failure_mode_addressed": "non-applicable", "primary_focus": "alignment"}, "authors": ["Hongliang Lu", "Yuhang Wen", "Pengyu Cheng", "Ruijin Ding", "Haotian Xu", "Jiaqi Guo", "Chutian Wang", "Haonan Chen", "Xiaoxi Jiang", "Guanjun Jiang"]}, "usage": {"completion_tokens": 721, "prompt_tokens": 3499, "total_tokens": 4220, "completion_tokens_details": {"accepted_prediction_tokens": null, "audio_tokens": null, "reasoning_tokens": 471, "rejected_prediction_tokens": null, "image_tokens": 0}, "prompt_tokens_details": {"audio_tokens": 0, "cached_tokens": 3152}, "cost": 0.00066471, "is_byok": false, "cost_details": {"upstream_inference_cost": null, "upstream_inference_prompt_cost": 0.00030421, "upstream_inference_completions_cost": 0.0003605}}, "model": "openai/gpt-oss-120b"}
{"timestamp": "2025-10-22T03:29:05.690739", "feed": "arxiv_cslg", "title": "Unrolled-SINDy: A Stable Explicit Method for Non linear PDE Discovery from Sparsely Sampled Data", "link": "https://papers.cool/arxiv/2510.18611", "analysis": {"summary": "The paper introduces Unrolled-SINDy, an unrolling scheme that stabilizes explicit methods for discovering governing PDEs from sparsely sampled temporal data by decoupling the numerical time step from the data sampling rate. The approach can be implemented via a closed‑form iterative update or gradient descent and demonstrates improved parameter recovery on both classic SINDy and the noise‑robust iNeuralSINDy across Euler and RK4 discretizations. Experiments show that the unrolled method enables the identification of equations that standard SINDy cannot recover due to large local truncation errors.", "summary_cn": "本文提出 Unrolled‑SINDy 方法，通过将数值时间步长与稀疏采样的观测数据率解耦，实现了显式数值方法在 PDE 发现任务中的稳定性提升。该方案可采用闭式迭代或梯度下降实现，并在传统 SINDy 与抗噪 iNeuralSINDy 以及 Euler、RK4 等离散方案上展示了更好的参数恢复能力，使得原本因局部截断误差过大而无法识别的方程得以重建。实验验证了该解卷方法在稀疏数据情形下的通用性和有效性。", "keywords": "PDE discovery, SINDy, unrolling, sparse data, stability, gradient descent, iNeuralSINDy, system identification, explicit methods, numerical integration", "scoring": {"interpretability": 4, "understanding": 7, "safety": 2, "technicality": 7, "surprisal": 6}, "category": {"failure_mode_addressed": "non-applicable", "primary_focus": "interpretability"}, "authors": ["Fayad Ali Banna", "Antoine Caradot", "Eduardo Brandao", "Jean-Philippe Colombier", "Rémi Emonet", "Marc Sebban"]}, "usage": {"completion_tokens": 763, "prompt_tokens": 3416, "total_tokens": 4179, "completion_tokens_details": {"accepted_prediction_tokens": null, "audio_tokens": null, "reasoning_tokens": 450, "rejected_prediction_tokens": null, "image_tokens": 0}, "prompt_tokens_details": {"audio_tokens": 0, "cached_tokens": 3152}, "cost": 0.00067326, "is_byok": false, "cost_details": {"upstream_inference_cost": null, "upstream_inference_prompt_cost": 0.00029176, "upstream_inference_completions_cost": 0.0003815}}, "model": "openai/gpt-oss-120b"}
{"timestamp": "2025-10-22T03:29:05.697823", "feed": "arxiv_cslg", "title": "Fine-tuning Flow Matching Generative Models with Intermediate Feedback", "link": "https://papers.cool/arxiv/2510.18072", "analysis": {"summary": "The paper introduces AC-Flow, an actor-critic framework designed to fine‑tune continuous‑time flow matching generative models using intermediate feedback. It employs reward shaping, advantage clipping with a warm‑up phase, and a generalized critic weighting scheme with Wasserstein regularization to stabilize training and preserve diversity. Experiments on Stable Diffusion 3 show state‑of‑the‑art performance on text‑to‑image alignment and generalization to unseen human preference models.", "summary_cn": "本文提出了 AC-Flow，一种基于 actor‑critic 的框架，用于利用中间反馈微调连续时间流匹配生成模型。通过奖励整形、优势裁剪加热身阶段以及带 Wasserstein 正则化的广义批评者加权机制，实现了训练的稳定性并保持生成多样性。实验在 Stable Diffusion 3 上展示了在文本到图像对齐任务以及对未见人类偏好模型的泛化方面的先进表现。", "keywords": "flow matching, generative models, actor-critic, reward shaping, text-to-image alignment, Wasserstein regularization, fine-tuning, preference modeling", "scoring": {"interpretability": 3, "understanding": 7, "safety": 6, "technicality": 8, "surprisal": 7}, "category": {"failure_mode_addressed": "misalignment", "primary_focus": "alignment"}, "authors": ["Jiajun Fan", "Chaoran Cheng", "Shuaike Shen", "Xiangxin Zhou", "Ge Liu"]}, "usage": {"completion_tokens": 565, "prompt_tokens": 4056, "total_tokens": 4621, "completion_tokens_details": {"accepted_prediction_tokens": null, "audio_tokens": null, "reasoning_tokens": 228, "rejected_prediction_tokens": null, "image_tokens": 0}, "prompt_tokens_details": {"audio_tokens": 0, "cached_tokens": 0}, "cost": 0.00034405, "is_byok": false, "cost_details": {"upstream_inference_cost": null, "upstream_inference_prompt_cost": 0.0002028, "upstream_inference_completions_cost": 0.00014125}}, "model": "openai/gpt-oss-120b"}
{"timestamp": "2025-10-22T03:29:05.791171", "feed": "arxiv_cslg", "title": "CAGE: Curvature-Aware Gradient Estimation For Accurate Quantization-Aware Training", "link": "https://papers.cool/arxiv/2510.18784", "analysis": {"summary": "The paper proposes CAGE, a curvature-aware gradient correction for quantization-aware training that augments the straight-through estimator to mitigate loss increases caused by low-bit quantization. By formulating QAT as a multi‑objective optimization problem and deriving a Pareto‑optimal correction term using local curvature, CAGE provides optimizer‑agnostic, theoretically‑grounded updates with strong convergence guarantees. Experiments on Llama‑style models up to 800M parameters show that CAGE recovers more than 10% of the quantization‑induced loss in the W4A4 regime compared to existing outlier‑mitigation methods.", "summary_cn": "本文提出了 CAGE，一种基于曲率的梯度校正方法，用于量化感知训练（QAT），在直通估计器（STE）梯度上加入校正以抵消低比特量化导致的损失增加。通过将 QAT 建模为多目标优化并利用局部曲率信息推导出 Pareto 最优校正项，CAGE 在保持优化器无关的同时提供了理论收敛保证。实验在最高 800M 参数的 Llama 系列模型上进行，显示在 W4A4 设定下相较于现有异常值处理方法，CAGE 能恢复超过 10% 的量化引起的损失。", "keywords": "quantization-aware training, curvature-aware gradient, straight-through estimator, Pareto-optimal, low-bit quantization, optimizer-agnostic, Llama, W4A4", "scoring": {"interpretability": 2, "understanding": 6, "safety": 3, "technicality": 8, "surprisal": 6}, "category": {"failure_mode_addressed": "non-applicable", "primary_focus": "other"}, "authors": ["Soroush Tabesh", "Mher Safaryan", "Dan Alistarh"]}, "usage": {"completion_tokens": 780, "prompt_tokens": 3442, "total_tokens": 4222, "completion_tokens_details": {"accepted_prediction_tokens": null, "audio_tokens": null, "reasoning_tokens": 426, "rejected_prediction_tokens": null, "image_tokens": 0}, "prompt_tokens_details": {"audio_tokens": 0, "cached_tokens": 3152}, "cost": 0.00068566, "is_byok": false, "cost_details": {"upstream_inference_cost": null, "upstream_inference_prompt_cost": 0.00029566, "upstream_inference_completions_cost": 0.00039}}, "model": "openai/gpt-oss-120b"}
{"timestamp": "2025-10-22T03:29:06.086625", "feed": "arxiv_cslg", "title": "Online SFT for LLM Reasoning: Surprising Effectiveness of Self-Tuning without Rewards", "link": "https://papers.cool/arxiv/2510.18814", "analysis": {"summary": "The paper introduces Online Supervised Fine‑Tuning (OSFT), a simple reward‑free paradigm where a large language model generates its own answers and is immediately fine‑tuned on this self‑generated data. Experiments on challenging mathematical reasoning benchmarks show that OSFT attains performance comparable to strong reinforcement‑learning‑with‑verifiable‑rewards methods such as GRPO while using only a single rollout per example. An ablation study attributes the gains to the model's latent preferences learned during pretraining, highlighting OSFT as an efficient alternative to complex reward‑based training.", "summary_cn": "本文提出在线监督微调（OSFT）范式，即让大型语言模型自行生成答案并立即在这些自生成数据上进行微调，整个过程无需奖励信号。实验在挑战性的数学推理基准上显示，OSFT 只使用一次采样即可实现与强大的可验证奖励强化学习方法（如 GRPO）相当的性能。消融实验表明，效果提升来源于模型在预训练阶段已学习的潜在偏好，凸显 OSFT 作为一种高效的、无需复杂奖励机制的训练替代方案。", "keywords": "online supervised finetuning, self-tuning, LLM reasoning, reward-free training, RLVR, GRPO, mathematical reasoning", "scoring": {"interpretability": 2, "understanding": 6, "safety": 4, "technicality": 7, "surprisal": 7}, "category": {"failure_mode_addressed": "non-applicable", "primary_focus": "other"}, "authors": ["Mengqi Li", "Lei Zhao", "Anthony Man-Cho So", "Ruoyu Sun", "Xiao Li"]}, "usage": {"completion_tokens": 720, "prompt_tokens": 3382, "total_tokens": 4102, "completion_tokens_details": {"accepted_prediction_tokens": null, "audio_tokens": null, "reasoning_tokens": 438, "rejected_prediction_tokens": null, "image_tokens": 0}, "prompt_tokens_details": {"audio_tokens": 0, "cached_tokens": 3152}, "cost": 0.00064666, "is_byok": false, "cost_details": {"upstream_inference_cost": null, "upstream_inference_prompt_cost": 0.00028666, "upstream_inference_completions_cost": 0.00036}}, "model": "openai/gpt-oss-120b"}
{"timestamp": "2025-10-22T03:29:06.297147", "feed": "arxiv_cslg", "title": "Benchmarking Probabilistic Time Series Forecasting Models on Neural Activity", "link": "https://papers.cool/arxiv/2510.18037", "analysis": {"summary": "The paper systematically evaluates eight probabilistic deep learning models, including two foundation models, against four classical statistical approaches for forecasting spontaneous neural activity recorded via widefield imaging in mouse cortex. Results show that several deep learning models consistently outperform classical methods, with the best model providing informative forecasts up to 1.5 seconds ahead, highlighting potential for closed-loop neural control and deeper insight into neural dynamics.", "summary_cn": "本文系统评估了八种概率深度学习模型（含两个基础模型）在小鼠皮层宽视野成像记录的自发神经活动时间序列预测任务中的表现，并与四种经典统计模型及两种基线方法进行比较。实验表明，多种深度学习模型在各预测时长上均优于传统方法，最佳模型能够提供约1.5秒的有效预测，显示出对闭环神经控制和神经活动内在时间结构探索的潜在价值。", "keywords": "probabilistic forecasting, neural activity, time series, deep learning, widefield imaging, benchmark, foundation models", "scoring": {"interpretability": 2, "understanding": 6, "safety": 2, "technicality": 7, "surprisal": 5}, "category": {"failure_mode_addressed": "non-applicable", "primary_focus": "other"}, "authors": ["Ziyu Lu", "Anna J. Li", "Alexander E. Ladd", "Pascha Matveev", "Aditya Deole", "Eric Shea-Brown", "J. Nathan Kutz", "Nicholas A. Steinmetz"]}, "usage": {"completion_tokens": 629, "prompt_tokens": 3341, "total_tokens": 3970, "completion_tokens_details": {"accepted_prediction_tokens": null, "audio_tokens": null, "reasoning_tokens": 405, "rejected_prediction_tokens": null, "image_tokens": 0}, "prompt_tokens_details": {"audio_tokens": 0, "cached_tokens": 3136}, "cost": 0.00087855, "is_byok": false, "cost_details": {"upstream_inference_cost": null, "upstream_inference_prompt_cost": 0.00050115, "upstream_inference_completions_cost": 0.0003774}}, "model": "openai/gpt-oss-120b"}
{"timestamp": "2025-10-22T03:29:06.415545", "feed": "arxiv_cslg", "title": "Learning to Flow from Generative Pretext Tasks for Neural Architecture Encoding", "link": "https://papers.cool/arxiv/2510.18360", "analysis": {"summary": "The paper introduces FGP, a pre‑training approach that trains a neural architecture encoder to reconstruct a surrogate representation of information flow, allowing the encoder to capture flow information without specialized model structures. Experiments show that FGP improves encoder performance by up to 106% in Precision‑1% compared to the same encoder trained only with supervised learning, while being computationally faster than existing flow‑based encoders.", "summary_cn": "本文提出了 FGP，一种预训练方法，使神经网络结构编码器学习重建信息流的代理表示，从而在无需专门模型结构的情况下捕获信息流特征。实验表明，与仅使用监督学习的同一编码器相比，FGP 在 Precision‑1% 指标上提升最高达 106%，且处理速度快于现有基于信息流的编码器。", "keywords": "neural architecture encoding, information flow, pretraining, flow surrogate, performance prediction, neural architecture search, representation learning", "scoring": {"interpretability": 4, "understanding": 5, "safety": 2, "technicality": 7, "surprisal": 6}, "category": {"failure_mode_addressed": "non-applicable", "primary_focus": "other"}, "authors": ["Sunwoo Kim", "Hyunjin Hwang", "Kijung Shin"]}, "usage": {"completion_tokens": 771, "prompt_tokens": 3406, "total_tokens": 4177, "completion_tokens_details": {"accepted_prediction_tokens": null, "audio_tokens": null, "reasoning_tokens": 629, "rejected_prediction_tokens": null, "image_tokens": 0}, "prompt_tokens_details": {"audio_tokens": 0, "cached_tokens": 3152}, "cost": 0.00067576, "is_byok": false, "cost_details": {"upstream_inference_cost": null, "upstream_inference_prompt_cost": 0.00029026, "upstream_inference_completions_cost": 0.0003855}}, "model": "openai/gpt-oss-120b"}
{"timestamp": "2025-10-22T03:29:06.483636", "feed": "arxiv_cslg", "title": "Hardness of Learning Regular Languages in the Next Symbol Prediction Setting", "link": "https://papers.cool/arxiv/2510.18634", "analysis": {"summary": "The paper formalizes the Next Symbol Prediction (NSP) learning setting—where a learner receives positive strings together with prefix membership and admissible next-symbol information—and studies its PAC learnability. It proves that even with these richer labels, learning concept classes such as deterministic finite automata (DFAs) and Boolean formulas remains computationally hard, providing a reduction that makes most extra labels uninformative and, under standard cryptographic assumptions, establishing hardness of DFA learning in the NSP setting.", "summary_cn": "本文形式化了“下一个符号预测”(NSP)学习设置——学习者在获得正例字符串的同时，还得到每个前缀是否属于语言以及可导致接受字符串的下一符号信息，并对其在 PAC 学习框架下的可学习性进行研究。研究表明，即使标签更丰富，学习确定性有限自动机（DFA）和布尔公式等概念类仍然在计算上是困难的，作者通过构造几乎所有额外标签都是无信息的归约，且在标准密码学假设下证明了 DFA 在 NSP 设置下的学习硬度。", "keywords": "regular languages, DFA learning, next symbol prediction, PAC learning, computational hardness, cryptographic assumptions", "scoring": {"interpretability": 2, "understanding": 5, "safety": 2, "technicality": 8, "surprisal": 6}, "category": {"failure_mode_addressed": "non-applicable", "primary_focus": "other"}, "authors": ["Satwik Bhattamishra", "Phil Blunsom", "Varun Kanade"]}, "usage": {"completion_tokens": 928, "prompt_tokens": 3397, "total_tokens": 4325, "completion_tokens_details": {"accepted_prediction_tokens": null, "audio_tokens": null, "reasoning_tokens": 738, "rejected_prediction_tokens": null, "image_tokens": 0}, "prompt_tokens_details": {"audio_tokens": 0, "cached_tokens": 64}, "cost": 0.00096907, "is_byok": false, "cost_details": {"upstream_inference_cost": null, "upstream_inference_prompt_cost": 0.00050507, "upstream_inference_completions_cost": 0.000464}}, "model": "openai/gpt-oss-120b"}
{"timestamp": "2025-10-22T03:29:06.503590", "feed": "arxiv_cslg", "title": "Reinforcement Learning with Imperfect Transition Predictions: A Bellman-Jensen Approach", "link": "https://papers.cool/arxiv/2510.18687", "analysis": {"summary": "The paper introduces a Bayesian value function to enable tractable optimal policies in reinforcement learning when agents have access to imperfect multi-step transition predictions. It proposes a Bellman-Jensen Gap analysis to quantify the value of such predictions and presents BOLA, a two-stage model-based RL algorithm that learns offline and adapts online, with theoretical sample-efficiency guarantees and empirical validation on synthetic tasks and a wind-energy storage control problem.", "summary_cn": "本文提出了贝叶斯价值函数，以在强化学习中处理具有不完美多步转移预测的代理，实现可求解的最优策略。通过 Bellman-Jensen Gap 分析量化这些预测的价值，并引入 BOLA（Bayesian Offline Learning with Online Adaptation）两阶段模型式 RL 算法，在离线学习后进行轻量级在线适配，理论上保持样本效率，并在合成 MDP 和实际风能储能控制任务上进行验证。", "keywords": "reinforcement learning, multi-step predictions, Bayesian value function, Bellman-Jensen Gap, model-based RL, sample efficiency, offline learning, online adaptation, wind energy storage", "scoring": {"interpretability": 2, "understanding": 6, "safety": 3, "technicality": 8, "surprisal": 7}, "category": {"failure_mode_addressed": "non-applicable", "primary_focus": "robustness"}, "authors": ["Chenbei Lu", "Zaiwei Chen", "Tongxin Li", "Chenye Wu", "Adam Wierman"]}, "usage": {"completion_tokens": 749, "prompt_tokens": 3465, "total_tokens": 4214, "completion_tokens_details": {"accepted_prediction_tokens": null, "audio_tokens": null, "reasoning_tokens": 526, "rejected_prediction_tokens": null, "image_tokens": 0}, "prompt_tokens_details": {"audio_tokens": 0, "cached_tokens": 3152}, "cost": 0.00067361, "is_byok": false, "cost_details": {"upstream_inference_cost": null, "upstream_inference_prompt_cost": 0.00029911, "upstream_inference_completions_cost": 0.0003745}}, "model": "openai/gpt-oss-120b"}
{"timestamp": "2025-10-22T03:29:06.760825", "feed": "arxiv_cslg", "title": "Stick-Breaking Embedded Topic Model with Continuous Optimal Transport for Online Analysis of Document Streams", "link": "https://papers.cool/arxiv/2510.18786", "analysis": {"summary": "The paper introduces SB-SETM, a novel online extension of the Embedded Topic Model that uses a truncated stick-breaking process to adaptively determine the number of active topics and merges topic embeddings across time steps via a continuous optimal transport formulation. This enables effective analysis of evolving document streams, demonstrated on simulated data and a real-world news corpus covering the Russian-Ukrainian war. Experiments show SB-SETM outperforms existing baselines in tracking topic dynamics over time.", "summary_cn": "本文提出 SB-SETM，一种基于嵌入式主题模型的在线扩展，通过截断 Stick-Breaking 过程自适应推断每个时间步的活跃主题数，并利用连续最优传输方法合并跨时间的主题嵌入，实现对文档流的动态分析。实验在模拟情景和涵盖 2022-2023 年俄乌战争的新闻数据集上验证了其相较于现有基线的优越性能。", "keywords": "online topic modeling, stick-breaking, embedded topic model, optimal transport, streaming documents, dynamic topics, latent space alignment, document streams", "scoring": {"interpretability": 2, "understanding": 4, "safety": 1, "technicality": 7, "surprisal": 6}, "category": {"failure_mode_addressed": "non-applicable", "primary_focus": "other"}, "authors": ["Federica Granese", "Serena Villata", "Charles Bouveyron"]}, "usage": {"completion_tokens": 758, "prompt_tokens": 3402, "total_tokens": 4160, "completion_tokens_details": {"accepted_prediction_tokens": null, "audio_tokens": null, "reasoning_tokens": 523, "rejected_prediction_tokens": null, "image_tokens": 0}, "prompt_tokens_details": {"audio_tokens": 0, "cached_tokens": 3152}, "cost": 0.00066866, "is_byok": false, "cost_details": {"upstream_inference_cost": null, "upstream_inference_prompt_cost": 0.00028966, "upstream_inference_completions_cost": 0.000379}}, "model": "openai/gpt-oss-120b"}
{"timestamp": "2025-10-22T03:29:07.161154", "feed": "arxiv_cslg", "title": "Online Time Series Forecasting with Theoretical Guarantees", "link": "https://papers.cool/arxiv/2510.18281", "analysis": {"summary": "The paper introduces a theoretical framework (TOT) for online time‑series forecasting under latent distribution shifts, proving that providing a forecaster with latent variables tightens Bayes risk and that this benefit persists despite estimation uncertainty. It proposes a model‑agnostic blueprint using a temporal decoder and two noise estimators to infer latent variables and combines them with empirical results on synthetic and real benchmarks that support the theory. The approach demonstrates general performance improvements across multiple baseline methods.", "summary_cn": "本文提出了一种面向在线时间序列预测的理论框架（TOT），在潜在分布漂移下证明向预测器提供潜在变量可以收紧贝叶斯风险，且该收益在潜在变量估计不确定性下仍然维持并随可识别性提升而增长。文中进一步设计了基于时间解码器和两个独立噪声估计器的模型无关蓝图，用于推断潜在变量并匹配观测分布，并通过合成数据与真实基准实验验证了理论主张，展示了对多种基线模型的普遍性能提升。", "keywords": "online forecasting, latent variables, time series, Bayes risk, distribution shift, theoretical guarantees, causal inference, temporal decoder", "scoring": {"interpretability": 2, "understanding": 6, "safety": 1, "technicality": 7, "surprisal": 5}, "category": {"failure_mode_addressed": "non-applicable", "primary_focus": "other"}, "authors": ["Zijian Li", "Changze Zhou", "Minghao Fu", "Sanjay Manjunath", "Fan Feng", "Guangyi Chen", "Yingyao Hu", "Ruichu Cai", "Kun Zhang"]}, "usage": {"completion_tokens": 624, "prompt_tokens": 3398, "total_tokens": 4022, "completion_tokens_details": {"accepted_prediction_tokens": null, "audio_tokens": null, "reasoning_tokens": 328, "rejected_prediction_tokens": null, "image_tokens": 0}, "prompt_tokens_details": {"audio_tokens": 0, "cached_tokens": 3152}, "cost": 0.00060106, "is_byok": false, "cost_details": {"upstream_inference_cost": null, "upstream_inference_prompt_cost": 0.00028906, "upstream_inference_completions_cost": 0.000312}}, "model": "openai/gpt-oss-120b"}
{"timestamp": "2025-10-22T03:29:07.397131", "feed": "arxiv_cslg", "title": "NTKMTL: Mitigating Task Imbalance in Multi-Task Learning from Neural Tangent Kernel Perspective", "link": "https://papers.cool/arxiv/2510.18258", "analysis": {"summary": "The paper introduces NTKMTL, a multi-task learning framework that leverages Neural Tangent Kernel (NTK) theory to analyze and balance the convergence speeds of different tasks, thereby mitigating task imbalance. By extending the NTK matrix to the multi-task setting and applying spectral analysis, the authors develop NTKMTL and its efficient variant NTKMTL-SR, achieving state-of-the-art results on supervised and reinforcement learning benchmarks.", "summary_cn": "本文提出 NTKMTL 框架，利用神经切线核（NTK）理论分析并平衡多任务学习中各任务的收敛速度，以缓解任务不平衡问题。作者构建了多任务的扩展 NTK 矩阵并进行谱分析，进一步提出高效变体 NTKMTL‑SR，在监督学习和强化学习基准上实现了最新性能。", "keywords": "multi-task learning, task imbalance, neural tangent kernel, spectral analysis, NTKMTL, representation sharing, training dynamics, reinforcement learning", "scoring": {"interpretability": 4, "understanding": 7, "safety": 1, "technicality": 8, "surprisal": 6}, "category": {"failure_mode_addressed": "non-applicable", "primary_focus": "other"}, "authors": ["Xiaohan Qin", "Xiaoxing Wang", "Ning Liao", "Junchi Yan"]}, "usage": {"completion_tokens": 669, "prompt_tokens": 3433, "total_tokens": 4102, "completion_tokens_details": {"accepted_prediction_tokens": null, "audio_tokens": null, "reasoning_tokens": 423, "rejected_prediction_tokens": null, "image_tokens": 0}, "prompt_tokens_details": {"audio_tokens": 0, "cached_tokens": 3152}, "cost": 0.00062881, "is_byok": false, "cost_details": {"upstream_inference_cost": null, "upstream_inference_prompt_cost": 0.00029431, "upstream_inference_completions_cost": 0.0003345}}, "model": "openai/gpt-oss-120b"}
{"timestamp": "2025-10-22T03:29:07.488352", "feed": "arxiv_cslg", "title": "Safe But Not Sorry: Reducing Over-Conservatism in Safety Critics via Uncertainty-Aware Modulation", "link": "https://papers.cool/arxiv/2510.18478", "analysis": {"summary": "The paper proposes the Uncertain Safety Critic (USC), which integrates uncertainty‑aware modulation into safety‑critic training to concentrate conservatism in uncertain, high‑cost regions while keeping gradients sharp in safe areas. Experiments demonstrate that USC cuts safety violations by about 40% and improves cost‑gradient prediction error by roughly 83%, effectively breaking the usual safety‑performance trade‑off in reinforcement learning.", "summary_cn": "本文提出了不确定安全评论家（USC），在安全评论家的训练中加入不确定性感知调制，使保守性集中于不确定且高代价的区域，同时在安全区域保持梯度的锐利性。实验表明，USC 将安全违规率降低约40%，并将成本梯度预测误差降低约83%，从而有效突破强化学习中安全与性能之间的传统权衡。", "keywords": "safe reinforcement learning, safety critic, uncertainty-aware modulation, reward-safety trade-off, conservative safety, RL safety, uncertainty estimation, policy optimization", "scoring": {"interpretability": 2, "understanding": 6, "safety": 8, "technicality": 7, "surprisal": 7}, "category": {"failure_mode_addressed": "misalignment", "primary_focus": "control"}, "authors": ["Daniel Bethell", "Simos Gerasimou", "Radu Calinescu", "Calum Imrie"]}, "usage": {"completion_tokens": 788, "prompt_tokens": 3372, "total_tokens": 4160, "completion_tokens_details": {"accepted_prediction_tokens": null, "audio_tokens": null, "reasoning_tokens": 593, "rejected_prediction_tokens": null, "image_tokens": 0}, "prompt_tokens_details": {"audio_tokens": 0, "cached_tokens": 3152}, "cost": 0.00067916, "is_byok": false, "cost_details": {"upstream_inference_cost": null, "upstream_inference_prompt_cost": 0.00028516, "upstream_inference_completions_cost": 0.000394}}, "model": "openai/gpt-oss-120b"}
{"timestamp": "2025-10-22T03:29:07.891888", "feed": "arxiv_cslg", "title": "EvoSyn: Generalizable Evolutionary Data Synthesis for Verifiable Learning", "link": "https://papers.cool/arxiv/2510.17928", "analysis": {"summary": "EvoSyn proposes an evolutionary, task-agnostic framework that jointly synthesizes problems, candidate solutions, and verification artifacts for language models, using a consistency-based evaluator to discover strategies that enforce agreement between human annotations and generated checks. By turning filtering into principled synthesis, the method produces coherent, verifiable training instances that improve performance on RL with verifiable rewards and model distillation across diverse benchmarks such as LiveCodeBench and AgentBench-OS.", "summary_cn": "EvoSyn 提出了一个进化式、任务无关的数据合成框架，能够同时生成问题、候选解答和验证机制，并通过一致性评估器发现策略，使人工标注与生成检查保持一致，从而实现可验证的学习。该方法将过滤升级为原则化的合成，产生连贯的可验证训练实例，并在 RLVR 与模型蒸馏等场景下显著提升 LiveCodeBench 与 AgentBench-OS 等基准的表现。", "keywords": "evolutionary data synthesis, verifiable learning, consistency evaluator, strategy-guided generation, language model distillation, RL with verifiable rewards, synthetic verification, generalization", "scoring": {"interpretability": 2, "understanding": 6, "safety": 7, "technicality": 7, "surprisal": 6}, "category": {"failure_mode_addressed": "misalignment", "primary_focus": "alignment"}, "authors": ["He Du", "Bowen Li", "Aijun Yang", "Siyang He", "Qipeng Guo", "Dacheng Tao"]}, "usage": {"completion_tokens": 674, "prompt_tokens": 3452, "total_tokens": 4126, "completion_tokens_details": {"accepted_prediction_tokens": null, "audio_tokens": null, "reasoning_tokens": 425, "rejected_prediction_tokens": null, "image_tokens": 0}, "prompt_tokens_details": {"audio_tokens": 0, "cached_tokens": 0}, "cost": 0.0009222, "is_byok": false, "cost_details": {"upstream_inference_cost": null, "upstream_inference_prompt_cost": 0.0005178, "upstream_inference_completions_cost": 0.0004044}}, "model": "openai/gpt-oss-120b"}
{"timestamp": "2025-10-22T03:29:07.926090", "feed": "arxiv_cslg", "title": "Learning to Navigate Under Imperfect Perception: Conformalised Segmentation for Safe Reinforcement Learning", "link": "https://papers.cool/arxiv/2510.18485", "analysis": {"summary": "The paper introduces COPPOL, a conformal‑prediction‑driven method that yields calibrated semantic‑segmentation hazard maps with finite‑sample safety guarantees and incorporates them into risk‑aware cost fields for reinforcement‑learning navigation. Across two satellite‑derived benchmarks, COPPOL achieves up to six‑fold higher hazard coverage and roughly 50% fewer safety violations while maintaining robustness under distributional shift.", "summary_cn": "本文提出 COPPOL，一种基于共形预测的感知到策略学习方法，生成具有有限样本安全保证的校准语义分割危害图，并将其转化为风险感知的代价场用于强化学习导航。在两个卫星衍生基准上，COPPOL 提升了最高 6 倍的危害覆盖率，并将导航中的安全违规降低约 50%，同时在分布漂移情况下保持鲁棒性。", "keywords": "conformal prediction, semantic segmentation, safety reinforcement learning, uncertainty quantification, hazard mapping, distributional shift, risk-aware planning", "scoring": {"interpretability": 3, "understanding": 6, "safety": 8, "technicality": 7, "surprisal": 7}, "category": {"failure_mode_addressed": "other", "primary_focus": "robustness"}, "authors": ["Daniel Bethell", "Simos Gerasimou", "Radu Calinescu", "Calum Imrie"]}, "usage": {"completion_tokens": 845, "prompt_tokens": 3358, "total_tokens": 4203, "completion_tokens_details": {"accepted_prediction_tokens": null, "audio_tokens": null, "reasoning_tokens": 712, "rejected_prediction_tokens": null, "image_tokens": 0}, "prompt_tokens_details": {"audio_tokens": 0, "cached_tokens": 3152}, "cost": 0.00070556, "is_byok": false, "cost_details": {"upstream_inference_cost": null, "upstream_inference_prompt_cost": 0.00028306, "upstream_inference_completions_cost": 0.0004225}}, "model": "openai/gpt-oss-120b"}
{"timestamp": "2025-10-22T03:29:08.079034", "feed": "arxiv_cslg", "title": "Learning Time-Varying Turn-Taking Behavior in Group Conversations", "link": "https://papers.cool/arxiv/2510.18649", "analysis": {"summary": "The paper introduces a flexible probabilistic model that predicts turn‑taking patterns in group conversations using individuals' personality traits and their recent speaking history. Unlike prior models that assume a universal formulation, this approach learns how a speaker’s inclination changes over time after they last spoke, and is evaluated on synthetic and real‑world datasets. Results show that conventional behavioral models can be unrealistic, highlighting the benefit of a data‑driven yet theoretically grounded method.", "summary_cn": "本文提出了一种灵活的概率模型，利用个体的性格特质和近期发言历史来预测群体对话中的轮换发言模式。不同于以往假设统一公式的模型，该方法能够学习说话者在上一次发言之后随时间变化的发言倾向，并在合成数据和真实对话数据上进行评估。实验结果表明传统行为模型并非总是现实的，凸显了数据驱动且理论扎实的方法的优势。", "keywords": "turn-taking, probabilistic model, group conversation, personality traits, temporal dynamics, conversational modeling, synthetic data, real-world data, behavioral modeling", "scoring": {"interpretability": 2, "understanding": 6, "safety": 1, "technicality": 7, "surprisal": 6}, "category": {"failure_mode_addressed": "non-applicable", "primary_focus": "other"}, "authors": ["Madeline Navarro", "Lisa O'Bryan", "Santiago Segarra"]}, "usage": {"completion_tokens": 819, "prompt_tokens": 3355, "total_tokens": 4174, "completion_tokens_details": {"accepted_prediction_tokens": null, "audio_tokens": null, "reasoning_tokens": 630, "rejected_prediction_tokens": null, "image_tokens": 0}, "prompt_tokens_details": {"audio_tokens": 0, "cached_tokens": 3152}, "cost": 0.00069211, "is_byok": false, "cost_details": {"upstream_inference_cost": null, "upstream_inference_prompt_cost": 0.00028261, "upstream_inference_completions_cost": 0.0004095}}, "model": "openai/gpt-oss-120b"}
{"timestamp": "2025-10-22T03:29:08.131319", "feed": "arxiv_cslg", "title": "From Competition to Synergy: Unlocking Reinforcement Learning for Subject-Driven Image Generation", "link": "https://papers.cool/arxiv/2510.18263", "analysis": {"summary": "The paper proposes Customized-GRPO, a reinforcement‑learning framework that improves subject‑driven image generation by addressing the trade‑off between identity preservation and prompt adherence. It introduces Synergy‑Aware Reward Shaping to resolve conflicting reward signals and Time‑Aware Dynamic Weighting to align optimization with the diffusion process timeline, achieving better fidelity‑editability balance than naive GRPO baselines.", "summary_cn": "本文提出了 Customized‑GRPO 框架，通过强化学习提升以主题为驱动的图像生成质量，解决身份保持（忠实度）与文本提示遵循（可编辑性）之间的权衡。创新点包括协同感知奖励塑形（SARS），用于消除冲突奖励并放大协同信号，以及时间感知动态加权（TDW），根据扩散过程的不同阶段调整优化力度，从而在保持关键特征的同时更准确地满足复杂文本提示。", "keywords": "reinforcement learning, subject-driven image generation, diffusion models, reward shaping, time-aware weighting, synergy, fidelity-editability tradeoff, GRPO", "scoring": {"interpretability": 2, "understanding": 6, "safety": 1, "technicality": 8, "surprisal": 6}, "category": {"failure_mode_addressed": "non-applicable", "primary_focus": "other"}, "authors": ["Ziwei Huang", "Ying Shu", "Hao Fang", "Quanyu Long", "Wenya Wang", "Qiushi Guo", "Tiezheng Ge", "Leilei Gan"]}, "usage": {"completion_tokens": 665, "prompt_tokens": 3420, "total_tokens": 4085, "completion_tokens_details": {"accepted_prediction_tokens": null, "audio_tokens": null, "reasoning_tokens": 415, "rejected_prediction_tokens": null, "image_tokens": 0}, "prompt_tokens_details": {"audio_tokens": 0, "cached_tokens": 3152}, "cost": 0.00062486, "is_byok": false, "cost_details": {"upstream_inference_cost": null, "upstream_inference_prompt_cost": 0.00029236, "upstream_inference_completions_cost": 0.0003325}}, "model": "openai/gpt-oss-120b"}
{"timestamp": "2025-10-22T03:29:08.643316", "feed": "arxiv_cslg", "title": "Scalable, Explainable and Provably Robust Anomaly Detection with One-Step Flow Matching", "link": "https://papers.cool/arxiv/2510.18328", "analysis": {"summary": "The paper introduces Time-Conditioned Contraction Matching (TCCM), a semi-supervised anomaly detection method for tabular data that learns a velocity field toward a fixed target and provides a lightweight, scalable training objective. TCCM offers an efficient one-step scoring strategy, feature-wise explainability, and provable Lipschitz robustness, achieving strong performance on the ADBench benchmark with reduced inference cost. Experiments demonstrate its advantages over diffusion‑based models, especially on high‑dimensional and large‑scale datasets.", "summary_cn": "本文提出了时间条件收缩匹配（TCCM），一种用于表格数据的半监督异常检测方法，通过学习指向固定目标（原点）的速度场，实现轻量级、可扩展的训练目标。TCCM 提供了一步得分策略，使异常分数具备特征层面的可解释性，并在输入空间上具备 Lipschitz 连续性，提供理论鲁棒性保证，在 ADBench 基准上表现优异，尤其在高维大规模数据集上优于基于扩散的模型。", "keywords": "anomaly detection, flow matching, time-conditioned contraction, explainability, provable robustness, tabular data, one-step scoring, velocity field", "scoring": {"interpretability": 7, "understanding": 6, "safety": 4, "technicality": 7, "surprisal": 7}, "category": {"failure_mode_addressed": "non-applicable", "primary_focus": "interpretability"}, "authors": ["Zhong Li", "Qi Huang", "Yuxuan Zhu", "Lincen Yang", "Mohammad Mohammadi Amiri", "Niki van Stein", "Matthijs van Leeuwen"]}, "usage": {"completion_tokens": 842, "prompt_tokens": 3505, "total_tokens": 4347, "completion_tokens_details": {"accepted_prediction_tokens": null, "audio_tokens": null, "reasoning_tokens": 607, "rejected_prediction_tokens": null, "image_tokens": 0}, "prompt_tokens_details": {"audio_tokens": 0, "cached_tokens": 3152}, "cost": 0.00072611, "is_byok": false, "cost_details": {"upstream_inference_cost": null, "upstream_inference_prompt_cost": 0.00030511, "upstream_inference_completions_cost": 0.000421}}, "model": "openai/gpt-oss-120b"}
{"timestamp": "2025-10-22T03:29:09.255096", "feed": "arxiv_cslg", "title": "Uncertainty-Aware Post-Hoc Calibration: Mitigating Confidently Incorrect Predictions Beyond Calibration Metrics", "link": "https://papers.cool/arxiv/2510.17915", "analysis": {"summary": "The paper proposes an uncertainty-aware post-hoc calibration framework that first stratifies predictions into putatively correct and incorrect groups using proximity‑based conformal prediction, then applies a dual isotonic regression strategy—standard isotonic regression for the correct group and an underconfidence‑regularized isotonic regression for the incorrect group. This instance‑level adaptivity reduces confidently incorrect predictions while maintaining competitive Expected Calibration Error, demonstrated on CIFAR‑10/100 with BiT and CoAtNet backbones. The method requires no model retraining and bridges calibration with uncertainty‑aware decision‑making.", "summary_cn": "本文提出一种不确定性感知的后置校准框架，利用基于相似度的共形预测将预测划分为可能正确和可能错误两类，再对这两类分别使用标准等距回归和欠置信正则化等距回归进行双重校准，从而降低高置信错误预测并保持竞争性的期望校准误差（Expected Calibration Error）。在 CIFAR‑10/100 上使用 BiT 与 CoAtNet 骨干网络的实验表明，该方法无需重新训练模型即可提升概率对齐与不确定性感知决策性能。", "keywords": "post-hoc calibration, uncertainty quantification, isotonic regression, conformal prediction, confidently incorrect predictions, neural network reliability", "scoring": {"interpretability": 3, "understanding": 6, "safety": 6, "technicality": 7, "surprisal": 6}, "category": {"failure_mode_addressed": "misalignment", "primary_focus": "robustness"}, "authors": ["Hassan Gharoun", "Mohammad Sadegh Khorshidi", "Kasra Ranjbarigderi", "Fang Chen", "Amir H. Gandomi"]}, "usage": {"completion_tokens": 742, "prompt_tokens": 3452, "total_tokens": 4194, "completion_tokens_details": {"accepted_prediction_tokens": null, "audio_tokens": null, "reasoning_tokens": 485, "rejected_prediction_tokens": null, "image_tokens": 0}, "prompt_tokens_details": {"audio_tokens": 0, "cached_tokens": 0}, "cost": 0.00043488, "is_byok": false, "cost_details": {"upstream_inference_cost": null, "upstream_inference_prompt_cost": 0.00013808, "upstream_inference_completions_cost": 0.0002968}}, "model": "openai/gpt-oss-120b"}
{"timestamp": "2025-10-22T03:29:10.439340", "feed": "arxiv_cslg", "title": "Scaling Laws Meet Model Architecture: Toward Inference-Efficient LLMs", "link": "https://papers.cool/arxiv/2510.18245", "analysis": {"summary": "The paper introduces a conditional scaling law that extends the Chinchilla framework by incorporating architectural factors such as hidden size, mlp-to-attention ratio, and grouped-query attention, enabling the prediction of inference-efficient and accurate LLM designs. By training over 200 models ranging from 80M to 3B parameters, the authors demonstrate that architectures selected via this law achieve up to 2.1% higher accuracy and 42% greater inference throughput compared to strong baselines. This work provides a systematic approach to balance model performance and inference cost.", "summary_cn": "本文在 Chinchilla 框架基础上加入隐藏层大小、MLP 与注意力比例以及分组查询注意力（GQA）等架构信息，提出条件尺度律，用于预测兼具推理效率和准确性的 LLM 结构。通过训练 200 多个参数规模在 80M 到 3B、训练数据在 80 亿到 1000 亿 tokens 的模型，验证该尺度律能够可靠地选出最优架构，使模型在相同训练预算下相较 LLaMA-3.2 提升最高 2.1% 的准确率并实现 42% 的推理吞吐提升。该研究提供了在性能与推理成本之间系统权衡的方法。", "keywords": "scaling laws, model architecture, inference efficiency, conditional scaling law, Chinchilla, grouped-query attention, mlp-to-attention ratio, hidden size, LLM performance, throughput", "scoring": {"interpretability": 2, "understanding": 7, "safety": 3, "technicality": 8, "surprisal": 6}, "category": {"failure_mode_addressed": "non-applicable", "primary_focus": "other"}, "authors": ["Song Bian", "Tao Yu", "Shivaram Venkataraman", "Youngsuk Park"]}, "usage": {"completion_tokens": 735, "prompt_tokens": 3441, "total_tokens": 4176, "completion_tokens_details": {"accepted_prediction_tokens": null, "audio_tokens": null, "reasoning_tokens": 411, "rejected_prediction_tokens": null, "image_tokens": 0}, "prompt_tokens_details": {"audio_tokens": 0, "cached_tokens": 3152}, "cost": 0.00066301, "is_byok": false, "cost_details": {"upstream_inference_cost": null, "upstream_inference_prompt_cost": 0.00029551, "upstream_inference_completions_cost": 0.0003675}}, "model": "openai/gpt-oss-120b"}
{"timestamp": "2025-10-22T03:29:10.564619", "feed": "arxiv_cslg", "title": "Optimality and NP-Hardness of Transformers in Learning Markovian Dynamical Functions", "link": "https://papers.cool/arxiv/2510.18638", "analysis": {"summary": "The paper studies how single‑layer linear self‑attention transformers learn Markovian dynamical functions in an in‑context learning setting. It derives a closed‑form global minimizer, shows that recovering exact transformer parameters that achieve this optimum is NP‑hard, and interprets multilayer LSA as a preconditioned gradient‑descent optimizer for multiple objectives. Empirical experiments on simplified transformers validate the theoretical predictions.", "summary_cn": "本文研究单层线性自注意力 Transformer 在上下文学习设置中学习马尔可夫动力学函数的能力。作者给出全局最小解的闭式表达式，证明在一般情况下恢复实现该最优解的 Transformer 参数是 NP‑hard，并将多层 LSA 解释为对多个目标进行预条件化梯度下降的优化器。通过简化的 Transformer 实验验证了理论结果。", "keywords": "transformers, in-context learning, linear self-attention, Markovian dynamics, NP-hardness, optimization landscape, gradient descent interpretation, theoretical analysis", "scoring": {"interpretability": 4, "understanding": 7, "safety": 2, "technicality": 8, "surprisal": 7}, "category": {"failure_mode_addressed": "non-applicable", "primary_focus": "interpretability"}, "authors": ["Yanna Ding", "Songtao Lu", "Yingdong Lu", "Tomasz Nowicki", "Jianxi Gao"]}, "usage": {"completion_tokens": 908, "prompt_tokens": 3392, "total_tokens": 4300, "completion_tokens_details": {"accepted_prediction_tokens": null, "audio_tokens": null, "reasoning_tokens": 792, "rejected_prediction_tokens": null, "image_tokens": 0}, "prompt_tokens_details": {"audio_tokens": 0, "cached_tokens": 3152}, "cost": 0.00074216, "is_byok": false, "cost_details": {"upstream_inference_cost": null, "upstream_inference_prompt_cost": 0.00028816, "upstream_inference_completions_cost": 0.000454}}, "model": "openai/gpt-oss-120b"}
{"timestamp": "2025-10-22T03:29:10.846576", "feed": "arxiv_cslg", "title": "Rewarding the Journey, Not Just the Destination: A Composite Path and Answer Self-Scoring Reward Mechanism for Test-Time Reinforcement Learning", "link": "https://papers.cool/arxiv/2510.17923", "analysis": {"summary": "The paper introduces COMPASS, a composite self-scoring reward mechanism for test-time reinforcement learning of large language models that operates without external supervision. COMPASS combines a Dual-Calibration Answer Reward to create trustworthy pseudo‑labels and a Decisive Path Reward to directly optimize the quality of reasoning chains, leading to consistent performance gains on diverse reasoning tasks.", "summary_cn": "本文提出了 COMPASS，一种在无外部监督下进行测试时强化学习的复合自评分奖励机制，专为大语言模型设计。COMPASS 通过双校准答案奖励（DCAR）生成可信的伪标签，并利用决定性路径奖励（DPR）直接优化推理链质量，从而在多种推理任务和模型上实现了显著且稳定的性能提升。", "keywords": "test-time reinforcement learning, self-scoring reward, composite reward, LLM reasoning, dual-calibration answer reward, decisive path reward, autonomous learning, RL without labels", "scoring": {"interpretability": 5, "understanding": 7, "safety": 4, "technicality": 7, "surprisal": 6}, "category": {"failure_mode_addressed": "non-applicable", "primary_focus": "alignment"}, "authors": ["Chenwei Tang", "Jingyu Xing", "Xinyu Liu", "Wei Ju", "Jiancheng Lv", "Deng Xiong", "Ziyue Qiao"]}, "usage": {"completion_tokens": 767, "prompt_tokens": 3477, "total_tokens": 4244, "completion_tokens_details": {"accepted_prediction_tokens": null, "audio_tokens": null, "reasoning_tokens": 584, "rejected_prediction_tokens": null, "image_tokens": 0}, "prompt_tokens_details": {"audio_tokens": 0, "cached_tokens": 0}, "cost": 0.00044588, "is_byok": false, "cost_details": {"upstream_inference_cost": null, "upstream_inference_prompt_cost": 0.00013908, "upstream_inference_completions_cost": 0.0003068}}, "model": "openai/gpt-oss-120b"}
{"timestamp": "2025-10-22T03:29:11.001520", "feed": "arxiv_cslg", "title": "Towards Identifiability of Hierarchical Temporal Causal Representation Learning", "link": "https://papers.cool/arxiv/2510.18310", "analysis": {"summary": "The paper introduces the Causally Hierarchical Latent Dynamic (CHiLD) framework, which establishes identifiability of multi‑layer latent variables in time‑series data using three conditionally independent observations and leverages sparsity to recover hierarchical causal dynamics. It presents theoretical guarantees, a variational inference‑based generative model with contextual encoders and flow‑based hierarchical priors, and validates the approach on synthetic and real‑world datasets.", "summary_cn": "本文提出因果层次潜在动态（CHiLD）框架，通过利用三个条件独立的观测以及层次结构的稀疏性，实现时间序列数据中多层潜在变量的唯一可识别性。文中给出理论保证，构建基于变分推断的生成模型，结合上下文编码器和基于流的层次先验，并在合成及真实数据集上验证了方法的有效性。", "keywords": "hierarchical latent dynamics, causal representation learning, identifiability, temporal causal models, variational inference, flow-based prior, CHiLD, multi-layer latent variables", "scoring": {"interpretability": 6, "understanding": 7, "safety": 3, "technicality": 8, "surprisal": 7}, "category": {"failure_mode_addressed": "non-applicable", "primary_focus": "interpretability"}, "authors": ["Zijian Li", "Minghao Fu", "Junxian Huang", "Yifan Shen", "Ruichu Cai", "Yuewen Sun", "Guangyi Chen", "Kun Zhang"]}, "usage": {"completion_tokens": 958, "prompt_tokens": 3419, "total_tokens": 4377, "completion_tokens_details": {"accepted_prediction_tokens": null, "audio_tokens": null, "reasoning_tokens": 822, "rejected_prediction_tokens": null, "image_tokens": 0}, "prompt_tokens_details": {"audio_tokens": 0, "cached_tokens": 3152}, "cost": 0.00077121, "is_byok": false, "cost_details": {"upstream_inference_cost": null, "upstream_inference_prompt_cost": 0.00029221, "upstream_inference_completions_cost": 0.000479}}, "model": "openai/gpt-oss-120b"}
{"timestamp": "2025-10-22T03:29:11.416899", "feed": "arxiv_cslg", "title": "Cross-Domain Long-Term Forecasting: Radiation Dose from Sparse Neutron Sensor via Spatio-Temporal Operator Network", "link": "https://papers.cool/arxiv/2510.18041", "analysis": {"summary": "The paper presents a Spatio‑Temporal Operator Network (STONe) that learns a non‑autoregressive mapping from sparse ground‑based neutron sensor data to high‑altitude radiation dose fields, enabling accurate 180‑day forecasts with millisecond inference speed. It tackles cross‑domain, long‑term forecasting challenges in scientific‑machine‑learning contexts, showing that operator learning can work without domain alignment or recurrent propagation. The work is evaluated on 23 years of global neutron measurements and demonstrates applicability to broader physical, climate and energy systems.", "summary_cn": "本文提出一种跨域长时序预测模型 STONe，利用稀疏地面中子传感器数据直接预测高空辐射剂量场，实现 180 天的精准预报并具备毫秒级推理速度。该方法解决了科学机器学习中跨域、长时序预测的难题，突破了传统算子学习需域对齐或递归的限制。利用 23 年全球中子数据进行实验，展示了在物理、气候和能源系统中的广泛适用性。", "keywords": "cross-domain forecasting, neural operator, spatio-temporal modeling, radiation dose prediction, sparse sensors, long-term prediction, scientific machine learning, STONe", "scoring": {"interpretability": 3, "understanding": 6, "safety": 3, "technicality": 7, "surprisal": 6}, "category": {"failure_mode_addressed": "non-applicable", "primary_focus": "other"}, "authors": ["Jay Phil Yoo", "Kazuma Kobayashi", "Souvik Chakraborty", "Syed Bahauddin Alam"]}, "usage": {"completion_tokens": 315, "prompt_tokens": 3429, "total_tokens": 3744, "completion_tokens_details": {"accepted_prediction_tokens": null, "audio_tokens": null, "reasoning_tokens": 0, "rejected_prediction_tokens": null, "image_tokens": 0}, "prompt_tokens_details": {"audio_tokens": 0, "cached_tokens": 0}, "cost": 0.0003132, "is_byok": false, "cost_details": {"upstream_inference_cost": null, "upstream_inference_prompt_cost": 0.00017145, "upstream_inference_completions_cost": 0.00014175}}, "model": "openai/gpt-oss-120b"}
{"timestamp": "2025-10-22T03:29:11.909498", "feed": "arxiv_cslg", "title": "Efficient Long-context Language Model Training by Core Attention Disaggregation", "link": "https://papers.cool/arxiv/2510.18121", "analysis": {"summary": "The paper introduces Core Attention Disaggregation (CAD), a method that separates the stateless core attention computation from the rest of a large language model and runs it on dedicated attention servers. By partitioning attention into token-level tasks and dynamically rebatching them, CAD balances compute across devices, reduces stragglers, and improves training throughput up to 1.35× on 512 GPUs with context lengths up to 512k tokens.", "summary_cn": "本文提出核心注意力解耦（CAD）技术，将无状态的核心注意力计算从模型主体中分离并在专用注意力服务器上执行。通过将注意力分割为基于 token 的任务并动态重批，CAD 实现了计算负载平衡，消除数据和流水线并行的瓶颈，在 512 张 GPU、上下文长度达 512k Token 的情况下提升训练吞吐量至最高 1.35 倍。", "keywords": "long-context, language model, attention disaggregation, core attention, distributed training, compute balancing, pipeline parallelism, DistCA, efficiency, scaling", "scoring": {"interpretability": 2, "understanding": 6, "safety": 3, "technicality": 8, "surprisal": 7}, "category": {"failure_mode_addressed": "non-applicable", "primary_focus": "other"}, "authors": ["Yonghao Zhuang", "Junda Chen", "Bo Pang", "Yi Gu", "Yibo Zhu", "Yimin Jiang", "Ion Stoica", "Eric Xing", "Hao Zhang"]}, "usage": {"completion_tokens": 698, "prompt_tokens": 3466, "total_tokens": 4164, "completion_tokens_details": {"accepted_prediction_tokens": null, "audio_tokens": null, "reasoning_tokens": 497, "rejected_prediction_tokens": null, "image_tokens": 0}, "prompt_tokens_details": {"audio_tokens": 0, "cached_tokens": 3152}, "cost": 0.00064826, "is_byok": false, "cost_details": {"upstream_inference_cost": null, "upstream_inference_prompt_cost": 0.00029926, "upstream_inference_completions_cost": 0.000349}}, "model": "openai/gpt-oss-120b"}
{"timestamp": "2025-10-22T03:29:11.956645", "feed": "arxiv_cslg", "title": "Towards Fast LLM Fine-tuning through Zeroth-Order Optimization with Projected Gradient-Aligned Perturbations", "link": "https://papers.cool/arxiv/2510.18228", "analysis": {"summary": "The paper introduces P-GAP, a zeroth-order optimization method for fast fine-tuning of large language models that aligns perturbations with projected gradients in a low-dimensional space, reducing variance and the number of perturbed parameters. Experiments show that P-GAP achieves higher accuracy on classification and generation tasks while requiring significantly fewer training iterations and GPU hours compared to existing baselines.", "summary_cn": "本文提出了 P-GAP，一种用于快速微调大语言模型的零阶优化方法，通过在低维空间中对齐投影梯度方向的扰动，从而降低梯度估计方差并减少扰动参数数量。实验表明，P-GAP 在分类和生成任务上均提升了准确率，同时相较于现有基线显著减少了训练迭代次数和 GPU 计算时间。", "keywords": "zeroth-order optimization, projected gradient-aligned perturbations, LLM fine-tuning, resource-efficient training, gradient variance reduction, P-GAP", "scoring": {"interpretability": 2, "understanding": 5, "safety": 2, "technicality": 8, "surprisal": 6}, "category": {"failure_mode_addressed": "non-applicable", "primary_focus": "other"}, "authors": ["Zhendong Mi", "Qitao Tan", "Grace Li Zhang", "Zhaozhuo Xu", "Geng Yuan", "Shaoyi Huang"]}, "usage": {"completion_tokens": 666, "prompt_tokens": 4045, "total_tokens": 4711, "completion_tokens_details": {"accepted_prediction_tokens": null, "audio_tokens": null, "reasoning_tokens": 365, "rejected_prediction_tokens": null, "image_tokens": 0}, "prompt_tokens_details": {"audio_tokens": 0, "cached_tokens": 0}, "cost": 0.00036875, "is_byok": false, "cost_details": {"upstream_inference_cost": null, "upstream_inference_prompt_cost": 0.00020225, "upstream_inference_completions_cost": 0.0001665}}, "model": "openai/gpt-oss-120b"}
{"timestamp": "2025-10-22T03:29:12.337965", "feed": "arxiv_cslg", "title": "UniRL-Zero: Reinforcement Learning on Unified Models with Joint Language Model and Diffusion Model Experts", "link": "https://papers.cool/arxiv/2510.17937", "analysis": {"summary": "UniRL-Zero introduces a reinforcement learning framework that jointly trains language model and diffusion model experts within a unified multimodal architecture, enabling improved understanding, reasoning, and multimedia generation. The paper defines six RL scenarios for such unified models and provides baseline experiments demonstrating the benefits of integrated policy learning across language and visual generation tasks.", "summary_cn": "UniRL-Zero 提出一种强化学习框架，在统一的多模态模型中联合训练语言模型和扩散模型专家，从而提升理解、推理以及多媒体生成能力。论文定义了六种统一模型的强化学习场景，并提供基准实验，展示了跨语言与视觉生成任务的综合策略学习优势。", "keywords": "unified model, reinforcement learning, multimodal, language model, diffusion model, joint training", "scoring": {"interpretability": 3, "understanding": 6, "safety": 2, "technicality": 7, "surprisal": 6}, "category": {"failure_mode_addressed": "non-applicable", "primary_focus": "other"}, "authors": ["Fu-Yun Wang", "Han Zhang", "Michael Gharbi", "Hongsheng Li", "Taesung Park"]}, "usage": {"completion_tokens": 542, "prompt_tokens": 3279, "total_tokens": 3821, "completion_tokens_details": {"accepted_prediction_tokens": null, "audio_tokens": null, "reasoning_tokens": 348, "rejected_prediction_tokens": null, "image_tokens": 0}, "prompt_tokens_details": {"audio_tokens": 0, "cached_tokens": 0}, "cost": 0.00040785, "is_byok": false, "cost_details": {"upstream_inference_cost": null, "upstream_inference_prompt_cost": 0.00016395, "upstream_inference_completions_cost": 0.0002439}}, "model": "openai/gpt-oss-120b"}
{"timestamp": "2025-10-22T03:29:12.518821", "feed": "arxiv_cslg", "title": "Attention-Guided Deep Adversarial Temporal Subspace Clustering (A-DATSC) Model for multivariate spatiotemporal data", "link": "https://papers.cool/arxiv/2510.18004", "analysis": {"summary": "The paper introduces A-DATSC, an Attention-Guided Deep Adversarial Temporal Subspace Clustering model that combines a U-Net‑style generator with ConvLSTM2D layers and a graph‑attention transformer self‑expressive network to better capture local and global spatiotemporal dependencies in multivariate data, and uses an adversarial discriminator to verify clustering quality, achieving state‑of‑the‑art results on three real‑world datasets.", "summary_cn": "本文提出 A-DATSC 模型，通过 U‑Net 结构的生成器融合 ConvLSTM2D 层以及基于图注意力变换器的自表达网络，捕获多变量时空数据的局部空间关系和全局长短程依赖，并采用对抗式判别器验证聚类质量，在三个真实数据集上实现了领先的聚类性能。", "keywords": "subspace clustering, attention transformer, ConvLSTM, adversarial learning, spatiotemporal data, graph attention, self-expressive network", "scoring": {"interpretability": 2, "understanding": 6, "safety": 1, "technicality": 8, "surprisal": 7}, "category": {"failure_mode_addressed": "non-applicable", "primary_focus": "other"}, "authors": ["Francis Ndikum Nji", "Vandana Janeja", "Jianwu Wang"]}, "usage": {"completion_tokens": 602, "prompt_tokens": 3486, "total_tokens": 4088, "completion_tokens_details": {"accepted_prediction_tokens": null, "audio_tokens": null, "reasoning_tokens": 334, "rejected_prediction_tokens": null, "image_tokens": 0}, "prompt_tokens_details": {"audio_tokens": 0, "cached_tokens": 0}, "cost": 0.0004452, "is_byok": false, "cost_details": {"upstream_inference_cost": null, "upstream_inference_prompt_cost": 0.0001743, "upstream_inference_completions_cost": 0.0002709}}, "model": "openai/gpt-oss-120b"}
{"timestamp": "2025-10-22T03:29:12.975638", "feed": "arxiv_cslg", "title": "HyperDiffusionFields (HyDiF): Diffusion-Guided Hypernetworks for Learning Implicit Molecular Neural Fields", "link": "https://papers.cool/arxiv/2510.18122", "analysis": {"summary": "The paper introduces HyperDiffusionFields (HyDiF), a framework that represents 3D molecular conformers as continuous vector fields (Molecular Directional Fields) modeled by molecule-specific neural implicit fields generated by a hypernetwork. The hypernetwork is trained as a denoising diffusion model, enabling generation of molecular fields and supporting tasks such as molecular inpainting and property prediction. Experiments show the method scales to larger biomolecules and provides fine-grained spatial features beyond traditional graph or point‑cloud approaches.", "summary_cn": "本文提出 HyperDiffusionFields（HyDiF）框架，将三维分子构象表示为连续的向量场（分子方向场），通过分子特定的隐式神经场（MNF）实现，且这些隐式神经场的权重由一个以分子为条件的超网络生成。该超网络以去噪扩散模型方式训练，使得能够在函数空间中采样分子场，并支持诸如分子填补的结构条件生成以及细粒度的分子属性预测。实验表明该方法能够扩展到更大的生物分子，并提供比传统图或点云方法更精细的空间特征。", "keywords": "diffusion models, hypernetworks, implicit neural fields, molecular directional field, molecular neural fields, generative modeling, molecular property prediction, 3D conformer modeling", "scoring": {"interpretability": 3, "understanding": 5, "safety": 2, "technicality": 8, "surprisal": 7}, "category": {"failure_mode_addressed": "non-applicable", "primary_focus": "other"}, "authors": ["Sudarshan Babu", "Phillip Lo", "Xiao Zhang", "Aadi Srivastava", "Ali Davariashtiyani", "Jason Perera", "Michael Maire", "Aly A. Khan"]}, "usage": {"completion_tokens": 761, "prompt_tokens": 3450, "total_tokens": 4211, "completion_tokens_details": {"accepted_prediction_tokens": null, "audio_tokens": null, "reasoning_tokens": 477, "rejected_prediction_tokens": null, "image_tokens": 0}, "prompt_tokens_details": {"audio_tokens": 0, "cached_tokens": 3152}, "cost": 0.00067736, "is_byok": false, "cost_details": {"upstream_inference_cost": null, "upstream_inference_prompt_cost": 0.00029686, "upstream_inference_completions_cost": 0.0003805}}, "model": "openai/gpt-oss-120b"}
{"timestamp": "2025-10-22T03:29:13.488669", "feed": "arxiv_cslg", "title": "Demystifying Transition Matching: When and Why It Can Beat Flow Matching", "link": "https://papers.cool/arxiv/2510.17991", "analysis": {"summary": "The paper analyzes when Transition Matching (TM) outperforms Flow Matching (FM) in generative sampling, proving that TM yields lower KL divergence for unimodal Gaussian targets and faster convergence under a fixed compute budget. It extends the theory to Gaussian mixtures, showing TM benefits in regimes with well‑separated modes and non‑negligible variance, and validates the findings with experiments on synthetic and real image/video data.", "summary_cn": "本文研究了何时以及为何过渡匹配（TM）在生成式采样中优于流匹配（FM），并证明在单峰高斯目标下 TM 能获得更低的 KL 散度并在固定计算预算下收敛更快。进一步将分析推广至高斯混合模型，指出在模式分离充分且方差不趋于零的情形下 TM 具有优势，并通过合成高斯分布及真实图像/视频生成实验进行验证。", "keywords": "transition matching, flow matching, generative models, KL divergence, Gaussian mixture, sampling dynamics, convergence analysis, unimodal Gaussian", "scoring": {"interpretability": 2, "understanding": 7, "safety": 2, "technicality": 8, "surprisal": 6}, "category": {"failure_mode_addressed": "non-applicable", "primary_focus": "other"}, "authors": ["Jaihoon Kim", "Rajarshi Saha", "Minhyuk Sung", "Youngsuk Park"]}, "usage": {"completion_tokens": 644, "prompt_tokens": 3463, "total_tokens": 4107, "completion_tokens_details": {"accepted_prediction_tokens": null, "audio_tokens": null, "reasoning_tokens": 407, "rejected_prediction_tokens": null, "image_tokens": 0}, "prompt_tokens_details": {"audio_tokens": 0, "cached_tokens": 0}, "cost": 0.00046295, "is_byok": false, "cost_details": {"upstream_inference_cost": null, "upstream_inference_prompt_cost": 0.00017315, "upstream_inference_completions_cost": 0.0002898}}, "model": "openai/gpt-oss-120b"}
{"timestamp": "2025-10-22T03:29:13.547468", "feed": "arxiv_cslg", "title": "Gradient Variance Reveals Failure Modes in Flow-Based Generative Models", "link": "https://papers.cool/arxiv/2510.18118", "analysis": {"summary": "The paper shows that the straight‑path objective of Rectified Flow models hides a fundamental failure mode: under deterministic training, low gradient variance causes the model to memorize arbitrary training pairings, even when interpolating lines intersect. By analyzing Gaussian‑to‑Gaussian transport and proving the existence of a memorizing vector field, the authors demonstrate that deterministic integration at inference reproduces these exact pairings, while adding small noise restores generalization, as confirmed on CelebA.", "summary_cn": "本文指出，Rectified Flow 的直线路径目标在确定性训练下会导致梯度方差低，从而使模型记忆任意的训练配对，即便插值直线相交。通过对高斯到高斯传输的理论分析与证明记忆向量场的存在，作者展示了确定性积分在推理时会精确复制训练配对，而加入微小噪声则能恢复模型的泛化能力，实验证明了该现象（以 CelebA 数据集为例）。", "keywords": "flow-based generative models, rectified flows, gradient variance, memorization, deterministic training, ODE vector fields, generalization, stochastic training, CelebA, failure modes", "scoring": {"interpretability": 6, "understanding": 7, "safety": 5, "technicality": 8, "surprisal": 7}, "category": {"failure_mode_addressed": "other", "primary_focus": "robustness"}, "authors": ["Teodora Reu", "Sixtine Dromigny", "Michael Bronstein", "Francisco Vargas"]}, "usage": {"completion_tokens": 779, "prompt_tokens": 3398, "total_tokens": 4177, "completion_tokens_details": {"accepted_prediction_tokens": null, "audio_tokens": null, "reasoning_tokens": 550, "rejected_prediction_tokens": null, "image_tokens": 0}, "prompt_tokens_details": {"audio_tokens": 0, "cached_tokens": 3152}, "cost": 0.00067856, "is_byok": false, "cost_details": {"upstream_inference_cost": null, "upstream_inference_prompt_cost": 0.00028906, "upstream_inference_completions_cost": 0.0003895}}, "model": "openai/gpt-oss-120b"}
{"timestamp": "2025-10-22T03:29:15.005340", "feed": "arxiv_cslg", "title": "Retaining by Doing: The Role of On-Policy Data in Mitigating Forgetting", "link": "https://papers.cool/arxiv/2510.18874", "analysis": {"summary": "The paper compares catastrophic forgetting in language models when fine‑tuned with supervised learning versus reinforcement learning, finding that RL with on‑policy data preserves prior knowledge better while achieving strong task performance. A simple mixture‑of‑distributions analysis shows the mode‑seeking nature of RL as the cause, and experiments confirm that on‑policy data—not KL regularization or advantage estimation—drives reduced forgetting. The authors suggest that (approximate) on‑policy data can be an efficient practical tool for mitigating forgetting during post‑training.", "summary_cn": "本文比较了在语言模型的后训练阶段使用监督微调（SFT）与强化学习（RL）时出现的灾难性遗忘现象，发现使用 RL 并利用 on‑policy 数据能够更好地保留已有知识，同时实现较高的目标任务性能。通过一个简化的混合分布模型，作者解释了 RL 的模式寻找特性是降低遗忘的根本原因，并通过实验证明，on‑policy 数据而非 KL 正则或优势估计是实现鲁棒性的关键。最后指出，获取（近似）on‑policy 数据是一种高效的实用手段，可用于缓解后训练过程中的遗忘。", "keywords": "catastrophic forgetting, reinforcement learning, supervised fine-tuning, on-policy data, language models, continual learning, mixture model, retention, KL regularization, advantage estimation", "scoring": {"interpretability": 3, "understanding": 7, "safety": 3, "technicality": 7, "surprisal": 6}, "category": {"failure_mode_addressed": "other", "primary_focus": "robustness"}, "authors": ["Howard Chen", "Noam Razin", "Karthik Narasimhan", "Danqi Chen"]}, "usage": {"completion_tokens": 1067, "prompt_tokens": 3461, "total_tokens": 4528, "completion_tokens_details": {"accepted_prediction_tokens": null, "audio_tokens": null, "reasoning_tokens": 854, "rejected_prediction_tokens": null, "image_tokens": 0}, "prompt_tokens_details": {"audio_tokens": 0, "cached_tokens": 3456}, "cost": 0.00081073, "is_byok": false, "cost_details": {"upstream_inference_cost": null, "upstream_inference_prompt_cost": 0.00027723, "upstream_inference_completions_cost": 0.0005335}}, "model": "openai/gpt-oss-120b"}
{"timestamp": "2025-10-22T03:29:15.340112", "feed": "arxiv_cslg", "title": "MEG-GPT: A transformer-based foundation model for magnetoencephalography data", "link": "https://papers.cool/arxiv/2510.18080", "analysis": {"summary": "The paper introduces MEG-GPT, a transformer‑based foundation model for magnetoencephalography (MEG) data that uses a novel continuous‑tokenizer and next‑time‑point prediction. Trained on a large eyes‑closed resting‑state dataset, the model can generate realistic spatio‑spectral MEG signals and improves zero‑shot and fine‑tuned decoding performance across sessions and subjects. The work demonstrates the potential of large‑scale foundation models for electrophysiological data and neural decoding applications.", "summary_cn": "本文提出 MEG‑GPT，一种基于 Transformer 的磁共振脑电图（MEG）基础模型，采用新颖的连续数据分词器和下一个时间点预测任务。在大规模闭眼静息数据上进行训练后，模型能够生成具有真实时空频谱特性的 MEG 信号，并在跨会话、跨受试者的解码任务中显著提升零样本以及微调后的准确率。该工作展示了大规模基础模型在电生理数据和神经解码中的潜力。", "keywords": "MEG, transformer, foundation model, time-attention, neural decoding, tokenization, cross-subject generalization, brain dynamics", "scoring": {"interpretability": 3, "understanding": 3, "safety": 1, "technicality": 7, "surprisal": 6}, "category": {"failure_mode_addressed": "non-applicable", "primary_focus": "other"}, "authors": ["Rukuang Huang", "Sungjun Cho", "Chetan Gohil", "Oiwi Parker Jones", "Mark Woolrich"]}, "usage": {"completion_tokens": 638, "prompt_tokens": 3499, "total_tokens": 4137, "completion_tokens_details": {"accepted_prediction_tokens": null, "audio_tokens": null, "reasoning_tokens": 327, "rejected_prediction_tokens": null, "image_tokens": 0}, "prompt_tokens_details": {"audio_tokens": 0, "cached_tokens": 3152}, "cost": 0.00062321, "is_byok": false, "cost_details": {"upstream_inference_cost": null, "upstream_inference_prompt_cost": 0.00030421, "upstream_inference_completions_cost": 0.000319}}, "model": "openai/gpt-oss-120b"}
{"timestamp": "2025-10-22T03:29:15.383793", "feed": "arxiv_cslg", "title": "Binary Quadratic Quantization: Beyond First-Order Quantization for Real-Valued Matrix Compression", "link": "https://papers.cool/arxiv/2510.18650", "analysis": {"summary": "The paper introduces Binary Quadratic Quantization (BQQ), a novel matrix compression technique that extends beyond first‑order linear quantization by using binary quadratic expressions while keeping a highly compact representation. Experiments on a matrix‑compression benchmark and post‑training quantization of Vision‑Transformer models show that BQQ achieves a better memory‑error trade‑off and improves PTQ performance, outperforming state‑of‑the‑art methods by up to 2.2% (calibration‑based) and 59.1% (data‑free) at an effective 2‑bit precision.", "summary_cn": "本文提出二元二次量化（Binary Quadratic Quantization，BQQ）方法，利用二元二次表达式在保持极度紧凑数据格式的同时，超越传统的一阶线性量化，实现对实值矩阵的高效压缩。通过矩阵压缩基准测试以及对预训练 Vision Transformer 模型的后训练量化实验，BQQ 展现出更优的记忆‑误差折中，并在等价 2 位量化下相较于最先进的 PTQ 方法分别提升 2.2%（校准）和 59.1%（无数据） 的性能，显示出二元二次表达式在高效矩阵近似与网络压缩中的惊人效果。", "keywords": "binary quadratic quantization, matrix compression, post-training quantization, Vision Transformer, low-bit quantization, binary coding, neural network compression", "scoring": {"interpretability": 2, "understanding": 5, "safety": 3, "technicality": 7, "surprisal": 7}, "category": {"failure_mode_addressed": "non-applicable", "primary_focus": "other"}, "authors": ["Kyo Kuroki", "Yasuyuki Okoshi", "Thiem Van Chu", "Kazushi Kawamura", "Masato Motomura"]}, "usage": {"completion_tokens": 677, "prompt_tokens": 3434, "total_tokens": 4111, "completion_tokens_details": {"accepted_prediction_tokens": null, "audio_tokens": null, "reasoning_tokens": 407, "rejected_prediction_tokens": null, "image_tokens": 0}, "prompt_tokens_details": {"audio_tokens": 0, "cached_tokens": 0}, "cost": 0.00040816, "is_byok": false, "cost_details": {"upstream_inference_cost": null, "upstream_inference_prompt_cost": 0.00013736, "upstream_inference_completions_cost": 0.0002708}}, "model": "openai/gpt-oss-120b"}
{"timestamp": "2025-10-22T03:29:15.952418", "feed": "arxiv_cslg", "title": "Data Unlearning Beyond Uniform Forgetting via Diffusion Time and Frequency Selection", "link": "https://papers.cool/arxiv/2510.17917", "analysis": {"summary": "The paper studies data unlearning in diffusion models and shows that forgetting varies across diffusion timesteps and frequency bands. By selectively targeting specific time‑frequency ranges during unlearning, the authors improve generation quality while effectively removing targeted training samples. They also introduce a normalized SSCD metric to evaluate both deletion effectiveness and sample quality.", "summary_cn": "本文研究扩散模型中的数据删除，发现遗忘在不同扩散时间步和频率范围上表现不均匀。通过在训练时仅针对特定时间‑频率范围进行删除，提升了生成质量并有效去除目标训练样本。作者还提出了一种归一化的 SSCD 指标，用于同时评估删除效果和样本质量。", "keywords": "data unlearning, diffusion models, time-frequency selection, privacy, model forgetting, SSCD, gradient-based unlearning, preference optimization", "scoring": {"interpretability": 3, "understanding": 7, "safety": 5, "technicality": 7, "surprisal": 6}, "category": {"failure_mode_addressed": "other", "primary_focus": "control"}, "authors": ["Jinseong Park", "Mijung Park"]}, "usage": {"completion_tokens": 879, "prompt_tokens": 3403, "total_tokens": 4282, "completion_tokens_details": {"accepted_prediction_tokens": null, "audio_tokens": null, "reasoning_tokens": 744, "rejected_prediction_tokens": null, "image_tokens": 0}, "prompt_tokens_details": {"audio_tokens": 0, "cached_tokens": 0}, "cost": 0.00048772, "is_byok": false, "cost_details": {"upstream_inference_cost": null, "upstream_inference_prompt_cost": 0.00013612, "upstream_inference_completions_cost": 0.0003516}}, "model": "openai/gpt-oss-120b"}
{"timestamp": "2025-10-22T03:29:16.084391", "feed": "arxiv_cslg", "title": "ε-Seg: Sparsely Supervised Semantic Segmentation of Microscopy Data", "link": "https://papers.cool/arxiv/2510.18637", "analysis": {"summary": "ε‑Seg introduces a hierarchical variational autoencoder framework with center‑region masking, contrastive learning and a Gaussian‑mixture‑model prior to achieve semantic segmentation of electron‑microscopy images using extremely sparse labels. The method learns robust latent embeddings and directly predicts class labels with an MLP head, demonstrating competitive performance on dense EM and fluorescence microscopy datasets.", "summary_cn": "ε‑Seg 利用层级变分自编码器、中心区域掩码、对比学习和高斯混合模型先验，在极少标注（0.05%）下实现电子显微镜图像的语义分割。该方法通过学习稳健的潜在嵌入并使用 MLP 头直接预测类别，在密集 EM 数据集和荧光显微数据上表现出竞争力。", "keywords": "semantic segmentation, electron microscopy, hierarchical variational autoencoder, contrastive learning, sparse supervision", "scoring": {"interpretability": 6, "understanding": 6, "safety": 2, "technicality": 7, "surprisal": 5}, "category": {"failure_mode_addressed": "non-applicable", "primary_focus": "interpretability"}, "authors": ["Sheida Rahnamai Kordasiabi", "Damian Dalle Nogare", "Florian Jug"]}, "usage": {"completion_tokens": 243, "prompt_tokens": 3466, "total_tokens": 3709, "completion_tokens_details": {"accepted_prediction_tokens": null, "audio_tokens": null, "reasoning_tokens": 0, "rejected_prediction_tokens": null, "image_tokens": 0}, "prompt_tokens_details": {"audio_tokens": 0, "cached_tokens": 0}, "cost": 0.00028265, "is_byok": false, "cost_details": {"upstream_inference_cost": null, "upstream_inference_prompt_cost": 0.0001733, "upstream_inference_completions_cost": 0.00010935}}, "model": "openai/gpt-oss-120b"}
{"timestamp": "2025-10-22T03:29:17.281673", "feed": "arxiv_cslg", "title": "Adaptive Divergence Regularized Policy Optimization for Fine-tuning Generative Models", "link": "https://papers.cool/arxiv/2510.18053", "analysis": {"summary": "The paper introduces Adaptive Divergence Regularized Policy Optimization (ADRPO), which dynamically adjusts divergence regularization strength based on advantage estimates, allowing fine‑tuning of generative models to balance exploration and exploitation. ADRPO, instantiated with Wasserstein‑2 regularization for diffusion models and KL regularization for LLMs, achieves superior semantic alignment, diversity, and compositional control compared to fixed‑regularization baselines across text‑to‑image, language, and audio‑reasoning tasks. The method also mitigates reward‑hacking and instability, enabling smaller models to outperform much larger commercial systems.", "summary_cn": "本文提出自适应散度正则化策略优化（ADRPO），通过依据优势估计动态调节散度正则化强度，实现生成模型微调过程中的探索与利用平衡。该方法在文本到图像、语言模型以及音频推理等多模态任务中，使用 Wasserstein‑2 或 KL 正则化，实现了比固定正则化基线更好的语义对齐、多样性和组合控制，并减轻了奖励黑客和训练不稳定的问题，使得较小模型能够超越更大商业模型。", "keywords": "adaptive regularization, policy optimization, reinforcement learning fine-tuning, generative models, Wasserstein-2, KL regularization, exploration-exploitation, text-to-image, large language models, reward hacking mitigation", "scoring": {"interpretability": 2, "understanding": 6, "safety": 5, "technicality": 8, "surprisal": 7}, "category": {"failure_mode_addressed": "misalignment", "primary_focus": "alignment"}, "authors": ["Jiajun Fan", "Tong Wei", "Chaoran Cheng", "Yuxin Chen", "Ge Liu"]}, "usage": {"completion_tokens": 749, "prompt_tokens": 3528, "total_tokens": 4277, "completion_tokens_details": {"accepted_prediction_tokens": null, "audio_tokens": null, "reasoning_tokens": 455, "rejected_prediction_tokens": null, "image_tokens": 0}, "prompt_tokens_details": {"audio_tokens": 0, "cached_tokens": 3152}, "cost": 0.00068306, "is_byok": false, "cost_details": {"upstream_inference_cost": null, "upstream_inference_prompt_cost": 0.00030856, "upstream_inference_completions_cost": 0.0003745}}, "model": "openai/gpt-oss-120b"}
{"timestamp": "2025-10-22T03:29:17.540733", "feed": "arxiv_cslg", "title": "Provably Optimal Reinforcement Learning under Safety Filtering", "link": "https://papers.cool/arxiv/2510.18082", "analysis": {"summary": "The paper introduces a formal safety-critical MDP framework and proves that training reinforcement‑learning agents with a sufficiently permissive safety filter retains asymptotic optimality, eliminating the perceived safety‑performance trade‑off. It shows that learning in the filtered MDP is categorically safe, that standard RL convergence results apply, and that optimal policies in the filtered MDP achieve the same return as the best safe policy in the original problem. Empirical validation on Safety Gymnasium demonstrates zero safety violations during training while matching or exceeding the performance of unfiltered baselines.", "summary_cn": "本文提出了安全关键马尔可夫决策过程（SC‑MDP）框架，并证明在使用足够宽松的安全过滤器进行强化学习训练时，仍能保持渐近最优性，从而消除安全‑性能权衡的误解。研究表明，在过滤后的 MDP 中学习可以确保类别性安全，标准的强化学习收敛性同样适用，并且在相同过滤器下的最优策略能够达到原始 SC‑MDP 中最佳安全策略的回报。实验在 Safety Gymnasium 上验证了训练期间零违规，同时最终性能与或超过未过滤的基线。", "keywords": "safe reinforcement learning, safety filtering, SC-MDP, provable optimality, control, RL convergence, safety-critical MDP, zero-violation training, performance guarantees", "scoring": {"interpretability": 2, "understanding": 7, "safety": 9, "technicality": 8, "surprisal": 7}, "category": {"failure_mode_addressed": "misalignment", "primary_focus": "control"}, "authors": ["Donggeon David Oh", "Duy P. Nguyen", "Haimin Hu", "Jaime F. Fisac"]}, "usage": {"completion_tokens": 787, "prompt_tokens": 3527, "total_tokens": 4314, "completion_tokens_details": {"accepted_prediction_tokens": null, "audio_tokens": null, "reasoning_tokens": 502, "rejected_prediction_tokens": null, "image_tokens": 0}, "prompt_tokens_details": {"audio_tokens": 0, "cached_tokens": 3152}, "cost": 0.00070191, "is_byok": false, "cost_details": {"upstream_inference_cost": null, "upstream_inference_prompt_cost": 0.00030841, "upstream_inference_completions_cost": 0.0003935}}, "model": "openai/gpt-oss-120b"}
{"timestamp": "2025-10-22T03:29:18.152039", "feed": "arxiv_cslg", "title": "On Biologically Plausible Learning in Continuous Time", "link": "https://papers.cool/arxiv/2510.18808", "analysis": {"summary": "The paper introduces a continuous‑time neural model that unifies several biologically plausible learning rules (SGD, FA, DFA, KP) and eliminates the need for separate inference and learning phases. Through analysis and simulations it shows that successful learning requires temporal overlap between inputs and error signals, predicting that synaptic plasticity windows must be orders of magnitude longer than stimulus durations. This leads to a testable prediction that seconds‑scale eligibility traces are necessary for error‑driven learning in cortical circuits.", "summary_cn": "本文提出一种连续时间神经模型，统一了多种生物学上可行的学习规则（如 SGD、反馈对齐（FA）、直接反馈对齐（DFA）和 Kolen‑Pollack（KP）），并消除了推理与学习阶段的分离。通过理论分析和仿真研究，展示了学习成功依赖于输入与误差信号的时间重叠，预测突触可塑性窗口必须比刺激持续时间长若干数量级。该模型提出了可检验的预言：在皮层电路中，错误驱动学习需要秒级的资格迹（eligibility traces）。", "keywords": "continuous-time learning, biologically plausible learning, eligibility traces, feedback alignment, stochastic gradient descent, Kolen-Pollack, synaptic plasticity, temporal overlap, neural dynamics, error-driven learning", "scoring": {"interpretability": 2, "understanding": 6, "safety": 2, "technicality": 7, "surprisal": 6}, "category": {"failure_mode_addressed": "non-applicable", "primary_focus": "other"}, "authors": ["Marc Gong Bacvanski", "Liu Ziyin", "Tomaso Poggio"]}, "usage": {"completion_tokens": 804, "prompt_tokens": 3433, "total_tokens": 4237, "completion_tokens_details": {"accepted_prediction_tokens": null, "audio_tokens": null, "reasoning_tokens": 562, "rejected_prediction_tokens": null, "image_tokens": 0}, "prompt_tokens_details": {"audio_tokens": 0, "cached_tokens": 3152}, "cost": 0.00069631, "is_byok": false, "cost_details": {"upstream_inference_cost": null, "upstream_inference_prompt_cost": 0.00029431, "upstream_inference_completions_cost": 0.000402}}, "model": "openai/gpt-oss-120b"}
{"timestamp": "2025-10-22T03:29:18.159796", "feed": "arxiv_cslg", "title": "Batch Distillation Data for Developing Machine Learning Anomaly Detection Methods", "link": "https://papers.cool/arxiv/2510.18075", "analysis": {"summary": "The paper introduces a publicly available, laboratory‑scale batch distillation dataset containing 119 experiments with both fault‑free and intentionally induced anomalies. The data include multivariate time‑series sensor readings, online NMR concentration profiles, video, audio, uncertainty estimates, extensive metadata, and expert annotations based on a newly developed anomaly ontology. This resource is intended to facilitate the development and evaluation of advanced machine‑learning‑based anomaly detection, interpretability, and mitigation methods for chemical processes.", "summary_cn": "本文发布了一个公开的实验室规模批式蒸馏数据集，包含119次实验的正常和人为诱导异常数据。数据集提供多传感器时间序列、在线核磁共振(NMR)浓度曲线、视频、音频、测量不确定性、丰富的元数据以及基于新建异常本体的专家标注。该资源旨在促进机器学习异常检测、可解释性以及异常缓解方法在化工过程中的研发与评估。", "keywords": "batch distillation, anomaly detection, dataset, chemical process, machine learning, time-series, NMR spectroscopy, interpretability, fault detection, process control", "scoring": {"interpretability": 5, "understanding": 6, "safety": 6, "technicality": 6, "surprisal": 5}, "category": {"failure_mode_addressed": "other", "primary_focus": "robustness"}, "authors": ["Justus Arweiler", "Indra Jungjohann", "Aparna Muraleedharan", "Heike Leitte", "Jakob Burger", "Kerstin Münnemann", "Fabian Jirasek", "Hans Hasse"]}, "usage": {"completion_tokens": 752, "prompt_tokens": 3460, "total_tokens": 4212, "completion_tokens_details": {"accepted_prediction_tokens": null, "audio_tokens": null, "reasoning_tokens": 529, "rejected_prediction_tokens": null, "image_tokens": 0}, "prompt_tokens_details": {"audio_tokens": 0, "cached_tokens": 3152}, "cost": 0.00067436, "is_byok": false, "cost_details": {"upstream_inference_cost": null, "upstream_inference_prompt_cost": 0.00029836, "upstream_inference_completions_cost": 0.000376}}, "model": "openai/gpt-oss-120b"}
{"timestamp": "2025-10-22T03:29:18.166944", "feed": "arxiv_cslg", "title": "Automated Algorithm Design for Auto-Tuning Optimizers", "link": "https://papers.cool/arxiv/2510.17899", "analysis": {"summary": "The paper proposes a framework that uses large language models (LLMs) to automatically generate optimization algorithms tailored for auto-tuning tasks, leveraging problem descriptions and search‑space characteristics as prompts. Empirical evaluation on four real‑world auto‑tuning applications across six hardware platforms shows that LLM‑generated optimizers can achieve up to 72.4% improvement over state‑of‑the‑art human‑designed methods.", "summary_cn": "本文提出一种利用大语言模型（LLM）自动生成针对自动调优任务的优化算法的框架，使用问题描述和搜索空间特征作为提示词。对四个真实应用和六个平台的实验表明，LLM 生成的优化器在性能上可比现有人工设计的方法提升最高达 72.4%。", "keywords": "auto-tuning, optimizer design, large language models, meta-optimization, performance tuning", "scoring": {"interpretability": 2, "understanding": 5, "safety": 2, "technicality": 7, "surprisal": 7}, "category": {"failure_mode_addressed": "non-applicable", "primary_focus": "other"}, "authors": ["Floris-Jan Willemsen", "Niki van Stein", "Ben van Werkhoven"]}, "usage": {"completion_tokens": 488, "prompt_tokens": 3461, "total_tokens": 3949, "completion_tokens_details": {"accepted_prediction_tokens": null, "audio_tokens": null, "reasoning_tokens": 244, "rejected_prediction_tokens": null, "image_tokens": 0}, "prompt_tokens_details": {"audio_tokens": 0, "cached_tokens": 3152}, "cost": 0.00054251, "is_byok": false, "cost_details": {"upstream_inference_cost": null, "upstream_inference_prompt_cost": 0.00029851, "upstream_inference_completions_cost": 0.000244}}, "model": "openai/gpt-oss-120b"}
{"timestamp": "2025-10-22T03:29:18.258980", "feed": "arxiv_cslg", "title": "Measure-Theoretic Anti-Causal Representation Learning", "link": "https://papers.cool/arxiv/2510.18052", "analysis": {"summary": "The paper introduces Anti-Causal Invariant Abstractions (ACIA), a measure-theoretic framework for learning representations in the anti-causal setting where labels generate features. ACIA uses a two-level design with low-level representations of the label-to-observation process and high-level representations that capture stable causal patterns across environments, providing theoretical out-of-distribution generalization guarantees and handling both perfect and imperfect interventions. Experiments on synthetic and medical datasets show ACIA outperforms existing methods in accuracy and invariance.", "summary_cn": "本文提出了 Anti-Causal Invariant Abstractions (ACIA)，一种基于测度论的反因果表征学习框架，假设标签产生特征。ACIA 采用两层设计，低层表征捕获标签到观测的生成过程，高层表征学习跨环境的稳定因果模式，提供了分布外泛化的理论保证并能处理完美或不完美的干预。实验在合成数据和医学数据上显示 ACIA 在准确率和不变性指标上 consistently 优于现有方法。", "keywords": "anti-causal representation learning, invariant abstractions, measure-theoretic framework, out-of-distribution generalization, interventional kernels, causal invariance, robust learning", "scoring": {"interpretability": 3, "understanding": 7, "safety": 3, "technicality": 8, "surprisal": 7}, "category": {"failure_mode_addressed": "non-applicable", "primary_focus": "robustness"}, "authors": ["Arman Behnam", "Binghui Wang"]}, "usage": {"completion_tokens": 944, "prompt_tokens": 3992, "total_tokens": 4936, "completion_tokens_details": {"accepted_prediction_tokens": null, "audio_tokens": null, "reasoning_tokens": 578, "rejected_prediction_tokens": null, "image_tokens": 0}, "prompt_tokens_details": {"audio_tokens": 0, "cached_tokens": 0}, "cost": 0.0004356, "is_byok": false, "cost_details": {"upstream_inference_cost": null, "upstream_inference_prompt_cost": 0.0001996, "upstream_inference_completions_cost": 0.000236}}, "model": "openai/gpt-oss-120b"}
{"timestamp": "2025-10-22T03:29:18.433611", "feed": "arxiv_cslg", "title": "Long-Context Attention Benchmark: From Kernel Efficiency to Distributed Context Parallelism", "link": "https://papers.cool/arxiv/2510.17896", "analysis": {"summary": "The paper introduces a unified benchmark for evaluating long-context attention mechanisms, integrating both kernel-level optimizations and distributed context‑parallel strategies. It assesses methods across attention mask patterns, sequence length, and multi‑GPU scale, providing reproducible performance comparisons up to 96 GPUs and highlighting trade‑offs for LLM training with extremely long contexts.", "summary_cn": "本文提出一个统一的基准，用于评估长上下文注意力机制，整合了核层优化和分布式上下文并行策略。评测重点包括注意力掩码模式、序列长度以及多 GPU（最高 96 卡）规模下的性能，对极长上下文的 LLM 训练提供可复现的比较并揭示各方法的权衡。", "keywords": "long-context attention, benchmark, kernel optimization, context parallelism, distributed training, LLM efficiency, attention mask patterns, scalability", "scoring": {"interpretability": 2, "understanding": 5, "safety": 3, "technicality": 8, "surprisal": 6}, "category": {"failure_mode_addressed": "non-applicable", "primary_focus": "other"}, "authors": ["Tao Bu", "Qiangang Wang", "Bowen Zeng", "Hanwen Sun", "Yunpeng Huang", "Chun Cao", "Jingwei Xu"]}, "usage": {"completion_tokens": 489, "prompt_tokens": 3431, "total_tokens": 3920, "completion_tokens_details": {"accepted_prediction_tokens": null, "audio_tokens": null, "reasoning_tokens": 240, "rejected_prediction_tokens": null, "image_tokens": 0}, "prompt_tokens_details": {"audio_tokens": 0, "cached_tokens": 3152}, "cost": 0.00053851, "is_byok": false, "cost_details": {"upstream_inference_cost": null, "upstream_inference_prompt_cost": 0.00029401, "upstream_inference_completions_cost": 0.0002445}}, "model": "openai/gpt-oss-120b"}
{"timestamp": "2025-10-22T03:29:18.586218", "feed": "arxiv_cslg", "title": "Any-Depth Alignment: Unlocking Innate Safety Alignment of LLMs to Any-Depth", "link": "https://papers.cool/arxiv/2510.18081", "analysis": {"summary": "The paper introduces Any-Depth Alignment (ADA), an inference-time technique that periodically re‑inserts alignment‑rich header tokens during generation, forcing large language models to reassess harmfulness and recover refusals at any depth. ADA achieves near‑100% refusal rates against strong adversarial pre‑fill and prompt attacks across multiple open‑source model families without modifying model parameters, while preserving utility on benign tasks. The method reveals that alignment priors are concentrated in early assistant tokens and can be leveraged to maintain safety throughout generation.", "summary_cn": "本文提出 Any‑Depth Alignment（ADA）作为一种推理时防御方法，通过在生成过程中周期性重新注入包含强对齐先验的助手头部标记，使大语言模型在任意深度重新评估有害性并恢复拒绝。ADA 在多个开源模型上实现了接近 100% 的拒绝率，能够抵御强大的对抗性前置与提示攻击且无需修改模型参数，同时在正常任务上保持效用。该工作揭示了对齐能力主要集中在助手开头的标记中，可利用这些标记在整个生成过程保持安全。", "keywords": "LLM alignment, inference-time defense, adversarial prompt attacks, refusal tokens, shallow alignment, safety, token prompting, robustness", "scoring": {"interpretability": 4, "understanding": 6, "safety": 8, "technicality": 7, "surprisal": 7}, "category": {"failure_mode_addressed": "misalignment", "primary_focus": "alignment"}, "authors": ["Jiawei Zhang", "Andrew Estornell", "David D. Baek", "Bo Li", "Xiaojun Xu"]}, "usage": {"completion_tokens": 819, "prompt_tokens": 3509, "total_tokens": 4328, "completion_tokens_details": {"accepted_prediction_tokens": null, "audio_tokens": null, "reasoning_tokens": 578, "rejected_prediction_tokens": null, "image_tokens": 0}, "prompt_tokens_details": {"audio_tokens": 0, "cached_tokens": 3152}, "cost": 0.00071521, "is_byok": false, "cost_details": {"upstream_inference_cost": null, "upstream_inference_prompt_cost": 0.00030571, "upstream_inference_completions_cost": 0.0004095}}, "model": "openai/gpt-oss-120b"}
{"timestamp": "2025-10-22T03:29:18.642192", "feed": "arxiv_cslg", "title": "Enhancing mortality prediction in cardiac arrest ICU patients through meta-modeling of structured clinical data from MIMIC-IV", "link": "https://papers.cool/arxiv/2510.18103", "analysis": {"summary": "The paper develops a meta‑model that combines structured clinical variables with textual features extracted from discharge summaries and radiology reports to predict in‑hospital mortality of cardiac‑arrest ICU patients in the MIMIC‑IV database. Using LASSO and XGBoost for feature selection and a logistic regression on the top features, augmented with TF‑IDF and BERT embeddings, the final model achieves an AUC of 0.918, markedly outperforming a structured‑data‑only baseline. Decision‑curve analysis shows a broader range of clinically useful threshold probabilities, highlighting the prognostic value of unstructured notes in interpretable risk models.", "summary_cn": "本文构建了一个元模型，将结构化临床变量与出院摘要和影像学报告中的文本特征相结合，以预测 MIMIC‑IV 数据库中心脏骤停 ICU 患者的院内死亡率。通过 LASSO 与 XGBoost 进行特征选择，再使用逻辑回归结合 TF‑IDF 与 BERT 嵌入的顶级特征，最终模型的 AUC 达到 0.918，显著优于仅使用结构化数据的基线。决策曲线分析表明模型在更宽阄阈值概率范围内提供了更大的临床净收益，突显了非结构化笔记在可解释风险预测模型中的预后价值。", "keywords": "mortality prediction, ICU, MIMIC-IV, structured clinical data, unstructured text, BERT embeddings, logistic regression, feature selection, AUC, decision curve analysis", "scoring": {"interpretability": 5, "understanding": 4, "safety": 3, "technicality": 7, "surprisal": 5}, "category": {"failure_mode_addressed": "non-applicable", "primary_focus": "other"}, "authors": ["Nursultan Mamatov", "Philipp Kellmeyer"]}, "usage": {"completion_tokens": 790, "prompt_tokens": 3416, "total_tokens": 4206, "completion_tokens_details": {"accepted_prediction_tokens": null, "audio_tokens": null, "reasoning_tokens": 427, "rejected_prediction_tokens": null, "image_tokens": 0}, "prompt_tokens_details": {"audio_tokens": 0, "cached_tokens": 3152}, "cost": 0.00068676, "is_byok": false, "cost_details": {"upstream_inference_cost": null, "upstream_inference_prompt_cost": 0.00029176, "upstream_inference_completions_cost": 0.000395}}, "model": "openai/gpt-oss-120b"}
{"timestamp": "2025-10-22T03:29:18.733499", "feed": "arxiv_cslg", "title": "Learning with Dual-level Noisy Correspondence for Multi-modal Entity Alignment", "link": "https://papers.cool/arxiv/2510.18240", "analysis": {"summary": "The paper identifies the Dual-level Noisy Correspondence (DNC) problem in multi-modal entity alignment, where both intra-entity (entity-attribute) and inter-graph (entity-entity, attribute-attribute) correspondences may be corrupted. It proposes the RULE framework that estimates reliability of correspondences, mitigates intra-entity noise during attribute fusion, avoids overfitting to noisy inter-graph links, and adds a correspondence reasoning module to uncover attribute-attribute connections, achieving strong results on five benchmarks.", "summary_cn": "本文指出在多模态实体对齐中存在的双层噪声对应（Dual-level Noisy Correspondence, DNC）问题，即实体属性内部对应以及图间对应都可能出现错误。为此提出了 RULE 框架，通过两步原则估计对应的可靠性，在属性融合时降低内部噪声影响，防止对噪声图间对应的过拟合，并加入对应推理模块发现跨图属性关联，从而在五个基准上取得显著提升。", "keywords": "multi-modal entity alignment, noisy correspondence, knowledge graph, attribute fusion, reliability estimation, correspondence reasoning", "scoring": {"interpretability": 3, "understanding": 6, "safety": 2, "technicality": 7, "surprisal": 6}, "category": {"failure_mode_addressed": "non-applicable", "primary_focus": "other"}, "authors": ["Haobin Li", "Yijie Lin", "Peng Hu", "Mouxing Yang", "Xi Peng"]}, "usage": {"completion_tokens": 741, "prompt_tokens": 4107, "total_tokens": 4848, "completion_tokens_details": {"accepted_prediction_tokens": null, "audio_tokens": null, "reasoning_tokens": 407, "rejected_prediction_tokens": null, "image_tokens": 0}, "prompt_tokens_details": {"audio_tokens": 0, "cached_tokens": 0}, "cost": 0.0003906, "is_byok": false, "cost_details": {"upstream_inference_cost": null, "upstream_inference_prompt_cost": 0.00020535, "upstream_inference_completions_cost": 0.00018525}}, "model": "openai/gpt-oss-120b"}
{"timestamp": "2025-10-22T03:29:19.472534", "feed": "arxiv_cslg", "title": "NeuCo-Bench: A Novel Benchmark Framework for Neural Embeddings in Earth Observation", "link": "https://papers.cool/arxiv/2510.17914", "analysis": {"summary": "NeuCo-Bench is a new benchmark framework that evaluates lossy neural compression and representation learning for Earth Observation by using fixed-size, task‑agnostic embeddings. It provides an evaluation pipeline, a hidden‑task challenge leaderboard to reduce pretraining bias, and a scoring system balancing accuracy and stability, together with the SSL4EO‑S12‑downstream dataset. Initial results from a public challenge and ablations with foundation models demonstrate its potential as a community‑driven standard for neural embeddings in EO.", "summary_cn": "NeuCo-Bench 是一个用于评估地球观测（EO）中有损神经压缩和表征学习的基准框架，采用固定大小、任务无关的嵌入向量。它提供了评估流水线、用于降低预训练偏差的隐藏任务挑战排行榜以及兼顾准确性和稳定性的评分系统，并发布了 SSL4EO‑S12‑downstream 数据集。通过在 2025 CVPR EARTHVISION 研讨会的公开挑战以及对最先进基础模型的消融实验，展示了该框架在 EO 及其他领域推动社区标准化评估的潜力。", "keywords": "neural embeddings, Earth observation, benchmark, representation learning, compression, downstream tasks, SSL4EO, evaluation pipeline", "scoring": {"interpretability": 3, "understanding": 5, "safety": 2, "technicality": 7, "surprisal": 6}, "category": {"failure_mode_addressed": "non-applicable", "primary_focus": "other"}, "authors": ["Rikard Vinge", "Isabelle Wittmann", "Jannik Schneider", "Michael Marszalek", "Luis Gilch", "Thomas Brunschwiler", "Conrad M Albrecht"]}, "usage": {"completion_tokens": 672, "prompt_tokens": 3381, "total_tokens": 4053, "completion_tokens_details": {"accepted_prediction_tokens": null, "audio_tokens": null, "reasoning_tokens": 351, "rejected_prediction_tokens": null, "image_tokens": 0}, "prompt_tokens_details": {"audio_tokens": 0, "cached_tokens": 3152}, "cost": 0.00062251, "is_byok": false, "cost_details": {"upstream_inference_cost": null, "upstream_inference_prompt_cost": 0.00028651, "upstream_inference_completions_cost": 0.000336}}, "model": "openai/gpt-oss-120b"}
{"timestamp": "2025-10-22T03:29:19.562485", "feed": "arxiv_cslg", "title": "The Sherpa.ai Blind Vertical Federated Learning Paradigm to Minimize the Number of Communications", "link": "https://papers.cool/arxiv/2510.17901", "analysis": {"summary": "The paper proposes the Sherpa.ai Blind Vertical Federated Learning (SBVFL) paradigm, which decouples most node updates from the central server to drastically cut communication overhead in vertical federated learning. Experiments demonstrate that SBVFL achieves about a 99% reduction in communication rounds while retaining model accuracy and robustness across various sensitive domains such as healthcare and finance.", "summary_cn": "本文提出了 Sherpa.ai Blind Vertical Federated Learning (SBVFL) 框架，通过将大部分节点更新与中心服务器解耦，实现垂直联邦学习中通信开销的极大削减。实验表明，SBVFL 在保持模型准确性和鲁棒性的同时，可将通信次数降低约 99%，适用于医疗、金融等敏感领域。", "keywords": "vertical federated learning, communication reduction, privacy, distributed training, SBVFL, federated learning, security, healthcare, finance", "scoring": {"interpretability": 2, "understanding": 6, "safety": 6, "technicality": 7, "surprisal": 7}, "category": {"failure_mode_addressed": "other", "primary_focus": "robustness"}, "authors": ["Alex Acero", "Daniel M. Jimenez-Gutierrez", "Dario Pighin", "Enrique Zuazua", "Joaquin Del Rio", "Xabi Uribe-Etxebarria"]}, "usage": {"completion_tokens": 675, "prompt_tokens": 3447, "total_tokens": 4122, "completion_tokens_details": {"accepted_prediction_tokens": null, "audio_tokens": null, "reasoning_tokens": 472, "rejected_prediction_tokens": null, "image_tokens": 0}, "prompt_tokens_details": {"audio_tokens": 0, "cached_tokens": 3152}, "cost": 0.00063391, "is_byok": false, "cost_details": {"upstream_inference_cost": null, "upstream_inference_prompt_cost": 0.00029641, "upstream_inference_completions_cost": 0.0003375}}, "model": "openai/gpt-oss-120b"}
{"timestamp": "2025-10-22T03:29:19.980955", "feed": "arxiv_cslg", "title": "Decoding Dynamic Visual Experience from Calcium Imaging via Cell-Pattern-Aware SSL", "link": "https://papers.cool/arxiv/2510.18516", "analysis": {"summary": "The paper introduces POYO-SSL, a self‑supervised learning approach that first isolates statistically predictable neurons (using skewness and kurtosis) for pretraining and then fine‑tunes on the unpredictable population to decode dynamic visual experience from calcium imaging. On the Allen Brain Observatory dataset, POYO‑SSL achieves 12–13% relative improvement over training from scratch and demonstrates smooth, monotonic scaling with model size, unlike existing baselines that plateau or destabilize.", "summary_cn": "本文提出 POYO‑SSL，一种自监督学习方法，先使用偏度和峰度等高阶统计量挑选出统计上可预测的神经元进行预训练，再在不可预测的神经元上微调，以解码钙成像的动态视觉体验。 在 Allen 脑观测站数据集上，POYO‑SSL 相比从头训练提升约 12%‑13%，并随模型规模呈平滑单调的性能提升，而现有基线在扩大模型时出现平台期或不稳定。", "keywords": "self-supervised learning, calcium imaging, neural decoding, POYO-SSL, predictability, Allen Brain Observatory, neural dynamics, foundation models", "scoring": {"interpretability": 2, "understanding": 5, "safety": 1, "technicality": 7, "surprisal": 6}, "category": {"failure_mode_addressed": "non-applicable", "primary_focus": "other"}, "authors": ["Sangyoon Bae", "Mehdi Azabou", "Jiook Cha", "Blake Richards"]}, "usage": {"completion_tokens": 700, "prompt_tokens": 3474, "total_tokens": 4174, "completion_tokens_details": {"accepted_prediction_tokens": null, "audio_tokens": null, "reasoning_tokens": 495, "rejected_prediction_tokens": null, "image_tokens": 0}, "prompt_tokens_details": {"audio_tokens": 0, "cached_tokens": 0}, "cost": 0.00041896, "is_byok": false, "cost_details": {"upstream_inference_cost": null, "upstream_inference_prompt_cost": 0.00013896, "upstream_inference_completions_cost": 0.00028}}, "model": "openai/gpt-oss-120b"}
{"timestamp": "2025-10-22T03:29:20.149461", "feed": "arxiv_cslg", "title": "Bayesian Low-Rank Factorization for Robust Model Adaptation", "link": "https://papers.cool/arxiv/2510.18723", "analysis": {"summary": "The paper proposes Bayesian low-rank factorized adapters for speech foundation models to enable robust domain adaptation, especially for code-switching scenarios, by placing near-zero priors on adaptation matrices to keep them sparse. Experiments on the Whisper model show minimal performance loss on the original tasks while achieving significant gains on new multilingual domains and reducing catastrophic forgetting compared to LoRA. The results suggest Bayesian adapters can fine‑tune large speech models without sacrificing their general capabilities.", "summary_cn": "本文提出了基于贝叶斯低秩因子化的适配器，用于在保持稀疏性的同时对语音基础模型进行稳健的领域适配，特别针对代码切换场景。对 Whisper 模型的实验表明，在保持原有任务性能基本不变的情况下，新领域表现显著提升，并相比 LoRA 大幅降低了对基础模型的灾难性遗忘。结果显示，贝叶斯适配器能够在不牺牲通用能力的前提下对大规模语音模型进行微调。", "keywords": "Bayesian adaptation, low-rank factorization, adapters, speech foundation models, Whisper, code-switching, catastrophic forgetting, LoRA, robust fine-tuning", "scoring": {"interpretability": 2, "understanding": 6, "safety": 3, "technicality": 8, "surprisal": 6}, "category": {"failure_mode_addressed": "non-applicable", "primary_focus": "robustness"}, "authors": ["Enes Yavuz Ugan", "Ngoc-Quan Pham", "Alexander Waibel"]}, "usage": {"completion_tokens": 729, "prompt_tokens": 3989, "total_tokens": 4718, "completion_tokens_details": {"accepted_prediction_tokens": null, "audio_tokens": null, "reasoning_tokens": 379, "rejected_prediction_tokens": null, "image_tokens": 0}, "prompt_tokens_details": {"audio_tokens": 0, "cached_tokens": 0}, "cost": 0.0003817, "is_byok": false, "cost_details": {"upstream_inference_cost": null, "upstream_inference_prompt_cost": 0.00019945, "upstream_inference_completions_cost": 0.00018225}}, "model": "openai/gpt-oss-120b"}
{"timestamp": "2025-10-22T03:29:20.671541", "feed": "arxiv_cslg", "title": "L-MoE: End-to-End Training of a Lightweight Mixture of Low-Rank Adaptation Experts", "link": "https://papers.cool/arxiv/2510.17898", "analysis": {"summary": "L-MoE introduces a lightweight mixture-of-experts framework where each expert is a LoRA adapter, enabling end-to-end differentiable routing and joint optimization of expert parameters and gating. The gating network computes a weighted average of adapter weights per token, allowing dynamic skill composition while keeping inference cost constant. This design yields a parameter‑efficient, modular language model that can be trained from scratch on specialized tasks.", "summary_cn": "L-MoE 提出一种轻量化的专家混合框架，将每个专家定义为 LoRA 适配器，实现了可微分的路由并联合优化专家参数与门控网络。门控网络为每个 token 计算适配器权重的加权平均，从而实现动态技能组合且推理成本保持恒定。该设计产生参数高效、模块化的语言模型，可从头在特定任务上端到端训练。", "keywords": "Mixture of Experts, LoRA, low-rank adaptation, parameter-efficient fine-tuning, dynamic routing, modular language models", "scoring": {"interpretability": 3, "understanding": 6, "safety": 1, "technicality": 8, "surprisal": 6}, "category": {"failure_mode_addressed": "non-applicable", "primary_focus": "other"}, "authors": ["Shihao Ji", "Zihui Song"]}, "usage": {"completion_tokens": 572, "prompt_tokens": 3480, "total_tokens": 4052, "completion_tokens_details": {"accepted_prediction_tokens": null, "audio_tokens": null, "reasoning_tokens": 299, "rejected_prediction_tokens": null, "image_tokens": 0}, "prompt_tokens_details": {"audio_tokens": 0, "cached_tokens": 3152}, "cost": 0.00058736, "is_byok": false, "cost_details": {"upstream_inference_cost": null, "upstream_inference_prompt_cost": 0.00030136, "upstream_inference_completions_cost": 0.000286}}, "model": "openai/gpt-oss-120b"}
{"timestamp": "2025-10-22T03:29:20.790738", "feed": "arxiv_cslg", "title": "R2L: Reliable Reinforcement Learning: Guaranteed Return & Reliable Policies in Reinforcement Learning", "link": "https://papers.cool/arxiv/2510.18074", "analysis": {"summary": "The paper introduces a reliable reinforcement learning formulation that maximizes the probability that cumulative return exceeds a given threshold, and shows how this can be transformed into a standard RL problem via state augmentation, enabling the use of existing algorithms such as Q‑learning and Dueling Double DQN. Theoretical analysis proves equivalence of the formulations, and experiments on a reliable routing task demonstrate policies that balance efficiency and success probability, highlighting applicability to stochastic and safety‑critical domains.", "summary_cn": "本文提出一种可靠强化学习的形式化目标，即最大化累计回报超过预设阈值的概率，并通过状态增强将其转化为标准强化学习问题，从而可以直接使用 Q‑学习、双 DQN 等现有算法。理论结果证明了两种形式的等价性，实验在可靠路由任务上展示了能够在效率与成功概率之间取得平衡的策略，凸显了该方法在随机且安全关键环境中的潜在价值。", "keywords": "reliable reinforcement learning, probability of return, risk-sensitive RL, safety-critical RL, robust RL, Q-learning, Dueling Double DQN, reliable routing, performance guarantees", "scoring": {"interpretability": 2, "understanding": 6, "safety": 7, "technicality": 7, "surprisal": 6}, "category": {"failure_mode_addressed": "non-applicable", "primary_focus": "robustness"}, "authors": ["Nadir Farhi"]}, "usage": {"completion_tokens": 835, "prompt_tokens": 3460, "total_tokens": 4295, "completion_tokens_details": {"accepted_prediction_tokens": null, "audio_tokens": null, "reasoning_tokens": 665, "rejected_prediction_tokens": null, "image_tokens": 0}, "prompt_tokens_details": {"audio_tokens": 0, "cached_tokens": 3152}, "cost": 0.00071586, "is_byok": false, "cost_details": {"upstream_inference_cost": null, "upstream_inference_prompt_cost": 0.00029836, "upstream_inference_completions_cost": 0.0004175}}, "model": "openai/gpt-oss-120b"}
{"timestamp": "2025-10-22T03:29:20.998361", "feed": "arxiv_cslg", "title": "Latent Discrete Diffusion Models", "link": "https://papers.cool/arxiv/2510.18114", "analysis": {"summary": "The paper introduces Latent Discrete Diffusion Models (LDDMs), which combine a masked discrete diffusion over tokens with a continuous diffusion over latent embeddings to capture cross‑token dependencies. Two variants are proposed—FUJI‑LDDMs that jointly denoise tokens and latents, and SEQ‑LDDMs that resolve latents first and then the discrete chain—and ELBO‑based training objectives are derived. Experiments on unconditional language generation show that LDDMs outperform existing masked discrete diffusion baselines, especially under low‑step sampling budgets.", "summary_cn": "本文提出潜在离散扩散模型 (LDDM)，将对 token 的掩码离散扩散与对潜在嵌入的连续扩散相耦合，以捕获跨 token 的依赖关系。介绍了两种实现：FUJI‑LDDM 同时对 token 与潜在进行联合去噪，SEQ‑LDDM 先解码潜在再条件化离散链，并给出基于 ELBO 的目标函数。实验表明，在无条件语言生成任务中，LDDM 在整体质量和低步采样预算下均优于现有的掩码离散扩散基线。", "keywords": "latent diffusion, discrete diffusion, masked diffusion, language modeling, joint denoising, ELBO, generative modeling", "scoring": {"interpretability": 2, "understanding": 6, "safety": 3, "technicality": 8, "surprisal": 7}, "category": {"failure_mode_addressed": "non-applicable", "primary_focus": "other"}, "authors": ["Dario Shariatian", "Alain Durmus", "Stefano Peluchetti"]}, "usage": {"completion_tokens": 969, "prompt_tokens": 3405, "total_tokens": 4374, "completion_tokens_details": {"accepted_prediction_tokens": null, "audio_tokens": null, "reasoning_tokens": 701, "rejected_prediction_tokens": null, "image_tokens": 0}, "prompt_tokens_details": {"audio_tokens": 0, "cached_tokens": 3152}, "cost": 0.00077461, "is_byok": false, "cost_details": {"upstream_inference_cost": null, "upstream_inference_prompt_cost": 0.00029011, "upstream_inference_completions_cost": 0.0004845}}, "model": "openai/gpt-oss-120b"}
{"timestamp": "2025-10-22T03:29:21.434449", "feed": "arxiv_cslg", "title": "Shock-Aware Physics-Guided Fusion-DeepONet Operator for Rarefied Micro-Nozzle Flows", "link": "https://papers.cool/arxiv/2510.17887", "analysis": {"summary": "The paper introduces a physics‑aware deep learning framework that combines a Fusion DeepONet operator architecture, a shock‑aligned coordinate system, and a two‑phase curriculum to build fast and accurate surrogate models for rarefied micro‑nozzle flows containing shocks. By first validating the method on the viscous Burgers equation, the authors demonstrate its ability to capture steep gradient dynamics and parameter dependencies efficiently.", "summary_cn": "本文提出了一种物理感知的深度学习框架，融合了 Fusion DeepONet 运算子结构、冲击对齐坐标系以及两阶段课程学习，以快速、精确地构建稀薄微喷嘴流动（含冲击） 的代理模型。作者首先在粘性 Burgers 方程上进行验证，展示了该方法在捕获陡峭梯度和参数依赖性方面的有效性。", "keywords": "physics-informed neural networks, DeepONet, operator learning, shock-aware modeling, rarefied flow, micro-nozzle, surrogate modeling, curriculum learning", "scoring": {"interpretability": 3, "understanding": 6, "safety": 2, "technicality": 8, "surprisal": 7}, "category": {"failure_mode_addressed": "non-applicable", "primary_focus": "other"}, "authors": ["Ehsan Roohi", "Amirmehran Mahdavi"]}, "usage": {"completion_tokens": 605, "prompt_tokens": 3311, "total_tokens": 3916, "completion_tokens_details": {"accepted_prediction_tokens": null, "audio_tokens": null, "reasoning_tokens": 344, "rejected_prediction_tokens": null, "image_tokens": 0}, "prompt_tokens_details": {"audio_tokens": 0, "cached_tokens": 3152}, "cost": 0.00057851, "is_byok": false, "cost_details": {"upstream_inference_cost": null, "upstream_inference_prompt_cost": 0.00027601, "upstream_inference_completions_cost": 0.0003025}}, "model": "openai/gpt-oss-120b"}
{"timestamp": "2025-10-22T03:29:21.536759", "feed": "arxiv_cslg", "title": "SO(3)-invariant PCA with application to molecular data", "link": "https://papers.cool/arxiv/2510.18827", "analysis": {"summary": "The paper introduces a principled framework for SO(3)-invariant principal component analysis that handles 3D volumetric datasets with unknown orientations without explicit data augmentation, reducing computational complexity to the square root of the number of covariance entries. By exploiting algebraic structure, the method enables efficient dimensionality reduction and denoising for molecular data, and experimental validation on real molecular datasets demonstrates its effectiveness.", "summary_cn": "本文提出了一种 SO(3) 不变的主成分分析框架，可在不进行显式数据增强的情况下处理未知方向的三维体数据，将计算复杂度降低至协方差条目数量的平方根。通过利用代数结构，该方法实现了对分子数据的高效降维和去噪，并在真实分子数据集上验证了其有效性。", "keywords": "SO(3)-invariant PCA, rotational invariance, volumetric data, molecular structures, dimensionality reduction, covariance, algebraic methods, 3D data analysis", "scoring": {"interpretability": 2, "understanding": 3, "safety": 1, "technicality": 7, "surprisal": 5}, "category": {"failure_mode_addressed": "non-applicable", "primary_focus": "other"}, "authors": ["Michael Fraiman", "Paulina Hoyos", "Tamir Bendory", "Joe Kileel", "Oscar Mickelin", "Nir Sharon", "Amit Singer"]}, "usage": {"completion_tokens": 637, "prompt_tokens": 3357, "total_tokens": 3994, "completion_tokens_details": {"accepted_prediction_tokens": null, "audio_tokens": null, "reasoning_tokens": 376, "rejected_prediction_tokens": null, "image_tokens": 0}, "prompt_tokens_details": {"audio_tokens": 0, "cached_tokens": 3152}, "cost": 0.00060141, "is_byok": false, "cost_details": {"upstream_inference_cost": null, "upstream_inference_prompt_cost": 0.00028291, "upstream_inference_completions_cost": 0.0003185}}, "model": "openai/gpt-oss-120b"}
{"timestamp": "2025-10-22T03:29:22.316402", "feed": "arxiv_cslg", "title": "Adapting Language Balance in Code-Switching Speech", "link": "https://papers.cool/arxiv/2510.18724", "analysis": {"summary": "The paper proposes a differentiable surrogate that highlights code‑switching points by exploiting the difference between the embedded and main language embeddings, thereby reducing context bias during generation. Experiments on Arabic and Chinese‑English code‑switched speech show improved prediction of switching locations and lower substitution errors, indicating increased robustness of large foundational models to code‑switching scenarios.", "summary_cn": "本文提出一种可微分的代理方法，通过利用嵌入语言与主体语言之间的差异来突出代码切换点，从而降低生成过程中的上下文偏差。对阿拉伯语和中英代码切换语音的实验显示，该方法能够更准确地预测切换位置并减少替换错误，提升了大型基础模型在代码切换情形下的鲁棒性。", "keywords": "code-switching, speech recognition, language balance, differentiable surrogate, robustness, Arabic, Chinese-English, embedding bias", "scoring": {"interpretability": 3, "understanding": 5, "safety": 1, "technicality": 6, "surprisal": 6}, "category": {"failure_mode_addressed": "non-applicable", "primary_focus": "robustness"}, "authors": ["Enes Yavuz Ugan", "Ngoc-Quan Pham", "Alexander Waibel"]}, "usage": {"completion_tokens": 513, "prompt_tokens": 3396, "total_tokens": 3909, "completion_tokens_details": {"accepted_prediction_tokens": null, "audio_tokens": null, "reasoning_tokens": 295, "rejected_prediction_tokens": null, "image_tokens": 0}, "prompt_tokens_details": {"audio_tokens": 0, "cached_tokens": 3152}, "cost": 0.00054526, "is_byok": false, "cost_details": {"upstream_inference_cost": null, "upstream_inference_prompt_cost": 0.00028876, "upstream_inference_completions_cost": 0.0002565}}, "model": "openai/gpt-oss-120b"}
{"timestamp": "2025-10-22T03:29:22.351513", "feed": "arxiv_cslg", "title": "Symbolic Emulators for Cosmology: Accelerating Cosmological Analyses Without Sacrificing Precision", "link": "https://papers.cool/arxiv/2510.18749", "analysis": {"summary": "The paper introduces symbolic emulators that approximate hypergeometric functions for ΛCDM comoving distance and linear growth factor, achieving sub‑0.001% and 0.05% errors across relevant redshifts and Ωm values. Integrated into a Dark Energy Survey‑like 3×2pt analysis, these emulators yield cosmological constraints matching those from standard numerical methods while dramatically reducing computation time and memory usage. The work demonstrates that symbolic approximations can scale likelihood‑based inference without sacrificing precision.", "summary_cn": "本文提出了用于 ΛCDM 宇宙学模型的符号化仿真器，通过近似超几何函数实现对共动距离和线性增长因子的高精度（误差分别低于 0.001% 和 0.05%）并覆盖 Ωₘ∈[0.1,0.5] 的红移范围。将这些仿真器整合到类似暗能量巡天的 3×2pt 分析中，得到的宇宙学约束与传统数值方法一致，同时显著提升了计算速度和内存效率。该工作展示了符号近似在保持精度的前提下，可实现可扩展的似然推断。", "keywords": "symbolic emulator, cosmology, ΛCDM, hypergeometric approximation, dark energy survey, 3x2pt analysis, fast inference", "scoring": {"interpretability": 1, "understanding": 4, "safety": 1, "technicality": 7, "surprisal": 5}, "category": {"failure_mode_addressed": "non-applicable", "primary_focus": "other"}, "authors": ["Deaglan J. Bartlett", "Shivam Pandey"]}, "usage": {"completion_tokens": 648, "prompt_tokens": 3415, "total_tokens": 4063, "completion_tokens_details": {"accepted_prediction_tokens": null, "audio_tokens": null, "reasoning_tokens": 304, "rejected_prediction_tokens": null, "image_tokens": 0}, "prompt_tokens_details": {"audio_tokens": 0, "cached_tokens": 3152}, "cost": 0.00061561, "is_byok": false, "cost_details": {"upstream_inference_cost": null, "upstream_inference_prompt_cost": 0.00029161, "upstream_inference_completions_cost": 0.000324}}, "model": "openai/gpt-oss-120b"}
{"timestamp": "2025-10-22T03:29:22.470179", "feed": "arxiv_cslg", "title": "A Frequentist Statistical Introduction to Variational Inference, Autoencoders, and Diffusion Models", "link": "https://papers.cool/arxiv/2510.18777", "analysis": {"summary": "The paper presents a purely Frequentist treatment of Variational Inference (VI), showing how it emerges from the Expectation‑Maximization algorithm and how Variational Autoencoders (VAEs) and Denoising Diffusion Models (DDMs) can be viewed as deep‑learning extensions of this framework. By framing VI as a scalable approximation to intractable E‑steps for maximum‑likelihood estimation, the authors bridge the conceptual gap between classical statistical inference and modern generative AI.", "summary_cn": "本文从纯频率主义视角阐述变分推断（VI），展示其如何源自期望最大化（EM）算法，并将变分自编码器（VAE）和去噪扩散模型（DDM）视为该框架的深度学习扩展。通过将 VI 视为对不可解 E 步的可扩展近似用于最大似然估计，作者搭建了经典统计推断与现代生成式 AI 之间的概念桥梁。", "keywords": "variational inference, frequentist perspective, expectation-maximization, variational autoencoder, diffusion model, generative modeling, statistical learning", "scoring": {"interpretability": 3, "understanding": 7, "safety": 3, "technicality": 7, "surprisal": 5}, "category": {"failure_mode_addressed": "non-applicable", "primary_focus": "other"}, "authors": ["Yen-Chi Chen"]}, "usage": {"completion_tokens": 663, "prompt_tokens": 3409, "total_tokens": 4072, "completion_tokens_details": {"accepted_prediction_tokens": null, "audio_tokens": null, "reasoning_tokens": 391, "rejected_prediction_tokens": null, "image_tokens": 0}, "prompt_tokens_details": {"audio_tokens": 0, "cached_tokens": 3152}, "cost": 0.00062221, "is_byok": false, "cost_details": {"upstream_inference_cost": null, "upstream_inference_prompt_cost": 0.00029071, "upstream_inference_completions_cost": 0.0003315}}, "model": "openai/gpt-oss-120b"}
{"timestamp": "2025-10-22T03:29:22.709643", "feed": "arxiv_cslg", "title": "Hierarchical Federated Unlearning for Large Language Models", "link": "https://papers.cool/arxiv/2510.17895", "analysis": {"summary": "The paper proposes a federated unlearning framework for large language models that separates unlearning from retention using task-specific adapter modules and a hierarchical merging strategy, enabling scalable and privacy-preserving removal of undesired knowledge. Experiments on benchmarks such as WMDP, MUSE, and TOFU demonstrate that the method handles heterogeneous unlearning requests while preserving model utility compared to baselines.", "summary_cn": "本文提出了一种面向大型语言模型的联邦删除框架，通过任务特定的适配器学习将删除与保留解耦，并采用层次合并策略减轻冲突目标，实现可扩展且隐私保护的去除不良知识。实验在 WMDP、MUSE、TOFU 等基准上表明，该方法能够处理多样化的删除请求，同时相较于基线保持模型效用。", "keywords": "federated unlearning, large language models, privacy, adapter learning, hierarchical merging, decentralized learning, continual unlearning, model forgetting, performance retention", "scoring": {"interpretability": 4, "understanding": 6, "safety": 7, "technicality": 8, "surprisal": 7}, "category": {"failure_mode_addressed": "misalignment", "primary_focus": "control"}, "authors": ["Yisheng Zhong", "Zhengbang Yang", "Zhuangdi Zhu"]}, "usage": {"completion_tokens": 706, "prompt_tokens": 3375, "total_tokens": 4081, "completion_tokens_details": {"accepted_prediction_tokens": null, "audio_tokens": null, "reasoning_tokens": 497, "rejected_prediction_tokens": null, "image_tokens": 0}, "prompt_tokens_details": {"audio_tokens": 0, "cached_tokens": 3152}, "cost": 0.00063861, "is_byok": false, "cost_details": {"upstream_inference_cost": null, "upstream_inference_prompt_cost": 0.00028561, "upstream_inference_completions_cost": 0.000353}}, "model": "openai/gpt-oss-120b"}
{"timestamp": "2025-10-22T03:29:22.895506", "feed": "arxiv_cslg", "title": "MIN-Merging: Merge the Important Neurons for Model Merging", "link": "https://papers.cool/arxiv/2510.17890", "analysis": {"summary": "The paper introduces MIN-Merging, a router-based framework that selectively merges the most important neurons from pre‑trained models to mitigate parameter conflicts during model merging. Experiments on both computer‑vision and natural‑language‑processing benchmarks demonstrate consistent in‑domain performance gains while preserving out‑of‑domain generalization. The results suggest that focusing on important neurons is an effective practical solution for improving merged model performance.", "summary_cn": "本文提出 MIN-Merging，一种基于路由器的框架，通过选择并合并最重要的神经元来降低模型合并过程中的参数冲突。在计算机视觉和自然语言处理基准上的实验表明，该方法在保持域外泛化能力的同时，实现了域内任务性能的持续提升。结果表明，聚焦重要神经元是提升合并模型表现的有效实用方案。", "keywords": "model merging, important neuron selection, router-based framework, parameter conflict, in-domain performance, out-of-domain generalization, computer vision, natural language processing", "scoring": {"interpretability": 5, "understanding": 6, "safety": 3, "technicality": 7, "surprisal": 5}, "category": {"failure_mode_addressed": "other", "primary_focus": "robustness"}, "authors": ["Yunfei Liang"]}, "usage": {"completion_tokens": 696, "prompt_tokens": 3318, "total_tokens": 4014, "completion_tokens_details": {"accepted_prediction_tokens": null, "audio_tokens": null, "reasoning_tokens": 507, "rejected_prediction_tokens": null, "image_tokens": 0}, "prompt_tokens_details": {"audio_tokens": 0, "cached_tokens": 3152}, "cost": 0.00062506, "is_byok": false, "cost_details": {"upstream_inference_cost": null, "upstream_inference_prompt_cost": 0.00027706, "upstream_inference_completions_cost": 0.000348}}, "model": "openai/gpt-oss-120b"}
{"timestamp": "2025-10-22T03:29:22.990058", "feed": "arxiv_cslg", "title": "Verifiable Accuracy and Abstention Rewards in Curriculum RL to Alleviate Lost-in-Conversation", "link": "https://papers.cool/arxiv/2510.18731", "analysis": {"summary": "The paper introduces Curriculum Reinforcement Learning with Verifiable Accuracy and Abstention Rewards (RLAAR), a framework that rewards large language models for providing correct answers and for abstaining when a question is unsolvable within a multi-turn conversation. By progressively increasing dialogue difficulty through a competence‑gated curriculum, RLAAR stabilizes training and reduces the Lost-in-Conversation degradation, achieving higher accuracy and calibrated abstention rates on benchmark tasks.", "summary_cn": "本文提出了“可验证准确性与弃答奖励的课程强化学习”（RLAAR）框架，鼓励大语言模型在多轮对话中不仅给出正确答案，还在问题不可解时进行弃答。该方法通过能力门控的课程逐步提升对话难度，稳定训练并显著缓解对话中性能衰减（Lost-in-Conversation），在基准测试中提升了准确率并实现了更高的校准弃答率。", "keywords": "curriculum learning, reinforcement learning with verifiable rewards, abstention, lost-in-conversation, multi-turn dialogue, LLM safety, reliability", "scoring": {"interpretability": 2, "understanding": 7, "safety": 8, "technicality": 7, "surprisal": 6}, "category": {"failure_mode_addressed": "misalignment", "primary_focus": "alignment"}, "authors": ["Ming Li"]}, "usage": {"completion_tokens": 618, "prompt_tokens": 3426, "total_tokens": 4044, "completion_tokens_details": {"accepted_prediction_tokens": null, "audio_tokens": null, "reasoning_tokens": 358, "rejected_prediction_tokens": null, "image_tokens": 0}, "prompt_tokens_details": {"audio_tokens": 0, "cached_tokens": 3152}, "cost": 0.00060226, "is_byok": false, "cost_details": {"upstream_inference_cost": null, "upstream_inference_prompt_cost": 0.00029326, "upstream_inference_completions_cost": 0.000309}}, "model": "openai/gpt-oss-120b"}
{"timestamp": "2025-10-22T03:29:23.565387", "feed": "arxiv_cslg", "title": "From Noise to Laws: Regularized Time-Series Forecasting via Denoised Dynamic Graphs", "link": "https://papers.cool/arxiv/2510.17817", "analysis": {"summary": "The paper introduces PRISM, a forecasting framework that combines a score-based diffusion preconditioner with a dynamic, correlation‑thresholded graph encoder and a physics‑regularized forecast head, and provides theoretical contraction and Lipschitz guarantees for long‑horizon stability. Empirical results on six benchmarks show state‑of‑the‑art performance with notable improvements in MSE and MAE.", "summary_cn": "本文提出 PRISM 框架，将基于分数的扩散预处理器 (score‑based diffusion preconditioner) 与动态相关阈值图编码器 (dynamic, correlation‑thresholded graph encoder) 以及带有通用物理惩罚的预测头相结合，并证明了在温和条件下的收敛性以及图块的 Lipschitz 上界，解释了模型的鲁棒性。实验在六个标准基准上实现了 SOTA，显著提升了 MSE 和 MAE。", "keywords": "time-series forecasting, diffusion preconditioner, dynamic graph encoder, physics-informed regularization, Lipschitz bounds, robustness", "scoring": {"interpretability": 3, "understanding": 6, "safety": 3, "technicality": 8, "surprisal": 6}, "category": {"failure_mode_addressed": "non-applicable", "primary_focus": "robustness"}, "authors": ["Hongwei Ma", "Junbin Gao", "Minh-ngoc Tran"]}, "usage": {"completion_tokens": 662, "prompt_tokens": 3325, "total_tokens": 3987, "completion_tokens_details": {"accepted_prediction_tokens": null, "audio_tokens": null, "reasoning_tokens": 439, "rejected_prediction_tokens": null, "image_tokens": 0}, "prompt_tokens_details": {"audio_tokens": 0, "cached_tokens": 3152}, "cost": 0.00060911, "is_byok": false, "cost_details": {"upstream_inference_cost": null, "upstream_inference_prompt_cost": 0.00027811, "upstream_inference_completions_cost": 0.000331}}, "model": "openai/gpt-oss-120b"}
{"timestamp": "2025-10-22T03:29:23.656236", "feed": "arxiv_cslg", "title": "Diffusion Buffer for Online Generative Speech Enhancement", "link": "https://papers.cool/arxiv/2510.18744", "analysis": {"summary": "The paper introduces the Diffusion Buffer, a diffusion‑based generative speech‑enhancement model that processes each incoming audio frame with a single neural‑network call, enabling online operation on consumer‑grade GPUs. By aligning physical time with diffusion timesteps and employing a specially designed 2‑D convolutional UNet and a data‑prediction loss, the approach reduces algorithmic latency from 320‑960 ms to 32‑176 ms while improving quality, and it outperforms predictive baselines on unseen noisy speech.", "summary_cn": "本文提出 Diffusion Buffer，一种基于扩散的生成式语音增强模型，能够在每个输入音频帧只调用一次神经网络，从而在消费级 GPU 上实现在线处理。该方法通过将物理时间与扩散时间步对齐，并使用专门设计的 2D 卷积 UNet 与数据预测损失，大幅将算法延迟从 320‑960 ms 降至 32‑176 ms，同时提升了性能，并在未见噪声语音上超过了预测式基线。", "keywords": "diffusion, speech enhancement, online generative models, UNet, algorithmic latency, data prediction loss", "scoring": {"interpretability": 2, "understanding": 5, "safety": 2, "technicality": 8, "surprisal": 6}, "category": {"failure_mode_addressed": "non-applicable", "primary_focus": "other"}, "authors": ["Bunlong Lay", "Rostislav Makarov", "Simon Welker", "Maris Hillemann", "Timo Gerkmann"]}, "usage": {"completion_tokens": 624, "prompt_tokens": 3537, "total_tokens": 4161, "completion_tokens_details": {"accepted_prediction_tokens": null, "audio_tokens": null, "reasoning_tokens": 332, "rejected_prediction_tokens": null, "image_tokens": 0}, "prompt_tokens_details": {"audio_tokens": 0, "cached_tokens": 3152}, "cost": 0.00062191, "is_byok": false, "cost_details": {"upstream_inference_cost": null, "upstream_inference_prompt_cost": 0.00030991, "upstream_inference_completions_cost": 0.000312}}, "model": "openai/gpt-oss-120b"}
{"timestamp": "2025-10-22T03:29:24.219344", "feed": "arxiv_cslg", "title": "GRETEL: A Goal-driven Retrieval and Execution-based Trial Framework for LLM Tool Selection Enhancing", "link": "https://papers.cool/arxiv/2510.17843", "analysis": {"summary": "The paper introduces GRETEL, a goal-driven retrieval and execution-based trial framework that augments LLM tool selection by validating semantically retrieved candidates through sandboxed plan‑execute‑evaluate cycles, thereby bridging the semantic‑functional gap. Empirical results on the ToolBench benchmark show large gains in pass rate, recall, and NDCG compared to purely semantic retrieval methods. This demonstrates that execution‑grounded evidence yields more reliable tool choices for agentic systems.", "summary_cn": "本文提出 GRETEL——一种目标驱动的检索与执行式试验框架，通过在沙箱中对语义检索得到的候选工具进行计划‑执行‑评估循环，提供基于执行的证据，以弥合语义‑功能差距。 在 ToolBench 基准上的实验显示，与仅依赖语义相似度的检索相比，GRETEL 在通过率、召回率和 NDCG 等指标上均有显著提升。 该方法表明执行验证能够显著提升 LLM 代理系统的工具选择可靠性。", "keywords": "tool selection, LLM agents, execution validation, semantic-functional gap, sandbox evaluation, ToolBench, retrieval, functional tools, agentic workflow, reliability", "scoring": {"interpretability": 2, "understanding": 6, "safety": 5, "technicality": 7, "surprisal": 7}, "category": {"failure_mode_addressed": "other", "primary_focus": "robustness"}, "authors": ["Zongze Wu", "Yani Guo", "Churong Liang", "Runnan Li"]}, "usage": {"completion_tokens": 744, "prompt_tokens": 3420, "total_tokens": 4164, "completion_tokens_details": {"accepted_prediction_tokens": null, "audio_tokens": null, "reasoning_tokens": 497, "rejected_prediction_tokens": null, "image_tokens": 0}, "prompt_tokens_details": {"audio_tokens": 0, "cached_tokens": 3152}, "cost": 0.00066436, "is_byok": false, "cost_details": {"upstream_inference_cost": null, "upstream_inference_prompt_cost": 0.00029236, "upstream_inference_completions_cost": 0.000372}}, "model": "openai/gpt-oss-120b"}
{"timestamp": "2025-10-22T03:29:24.798848", "feed": "arxiv_cslg", "title": "LightMem: Lightweight and Efficient Memory-Augmented Generation", "link": "https://papers.cool/arxiv/2510.18866", "analysis": {"summary": "LightMem introduces a three-stage memory system for large language models, inspired by the Atkinson-Shiffrin human memory model, to efficiently store, retrieve, and consolidate historical interaction information. By using a sensory memory for rapid filtering, a topic-aware short-term memory for structured consolidation, and an offline-updated long-term memory, LightMem achieves up to 10.9% accuracy improvements while drastically reducing token usage, API calls, and runtime. Experiments on LongMemEval with GPT and Qwen backbones demonstrate its superior performance‑efficiency trade‑off.", "summary_cn": "LightMem 基于阿特金森‑舒弗林（Atkinson‑Shiffrin）的人类记忆模型，提出了一个由感官记忆、主题感知短期记忆和离线更新的长期记忆组成的三阶段记忆系统，用于大语言模型的历史交互信息的高效存储与检索。该系统通过快速过滤无关信息、主题化组织与摘要以及脱钩的离线合并，实现了准确率最高提升 10.9% 并显著降低 token 使用、API 调用次数和运行时间。 在 GPT 与 Qwen 骨干模型上的 LongMemEval 实验验证了其优越的性能‑效率平衡。", "keywords": "memory-augmented generation, lightweight memory, LLM, efficient retrieval, long-term memory, Atkinson-Shiffrin model", "scoring": {"interpretability": 2, "understanding": 6, "safety": 2, "technicality": 8, "surprisal": 6}, "category": {"failure_mode_addressed": "non-applicable", "primary_focus": "other"}, "authors": ["Jizhan Fang", "Xinle Deng", "Haoming Xu", "Ziyan Jiang", "Yuqi Tang", "Ziwen Xu", "Shumin Deng", "Yunzhi Yao", "Mengru Wang", "Shuofei Qiao", "Huajun Chen", "Ningyu Zhang"]}, "usage": {"completion_tokens": 761, "prompt_tokens": 3445, "total_tokens": 4206, "completion_tokens_details": {"accepted_prediction_tokens": null, "audio_tokens": null, "reasoning_tokens": 431, "rejected_prediction_tokens": null, "image_tokens": 0}, "prompt_tokens_details": {"audio_tokens": 0, "cached_tokens": 3152}, "cost": 0.00067661, "is_byok": false, "cost_details": {"upstream_inference_cost": null, "upstream_inference_prompt_cost": 0.00029611, "upstream_inference_completions_cost": 0.0003805}}, "model": "openai/gpt-oss-120b"}
{"timestamp": "2025-10-22T03:29:25.329163", "feed": "arxiv_cslg", "title": "FST.ai 2.0: An Explainable AI Ecosystem for Fair, Fast, and Inclusive Decision-Making in Olympic and Paralympic Taekwondo", "link": "https://papers.cool/arxiv/2510.18193", "analysis": {"summary": "The paper introduces FST.ai 2.0, an ecosystem that combines graph‑convolutional‑network pose recognition, credal‑set epistemic uncertainty, and visual explainability overlays to assist referees, coaches, and athletes in real‑time Taekwondo competitions. Interactive dashboards enable transparent human‑AI collaboration for scoring, fairness monitoring, and Para‑Taekwondo classification, achieving an 85% reduction in decision‑review time and high referee trust. By integrating perception, uncertainty modeling, and governance‑aware design, the system aims to provide fair, accountable, and human‑aligned decision making in sports.", "summary_cn": "本文提出 FST.ai 2.0 系统，将基于图卷积网络的姿态动作识别、可信集合（credal set）不确定性建模以及可视化解释层叠加，实时支持跆拳道裁判、教练和运动员的决策。交互式仪表盘实现透明的人机协作，用于计分、公平性监测和残奥跆拳道分类，实现了 85% 的裁判复审时间降低并获得高信任度。通过感知、误差建模和治理层面的设计，系统旨在提供公平、可解释且与人类价值对齐的体育裁判方案。", "keywords": "explainable AI, pose action recognition, graph convolutional networks, epistemic uncertainty, credal sets, fairness, sports officiating, human-AI collaboration, decision support", "scoring": {"interpretability": 7, "understanding": 6, "safety": 4, "technicality": 7, "surprisal": 6}, "category": {"failure_mode_addressed": "misalignment", "primary_focus": "interpretability"}, "authors": ["Keivan Shariatmadar", "Ahmad Osman", "Ramin Ray", "Usman Dildar", "Kisam Kim"]}, "usage": {"completion_tokens": 856, "prompt_tokens": 3463, "total_tokens": 4319, "completion_tokens_details": {"accepted_prediction_tokens": null, "audio_tokens": null, "reasoning_tokens": 542, "rejected_prediction_tokens": null, "image_tokens": 0}, "prompt_tokens_details": {"audio_tokens": 0, "cached_tokens": 3136}, "cost": 0.00103305, "is_byok": false, "cost_details": {"upstream_inference_cost": null, "upstream_inference_prompt_cost": 0.00051945, "upstream_inference_completions_cost": 0.0005136}}, "model": "openai/gpt-oss-120b"}
{"timestamp": "2025-10-22T03:29:25.384905", "feed": "arxiv_cslg", "title": "From Observations to Parameters: Detecting Changepoint in Nonlinear Dynamics with Simulation-based Inference", "link": "https://papers.cool/arxiv/2510.17933", "analysis": {"summary": "The paper introduces Parameter‑Space Changepoint Detection (Param‑CPD), a two‑stage method that first learns amortized Bayesian posteriors over governing parameters of a nonlinear system using simulation‑based inference, and then applies a conventional changepoint detection algorithm to the inferred parameter trajectory. Experiments on piecewise‑constant Lorenz‑63 dynamics show improved F1 scores, reduced localization error, and fewer false positives compared to observation‑space baselines, and the authors provide identifiability and calibration analyses to justify the benefits of operating in parameter space.", "summary_cn": "本文提出了参数空间变点检测（Param‑CPD）框架，先通过仿真推断（simulation‑based inference）训练神经后验估计器，实现对非线性系统控制参数的贝叶斯推断，然后在得到的参数轨迹上使用传统变点检测算法。实验证明，在具有分段常数参数的 Lorenz‑63 系统上，Param‑CPD 相比基于观测空间的方法提升了 F1 分数、降低了定位误差并减少误报，且通过可辨识性和校准分析解释了参数空间提供更清晰检测信号的原因。", "keywords": "changepoint detection, simulation-based inference, Bayesian posterior estimation, parameter space, nonlinear dynamics, Lorenz-63, amortized inference", "scoring": {"interpretability": 6, "understanding": 7, "safety": 3, "technicality": 7, "surprisal": 6}, "category": {"failure_mode_addressed": "non-applicable", "primary_focus": "interpretability"}, "authors": ["Xiangbo Deng", "Cheng Chen", "Peng Yang"]}, "usage": {"completion_tokens": 676, "prompt_tokens": 3378, "total_tokens": 4054, "completion_tokens_details": {"accepted_prediction_tokens": null, "audio_tokens": null, "reasoning_tokens": 385, "rejected_prediction_tokens": null, "image_tokens": 0}, "prompt_tokens_details": {"audio_tokens": 0, "cached_tokens": 3152}, "cost": 0.00062406, "is_byok": false, "cost_details": {"upstream_inference_cost": null, "upstream_inference_prompt_cost": 0.00028606, "upstream_inference_completions_cost": 0.000338}}, "model": "openai/gpt-oss-120b"}
{"timestamp": "2025-10-22T03:29:25.440145", "feed": "arxiv_cslg", "title": "SPACeR: Self-Play Anchoring with Centralized Reference Models", "link": "https://papers.cool/arxiv/2510.18060", "analysis": {"summary": "SPACeR combines a pretrained tokenized autoregressive motion model as a centralized reference policy that supplies likelihood and KL‑divergence rewards during decentralized self‑play reinforcement learning, producing human‑like traffic agents that are up to 10× faster and 50× smaller than large diffusion models while achieving competitive performance on the Waymo Sim Agents Challenge and effective closed‑loop ego‑planning evaluation.", "summary_cn": "SPACeR利用预训练的基于令牌的自动回归运动模型作为中心参考策略，在去中心化的自博弈强化学习中提供似然奖励和 KL 散度，从而锚定策略到人类驾驶分布，实现了比大型生成模型快 10 倍、参数体积小 50 倍的逼真交通代理，并在 Waymo Sim Agents 挑战及闭环规划评估中取得竞争性能。", "keywords": "self-play, reinforcement learning, tokenized motion model, imitation learning, autonomous driving, human-like behavior, likelihood reward, KL anchoring, Waymo Sim Agents, scalable traffic simulation", "scoring": {"interpretability": 3, "understanding": 7, "safety": 7, "technicality": 8, "surprisal": 6}, "category": {"failure_mode_addressed": "misalignment", "primary_focus": "alignment"}, "authors": ["Wei-Jer Chang", "Akshay Rangesh", "Kevin Joseph", "Matthew Strong", "Masayoshi Tomizuka", "Yihan Hu", "Wei Zhan"]}, "usage": {"completion_tokens": 979, "prompt_tokens": 3474, "total_tokens": 4453, "completion_tokens_details": {"accepted_prediction_tokens": null, "audio_tokens": null, "reasoning_tokens": 857, "rejected_prediction_tokens": null, "image_tokens": 0}, "prompt_tokens_details": {"audio_tokens": 0, "cached_tokens": 3152}, "cost": 0.00078996, "is_byok": false, "cost_details": {"upstream_inference_cost": null, "upstream_inference_prompt_cost": 0.00030046, "upstream_inference_completions_cost": 0.0004895}}, "model": "openai/gpt-oss-120b"}
{"timestamp": "2025-10-22T03:29:25.809112", "feed": "arxiv_cslg", "title": "Joint Estimation of Piano Dynamics and Metrical Structure with a Multi-task Multi-Scale Network", "link": "https://papers.cool/arxiv/2510.18190", "analysis": {"summary": "The paper introduces a compact multi‑task multi‑scale neural network that jointly estimates piano dynamic levels, change points, beats, and downbeats from Bark‑scale specific loudness features, allowing 60‑second audio inputs with only 0.5 M parameters. Evaluated on the MazurkaBL dataset, it achieves state‑of‑the‑art performance across all four tasks, setting a new benchmark for piano dynamic estimation and enabling large‑scale, resource‑efficient analysis of musical expression.", "summary_cn": "本文提出一种紧凑的多任务多尺度神经网络，利用 Bark 频率尺度的特定响度特征，共享潜在表示以同时预测钢琴力度水平、变化点、拍子和下拍，实现 60 秒音频输入且仅需 0.5 M 参数。基于公开的 MazurkaBL 数据集评估后，模型在四项任务上均达到了最新的性能水平，树立了钢琴力度估计的新基准，并为大规模、资源高效的音乐表情分析提供了强大工具。", "keywords": "piano dynamics, beat tracking, downbeat detection, multi-task learning, multi-scale network, Bark-scale loudness", "scoring": {"interpretability": 2, "understanding": 5, "safety": 1, "technicality": 7, "surprisal": 5}, "category": {"failure_mode_addressed": "non-applicable", "primary_focus": "other"}, "authors": ["Zhanhong He", "Hanyu Meng", "David Huang", "Roberto Togneri"]}, "usage": {"completion_tokens": 725, "prompt_tokens": 3394, "total_tokens": 4119, "completion_tokens_details": {"accepted_prediction_tokens": null, "audio_tokens": null, "reasoning_tokens": 493, "rejected_prediction_tokens": null, "image_tokens": 0}, "prompt_tokens_details": {"audio_tokens": 0, "cached_tokens": 0}, "cost": 0.00042576, "is_byok": false, "cost_details": {"upstream_inference_cost": null, "upstream_inference_prompt_cost": 0.00013576, "upstream_inference_completions_cost": 0.00029}}, "model": "openai/gpt-oss-120b"}
{"timestamp": "2025-10-22T03:29:25.951342", "feed": "arxiv_cslg", "title": "Beating the Winner's Curse via Inference-Aware Policy Optimization", "link": "https://papers.cool/arxiv/2510.18161", "analysis": {"summary": "The paper introduces inference‑aware policy optimization, a method that jointly maximizes estimated objective value and the probability of achieving statistically significant improvement over an observational baseline, thereby mitigating the winner's curse in offline treatment‑selection problems. The authors derive the Pareto frontier of this trade‑off, propose an algorithm that uses counterfactual outcome predictors to estimate the frontier, and demonstrate its advantages in simulated experiments.", "summary_cn": "本文提出了推断感知的策略优化方法，在离线治疗决策问题中同时最大化预测目标值和超越观测基线并达到统计显著性的概率，以缓解胜者诅咒现象。作者推导了该两目标权衡的帕累托前沿，设计了利用反事实结果预测器估计前沿的算法，并模拟实验中展示了其效果。", "keywords": "offline policy learning, winner's curse, inference-aware optimization, counterfactual prediction, Pareto frontier, policy evaluation", "scoring": {"interpretability": 2, "understanding": 7, "safety": 5, "technicality": 8, "surprisal": 7}, "category": {"failure_mode_addressed": "misalignment", "primary_focus": "robustness"}, "authors": ["Hamsa Bastani", "Osbert Bastani", "Bryce McLaughlin"]}, "usage": {"completion_tokens": 595, "prompt_tokens": 3473, "total_tokens": 4068, "completion_tokens_details": {"accepted_prediction_tokens": null, "audio_tokens": null, "reasoning_tokens": 355, "rejected_prediction_tokens": null, "image_tokens": 0}, "prompt_tokens_details": {"audio_tokens": 0, "cached_tokens": 0}, "cost": 0.00087795, "is_byok": false, "cost_details": {"upstream_inference_cost": null, "upstream_inference_prompt_cost": 0.00052095, "upstream_inference_completions_cost": 0.000357}}, "model": "openai/gpt-oss-120b"}
{"timestamp": "2025-10-22T03:29:26.322025", "feed": "arxiv_cslg", "title": "AgentChangeBench: A Multi-Dimensional Evaluation Framework for Goal-Shift Robustness in Conversational AI", "link": "https://papers.cool/arxiv/2510.18170", "analysis": {"summary": "AgentChangeBench is a benchmark that evaluates how tool-augmented language model agents handle mid‑dialogue goal shifts across multiple enterprise domains, using four metrics: Task Success Rate, Tool Use Efficiency, Tool Call Redundancy Rate, and Goal‑Shift Recovery Time. The dataset contains 2,835 task sequences with five user personas designed to trigger realistic shifts, revealing that high static accuracy does not guarantee robustness under dynamic goals. Experiments on frontier models (e.g., GPT‑4o vs. Gemini) show large gaps in recovery performance and redundancy, highlighting the need for dedicated evaluation of goal‑shift resilience.", "summary_cn": "AgentChangeBench 是一个评估工具增强语言模型代理在多轮对话中应对目标变更能力的基准，使用任务成功率、工具使用效率、工具调用冗余率和目标变更恢复时间四个指标。数据集包含 2,835 条任务序列和五种用户角色，旨在模拟真实企业场景中的目标切换，揭示仅凭静态准确率并不能保证在动态目标下的鲁棒性。对前沿模型（如 GPT‑4o 与 Gemini）的实验显示恢复率和冗余率存在显著差距，强调了专门评估目标变更适应性的必要性。", "keywords": "goal shift, conversational AI, tool-augmented agents, robustness benchmark, task success rate, recovery time, enterprise domains, evaluation metrics", "scoring": {"interpretability": 2, "understanding": 7, "safety": 5, "technicality": 7, "surprisal": 7}, "category": {"failure_mode_addressed": "misalignment", "primary_focus": "robustness"}, "authors": ["Manik Rana", "Calissa Man", "Anotida Expected Msiiwa", "Jeffrey Paine", "Kevin Zhu", "Sunishchal Dev", "Vasu Sharma", "Ahan M R"]}, "usage": {"completion_tokens": 714, "prompt_tokens": 3466, "total_tokens": 4180, "completion_tokens_details": {"accepted_prediction_tokens": null, "audio_tokens": null, "reasoning_tokens": 374, "rejected_prediction_tokens": null, "image_tokens": 0}, "prompt_tokens_details": {"audio_tokens": 0, "cached_tokens": 0}, "cost": 0.00042424, "is_byok": false, "cost_details": {"upstream_inference_cost": null, "upstream_inference_prompt_cost": 0.00013864, "upstream_inference_completions_cost": 0.0002856}}, "model": "openai/gpt-oss-120b"}
{"timestamp": "2025-10-22T03:29:26.349065", "feed": "arxiv_cslg", "title": "Local Coherence or Global Validity? Investigating RLVR Traces in Math Domains", "link": "https://papers.cool/arxiv/2510.18176", "analysis": {"summary": "The paper investigates how post‑training with Reinforcement Learning with Verifiable Rewards (RLVR) affects the intermediate reasoning steps of a small LLM on math problems. By introducing a First‑Order Logic‑based trace‑coherence metric, they show that RLVR improves local coherence of reasoning traces, especially on cases where the base model fails, but this does not necessarily lead to logically valid or correct solutions. The work highlights the gap between improved trace coherence and final answer correctness, cautioning against conflating the two when claiming reasoning improvements.", "summary_cn": "本文研究了使用可验证奖励的强化学习（RLVR）进行后训练对小型语言模型在数学题目中间推理步骤的影响。通过引入基于一阶逻辑的“轨迹一致性”度量，作者发现 RLVR 能提升推理轨迹的局部一致性，尤其是在基础模型失败但 RL 模型成功的案例中，但这并不必然带来逻辑上有效或答案正确的解答。研究指出，提高局部一致性并不等同于获得有效的数学证明，提醒在声称推理能力提升时需谨慎区分两者。", "keywords": "RLVR, trace coherence, reasoning traces, GSM8K, GRPO, LLM alignment, interpretability, math reasoning, token-level analysis", "scoring": {"interpretability": 6, "understanding": 7, "safety": 2, "technicality": 7, "surprisal": 7}, "category": {"failure_mode_addressed": "non-applicable", "primary_focus": "interpretability"}, "authors": ["Soumya Rani Samineni", "Durgesh Kalwar", "Vardaan Gangal", "Siddhant Bhambri", "Subbarao Kambhampati"]}, "usage": {"completion_tokens": 867, "prompt_tokens": 3492, "total_tokens": 4359, "completion_tokens_details": {"accepted_prediction_tokens": null, "audio_tokens": null, "reasoning_tokens": 643, "rejected_prediction_tokens": null, "image_tokens": 0}, "prompt_tokens_details": {"audio_tokens": 0, "cached_tokens": 64}, "cost": 0.001044, "is_byok": false, "cost_details": {"upstream_inference_cost": null, "upstream_inference_prompt_cost": 0.0005238, "upstream_inference_completions_cost": 0.0005202}}, "model": "openai/gpt-oss-120b"}
{"timestamp": "2025-10-22T03:29:26.387774", "feed": "arxiv_cslg", "title": "Analyse comparative d'algorithmes de restauration en architecture dépliée pour des signaux chromatographiques parcimonieux", "link": "https://papers.cool/arxiv/2510.18760", "analysis": {"summary": "The paper conducts a comparative evaluation of three unfolded neural network architectures for restoring sparse chromatographic signals from degraded observations. Using parameterized chromatographic signal databases, the study assesses performance with metrics tailored to physico‑chemical peak characterization, highlighting the strengths of each approach.", "summary_cn": "本文比较了三种展开（unfolded）神经网络结构在稀疏色谱信号恢复中的表现。通过基于参数化色谱信号数据库的实验，使用针对物理化学峰特征的指标评估各方法的性能，揭示了它们的优势。", "keywords": "unfolded neural networks, signal restoration, sparse chromatographic signals, physico-chemical peak metrics, comparative study", "scoring": {"interpretability": 4, "understanding": 6, "safety": 2, "technicality": 7, "surprisal": 4}, "category": {"failure_mode_addressed": "non-applicable", "primary_focus": "other"}, "authors": ["Mouna Gharbi", "Silvia Villa", "Emilie Chouzenoux", "Jean-Christophe Pesquet", "Laurent Duval"]}, "usage": {"completion_tokens": 766, "prompt_tokens": 3278, "total_tokens": 4044, "completion_tokens_details": {"accepted_prediction_tokens": null, "audio_tokens": null, "reasoning_tokens": 683, "rejected_prediction_tokens": null, "image_tokens": 0}, "prompt_tokens_details": {"audio_tokens": 0, "cached_tokens": 3152}, "cost": 0.00065406, "is_byok": false, "cost_details": {"upstream_inference_cost": null, "upstream_inference_prompt_cost": 0.00027106, "upstream_inference_completions_cost": 0.000383}}, "model": "openai/gpt-oss-120b"}
{"timestamp": "2025-10-22T03:29:26.483585", "feed": "arxiv_cslg", "title": "Extracting Rule-based Descriptions of Attention Features in Transformers", "link": "https://papers.cool/arxiv/2510.18148", "analysis": {"summary": "The paper introduces a method to automatically extract rule‑based descriptions for Sparse Autoencoder (SAE) features in transformer attention layers, using skip‑gram, absence, and counting rules to capture token pattern influences on output probabilities. Experiments on GPT‑2 small show that most features can be succinctly described with about 100 skip‑gram rules, and that absence and counting rules are prevalent even in early layers. This work provides a taxonomy of rule types and demonstrates their utility as an alternative to exemplar‑based interpretations.", "summary_cn": "本文提出一种自动提取 Transformer 注意力层中稀疏自动编码器（SAE）特征的规则化描述的方法，利用跳词规则、缺失规则和计数规则捕获输入词模式对输出概率的影响。对 GPT‑2 small 的实验表明，大多数特征可以用约 100 条跳词规则简洁描述，且缺失规则和计数规则在早期层就已广泛出现。该工作给出了规则类型的初步分类，并展示了其相对于基于示例的解释的优势。", "keywords": "mechanistic interpretability, sparse autoencoder, attention features, rule-based description, skip-gram rules, absence rules, counting rules, GPT-2, transformer", "scoring": {"interpretability": 8, "understanding": 7, "safety": 2, "technicality": 7, "surprisal": 6}, "category": {"failure_mode_addressed": "non-applicable", "primary_focus": "interpretability"}, "authors": ["Dan Friedman", "Adithya Bhaskar", "Alexander Wettig", "Danqi Chen"]}, "usage": {"completion_tokens": 661, "prompt_tokens": 3547, "total_tokens": 4208, "completion_tokens_details": {"accepted_prediction_tokens": null, "audio_tokens": null, "reasoning_tokens": 368, "rejected_prediction_tokens": null, "image_tokens": 0}, "prompt_tokens_details": {"audio_tokens": 0, "cached_tokens": 0}, "cost": 0.00092865, "is_byok": false, "cost_details": {"upstream_inference_cost": null, "upstream_inference_prompt_cost": 0.00053205, "upstream_inference_completions_cost": 0.0003966}}, "model": "openai/gpt-oss-120b"}
{"timestamp": "2025-10-22T03:29:26.950908", "feed": "arxiv_cslg", "title": "A Definition of AGI", "link": "https://papers.cool/arxiv/2510.18212", "analysis": {"summary": "The paper proposes a quantifiable framework for defining Artificial General Intelligence (AGI) by aligning it with the cognitive versatility of a well‑educated adult, using the Cattell‑Horn‑Carroll theory to break intelligence into ten core domains and adapting human psychometric tests for AI evaluation. Applying the framework to current models reveals a highly uneven cognitive profile, with strong performance in knowledge‑intensive domains but major deficits in fundamental abilities such as long‑term memory storage, and provides concrete AGI scores for systems like GPT‑4 and GPT‑5.", "summary_cn": "本文提出一个可量化的 AGI（人工通用智能）定义框架，将其与受过良好教育的成人的认知多样性和熟练程度相匹配，基于 Cattell‑Horn‑Carroll（CHC）理论将智力划分为十个核心认知领域，并将已有的人类心理测量工具适配用于 AI 系统评估。对现有模型的应用显示出极其“锯齿形”的认知画像——在知识密集型领域表现优异，却在长期记忆存储等基础认知机器方面存在关键缺失，并给出如 GPT‑4（27%）和 GPT‑5（58%）等系统的 AGI 分数。", "keywords": "AGI definition, Cattell-Horn-Carroll, cognitive benchmarking, AI evaluation, psychometrics, intelligence measurement, capability gap", "scoring": {"interpretability": 2, "understanding": 7, "safety": 3, "technicality": 7, "surprisal": 6}, "category": {"failure_mode_addressed": "non-applicable", "primary_focus": "other"}, "authors": ["Dan Hendrycks", "Dawn Song", "Christian Szegedy", "Honglak Lee", "Yarin Gal", "Erik Brynjolfsson", "Sharon Li", "Andy Zou", "Lionel Levine", "Bo Han", "Jie Fu", "Ziwei Liu", "Jinwoo Shin", "Kimin Lee", "Mantas Mazeika", "Long Phan", "George Ingebretsen", "Adam Khoja", "Cihang Xie", "Olawale Salaudeen", "Matthias Hein", "Kevin Zhao", "Alexander Pan", "David Duvenaud", "Bo Li", "Steve Omohundro", "Gabriel Alfour", "Max Tegmark", "Kevin McGrew", "Gary Marcus", "Jaan Tallinn", "Eric Schmidt", "Yoshua Bengio"]}, "usage": {"completion_tokens": 723, "prompt_tokens": 3378, "total_tokens": 4101, "completion_tokens_details": {"accepted_prediction_tokens": null, "audio_tokens": null, "reasoning_tokens": 416, "rejected_prediction_tokens": null, "image_tokens": 0}, "prompt_tokens_details": {"audio_tokens": 0, "cached_tokens": 0}, "cost": 0.00049425, "is_byok": false, "cost_details": {"upstream_inference_cost": null, "upstream_inference_prompt_cost": 0.0001689, "upstream_inference_completions_cost": 0.00032535}}, "model": "openai/gpt-oss-120b"}
{"timestamp": "2025-10-22T03:29:27.612799", "feed": "arxiv_cslg", "title": "RESCUE: Retrieval Augmented Secure Code Generation", "link": "https://papers.cool/arxiv/2510.18204", "analysis": {"summary": "The paper introduces RESCUE, a retrieval‑augmented generation framework designed to improve the security of code produced by large language models. RESCUE builds a hybrid knowledge base by distilling security guidelines and slicing programs, then employs a hierarchical multi‑faceted retrieval that traverses this base and injects relevant security facts at each level. Experiments on four benchmarks show that RESCUE raises SecurePass@1 by about 4.8 points over existing methods, establishing a new state‑of‑the‑art for secure code generation.", "summary_cn": "本文提出 RESCUE，一种检索增强生成框架，旨在提升大语言模型生成代码的安全性。RESCUE 通过 LLM 辅助的聚类‑摘要蒸馏结合程序切片构建混合知识库，并采用层次化多层面检索，从上至下遍历知识库，在每一层整合关键的安全事实。实验在四个基准上表明，RESCUE 将 SecurePass@1 提升约 4.8 分，达到安全代码生成的最新水平。", "keywords": "secure code generation, retrieval-augmented generation, knowledge base distillation, hierarchical retrieval, security guidelines, code vulnerability, LLM safety, SecurePass, program slicing, RAG", "scoring": {"interpretability": 3, "understanding": 6, "safety": 8, "technicality": 7, "surprisal": 6}, "category": {"failure_mode_addressed": "misalignment", "primary_focus": "control"}, "authors": ["Jiahao Shi", "Tianyi Zhang"]}, "usage": {"completion_tokens": 1110, "prompt_tokens": 3452, "total_tokens": 4562, "completion_tokens_details": {"accepted_prediction_tokens": null, "audio_tokens": null, "reasoning_tokens": 989, "rejected_prediction_tokens": null, "image_tokens": 0}, "prompt_tokens_details": {"audio_tokens": 0, "cached_tokens": 0}, "cost": 0.00058208, "is_byok": false, "cost_details": {"upstream_inference_cost": null, "upstream_inference_prompt_cost": 0.00013808, "upstream_inference_completions_cost": 0.000444}}, "model": "openai/gpt-oss-120b"}
{"timestamp": "2025-10-22T03:29:27.742972", "feed": "arxiv_cslg", "title": "CARLE: A Hybrid Deep-Shallow Learning Framework for Robust and Explainable RUL Estimation of Rolling Element Bearings", "link": "https://papers.cool/arxiv/2510.17846", "analysis": {"summary": "The paper proposes CARLE, a hybrid deep‑shallow framework that combines Res‑CNN, Res‑LSTM with multi‑head attention and a Random Forest Regressor to predict the Remaining Useful Life of rolling element bearings. It includes a preprocessing stage with Gaussian filtering and Continuous Wavelet Transform, and demonstrates robustness and generalization across bearing datasets through extensive ablation, noise, and cross‑domain experiments. Model transparency is examined using LIME and SHAP to provide interpretability insights.", "summary_cn": "本文提出了 CARLE，一种融合 Res‑CNN、Res‑LSTM 多头注意力和随机森林回归器的深浅结合框架，用于预测滚动轴承的剩余使用寿命。系统采用高斯滤波和连续小波变换进行预处理，并通过消融、噪声和跨域实验在 XJTU‑SY 与 PRONOSTIA 数据集上展示了鲁棒性和泛化能力。作者使用 LIME 和 SHAP 分析模型透明性，以提升解释性。", "keywords": "remaining useful life, rolling element bearings, hybrid deep-shallow, Res-CNN, Res-LSTM, multi-head attention, random forest regressor, continuous wavelet transform, LIME, SHAP", "scoring": {"interpretability": 5, "understanding": 6, "safety": 2, "technicality": 7, "surprisal": 5}, "category": {"failure_mode_addressed": "non-applicable", "primary_focus": "robustness"}, "authors": ["Waleed Razzaq", "Yun-Bo Zhao"]}, "usage": {"completion_tokens": 845, "prompt_tokens": 3437, "total_tokens": 4282, "completion_tokens_details": {"accepted_prediction_tokens": null, "audio_tokens": null, "reasoning_tokens": 572, "rejected_prediction_tokens": null, "image_tokens": 0}, "prompt_tokens_details": {"audio_tokens": 0, "cached_tokens": 3152}, "cost": 0.00071741, "is_byok": false, "cost_details": {"upstream_inference_cost": null, "upstream_inference_prompt_cost": 0.00029491, "upstream_inference_completions_cost": 0.0004225}}, "model": "openai/gpt-oss-120b"}
{"timestamp": "2025-10-22T03:29:28.009679", "feed": "arxiv_cslg", "title": "Decoding Funded Research: Comparative Analysis of Topic Models and Uncovering the Effect of Gender and Geographic Location", "link": "https://papers.cool/arxiv/2510.18803", "analysis": {"summary": "This study analyzes 18 years (2005-2022) of NSERC-funded research proposals using three topic‑modeling approaches—LDA, Structural Topic Modeling, and BERTopic—and introduces COFFEE, a novel algorithm that enables covariate effect estimation for BERTopic. BERTopic consistently yields more granular, coherent, and emergent topics, such as the rapid growth of artificial‑intelligence research, while the covariate analysis uncovers provincial specializations and stable gender‑based thematic patterns across disciplines. The results provide an empirical basis for designing more equitable and effective funding strategies.", "summary_cn": "本研究对 2005–2022 年 18 年间 NSERC 资助的研究提案进行分析，比较了 LDA、结构主题模型 (STM) 和 BERTopic 三种主题建模方法，并提出了 COFFEE——一种用于 BERTopic 的协变量效应估计新算法。结果显示，BERTopic 能持续发现更细粒度、连贯且新兴的主题（如人工智能的快速扩张），而协变量分析则揭示了各省研究专长以及跨学科的一致性别主题模式。该工作为制定更公平、有效的科研资助策略提供了实证依据。", "keywords": "topic modeling, LDA, STM, BERTopic, COFFEE algorithm, gender analysis, geographic analysis, research funding, AI trends, NSERC", "scoring": {"interpretability": 3, "understanding": 7, "safety": 2, "technicality": 7, "surprisal": 6}, "category": {"failure_mode_addressed": "non-applicable", "primary_focus": "other"}, "authors": ["Shirin Tavakoli Kafiabad", "Andrea Schiffauerova", "Ashkan Ebadi"]}, "usage": {"completion_tokens": 796, "prompt_tokens": 3453, "total_tokens": 4249, "completion_tokens_details": {"accepted_prediction_tokens": null, "audio_tokens": null, "reasoning_tokens": 510, "rejected_prediction_tokens": null, "image_tokens": 0}, "prompt_tokens_details": {"audio_tokens": 0, "cached_tokens": 3152}, "cost": 0.00069531, "is_byok": false, "cost_details": {"upstream_inference_cost": null, "upstream_inference_prompt_cost": 0.00029731, "upstream_inference_completions_cost": 0.000398}}, "model": "openai/gpt-oss-120b"}
{"timestamp": "2025-10-22T03:29:28.031251", "feed": "arxiv_cslg", "title": "MTraining: Distributed Dynamic Sparse Attention for Efficient Ultra-Long Context Training", "link": "https://papers.cool/arxiv/2510.18830", "analysis": {"summary": "The paper presents MTraining, a distributed training framework that combines dynamic sparse attention, balanced sparse ring attention, and hierarchical sparse ring attention to efficiently train large language models on ultra‑long context windows. Using MTraining, the authors expand Qwen2.5‑3B’s context from 32K to 512K tokens on 32 A100 GPUs, achieving up to 6× higher throughput while maintaining accuracy across tasks such as RULER, PG‑19, InfiniteBench, and Needle‑in‑a‑Haystack.", "summary_cn": "本文提出 MTraining，一种分布式训练框架，结合动态稀疏注意力、平衡稀疏环形注意力和层次稀疏环形注意力，实现对超长上下文的大型语言模型的高效训练。使用 MTraining，作者在 32 台 A100 GPU 上将 Qwen2.5‑3B 的上下文长度从 32K 扩展至 512K token，训练吞吐量提升最多 6 倍，并在 RULER、PG‑19、InfiniteBench、Needle‑in‑a‑Haystack 等任务上保持模型准确性。", "keywords": "dynamic sparse attention, distributed training, ultra-long context, sparse ring attention, hierarchical sparse ring, LLM efficiency, Qwen2.5, large-scale training", "scoring": {"interpretability": 2, "understanding": 5, "safety": 3, "technicality": 8, "surprisal": 7}, "category": {"failure_mode_addressed": "non-applicable", "primary_focus": "other"}, "authors": ["Wenxuan Li", "Chengruidong Zhang", "Huiqiang Jiang", "Yucheng Li", "Yuqing Yang", "Lili Qiu"]}, "usage": {"completion_tokens": 966, "prompt_tokens": 3474, "total_tokens": 4440, "completion_tokens_details": {"accepted_prediction_tokens": null, "audio_tokens": null, "reasoning_tokens": 711, "rejected_prediction_tokens": null, "image_tokens": 0}, "prompt_tokens_details": {"audio_tokens": 0, "cached_tokens": 3152}, "cost": 0.00078346, "is_byok": false, "cost_details": {"upstream_inference_cost": null, "upstream_inference_prompt_cost": 0.00030046, "upstream_inference_completions_cost": 0.000483}}, "model": "openai/gpt-oss-120b"}
{"timestamp": "2025-10-22T03:29:29.143321", "feed": "arxiv_cslg", "title": "Lyapunov-Aware Quantum-Inspired Reinforcement Learning for Continuous-Time Vehicle Control: A Feasibility Study", "link": "https://papers.cool/arxiv/2510.18852", "analysis": {"summary": "The paper introduces a Lyapunov-Aware Quantum-Inspired Reinforcement Learning (LQRL) framework that couples variational quantum circuits with Lyapunov stability constraints for continuous-time vehicle longitudinal control. In an adaptive cruise control simulation, the stability‑aware policy gradient ensures asymptotic convergence and bounded state evolution, demonstrating safety‑guaranteed quantum policy learning despite occasional transient overshoot. The results show the feasibility of embedding formal safety verification into quantum reinforcement learning for autonomous control.", "summary_cn": "本文提出了一种基于李雅普诺夫的量子强化学习（LQRL）框架，将变分量子电路与李雅普诺夫稳定性分析相结合，用于连续时间车辆纵向控制。通过在自适应巡航控制仿真中嵌入稳定性约束的策略梯度，展示了在保证有界状态演化的前提下实现安全且可解释的控制。实验表明该方法能够在激进加速下出现瞬时超调，但整体保持系统稳定，验证了在量子强化学习中融合安全保证的可行性。", "keywords": "quantum reinforcement learning, Lyapunov stability, continuous-time control, autonomous vehicle, variational quantum circuits, safety-aware RL, policy gradient, quantum-inspired control, stability-constrained learning, adaptive cruise control", "scoring": {"interpretability": 5, "understanding": 7, "safety": 8, "technicality": 7, "surprisal": 7}, "category": {"failure_mode_addressed": "non-applicable", "primary_focus": "control"}, "authors": ["Nutkritta Kraipatthanapong", "Natthaphat Thathong", "Pannita Suksawas", "Thanunnut Klunklin", "Kritin Vongthonglua", "Krit Attahakul", "Aueaphum Aueawatthanaphisut"]}, "usage": {"completion_tokens": 920, "prompt_tokens": 3416, "total_tokens": 4336, "completion_tokens_details": {"accepted_prediction_tokens": null, "audio_tokens": null, "reasoning_tokens": 676, "rejected_prediction_tokens": null, "image_tokens": 0}, "prompt_tokens_details": {"audio_tokens": 0, "cached_tokens": 3152}, "cost": 0.00075176, "is_byok": false, "cost_details": {"upstream_inference_cost": null, "upstream_inference_prompt_cost": 0.00029176, "upstream_inference_completions_cost": 0.00046}}, "model": "openai/gpt-oss-120b"}
{"timestamp": "2025-10-22T03:29:29.477015", "feed": "arxiv_cslg", "title": "Interval Prediction of Annual Average Daily Traffic on Local Roads via Quantile Random Forest with High-Dimensional Spatial Data", "link": "https://papers.cool/arxiv/2510.18548", "analysis": {"summary": "The paper introduces an interval prediction method for Annual Average Daily Traffic (AADT) on minor roads by combining a Quantile Random Forest with Principal Component Analysis to quantify predictive uncertainty. Using data from over 2,000 roads in England and Wales, the approach achieves an 88.22% interval coverage probability and demonstrates improved accuracy and interpretability for transport planning.", "summary_cn": "该研究提出使用量化随机森林结合主成分分析，对英国和威尔士的次要道路年均日流量（AADT）进行区间预测，以量化不确定性并提供预测区间。实验在2000余条道路上验证，取得约88%的区间覆盖率和较窄的区间宽度，提升了交通规划的可靠性和可解释性。", "keywords": "annual average daily traffic, quantile random forest, interval prediction, uncertainty quantification, principal component analysis, high-dimensional spatial data, traffic estimation", "scoring": {"interpretability": 4, "understanding": 5, "safety": 2, "technicality": 6, "surprisal": 4}, "category": {"failure_mode_addressed": "non-applicable", "primary_focus": "interpretability"}, "authors": ["Ying Yao", "Daniel J. Graham"]}, "usage": {"completion_tokens": 741, "prompt_tokens": 3407, "total_tokens": 4148, "completion_tokens_details": {"accepted_prediction_tokens": null, "audio_tokens": null, "reasoning_tokens": 596, "rejected_prediction_tokens": null, "image_tokens": 0}, "prompt_tokens_details": {"audio_tokens": 0, "cached_tokens": 3152}, "cost": 0.00066091, "is_byok": false, "cost_details": {"upstream_inference_cost": null, "upstream_inference_prompt_cost": 0.00029041, "upstream_inference_completions_cost": 0.0003705}}, "model": "openai/gpt-oss-120b"}
{"timestamp": "2025-10-22T03:29:29.841250", "feed": "arxiv_cslg", "title": "SPIKE: Stable Physics-Informed Kernel Evolution Method for Solving Hyperbolic Conservation Laws", "link": "https://papers.cool/arxiv/2510.18266", "analysis": {"summary": "The paper presents SPIKE, a Stable Physics-Informed Kernel Evolution method that solves inviscid hyperbolic conservation laws by minimizing strong-form residuals while still capturing weak solutions with discontinuities. Using reproducing kernel representations and Tikhonov regularization, SPIKE smoothly transitions through shock formation without explicit shock detection or artificial viscosity, preserving conservation and satisfying Rankine‑Hugoniot conditions. Experiments on scalar and vector-valued conservation laws demonstrate the method’s effectiveness.", "summary_cn": "本文提出了 SPIKE（Stable Physics-Informed Kernel Evolution）方法，用于求解无粘性双曲守恒律，通过最小化强形式残差仍能捕获包含不连续性的弱解。该方法利用再现核（reproducing kernel）表示并通过 Tikhonov 正则化平滑地跨越冲击形成过程，无需显式冲击检测或人工粘性，自动保持守恒并满足 Rankine‑Hugoniot 条件。对标量及向量守恒律的数值实验验证了该方法的有效性。", "keywords": "hyperbolic conservation laws, physics-informed kernel methods, shock capturing, Tikhonov regularization, Rankine-Hugoniot conditions, reproducing kernels, numerical PDEs", "scoring": {"interpretability": 2, "understanding": 5, "safety": 1, "technicality": 8, "surprisal": 6}, "category": {"failure_mode_addressed": "non-applicable", "primary_focus": "other"}, "authors": ["Hua Su", "Lei Zhang", "Jin Zhao"]}, "usage": {"completion_tokens": 517, "prompt_tokens": 3330, "total_tokens": 3847, "completion_tokens_details": {"accepted_prediction_tokens": null, "audio_tokens": null, "reasoning_tokens": 178, "rejected_prediction_tokens": null, "image_tokens": 0}, "prompt_tokens_details": {"audio_tokens": 0, "cached_tokens": 3152}, "cost": 0.00053736, "is_byok": false, "cost_details": {"upstream_inference_cost": null, "upstream_inference_prompt_cost": 0.00027886, "upstream_inference_completions_cost": 0.0002585}}, "model": "openai/gpt-oss-120b"}
{"timestamp": "2025-10-22T03:29:29.864848", "feed": "arxiv_cslg", "title": "Counterfactual Reasoning for Steerable Pluralistic Value Alignment of Large Language Models", "link": "https://papers.cool/arxiv/2510.18526", "analysis": {"summary": "The paper introduces COUPLE, a framework that uses structural causal models and counterfactual reasoning to align large language models with pluralistic human values, capturing interdependencies and priority among value dimensions. By explicitly modeling causal relationships between high‑level values and model behavior, COUPLE enables fine‑grained control over value steering and improves interpretability of the alignment process. Experiments on two datasets show that COUPLE outperforms existing baselines across diverse value objectives.", "summary_cn": "本文提出 COUPLE 框架，利用结构因果模型和反事实推理将大型语言模型与多元人类价值观对齐，捕捉价值维度之间的相互依赖和优先级。通过显式建模高层价值与模型行为之间的因果关系，COUPLE 能实现细粒度的价值引导并提升对齐过程的可解释性。在两个不同价值体系的数据集上实验表明，COUPLE 在多种价值目标下均优于现有基线。", "keywords": "pluralistic value alignment, counterfactual reasoning, structural causal model, LLM steerability, value prioritization, interpretability, alignment, causal modeling", "scoring": {"interpretability": 7, "understanding": 7, "safety": 7, "technicality": 7, "surprisal": 7}, "category": {"failure_mode_addressed": "misalignment", "primary_focus": "alignment"}, "authors": ["Hanze Guo", "Jing Yao", "Xiao Zhou", "Xiaoyuan Yi", "Xing Xie"]}, "usage": {"completion_tokens": 760, "prompt_tokens": 3457, "total_tokens": 4217, "completion_tokens_details": {"accepted_prediction_tokens": null, "audio_tokens": null, "reasoning_tokens": 558, "rejected_prediction_tokens": null, "image_tokens": 0}, "prompt_tokens_details": {"audio_tokens": 0, "cached_tokens": 3152}, "cost": 0.00067791, "is_byok": false, "cost_details": {"upstream_inference_cost": null, "upstream_inference_prompt_cost": 0.00029791, "upstream_inference_completions_cost": 0.00038}}, "model": "openai/gpt-oss-120b"}
{"timestamp": "2025-10-22T03:29:30.516928", "feed": "arxiv_cslg", "title": "Learning from Generalization Patterns: An Evaluation-Driven Approach to Enhanced Data Augmentation for Fine-Tuning Small Language Models", "link": "https://papers.cool/arxiv/2510.18143", "analysis": {"summary": "The paper introduces PaDA-Agent, an evaluation-driven data augmentation framework that discovers failure patterns from validation data and generates targeted augmentation samples to narrow the generalization gap of small language models during fine-tuning. Experiments on the Llama 3.2 1B Instruct model show notable performance gains over existing LLM-based augmentation methods.", "summary_cn": "本文提出了 PaDA-Agent，一种基于评估的数 据增强框架，通过从验证数据中发现失败模式并生成针对性的增强样本，以缩小小语言模型微调时的泛化差距。对 Llama 3.2 1B Instruct 模型的实验表明，其性能明显优于现有的基于大型语言模型的增强方法。", "keywords": "data augmentation, small language models, evaluation-driven, pattern discovery, fine-tuning, generalization, PaDA-Agent, Llama 3.2, domain adaptation", "scoring": {"interpretability": 2, "understanding": 6, "safety": 2, "technicality": 7, "surprisal": 6}, "category": {"failure_mode_addressed": "non-applicable", "primary_focus": "other"}, "authors": ["Huan Song", "Deeksha Razdan", "Yiyue Qian", "Arijit Ghosh Chowdhury", "Parth Patwa", "Aman Chadha", "Shinan Zhang", "Sharlina Keshava", "Hannah Marlowe"]}, "usage": {"completion_tokens": 655, "prompt_tokens": 3990, "total_tokens": 4645, "completion_tokens_details": {"accepted_prediction_tokens": null, "audio_tokens": null, "reasoning_tokens": 366, "rejected_prediction_tokens": null, "image_tokens": 0}, "prompt_tokens_details": {"audio_tokens": 0, "cached_tokens": 0}, "cost": 0.00036325, "is_byok": false, "cost_details": {"upstream_inference_cost": null, "upstream_inference_prompt_cost": 0.0001995, "upstream_inference_completions_cost": 0.00016375}}, "model": "openai/gpt-oss-120b"}
{"timestamp": "2025-10-22T03:29:30.888349", "feed": "arxiv_cslg", "title": "A Multi-Evidence Framework Rescues Low- Power Prognostic Signals and Rejects Statistical Artifacts in Cancer Genomics", "link": "https://papers.cool/arxiv/2510.18571", "analysis": {"summary": "The authors present a five‑criteria computational framework that combines causal inference methods (inverse probability weighting, doubly robust estimation) with orthogonal biological validation to separate true prognostic signals from statistical artifacts in underpowered cancer genomics cohorts. Applied to TCGA breast‑cancer mortality data, the framework discards a false‑positive driver (RYR2) and highlights a biologically plausible candidate (KMT2C) despite marginal statistical significance, demonstrating how multi‑evidence integration can rescue low‑power signals.", "summary_cn": "作者提出了一种五准则计算框架，将因果推断（逆概率加权、双稳健估计）与生物学验证（表达、突变模式、文献）相结合，以在低功效的癌症基因组学数据中区分真实的预后信号和统计伪迹。在 TCGA 乳腺癌死亡率分析中，该框架排除了伪阳性的 RYR2 基因，同时尽管统计显著性边缘，却因强生物证据而突出 KMT2C 基因，展示了多证据整合在拯救低功效信号方面的有效性。", "keywords": "causal inference, cancer genomics, prognostic biomarkers, low-power studies, multi-evidence framework, TCGA, KMT2C, RYR2, inverse probability weighting, doubly robust estimation", "scoring": {"interpretability": 2, "understanding": 2, "safety": 1, "technicality": 8, "surprisal": 6}, "category": {"failure_mode_addressed": "non-applicable", "primary_focus": "other"}, "authors": ["Gokturk Aytug Akarlar"]}, "usage": {"completion_tokens": 701, "prompt_tokens": 3551, "total_tokens": 4252, "completion_tokens_details": {"accepted_prediction_tokens": null, "audio_tokens": null, "reasoning_tokens": 371, "rejected_prediction_tokens": null, "image_tokens": 0}, "prompt_tokens_details": {"audio_tokens": 0, "cached_tokens": 3152}, "cost": 0.00066251, "is_byok": false, "cost_details": {"upstream_inference_cost": null, "upstream_inference_prompt_cost": 0.00031201, "upstream_inference_completions_cost": 0.0003505}}, "model": "openai/gpt-oss-120b"}
{"timestamp": "2025-10-22T03:29:31.323461", "feed": "arxiv_cslg", "title": "A machine learning approach to automation and uncertainty evaluation for self-validating thermocouples", "link": "https://papers.cool/arxiv/2510.18411", "analysis": {"summary": "The paper proposes a novel machine‑learning method to automatically detect the characteristic melting plateau of a phase‑change cell used in self‑validating thermocouples and to estimate the onset of melting with quantified uncertainty, eliminating manual analysis. Experiments on data from CCPI Europe achieve 100% plateau detection accuracy and a cross‑validated R² of 0.99 for calibration‑drift prediction.", "summary_cn": "本文提出一种新颖的机器学习方法，用于自动识别自校准热电偶中相变单元的熔融平台特征，并在检测到平台后量化熔融起始点及其不确定性，从而无需人工干预。基于 CCPI Europe 提供的测试数据，实验实现了 100% 的平台检测准确率，并在校准漂移预测上获得 0.99 的交叉验证 R²。", "keywords": "thermocouple, self-validating, phase-change cell, melting plateau detection, machine learning, uncertainty quantification, calibration drift", "scoring": {"interpretability": 2, "understanding": 5, "safety": 3, "technicality": 6, "surprisal": 5}, "category": {"failure_mode_addressed": "non-applicable", "primary_focus": "other"}, "authors": ["Samuel Bilson", "Andrew Thompson", "Declan Tucker", "Jonathan Pearce"]}, "usage": {"completion_tokens": 596, "prompt_tokens": 3471, "total_tokens": 4067, "completion_tokens_details": {"accepted_prediction_tokens": null, "audio_tokens": null, "reasoning_tokens": 355, "rejected_prediction_tokens": null, "image_tokens": 0}, "prompt_tokens_details": {"audio_tokens": 0, "cached_tokens": 3152}, "cost": 0.00059801, "is_byok": false, "cost_details": {"upstream_inference_cost": null, "upstream_inference_prompt_cost": 0.00030001, "upstream_inference_completions_cost": 0.000298}}, "model": "openai/gpt-oss-120b"}
{"timestamp": "2025-10-22T03:29:31.384446", "feed": "arxiv_cslg", "title": "Differentially Private E-Values", "link": "https://papers.cool/arxiv/2510.18654", "analysis": {"summary": "The paper introduces a general framework for converting non-private e-values into differentially private ones by using a novel biased multiplicative noise mechanism that preserves statistical validity. It proves that the private e-values retain strong power and are asymptotically as powerful as the original e-values, and validates the method on tasks such as online risk monitoring, private healthcare analysis, and conformal e-prediction.", "summary_cn": "本文提出了一种通用框架，将非私密 e 值通过新颖的带偏乘性噪声机制转化为差分隐私 e 值，从而保持统计有效性。作者证明了私密 e 值仍具有强大的统计功效，并在在线风险监控、私密医疗和符合性 e 预测等场景中验证了该方法的有效性。", "keywords": "differential privacy, e-values, biased multiplicative noise, statistical inference, private hypothesis testing, online risk monitoring, conformal prediction", "scoring": {"interpretability": 2, "understanding": 6, "safety": 4, "technicality": 8, "surprisal": 6}, "category": {"failure_mode_addressed": "non-applicable", "primary_focus": "other"}, "authors": ["Daniel Csillag", "Diego Mesquita"]}, "usage": {"completion_tokens": 713, "prompt_tokens": 3950, "total_tokens": 4663, "completion_tokens_details": {"accepted_prediction_tokens": null, "audio_tokens": null, "reasoning_tokens": 416, "rejected_prediction_tokens": null, "image_tokens": 0}, "prompt_tokens_details": {"audio_tokens": 0, "cached_tokens": 0}, "cost": 0.00037575, "is_byok": false, "cost_details": {"upstream_inference_cost": null, "upstream_inference_prompt_cost": 0.0001975, "upstream_inference_completions_cost": 0.00017825}}, "model": "openai/gpt-oss-120b"}
{"timestamp": "2025-10-22T03:29:31.516344", "feed": "arxiv_cslg", "title": "ECG-LLM-- training and evaluation of domain-specific large language models for electrocardiography", "link": "https://papers.cool/arxiv/2510.18339", "analysis": {"summary": "The paper investigates how to adapt open-weight large language models to the electrocardiography domain by fine‑tuning on specialty literature and compares them against retrieval‑augmented generation (RAG) and a proprietary model (Claude Sonnet 3.7). Finetuned Llama 3.1 70B outperforms its base model on multiple-choice and automatic metrics, while Claude 3.7 and RAG are preferred by human experts for complex queries. The study highlights significant heterogeneity across evaluation methods and demonstrates that domain‑specific adaptation can achieve competitive performance while preserving privacy.", "summary_cn": "本文研究了如何通过在心电图专用文献上微调开源大语言模型来实现领域适配，并将其与检索增强生成 (RAG) 和商业模型 Claude Sonnet 3.7 进行比较。微调后的 Llama 3.1 70B 在多项选择题和自动指标上超越了基础模型，而在人类专家的复杂查询评估中 Claude 3.7 与 RAG 更受青睐。研究指出评估方法之间存在显著差异，并证明领域特化的微调和 RAG 可以在保持隐私的前提下实现与专有模型竞争的性能。", "keywords": "electrocardiography, domain adaptation, large language models, fine-tuning, retrieval-augmented generation, medical AI, privacy, evaluation", "scoring": {"interpretability": 2, "understanding": 6, "safety": 4, "technicality": 7, "surprisal": 6}, "category": {"failure_mode_addressed": "non-applicable", "primary_focus": "other"}, "authors": ["Lara Ahrens", "Wilhelm Haverkamp", "Nils Strodthoff"]}, "usage": {"completion_tokens": 640, "prompt_tokens": 3447, "total_tokens": 4087, "completion_tokens_details": {"accepted_prediction_tokens": null, "audio_tokens": null, "reasoning_tokens": 286, "rejected_prediction_tokens": null, "image_tokens": 0}, "prompt_tokens_details": {"audio_tokens": 0, "cached_tokens": 3152}, "cost": 0.00061641, "is_byok": false, "cost_details": {"upstream_inference_cost": null, "upstream_inference_prompt_cost": 0.00029641, "upstream_inference_completions_cost": 0.00032}}, "model": "openai/gpt-oss-120b"}
{"timestamp": "2025-10-22T03:29:31.683250", "feed": "arxiv_cslg", "title": "Zero-Shot Vehicle Model Recognition via Text-Based Retrieval-Augmented Generation", "link": "https://papers.cool/arxiv/2510.18502", "analysis": {"summary": "The paper proposes a pipeline that combines a vision‑language model (VLM) with retrieval‑augmented generation (RAG) to achieve zero‑shot vehicle make and model recognition. The VLM extracts descriptive attributes from an image, retrieves matching textual entries from a database, and a language model uses the combined prompt to infer the vehicle identity, avoiding costly finetuning and enabling rapid updates for new models. Experiments show roughly a 20% improvement over a CLIP baseline, highlighting the potential of text‑based reasoning for scalable VMMR in smart‑city contexts.", "summary_cn": "本文提出一种将视觉语言模型（VLM）与检索增强生成（RAG）相结合的流水线，实现零样本车辆品牌和型号识别。VLM 从图像中提取描述性属性，检索匹配的文本特征条目，再将其与描述一起构成提示，语言模型据此推断车辆的品牌和型号，从而避免大规模微调并能够通过新增文本快速适配新车型。实验表明该方法比 CLIP 基线提升约 20%，展示了基于文本推理的可扩展车辆识别在智慧城市中的潜力。", "keywords": "vehicle model recognition, zero-shot, CLIP, retrieval-augmented generation, vision-language model, smart city", "scoring": {"interpretability": 2, "understanding": 5, "safety": 1, "technicality": 6, "surprisal": 5}, "category": {"failure_mode_addressed": "non-applicable", "primary_focus": "other"}, "authors": ["Wei-Chia Chang", "Yan-Ann Chen"]}, "usage": {"completion_tokens": 706, "prompt_tokens": 3392, "total_tokens": 4098, "completion_tokens_details": {"accepted_prediction_tokens": null, "audio_tokens": null, "reasoning_tokens": 396, "rejected_prediction_tokens": null, "image_tokens": 0}, "prompt_tokens_details": {"audio_tokens": 0, "cached_tokens": 3152}, "cost": 0.00064116, "is_byok": false, "cost_details": {"upstream_inference_cost": null, "upstream_inference_prompt_cost": 0.00028816, "upstream_inference_completions_cost": 0.000353}}, "model": "openai/gpt-oss-120b"}
{"timestamp": "2025-10-22T03:29:31.698931", "feed": "arxiv_cslg", "title": "Parametrising the Inhomogeneity Inducing Capacity of a Training Set, and its Impact on Supervised Learning", "link": "https://papers.cool/arxiv/2510.18332", "analysis": {"summary": "The paper defines an \"inhomogeneity parameter\" that quantifies the extent to which a training set requires an inhomogeneous correlation structure in the target function. It shows how to compute this parameter for various datasets and proves that, within Gaussian‑process regression, a non‑zero inhomogeneity parameter forces the use of a non‑stationary kernel, affecting prediction quality and reliability on test inputs.", "summary_cn": "本文提出了“inhomogeneity parameter”（不均匀性参数），用于量化训练集是否需要在目标函数中呈现不均匀的相关结构，并提供了在不同数据集上计算该参数的方法。文中证明，在基于高斯过程的回归框架中，若不均匀性参数为非零，则必须使用非平稳核函数，这会影响模型在测试输入上的预测质量和可靠性。", "keywords": "inhomogeneity parameter, non-stationary Gaussian process, dataset heterogeneity, supervised learning, prediction reliability, training set analysis", "scoring": {"interpretability": 2, "understanding": 6, "safety": 5, "technicality": 8, "surprisal": 6}, "category": {"failure_mode_addressed": "non-applicable", "primary_focus": "robustness"}, "authors": ["Gargi Roy", "Dalia Chakrabarty"]}, "usage": {"completion_tokens": 570, "prompt_tokens": 3410, "total_tokens": 3980, "completion_tokens_details": {"accepted_prediction_tokens": null, "audio_tokens": null, "reasoning_tokens": 338, "rejected_prediction_tokens": null, "image_tokens": 0}, "prompt_tokens_details": {"audio_tokens": 0, "cached_tokens": 3152}, "cost": 0.00057586, "is_byok": false, "cost_details": {"upstream_inference_cost": null, "upstream_inference_prompt_cost": 0.00029086, "upstream_inference_completions_cost": 0.000285}}, "model": "openai/gpt-oss-120b"}
{"timestamp": "2025-10-22T03:29:31.744686", "feed": "arxiv_cslg", "title": "Vision Foundation Models Can Be Good Tokenizers for Latent Diffusion Models", "link": "https://papers.cool/arxiv/2510.18457", "analysis": {"summary": "The paper introduces Vision Foundation Model Variational Autoencoder (VFM-VAE) as a direct tokenizer for Latent Diffusion Models, addressing the robustness issues of distillation‑based approaches. By redesigning the decoder with Multi‑Scale Latent Fusion and Progressive Resolution Reconstruction, and proposing the SE‑CKNNA metric for representation dynamics, the method achieves rapid convergence and state‑of‑the‑art image quality (gFID 1.62). The work demonstrates that integrating VFMs without distillation yields superior tokenization and diffusion alignment.", "summary_cn": "本文提出 Vision Foundation Model 变分自编码器 (VFM‑VAE) 直接用作潜在扩散模型的视觉分词器，以解决蒸馏方法导致的对齐鲁棒性下降问题。通过采用多尺度潜在融合与渐进分辨率重构的解码器设计，并引入 SE‑CKNNA 指标分析表示动态，方法显著加速收敛并实现先进的图像质量（gFID 1.62）。实验表明，直接整合 VFM 能够提供更优的分词与扩散对齐效果。", "keywords": "vision foundation models, latent diffusion, tokenizer, VFM-VAE, multi-scale latent fusion, SE-CKNNA, diffusion alignment, gFID", "scoring": {"interpretability": 3, "understanding": 6, "safety": 4, "technicality": 8, "surprisal": 7}, "category": {"failure_mode_addressed": "misalignment", "primary_focus": "alignment"}, "authors": ["Tianci Bi", "Xiaoyi Zhang", "Yan Lu", "Nanning Zheng"]}, "usage": {"completion_tokens": 756, "prompt_tokens": 3490, "total_tokens": 4246, "completion_tokens_details": {"accepted_prediction_tokens": null, "audio_tokens": null, "reasoning_tokens": 488, "rejected_prediction_tokens": null, "image_tokens": 0}, "prompt_tokens_details": {"audio_tokens": 0, "cached_tokens": 3152}, "cost": 0.00068086, "is_byok": false, "cost_details": {"upstream_inference_cost": null, "upstream_inference_prompt_cost": 0.00030286, "upstream_inference_completions_cost": 0.000378}}, "model": "openai/gpt-oss-120b"}
{"timestamp": "2025-10-22T03:29:31.967715", "feed": "arxiv_cslg", "title": "C-SWAP: Explainability-Aware Structured Pruning for Efficient Neural Networks Compression", "link": "https://papers.cool/arxiv/2510.18636", "analysis": {"summary": "The paper introduces C‑SWAP, an explainability‑aware one‑shot structured pruning framework that uses causal relationships between model predictions and internal structures to guide a progressive pruning process. By leveraging cause‑effect analysis, the method removes redundant components without fine‑tuning, achieving substantial model size reductions on CNN and vision‑transformer classifiers while preserving performance. Experiments show that C‑SWAP outperforms existing one‑shot pruning techniques in the trade‑off between compression and accuracy.", "summary_cn": "本文提出 C‑SWAP，一种基于可解释性的一次性结构化剪枝框架，利用模型预测与内部结构之间的因果关系（cause‑effect）进行渐进式剪枝。该方法在无需微调的情况下移除冗余结构，实现了对 CNN 和视觉 Transformer 分类模型的显著压缩，并保持了性能。实验表明，C‑SWAP 在压缩率与准确率的平衡上优于现有一次性剪枝方法。", "keywords": "structured pruning, one-shot pruning, explainability, causal-aware pruning, model compression, CNN, vision transformer, post-training pruning, efficiency, neural network compression", "scoring": {"interpretability": 6, "understanding": 6, "safety": 3, "technicality": 7, "surprisal": 7}, "category": {"failure_mode_addressed": "non-applicable", "primary_focus": "other"}, "authors": ["Baptiste Bauvin", "Loïc Baret", "Ola Ahmad"]}, "usage": {"completion_tokens": 782, "prompt_tokens": 3480, "total_tokens": 4262, "completion_tokens_details": {"accepted_prediction_tokens": null, "audio_tokens": null, "reasoning_tokens": 569, "rejected_prediction_tokens": null, "image_tokens": 0}, "prompt_tokens_details": {"audio_tokens": 0, "cached_tokens": 3152}, "cost": 0.00069236, "is_byok": false, "cost_details": {"upstream_inference_cost": null, "upstream_inference_prompt_cost": 0.00030136, "upstream_inference_completions_cost": 0.000391}}, "model": "openai/gpt-oss-120b"}
{"timestamp": "2025-10-22T03:29:32.482033", "feed": "arxiv_cslg", "title": "A Compositional Paradigm for Foundation Models: Towards Smarter Robotic Agents", "link": "https://papers.cool/arxiv/2510.18608", "analysis": {"summary": "The paper proposes integrating continual learning and compositionality principles into foundation models to enable more flexible and efficient robotic agents that can adapt to dynamic real‑world environments without full retraining. It outlines a compositional paradigm that leverages the rich representations of large multimodal models and introduces methods for incremental skill composition and knowledge transfer in robotics tasks.", "summary_cn": "本文提出将持续学习和组合性原则引入基础模型，以实现能够在动态真实环境中无需整体重新训练即可灵活、高效适应的机器人代理。文中阐述了一种组合范式，利用大规模多模态模型的丰富表征，提出了增量技能组合和知识转移的技术方法。", "keywords": "foundation models, continual learning, compositionality, robotic control, skill composition, knowledge transfer, adaptability, multimodal representations", "scoring": {"interpretability": 3, "understanding": 5, "safety": 4, "technicality": 7, "surprisal": 5}, "category": {"failure_mode_addressed": "non-applicable", "primary_focus": "robustness"}, "authors": ["Luigi Quarantiello", "Elia Piccoli", "Jack Bell", "Malio Li", "Giacomo Carfì", "Eric Nuertey Coleman", "Gerlando Gramaglia", "Lanpei Li", "Mauro Madeddu", "Irene Testa", "Vincenzo Lomonaco"]}, "usage": {"completion_tokens": 876, "prompt_tokens": 3301, "total_tokens": 4177, "completion_tokens_details": {"accepted_prediction_tokens": null, "audio_tokens": null, "reasoning_tokens": 826, "rejected_prediction_tokens": null, "image_tokens": 0}, "prompt_tokens_details": {"audio_tokens": 0, "cached_tokens": 3152}, "cost": 0.00071251, "is_byok": false, "cost_details": {"upstream_inference_cost": null, "upstream_inference_prompt_cost": 0.00027451, "upstream_inference_completions_cost": 0.000438}}, "model": "openai/gpt-oss-120b"}
{"timestamp": "2025-10-22T03:29:32.568690", "feed": "arxiv_cslg", "title": "Channel-Aware Vector Quantization for Robust Semantic Communication on Discrete Channels", "link": "https://papers.cool/arxiv/2510.18604", "analysis": {"summary": "The paper introduces Channel-Aware Vector Quantization (CAVQ) within a joint source-channel coding framework (VQJSCC) that incorporates channel transition probabilities into the quantization process for discrete semantic communication over memoryless channels. By aligning easily confused symbols with semantically similar codewords and employing a multi-codebook alignment mechanism, the method mitigates the digital cliff effect and improves reconstruction quality across various modulation schemes. Experiments show that VQJSCC outperforms existing digital semantic communication baselines in robustness and efficiency.", "summary_cn": "本文提出在联合源信道编码框架（VQJSCC）中加入通道感知向量量化（CAVQ），将离散信道的转移概率纳入量化过程，实现语义特征与调制星座的直接映射。通过多码本对齐机制，将易混淆的符号与语义相似的码字对应，从而缓解数字悬崖效应，在多种调制方案下提升重建质量。实验表明 VQJSCC 在鲁棒性和效率方面均优于现有的数字语义通信基线。", "keywords": "semantic communication, vector quantization, channel-aware quantization, joint source-channel coding, discrete memoryless channel, robustness, digital cliff effect, multi-codebook alignment, modulation schemes", "scoring": {"interpretability": 2, "understanding": 6, "safety": 3, "technicality": 7, "surprisal": 6}, "category": {"failure_mode_addressed": "non-applicable", "primary_focus": "robustness"}, "authors": ["Zian Meng", "Qiang Li", "Wenqian Tang", "Mingdie Yan", "Xiaohu Ge"]}, "usage": {"completion_tokens": 813, "prompt_tokens": 3415, "total_tokens": 4228, "completion_tokens_details": {"accepted_prediction_tokens": null, "audio_tokens": null, "reasoning_tokens": 552, "rejected_prediction_tokens": null, "image_tokens": 0}, "prompt_tokens_details": {"audio_tokens": 0, "cached_tokens": 3152}, "cost": 0.00069811, "is_byok": false, "cost_details": {"upstream_inference_cost": null, "upstream_inference_prompt_cost": 0.00029161, "upstream_inference_completions_cost": 0.0004065}}, "model": "openai/gpt-oss-120b"}
{"timestamp": "2025-10-22T03:29:32.574064", "feed": "arxiv_cslg", "title": "Fostering the Ecosystem of AI for Social Impact Requires Expanding and Strengthening Evaluation Standards", "link": "https://papers.cool/arxiv/2510.18238", "analysis": {"summary": "The paper argues that current review criteria for AI/ML for social impact overemphasize projects that combine deployment with novel methodological contributions, which can discourage valuable single-front contributions. It proposes expanding the notion of social impact beyond deployment and adopting more rigorous impact evaluations for deployed systems to sustain a healthy research ecosystem.", "summary_cn": "本文指出当前 AI/ML 社会影响研究的评审标准过于强调同时实现部署和创新方法的项目，这可能抑制仅在单一方向（如纯应用或纯方法）上有价值的工作。作者主张在评估标准中拓宽对社会影响的定义，超越仅关注部署，并对已部署系统进行更严格的影响评估，以促进社会影响 AI 研究生态的可持续发展。", "keywords": "AI for social impact, evaluation standards, deployment, methodological innovation, impact assessment, research ecosystem, social impact metrics, AI policy", "scoring": {"interpretability": 2, "understanding": 6, "safety": 5, "technicality": 6, "surprisal": 5}, "category": {"failure_mode_addressed": "societal-disruption", "primary_focus": "other"}, "authors": ["Bryan Wilder", "Angela Zhou"]}, "usage": {"completion_tokens": 686, "prompt_tokens": 3338, "total_tokens": 4024, "completion_tokens_details": {"accepted_prediction_tokens": null, "audio_tokens": null, "reasoning_tokens": 484, "rejected_prediction_tokens": null, "image_tokens": 0}, "prompt_tokens_details": {"audio_tokens": 0, "cached_tokens": 3152}, "cost": 0.00062306, "is_byok": false, "cost_details": {"upstream_inference_cost": null, "upstream_inference_prompt_cost": 0.00028006, "upstream_inference_completions_cost": 0.000343}}, "model": "openai/gpt-oss-120b"}
{"timestamp": "2025-10-22T03:29:32.860656", "feed": "arxiv_cslg", "title": "Mixed Monotonicity Reachability Analysis of Neural ODE: A Trade-Off Between Tightness and Efficiency", "link": "https://papers.cool/arxiv/2510.17859", "analysis": {"summary": "The paper introduces an interval‑based reachability analysis for neural ordinary differential equations that leverages continuous‑time mixed‑monotonicity embeddings to obtain sound over‑approximations of reachable sets. Implemented in the TIRA toolbox, the method offers a trade‑off between tightness and computational efficiency, outperforming zonotope and star‑set approaches on high‑dimensional, real‑time safety‑critical examples. The approach is demonstrated on two neural ODE models—a spiral system and a fixed‑point attractor—highlighting its scalability for formal verification.", "summary_cn": "本文提出了一种基于区间的神经常微分方程式（neural ODE）可达性分析方法，利用连续时间混合单调性嵌入来计算可达集合的可信上界。该方法在 TIRA 工具箱中实现，在紧致性与计算效率之间实现权衡，并在高维、实时安全关键场景中相较于 zonotope 与星形集方法表现更优。作者在螺旋系统和固定点吸引子两种神经 ODE 示例上展示了该方法的可扩展性，为形式化验证提供了轻量化手段。", "keywords": "neural ODE, mixed monotonicity, reachability analysis, interval methods, formal verification, safety-critical, TIRA, over-approximation, dynamical systems, real-time verification", "scoring": {"interpretability": 3, "understanding": 5, "safety": 7, "technicality": 8, "surprisal": 6}, "category": {"failure_mode_addressed": "other", "primary_focus": "robustness"}, "authors": ["Abdelrahman Sayed Sayed", "Pierre-Jean Meyer", "Mohamed Ghazel"]}, "usage": {"completion_tokens": 871, "prompt_tokens": 3478, "total_tokens": 4349, "completion_tokens_details": {"accepted_prediction_tokens": null, "audio_tokens": null, "reasoning_tokens": 596, "rejected_prediction_tokens": null, "image_tokens": 0}, "prompt_tokens_details": {"audio_tokens": 0, "cached_tokens": 0}, "cost": 0.0010443, "is_byok": false, "cost_details": {"upstream_inference_cost": null, "upstream_inference_prompt_cost": 0.0005217, "upstream_inference_completions_cost": 0.0005226}}, "model": "openai/gpt-oss-120b"}
{"timestamp": "2025-10-22T03:29:33.234610", "feed": "arxiv_cslg", "title": "A Distributed Framework for Causal Modeling of Performance Variability in GPU Traces", "link": "https://papers.cool/arxiv/2510.18300", "analysis": {"summary": "The paper introduces a distributed, end‑to‑end framework that partitions large GPU execution traces and processes them in parallel using causal graph methods to expose performance variability and dependencies. Experimental evaluation shows a 67% scalability improvement when analyzing multiple traces simultaneously, demonstrating the system’s effectiveness for high‑performance computing environments.", "summary_cn": "本文提出了一种分布式端到端框架，通过对大型 GPU 执行轨迹进行划分并并行处理，利用因果图方法揭示性能波动和执行流之间的依赖关系。实验结果显示，在同时分析多个轨迹时，系统的可扩展性提升了 67%，验证了其在高性能计算环境中的有效性。", "keywords": "causal modeling, GPU performance variability, distributed framework, parallel trace analysis, HPC, causal graphs, scalability, performance bottlenecks", "scoring": {"interpretability": 2, "understanding": 4, "safety": 1, "technicality": 7, "surprisal": 3}, "category": {"failure_mode_addressed": "non-applicable", "primary_focus": "other"}, "authors": ["Ankur Lahiry", "Ayush Pokharel", "Banooqa Banday", "Seth Ockerman", "Amal Gueroudji", "Mohammad Zaeed", "Tanzima Z. Islam", "Line Pouchard"]}, "usage": {"completion_tokens": 658, "prompt_tokens": 3320, "total_tokens": 3978, "completion_tokens_details": {"accepted_prediction_tokens": null, "audio_tokens": null, "reasoning_tokens": 501, "rejected_prediction_tokens": null, "image_tokens": 0}, "prompt_tokens_details": {"audio_tokens": 0, "cached_tokens": 3152}, "cost": 0.00060636, "is_byok": false, "cost_details": {"upstream_inference_cost": null, "upstream_inference_prompt_cost": 0.00027736, "upstream_inference_completions_cost": 0.000329}}, "model": "openai/gpt-oss-120b"}
{"timestamp": "2025-10-22T03:29:33.735697", "feed": "arxiv_cslg", "title": "S2AP: Score-space Sharpness Minimization for Adversarial Pruning", "link": "https://papers.cool/arxiv/2510.18381", "analysis": {"summary": "The paper introduces Score-space Sharpness-aware Adversarial Pruning (S2AP), a plug‑in technique that minimizes sharpness in the importance‑score space during mask selection for adversarial pruning, thereby stabilizing the binary mask and improving the robustness of compressed models. By perturbing importance scores and minimizing the resulting robust loss, S2AP reduces sharp local minima that previously caused unstable mask choices. Extensive experiments across datasets, models, and sparsity levels show consistent robustness gains over existing adversarial pruning pipelines.", "summary_cn": "本文提出了“Score-space Sharpness-aware Adversarial Pruning (S2AP)”方法，通过在权重重要性分数空间加入扰动并最小化相应的鲁棒损失，以降低分数空间的尖锐性，实现对抗性剪枝过程中的掩码选择更稳定，从而提升模型压缩后的鲁棒性。实验在多个数据集、模型和稀疏度下验证了 S2AP 相比传统对抗性剪枝方法在稳健性上的显著提升。", "keywords": "adversarial pruning, score-space sharpness, model compression, robustness, mask selection, importance scores, pruning stability, adversarial robustness, sparse networks, fine-tuning", "scoring": {"interpretability": 3, "understanding": 5, "safety": 6, "technicality": 7, "surprisal": 7}, "category": {"failure_mode_addressed": "other", "primary_focus": "robustness"}, "authors": ["Giorgio Piras", "Qi Zhao", "Fabio Brau", "Maura Pintor", "Christian Wressnegger", "Battista Biggio"]}, "usage": {"completion_tokens": 752, "prompt_tokens": 3435, "total_tokens": 4187, "completion_tokens_details": {"accepted_prediction_tokens": null, "audio_tokens": null, "reasoning_tokens": 482, "rejected_prediction_tokens": null, "image_tokens": 0}, "prompt_tokens_details": {"audio_tokens": 0, "cached_tokens": 3152}, "cost": 0.00067061, "is_byok": false, "cost_details": {"upstream_inference_cost": null, "upstream_inference_prompt_cost": 0.00029461, "upstream_inference_completions_cost": 0.000376}}, "model": "openai/gpt-oss-120b"}
{"timestamp": "2025-10-22T03:29:33.886595", "feed": "arxiv_cslg", "title": "CovMatch: Cross-Covariance Guided Multimodal Dataset Distillation with Trainable Text Encoder", "link": "https://papers.cool/arxiv/2510.18583", "analysis": {"summary": "CovMatch is a multimodal dataset distillation framework that aligns the cross‑covariance of real and synthetic image‑text features while regularizing each modality’s feature distribution. By jointly optimizing both the vision and text encoders, it achieves stronger cross‑modal alignment and improves retrieval performance, outperforming prior methods on Flickr30K and COCO with only 500 synthetic pairs.", "summary_cn": "CovMatch 是一种多模态数据蒸馏框架，通过对齐真实和合成图文特征的交叉协方差并对每个模态的特征分布进行正则化，实现对视觉编码器和文本编码器的联合优化，从而增强跨模态对齐并提升检索效果。实验表明，在 Flickr30K 与 COCO 数据集上，仅使用 500 对合成样本即可超越现有最先进方法，检索准确率提升最高 6.8%。", "keywords": "multimodal dataset distillation, cross-covariance alignment, vision-language models, synthetic image-text pairs, contrastive learning, Flickr30K, COCO, retrieval accuracy", "scoring": {"interpretability": 2, "understanding": 6, "safety": 2, "technicality": 8, "surprisal": 7}, "category": {"failure_mode_addressed": "non-applicable", "primary_focus": "other"}, "authors": ["Yongmin Lee", "Hye Won Chung"]}, "usage": {"completion_tokens": 885, "prompt_tokens": 3402, "total_tokens": 4287, "completion_tokens_details": {"accepted_prediction_tokens": null, "audio_tokens": null, "reasoning_tokens": 681, "rejected_prediction_tokens": null, "image_tokens": 0}, "prompt_tokens_details": {"audio_tokens": 0, "cached_tokens": 3152}, "cost": 0.00073216, "is_byok": false, "cost_details": {"upstream_inference_cost": null, "upstream_inference_prompt_cost": 0.00028966, "upstream_inference_completions_cost": 0.0004425}}, "model": "openai/gpt-oss-120b"}
{"timestamp": "2025-10-22T03:29:34.421035", "feed": "arxiv_cslg", "title": "CLARAE: Clarity Preserving Reconstruction AutoEncoder for Denoising and Rhythm Classification of Intracardiac Electrograms", "link": "https://papers.cool/arxiv/2510.17821", "analysis": {"summary": "CLARAE is a one‑dimensional encoder‑decoder designed for intracardiac atrial electrograms that preserves waveform morphology while compressing signals into a 64‑dimensional latent space. It delivers high‑fidelity reconstruction and robust denoising across a wide range of signal‑to‑noise ratios, and its latent embeddings enable rhythm classification with F1 scores above 0.97 and clear clustering by rhythm type. An interactive web application is provided for real‑time exploration of the pre‑trained models.", "summary_cn": "CLARAE 是一种一维 (autoencoder) 编码‑解码网络，专为心内房性电图设计，能够在保留波形形态的同时将信号压缩至 64 维的 latent 空间。该模型在广泛的信噪比范围内实现高保真重建和稳健去噪，并且其嵌入在节律分类任务中获得超过 0.97 的 F1 分数，且不同节律在 latent 空间中呈明显聚类。作者还提供交互式网页应用，方便实时探索预训练模型。", "keywords": "autoencoder, denoising, intracardiac electrogram, rhythm classification, latent embeddings, signal reconstruction, medical signal processing", "scoring": {"interpretability": 5, "understanding": 4, "safety": 2, "technicality": 7, "surprisal": 4}, "category": {"failure_mode_addressed": "non-applicable", "primary_focus": "other"}, "authors": ["Long Lin", "Pablo Peiro-Corbacho", "Pablo Ávila", "Alejandro Carta-Bergaz", "Ángel Arenal", "Gonzalo R. Ríos-Muñoz", "Carlos Sevilla-Salcedo"]}, "usage": {"completion_tokens": 811, "prompt_tokens": 3538, "total_tokens": 4349, "completion_tokens_details": {"accepted_prediction_tokens": null, "audio_tokens": null, "reasoning_tokens": 609, "rejected_prediction_tokens": null, "image_tokens": 0}, "prompt_tokens_details": {"audio_tokens": 0, "cached_tokens": 0}, "cost": 0.0010173, "is_byok": false, "cost_details": {"upstream_inference_cost": null, "upstream_inference_prompt_cost": 0.0005307, "upstream_inference_completions_cost": 0.0004866}}, "model": "openai/gpt-oss-120b"}
{"timestamp": "2025-10-22T03:29:34.966903", "feed": "arxiv_cslg", "title": "Decoding Listeners Identity: Person Identification from EEG Signals Using a Lightweight Spiking Transformer", "link": "https://papers.cool/arxiv/2510.17879", "analysis": {"summary": "The paper introduces a lightweight spiking transformer built on spiking neural networks for person identification from EEG signals, achieving 100% classification accuracy on the EEG-Music Emotion Recognition Challenge dataset while using less than 10% of the energy consumption of conventional deep neural networks. The approach leverages the temporal processing capabilities of SNNs to provide an efficient solution for security and personalized brain‑computer interface applications. Source code is released publicly.", "summary_cn": "本文提出一种基于脉冲神经网络（SNN）和轻量级脉冲Transformer的EEG个人身份识别方法，在EEG‑Music情感识别挑战数据集上实现了100%分类准确率，同时能耗仅为传统深度网络的10%以下。该方法利用SNN处理EEG信号的时间复杂性，为安全认证和个性化脑机接口提供了高效的解决方案。代码已公开发布。", "keywords": "EEG, person identification, spiking neural network, spiking transformer, energy-efficient BCI, low-power AI, temporal modeling, brain-computer interface, classification accuracy, lightweight architecture", "scoring": {"interpretability": 2, "understanding": 3, "safety": 3, "technicality": 7, "surprisal": 6}, "category": {"failure_mode_addressed": "non-applicable", "primary_focus": "other"}, "authors": ["Zheyuan Lin", "Siqi Cai", "Haizhou Li"]}, "usage": {"completion_tokens": 572, "prompt_tokens": 3357, "total_tokens": 3929, "completion_tokens_details": {"accepted_prediction_tokens": null, "audio_tokens": null, "reasoning_tokens": 295, "rejected_prediction_tokens": null, "image_tokens": 0}, "prompt_tokens_details": {"audio_tokens": 0, "cached_tokens": 0}, "cost": 0.00036308, "is_byok": false, "cost_details": {"upstream_inference_cost": null, "upstream_inference_prompt_cost": 0.00013428, "upstream_inference_completions_cost": 0.0002288}}, "model": "openai/gpt-oss-120b"}
{"timestamp": "2025-10-22T03:29:35.039350", "feed": "arxiv_cslg", "title": "Learning under Quantization for High-Dimensional Linear Regression", "link": "https://papers.cool/arxiv/2510.18259", "analysis": {"summary": "The paper provides the first rigorous theoretical analysis of low‑bit quantization effects on high‑dimensional linear regression trained with stochastic gradient descent, deriving algorithm‑ and data‑dependent excess risk bounds for quantizing data, labels, parameters, activations, and gradients. It shows that multiplicative (input‑dependent) quantization avoids spectral distortion of the data, while additive (fixed‑step) quantization yields a beneficial batch‑size scaling effect, and quantitatively compares these regimes for common polynomial‑decay spectra. These results illuminate how practical quantization strategies influence learning dynamics under hardware constraints.", "summary_cn": "本文首次对低位量化在高维线性回归中的影响进行严格理论分析，针对 SGD 训练过程中的数据、标签、参数、激活和梯度量化给出算法与数据相关的过剩风险上界。研究表明，乘性（输入相关）量化可以消除数据谱的失真，而加性（固定步长）量化则会产生随批量大小提升的有益尺度效应，并对常见的多项式衰减谱进行定量比较。这些结果阐明了实际硬件约束下量化策略对学习动态的影响。", "keywords": "quantization, high-dimensional linear regression, stochastic gradient descent, excess risk, additive quantization, multiplicative quantization, hardware constraints", "scoring": {"interpretability": 2, "understanding": 7, "safety": 2, "technicality": 8, "surprisal": 6}, "category": {"failure_mode_addressed": "non-applicable", "primary_focus": "other"}, "authors": ["Dechen Zhang", "Junwei Su", "Difan Zou"]}, "usage": {"completion_tokens": 720, "prompt_tokens": 3462, "total_tokens": 4182, "completion_tokens_details": {"accepted_prediction_tokens": null, "audio_tokens": null, "reasoning_tokens": 412, "rejected_prediction_tokens": null, "image_tokens": 0}, "prompt_tokens_details": {"audio_tokens": 0, "cached_tokens": 3152}, "cost": 0.00065866, "is_byok": false, "cost_details": {"upstream_inference_cost": null, "upstream_inference_prompt_cost": 0.00029866, "upstream_inference_completions_cost": 0.00036}}, "model": "openai/gpt-oss-120b"}
{"timestamp": "2025-10-22T03:29:35.185402", "feed": "arxiv_cslg", "title": "VLSU: Mapping the Limits of Joint Multimodal Understanding for AI Safety", "link": "https://papers.cool/arxiv/2510.18214", "analysis": {"summary": "The paper introduces Vision Language Safety Understanding (VLSU), a framework that evaluates multimodal foundation models by probing fine‑grained safety severity and combinatorial image‑text interactions across 17 safety patterns, revealing that joint reasoning performance drops dramatically compared to unimodal signals. Benchmarking eleven state‑of‑the‑art models on 8,187 annotated samples shows systematic failures in compositional safety judgment and a trade‑off between over‑blocking borderline content and under‑refusing clearly unsafe content. VLSU thus highlights critical alignment gaps and provides a testbed for improving robust vision‑language safety.", "summary_cn": "本文提出了视觉语言安全理解（VLSU）框架，通过对 17 种安全模式的细粒度严重程度分类和图文组合分析，系统评估多模态基础模型的安全性，发现模型在需要联合图像‑文本推理时表现大幅下降。对 8,187 条人工标注样本的十余种最先进模型评估显示，尽管单模态安全信号辨识准确率超 90%，但在联合理解上准确率仅为 20%~55%，且在边缘案例的阻断与拒绝之间存在显著权衡。VLSU 揭示了关键的对齐缺口，并提供了提升稳健视觉‑语言安全的基准测试平台。", "keywords": "multimodal safety, vision-language, compositional reasoning, benchmark, safety classification, joint understanding, alignment evaluation", "scoring": {"interpretability": 4, "understanding": 7, "safety": 9, "technicality": 8, "surprisal": 7}, "category": {"failure_mode_addressed": "misalignment", "primary_focus": "alignment"}, "authors": ["Shruti Palaskar", "Leon Gatys", "Mona Abdelrahman", "Mar Jacobo", "Larry Lindsey", "Rutika Moharir", "Gunnar Lund", "Yang Xu", "Navid Shiee", "Jeffrey Bigham", "Charles Maalouf", "Joseph Yitan Cheng"]}, "usage": {"completion_tokens": 684, "prompt_tokens": 3525, "total_tokens": 4209, "completion_tokens_details": {"accepted_prediction_tokens": null, "audio_tokens": null, "reasoning_tokens": 346, "rejected_prediction_tokens": null, "image_tokens": 0}, "prompt_tokens_details": {"audio_tokens": 0, "cached_tokens": 3152}, "cost": 0.00065011, "is_byok": false, "cost_details": {"upstream_inference_cost": null, "upstream_inference_prompt_cost": 0.00030811, "upstream_inference_completions_cost": 0.000342}}, "model": "openai/gpt-oss-120b"}
{"timestamp": "2025-10-22T03:29:35.370851", "feed": "arxiv_cslg", "title": "The Bias-Variance Tradeoff in Data-Driven Optimization: A Local Misspecification Perspective", "link": "https://papers.cool/arxiv/2510.18215", "analysis": {"summary": "The paper studies the bias-variance tradeoff among Sample Average Approximation (SAA), Estimate-Then-Optimize (ETO), and Integrated Estimation-Optimization (IEO) when the model is locally misspecified, i.e., nearly well‑specified. Using contiguity theory, it derives explicit formulas for decision bias and variance, revealing how the relative importance of bias and variance depends on the degree and direction of misspecification. These results provide a finer-grained understanding of when model‑based approaches outperform or underperform SAA under slight misspecification.", "summary_cn": "本文研究在局部失配（即模型几乎是良好指定）情形下，样本平均近似（SAA）、先估计再优化（ETO）以及集成估计‑优化（IEO）之间的偏差‑方差权衡。利用统计学中的相邻性理论，作者推导出决策偏差和方差的显式表达式，揭示偏差和方差的相对重要性随失配程度和方向的变化而变化。这些结果为在轻度失配情况下模型‑基方法相较于 SAA 的优劣提供了更细致的理解。", "keywords": "bias-variance tradeoff, data-driven stochastic optimization, local misspecification, sample average approximation, estimate-then-optimize, integrated estimation-optimization, contiguity theory", "scoring": {"interpretability": 2, "understanding": 6, "safety": 3, "technicality": 7, "surprisal": 5}, "category": {"failure_mode_addressed": "non-applicable", "primary_focus": "robustness"}, "authors": ["Haixiang Lan", "Luofeng Liao", "Adam N. Elmachtoub", "Christian Kroer", "Henry Lam", "Haofeng Zhang"]}, "usage": {"completion_tokens": 717, "prompt_tokens": 3436, "total_tokens": 4153, "completion_tokens_details": {"accepted_prediction_tokens": null, "audio_tokens": null, "reasoning_tokens": 388, "rejected_prediction_tokens": null, "image_tokens": 0}, "prompt_tokens_details": {"audio_tokens": 0, "cached_tokens": 3152}, "cost": 0.00065326, "is_byok": false, "cost_details": {"upstream_inference_cost": null, "upstream_inference_prompt_cost": 0.00029476, "upstream_inference_completions_cost": 0.0003585}}, "model": "openai/gpt-oss-120b"}
{"timestamp": "2025-10-22T03:29:35.387565", "feed": "arxiv_cslg", "title": "Three-dimensional inversion of gravity data using implicit neural representations", "link": "https://papers.cool/arxiv/2510.17876", "analysis": {"summary": "The paper introduces a scientific‑machine‑learning method for three‑dimensional gravity inversion that models subsurface density as a continuous field using an implicit neural representation (INR). By training a deep network with a physics‑based forward‑model loss and positional encoding, the approach reconstructs detailed geological structures without explicit meshes, regularisation, or depth weighting, demonstrating efficacy on synthetic Gaussian random fields and a dipping‑block model. The authors argue that INR provides a scalable and flexible inversion framework that could extend to other geophysical or joint‑physics problems.", "summary_cn": "本文提出一种基于科学机器学习的三维重力反演方法，使用隐式神经表示（INR）将地下密度建模为连续场。通过物理正演损失和位置编码直接训练深度网络，实现了无需预定义网格、正则化或深度加权的高分辨率地质结构重建，并在高斯随机场和倾斜块体模型上展示了效果。作者认为该框架具有可扩展性，可推广至其他地球物理或多物理联合反演。", "keywords": "implicit neural representation, gravity inversion, continuous density field, physics-informed neural network, positional encoding, geophysical inversion, synthetic experiments", "scoring": {"interpretability": 4, "understanding": 5, "safety": 2, "technicality": 7, "surprisal": 7}, "category": {"failure_mode_addressed": "non-applicable", "primary_focus": "other"}, "authors": ["Pankaj K Mishra", "Sanni Laaksonen", "Jochen Kamm", "Anand Singh"]}, "usage": {"completion_tokens": 665, "prompt_tokens": 3422, "total_tokens": 4087, "completion_tokens_details": {"accepted_prediction_tokens": null, "audio_tokens": null, "reasoning_tokens": 438, "rejected_prediction_tokens": null, "image_tokens": 0}, "prompt_tokens_details": {"audio_tokens": 0, "cached_tokens": 0}, "cost": 0.00040288, "is_byok": false, "cost_details": {"upstream_inference_cost": null, "upstream_inference_prompt_cost": 0.00013688, "upstream_inference_completions_cost": 0.000266}}, "model": "openai/gpt-oss-120b"}
{"timestamp": "2025-10-22T03:29:35.392813", "feed": "arxiv_cslg", "title": "LIME: Link-based user-item Interaction Modeling with decoupled xor attention for Efficient test time scaling", "link": "https://papers.cool/arxiv/2510.18239", "analysis": {"summary": "The paper introduces LIME, a novel recommendation architecture that decouples user‑candidate interactions via low‑rank link embeddings and employs a linear XOR‑based attention mechanism, reducing inference cost from quadratic to linear in sequence length and making it nearly independent of candidate set size. Experiments on public and industrial datasets demonstrate near‑state‑of‑the‑art accuracy with up to 10× speedup, and deployment on a large platform shows improved user engagement with minimal inference overhead.", "summary_cn": "本文提出 LIME，一种新颖的推荐系统架构，通过低秩“link embeddings”实现用户与候选项交互的预计算，并使用线性 XOR 注意力机制将对用户序列长度的复杂度从二次降至线性，使推理成本几乎与候选集规模无关。公共和工业数据集实验表明，在保持接近最先进准确率的同时，推理速度提升最高可达 10 倍；在大型推荐平台的实际部署也显示出用户互动提升且推理开销最小。", "keywords": "recommendation systems, efficient inference, linear attention, XOR attention, link embeddings, large-scale recommendation, decoupled attention, scaling, user-item interaction, LIME", "scoring": {"interpretability": 2, "understanding": 5, "safety": 2, "technicality": 8, "surprisal": 6}, "category": {"failure_mode_addressed": "non-applicable", "primary_focus": "other"}, "authors": ["Yunjiang Jiang", "Ayush Agarwal", "Yang Liu", "Bi Xue"]}, "usage": {"completion_tokens": 720, "prompt_tokens": 3458, "total_tokens": 4178, "completion_tokens_details": {"accepted_prediction_tokens": null, "audio_tokens": null, "reasoning_tokens": 461, "rejected_prediction_tokens": null, "image_tokens": 0}, "prompt_tokens_details": {"audio_tokens": 0, "cached_tokens": 3152}, "cost": 0.00065806, "is_byok": false, "cost_details": {"upstream_inference_cost": null, "upstream_inference_prompt_cost": 0.00029806, "upstream_inference_completions_cost": 0.00036}}, "model": "openai/gpt-oss-120b"}
{"timestamp": "2025-10-22T03:29:35.529013", "feed": "arxiv_cslg", "title": "Saber: An Efficient Sampling with Adaptive Acceleration and Backtracking Enhanced Remasking for Diffusion Language Model", "link": "https://papers.cool/arxiv/2510.18165", "analysis": {"summary": "Saber introduces a training‑free sampling algorithm for diffusion language models that adaptively accelerates generation and incorporates a back‑tracking remasking step, aiming to improve inference speed and maintain output quality in code‑generation tasks. Experiments on standard benchmarks show modest gains in Pass@1 accuracy (≈1.9 % improvement) while achieving over‑two‑fold speedup compared to existing DLM sampling methods. The method focuses on sampling efficiency rather than model interpretability or safety.", "summary_cn": "Saber 提出一种无需训练的采样算法，通过自适应加速和回溯重掩码来提升扩散语言模型在代码生成中的推理速度和输出质量。实验表明，在多个基准上 Pass@1 精度提升约 1.9%，推理速度提升约 251%。该工作主要关注采样效率，而非模型可解释性或安全性。", "keywords": "diffusion language model, code generation, adaptive acceleration, backtracking, sampling algorithm, inference speedup, Pass@1 accuracy", "scoring": {"interpretability": 3, "understanding": 5, "safety": 2, "technicality": 6, "surprisal": 5}, "category": {"failure_mode_addressed": "non-applicable", "primary_focus": "interpretability"}, "authors": ["Yihong Dong", "Zhaoyu Ma", "Xue Jiang", "Zhiyuan Fan", "Jiaru Qian", "Yongmin Li", "Jianha Xiao", "Zhi Jin", "Rongyu Cao", "Binhua Li", "Fei Huang", "Yongbin Li", "Ge Li"]}, "usage": {"completion_tokens": 266, "prompt_tokens": 3459, "total_tokens": 3725, "completion_tokens_details": {"accepted_prediction_tokens": null, "audio_tokens": null, "reasoning_tokens": 0, "rejected_prediction_tokens": null, "image_tokens": 0}, "prompt_tokens_details": {"audio_tokens": 0, "cached_tokens": 0}, "cost": 0.00029265, "is_byok": false, "cost_details": {"upstream_inference_cost": null, "upstream_inference_prompt_cost": 0.00017295, "upstream_inference_completions_cost": 0.0001197}}, "model": "openai/gpt-oss-120b"}
{"timestamp": "2025-10-22T03:29:35.667406", "feed": "arxiv_cslg", "title": "Provenance of AI-Generated Images: A Vector Similarity and Blockchain-based Approach", "link": "https://papers.cool/arxiv/2510.17854", "analysis": {"summary": "The paper introduces an embedding-based framework that uses image vectors and vector similarity to differentiate AI-generated images from human-created ones, hypothesizing that AI images cluster together in embedding space. Experiments across five benchmark embedding models show the method is robust to moderate perturbations and can efficiently verify image provenance, with a blockchain component for immutable tracking.", "summary_cn": "本文提出了一种基于图像嵌入向量和向量相似度的检测框架，用于区分 AI 生成的图像和人类创作的图像，假设 AI 图像在嵌入空间中会形成聚类。通过对五种基准嵌入模型的实验验证了该方法对中等程度扰动的鲁棒性，并结合区块链实现了图像来源的不可篡改追踪。", "keywords": "AI-generated image detection, vector similarity, image embeddings, blockchain provenance, deepfake detection, generative AI, content authentication", "scoring": {"interpretability": 2, "understanding": 5, "safety": 6, "technicality": 7, "surprisal": 5}, "category": {"failure_mode_addressed": "societal-disruption", "primary_focus": "robustness"}, "authors": ["Jitendra Sharma", "Arthur Carvalho", "Suman Bhunia"]}, "usage": {"completion_tokens": 528, "prompt_tokens": 3439, "total_tokens": 3967, "completion_tokens_details": {"accepted_prediction_tokens": null, "audio_tokens": null, "reasoning_tokens": 295, "rejected_prediction_tokens": null, "image_tokens": 0}, "prompt_tokens_details": {"audio_tokens": 0, "cached_tokens": 0}, "cost": 0.00034876, "is_byok": false, "cost_details": {"upstream_inference_cost": null, "upstream_inference_prompt_cost": 0.00013756, "upstream_inference_completions_cost": 0.0002112}}, "model": "openai/gpt-oss-120b"}
{"timestamp": "2025-10-22T03:29:35.803186", "feed": "arxiv_cslg", "title": "Illusions of reflection: open-ended task reveals systematic failures in Large Language Models' reflective reasoning", "link": "https://papers.cool/arxiv/2510.18254", "analysis": {"summary": "The paper investigates whether the \"reflection\" exhibited by frontier large language models functions like human reflective reasoning by testing them on an open‑ended, rule‑constrained task of generating scientific test items and revising them after self‑critique. Results show poor first‑pass performance and only modest gains after reflection, with models often repeating the same constraint violations, indicating that current reflective mechanisms lack goal‑driven error detection and principled repair. The authors conclude that reliable constraint adherence requires external structure rather than relying on internal reflection.", "summary_cn": "本文研究了前沿大语言模型的“反思”是否具有人类式的反思推理能力，采用一个开放式且受规则限制的任务：生成科学测试题并在自我批评后进行修正。实验发现模型首次生成表现差，反思后提升有限且常重复相同的约束违规，表明当前的反思机制缺乏目标驱动的错误检测和原则性修复。作者认为，要实现可靠的约束遵守仍需外部结构的强制，而不能仅依赖模型内部的反思。", "keywords": "reflective reasoning, large language models, self-correction, open-ended tasks, constraint violation, mechanistic interpretability, AI safety, evaluation", "scoring": {"interpretability": 6, "understanding": 7, "safety": 4, "technicality": 6, "surprisal": 7}, "category": {"failure_mode_addressed": "misalignment", "primary_focus": "interpretability"}, "authors": ["Sion Weatherhead", "Flora Salim", "Aaron Belbasis"]}, "usage": {"completion_tokens": 788, "prompt_tokens": 3479, "total_tokens": 4267, "completion_tokens_details": {"accepted_prediction_tokens": null, "audio_tokens": null, "reasoning_tokens": 553, "rejected_prediction_tokens": null, "image_tokens": 0}, "prompt_tokens_details": {"audio_tokens": 0, "cached_tokens": 3152}, "cost": 0.00069521, "is_byok": false, "cost_details": {"upstream_inference_cost": null, "upstream_inference_prompt_cost": 0.00030121, "upstream_inference_completions_cost": 0.000394}}, "model": "openai/gpt-oss-120b"}
{"timestamp": "2025-10-22T03:29:36.546538", "feed": "arxiv_cslg", "title": "Deploying Atmospheric and Oceanic AI Models on Chinese Hardware and Framework: Migration Strategies, Performance Optimization and Analysis", "link": "https://papers.cool/arxiv/2510.17852", "analysis": {"summary": "The paper presents a framework for migrating large-scale atmospheric and oceanic AI models, such as FourCastNet and AI‑GOMS, from PyTorch to MindSpore and optimizing them for Chinese domestic chips. It details software‑hardware adaptation, memory optimization, and parallelism techniques, and evaluates training speed, inference speed, accuracy, and energy efficiency compared to GPU implementations. Experimental results show that the migration preserves model accuracy while significantly improving operational efficiency on Chinese hardware.", "summary_cn": "本文提出了一个迁移大型大气和海洋 AI 模型（如 FourCastNet 和 AI‑GOMS）从 PyTorch 到 MindSpore 并针对国产芯片进行优化的框架。文章阐述了软件‑硬件适配、内存优化和并行化技术，并在训练速度、推理速度、模型精度和能效等指标上与 GPU 实现进行对比评估。实验结果表明，迁移过程保持了原有模型精度，同时在国产芯片上显著提升了运行效率。", "keywords": "atmospheric AI, oceanic AI, model migration, MindSpore, Chinese chips, performance optimization, FourCastNet, AI-GOMS", "scoring": {"interpretability": 2, "understanding": 5, "safety": 2, "technicality": 7, "surprisal": 5}, "category": {"failure_mode_addressed": "non-applicable", "primary_focus": "other"}, "authors": ["Yuze Sun", "Wentao Luo", "Yanfei Xiang", "Jiancheng Pan", "Jiahao Li", "Quan Zhang", "Xiaomeng Huang"]}, "usage": {"completion_tokens": 623, "prompt_tokens": 3404, "total_tokens": 4027, "completion_tokens_details": {"accepted_prediction_tokens": null, "audio_tokens": null, "reasoning_tokens": 369, "rejected_prediction_tokens": null, "image_tokens": 0}, "prompt_tokens_details": {"audio_tokens": 0, "cached_tokens": 0}, "cost": 0.00038536, "is_byok": false, "cost_details": {"upstream_inference_cost": null, "upstream_inference_prompt_cost": 0.00013616, "upstream_inference_completions_cost": 0.0002492}}, "model": "openai/gpt-oss-120b"}
{"timestamp": "2025-10-22T03:29:36.700700", "feed": "arxiv_cslg", "title": "Single-Snapshot Gridless 2D-DoA Estimation for UCAs: A Joint Optimization Approach", "link": "https://papers.cool/arxiv/2510.17818", "analysis": {"summary": "The paper proposes a joint optimization framework for gridless two‑dimensional direction‑of‑arrival (DOA) estimation using a uniform circular array (UCA) from a single snapshot. By simultaneously estimating a manifold transformation matrix and the azimuth‑elevation source pairs, the method is solved with an inexact Augmented Lagrangian Method (iALM), avoiding costly semidefinite programming. Simulations show the approach achieves robust, high‑resolution DOA estimates in the challenging single‑snapshot scenario.", "summary_cn": "本文提出一种联合优化框架，用于在仅有单次快照的情况下对均匀圆形阵列（UCA）进行无格二维方向到达（DOA）估计。通过同时估计流形变换矩阵和方位‑俯仰源对，并采用不完全增强拉格朗日方法（iALM）求解，完全规避了半正定规划的高计算成本。仿真结果表明该方法在单快照条件下能够实现稳健且高分辨率的DOA估计。", "keywords": "gridless DOA estimation, uniform circular array, single snapshot, augmented Lagrangian, iALM, joint optimization, signal processing", "scoring": {"interpretability": 1, "understanding": 3, "safety": 1, "technicality": 8, "surprisal": 5}, "category": {"failure_mode_addressed": "non-applicable", "primary_focus": "other"}, "authors": ["Salar Nouri"]}, "usage": {"completion_tokens": 641, "prompt_tokens": 3386, "total_tokens": 4027, "completion_tokens_details": {"accepted_prediction_tokens": null, "audio_tokens": null, "reasoning_tokens": 377, "rejected_prediction_tokens": null, "image_tokens": 0}, "prompt_tokens_details": {"audio_tokens": 0, "cached_tokens": 0}, "cost": 0.00039184, "is_byok": false, "cost_details": {"upstream_inference_cost": null, "upstream_inference_prompt_cost": 0.00013544, "upstream_inference_completions_cost": 0.0002564}}, "model": "openai/gpt-oss-120b"}
{"timestamp": "2025-10-22T03:29:36.714224", "feed": "arxiv_cslg", "title": "Synthetic EEG Generation using Diffusion Models for Motor Imagery Tasks", "link": "https://papers.cool/arxiv/2510.17832", "analysis": {"summary": "The paper introduces a methodology that employs Diffusion Probabilistic Models to generate synthetic EEG signals for motor imagery brain-computer interface tasks. Experimental results show that the generated data achieve classification accuracies above 95% and exhibit low mean squared error and high correlation with real recordings, indicating their potential to augment limited EEG datasets. This approach aims to alleviate data scarcity and improve model performance in EEG‑based BCI applications.", "summary_cn": "本文提出使用扩散概率模型（Diffusion Probabilistic Models）生成用于运动意象任务的合成脑电（EEG）信号的方法。实验表明，合成数据在分类任务中准确率超过 95%，且均方误差低、与真实信号高度相关，展示了其在补充有限 EEG 数据集、提升 BCI 模型性能方面的潜力。", "keywords": "synthetic EEG, diffusion probabilistic models, motor imagery, brain-computer interface, data augmentation, generative modeling, EEG classification", "scoring": {"interpretability": 3, "understanding": 6, "safety": 2, "technicality": 7, "surprisal": 6}, "category": {"failure_mode_addressed": "non-applicable", "primary_focus": "other"}, "authors": ["Henrique de Lima Alexandre", "Clodoaldo Aparecido de Moraes Lima"]}, "usage": {"completion_tokens": 672, "prompt_tokens": 3413, "total_tokens": 4085, "completion_tokens_details": {"accepted_prediction_tokens": null, "audio_tokens": null, "reasoning_tokens": 474, "rejected_prediction_tokens": null, "image_tokens": 0}, "prompt_tokens_details": {"audio_tokens": 0, "cached_tokens": 0}, "cost": 0.00047305, "is_byok": false, "cost_details": {"upstream_inference_cost": null, "upstream_inference_prompt_cost": 0.00017065, "upstream_inference_completions_cost": 0.0003024}}, "model": "openai/gpt-oss-120b"}
{"timestamp": "2025-10-22T03:29:37.051676", "feed": "arxiv_cslg", "title": "Arbitrated Indirect Treatment Comparisons", "link": "https://papers.cool/arxiv/2510.18071", "analysis": {"summary": "The paper proposes a new class of methods called arbitrated indirect treatment comparisons to resolve the MAIC paradox, where different sponsors reach conflicting conclusions due to targeting different populations. By estimating treatment effects in a common overlap population, the approach aims to provide consistent estimates across studies using individual participant data and aggregate data. The methodology is positioned as a solution for health technology assessment contexts where indirect comparisons are common.", "summary_cn": "本文提出一种称为仲裁间接治疗比较的新方法，以解决 MAIC 悖论——即不同资助方因针对不同人群而对同一数据得出冲突结论的问题。该方法通过在公共的重叠人群中估计治疗效果，实现了使用个体参与者数据和汇总数据的研究之间的一致估计。此方法旨在用于健康技术评估中的间接比较情境。", "keywords": "matching-adjusted indirect comparison, MAIC paradox, arbitrated indirect treatment comparison, overlap population, health technology assessment", "scoring": {"interpretability": 2, "understanding": 6, "safety": 1, "technicality": 7, "surprisal": 6}, "category": {"failure_mode_addressed": "non-applicable", "primary_focus": "other"}, "authors": ["Yixin Fang", "Weili He"]}, "usage": {"completion_tokens": 538, "prompt_tokens": 3362, "total_tokens": 3900, "completion_tokens_details": {"accepted_prediction_tokens": null, "audio_tokens": null, "reasoning_tokens": 287, "rejected_prediction_tokens": null, "image_tokens": 0}, "prompt_tokens_details": {"audio_tokens": 0, "cached_tokens": 3152}, "cost": 0.00055266, "is_byok": false, "cost_details": {"upstream_inference_cost": null, "upstream_inference_prompt_cost": 0.00028366, "upstream_inference_completions_cost": 0.000269}}, "model": "openai/gpt-oss-120b"}
{"timestamp": "2025-10-22T03:29:37.520958", "feed": "arxiv_cslg", "title": "In-Process Monitoring of Gear Power Honing Using Vibration Signal Analysis and Machine Learning", "link": "https://papers.cool/arxiv/2510.17809", "analysis": {"summary": "The paper proposes a data‑driven framework for real‑time monitoring of gear power honing by analyzing vibration signals with time‑frequency methods and machine learning. Three subspace learning techniques—PCA, PCA+LDA, and regularized uncorrelated multilinear discriminant analysis (R‑UMLDA)—are compared for feature extraction, and the resulting features are classified with an SVM into four gear‑quality categories, achieving up to 100% accuracy on industrial data. The approach yields interpretable spectral features linked to process dynamics, facilitating integration into predictive‑maintenance systems.", "summary_cn": "本文提出一种基于振动信号时频分析和机器学习的实时齿轮精整监控框架。比较了三种子空间学习方法（PCA、PCA+LDA、正则化非相关多线性判别分析 R‑UMLDA）用于特征提取，并用 SVM 将特征分类为四个齿轮质量等级，在工业实验数据上实现最高 100% 的准确率。该方法提供可解释的谱特征，能够反映加工过程动态，便于集成到预测性维护系统中。", "keywords": "vibration analysis, gear power honing, machine learning, PCA, LDA, R-UMLDA, SVM, in-process monitoring, predictive maintenance", "scoring": {"interpretability": 3, "understanding": 5, "safety": 2, "technicality": 7, "surprisal": 5}, "category": {"failure_mode_addressed": "non-applicable", "primary_focus": "other"}, "authors": ["Massimo Capurso", "Luciano Afferrante"]}, "usage": {"completion_tokens": 703, "prompt_tokens": 3512, "total_tokens": 4215, "completion_tokens_details": {"accepted_prediction_tokens": null, "audio_tokens": null, "reasoning_tokens": 399, "rejected_prediction_tokens": null, "image_tokens": 0}, "prompt_tokens_details": {"audio_tokens": 0, "cached_tokens": 0}, "cost": 0.00042168, "is_byok": false, "cost_details": {"upstream_inference_cost": null, "upstream_inference_prompt_cost": 0.00014048, "upstream_inference_completions_cost": 0.0002812}}, "model": "openai/gpt-oss-120b"}
{"timestamp": "2025-10-22T03:29:38.050709", "feed": "arxiv_cslg", "title": "Accelerating Vision Transformers with Adaptive Patch Sizes", "link": "https://papers.cool/arxiv/2510.18091", "analysis": {"summary": "The paper introduces Adaptive Patch Transformers (APT), which allocate multiple patch sizes within a single image, using larger patches in homogeneous regions and smaller patches in complex areas to reduce token count. This approach yields up to 50% speedup in inference and training for large Vision Transformers while preserving downstream performance, and can be applied to already fine‑tuned models with rapid convergence.", "summary_cn": "本文提出自适应补丁 Transformer（APT），在同一图像中使用不同尺寸的补丁，在结构单一的区域使用较大补丁，在复杂区域使用较小补丁，从而降低 token 数量。该方法在大型 Vision Transformer 上实现了最高 50% 的推理和训练加速，且保持下游任务性能，并可快速适配已微调模型。", "keywords": "adaptive patch, vision transformer, token reduction, efficient inference, dynamic patching, computer vision, ViT-L, ViT-H", "scoring": {"interpretability": 2, "understanding": 6, "safety": 1, "technicality": 8, "surprisal": 6}, "category": {"failure_mode_addressed": "non-applicable", "primary_focus": "other"}, "authors": ["Rohan Choudhury", "JungEun Kim", "Jinhyung Park", "Eunho Yang", "László A. Jeni", "Kris M. Kitani"]}, "usage": {"completion_tokens": 617, "prompt_tokens": 3363, "total_tokens": 3980, "completion_tokens_details": {"accepted_prediction_tokens": null, "audio_tokens": null, "reasoning_tokens": 398, "rejected_prediction_tokens": null, "image_tokens": 0}, "prompt_tokens_details": {"audio_tokens": 0, "cached_tokens": 3152}, "cost": 0.00059231, "is_byok": false, "cost_details": {"upstream_inference_cost": null, "upstream_inference_prompt_cost": 0.00028381, "upstream_inference_completions_cost": 0.0003085}}, "model": "openai/gpt-oss-120b"}
{"timestamp": "2025-10-22T03:29:38.149574", "feed": "arxiv_cslg", "title": "From AutoRecSys to AutoRecLab: A Call to Build, Evaluate, and Govern Autonomous Recommender-Systems Research Labs", "link": "https://papers.cool/arxiv/2510.18104", "analysis": {"summary": "The paper proposes a shift from narrow AutoRecSys tools to a fully autonomous Recommender‑Systems Research Lab (AutoRecLab) that automates the entire research pipeline, including problem ideation, experimental design, execution, result interpretation, and manuscript drafting. It outlines an agenda for the RecSys community to build open prototypes, establish benchmarks, create review venues for AI‑generated submissions, and define standards for attribution, reproducibility, ethics, governance, privacy, and fairness. The goal is to increase research throughput, uncover non‑obvious insights, and responsibly integrate automated research systems into the field.", "summary_cn": "本文提出将狭窄的 AutoRecSys 工具转变为完整的自主推荐系统研究实验室（AutoRecLab），实现从问题构思、实验设计与执行、结果解释到论文撰写的全流程自动化。文中提出社区应构建开源原型、设立评估基准、创建 AI 生成稿件的审稿渠道，并制定归属、可重复性以及伦理、治理、隐私和公平的标准，以提升研究产出效率并负责任地引入自动化研究系统。", "keywords": "autonomous recommender systems, AutoRecLab, automated research, LLM-driven ideation, reproducibility, AI governance, recommendation systems, safety, fairness", "scoring": {"interpretability": 2, "understanding": 5, "safety": 7, "technicality": 6, "surprisal": 5}, "category": {"failure_mode_addressed": "societal-disruption", "primary_focus": "control"}, "authors": ["Joeran Beel", "Bela Gipp", "Tobias Vente", "Moritz Baumgart", "Philipp Meister"]}, "usage": {"completion_tokens": 644, "prompt_tokens": 3474, "total_tokens": 4118, "completion_tokens_details": {"accepted_prediction_tokens": null, "audio_tokens": null, "reasoning_tokens": 325, "rejected_prediction_tokens": null, "image_tokens": 0}, "prompt_tokens_details": {"audio_tokens": 0, "cached_tokens": 3152}, "cost": 0.00062246, "is_byok": false, "cost_details": {"upstream_inference_cost": null, "upstream_inference_prompt_cost": 0.00030046, "upstream_inference_completions_cost": 0.000322}}, "model": "openai/gpt-oss-120b"}
{"timestamp": "2025-10-22T03:29:38.274413", "feed": "arxiv_cslg", "title": "Efficient Few-shot Identity Preserving Attribute Editing for 3D-aware Deep Generative Models", "link": "https://papers.cool/arxiv/2510.18287", "analysis": {"summary": "The paper proposes an efficient few-shot method for identity‑preserving attribute editing in 3D‑aware generative face models, requiring only ten or fewer labeled images to estimate latent space edit directions. By leveraging existing face datasets with masks and the 2D Attribute Style Manipulation (ASM) technique, the authors demonstrate linear and continuous edits across poses, including one‑shot stylization and face aging. Experimental results show that the estimated directions enable photorealistic, view‑consistent edits while maintaining the subject's identity.", "summary_cn": "本文提出一种高效的少样本方法，对 3D 感知生成模型中的人脸进行身份保持的属性编辑，仅需十张或更少的标记图像即可估计潜在空间的编辑方向。通过利用带有掩码的人脸数据集以及二维属性风格操作（ASM）技术，展示了跨姿态的线性连续编辑，包括一次性风格化和人脸老化。实验表明，该方法能够实现真实感、视角一致的编辑，同时保持主体身份。", "keywords": "few-shot editing, identity preservation, 3D-aware generative models, latent space directions, facial attribute manipulation, style manifold, ASM, synthetic data", "scoring": {"interpretability": 3, "understanding": 6, "safety": 3, "technicality": 7, "surprisal": 5}, "category": {"failure_mode_addressed": "human-misuse", "primary_focus": "other"}, "authors": ["Vishal Vinod"]}, "usage": {"completion_tokens": 843, "prompt_tokens": 3558, "total_tokens": 4401, "completion_tokens_details": {"accepted_prediction_tokens": null, "audio_tokens": null, "reasoning_tokens": 592, "rejected_prediction_tokens": null, "image_tokens": 0}, "prompt_tokens_details": {"audio_tokens": 0, "cached_tokens": 3152}, "cost": 0.00073456, "is_byok": false, "cost_details": {"upstream_inference_cost": null, "upstream_inference_prompt_cost": 0.00031306, "upstream_inference_completions_cost": 0.0004215}}, "model": "openai/gpt-oss-120b"}
{"timestamp": "2025-10-22T03:29:40.045027", "feed": "arxiv_cslg", "title": "Finding the Sweet Spot: Optimal Data Augmentation Ratio for Imbalanced Credit Scoring Using ADASYN", "link": "https://papers.cool/arxiv/2510.18252", "analysis": {"summary": "The paper systematically evaluates different synthetic oversampling ratios using SMOTE, BorderlineSMOTE, and ADASYN on the Give Me Some Credit dataset, training XGBoost models and assessing performance via AUC and Gini. It finds that ADASYN with a 1x multiplication (doubling the minority class) yields the best results, corresponding to an optimal majority‑to‑minority ratio of about 6.6:1, while higher oversampling harms performance. This demonstrates a diminishing‑returns effect and provides a reproducible framework for determining optimal augmentation ratios in imbalanced credit scoring.", "summary_cn": "本文在 Give Me Some Credit 数据集上系统评估了 SMOTE、BorderlineSMOTE 和 ADASYN 等合成过采样比例，使用 XGBoost 进行建模并通过 AUC 和 Gini 指标评估性能。研究发现，ADASYN 的 1 倍倍率（即将少数类样本数量翻倍）实现了最佳效果，对应的多数类:少数类比例约为 6.6:1，且更高的过采样倍率会导致性能下降。该结果揭示了合成过样的递减收益现象，并为在不平衡信用评分场景中确定最佳数据增强比例提供了可复现的框架。", "keywords": "credit scoring, class imbalance, data augmentation, ADASYN, SMOTE, XGBoost, oversampling ratio, bootstrap evaluation, AUC, Gini", "scoring": {"interpretability": 2, "understanding": 6, "safety": 1, "technicality": 6, "surprisal": 6}, "category": {"failure_mode_addressed": "non-applicable", "primary_focus": "other"}, "authors": ["Luis H. Chia"]}, "usage": {"completion_tokens": 964, "prompt_tokens": 3578, "total_tokens": 4542, "completion_tokens_details": {"accepted_prediction_tokens": null, "audio_tokens": null, "reasoning_tokens": 656, "rejected_prediction_tokens": null, "image_tokens": 0}, "prompt_tokens_details": {"audio_tokens": 0, "cached_tokens": 3152}, "cost": 0.00079806, "is_byok": false, "cost_details": {"upstream_inference_cost": null, "upstream_inference_prompt_cost": 0.00031606, "upstream_inference_completions_cost": 0.000482}}, "model": "openai/gpt-oss-120b"}
{"timestamp": "2025-10-22T03:29:40.223420", "feed": "arxiv_cslg", "title": "MoMaGen: Generating Demonstrations under Soft and Hard Constraints for Multi-Step Bimanual Mobile Manipulation", "link": "https://papers.cool/arxiv/2510.18316", "analysis": {"summary": "The paper presents MoMaGen, a constrained‑optimization framework that automatically generates large, diverse demonstration datasets for multi‑step bimanual mobile manipulation. By enforcing hard constraints such as reachability and soft constraints like camera visibility, MoMaGen enables training imitation‑learning policies from a single human demonstration and requires only a few real‑world fine‑tuning trajectories for deployment on physical robots. Experiments on four tasks show higher dataset diversity than prior static‑bimanual methods and successful transfer to real hardware.", "summary_cn": "本文提出 MoMaGen，一种基于约束优化的自动化演示数据生成框架，用于多步骤双臂移动操作任务。该框架在确保可达性（hard constraint）等硬约束的同时，平衡相机可视性（soft constraint）等软约束，从单一人为示例生成多样化数据，并只需少量真实演示即可微调出可在实体机器人上部署的模仿学习策略。实验在四个任务上展示了较以往静态双臂方法更高的数据多样性以及成功的实际机器人迁移。", "keywords": "constrained optimization, data generation, imitation learning, bimanual manipulation, mobile robotics, demonstration synthesis, reachability constraints, camera visibility, robot learning, dataset diversity", "scoring": {"interpretability": 2, "understanding": 5, "safety": 3, "technicality": 8, "surprisal": 7}, "category": {"failure_mode_addressed": "non-applicable", "primary_focus": "other"}, "authors": ["Chengshu Li", "Mengdi Xu", "Arpit Bahety", "Hang Yin", "Yunfan Jiang", "Huang Huang", "Josiah Wong", "Sujay Garlanka", "Cem Gokmen", "Ruohan Zhang", "Weiyu Liu", "Jiajun Wu", "Roberto Martín-Martín", "Li Fei-Fei"]}, "usage": {"completion_tokens": 936, "prompt_tokens": 3469, "total_tokens": 4405, "completion_tokens_details": {"accepted_prediction_tokens": null, "audio_tokens": null, "reasoning_tokens": 736, "rejected_prediction_tokens": null, "image_tokens": 0}, "prompt_tokens_details": {"audio_tokens": 0, "cached_tokens": 3152}, "cost": 0.00076771, "is_byok": false, "cost_details": {"upstream_inference_cost": null, "upstream_inference_prompt_cost": 0.00029971, "upstream_inference_completions_cost": 0.000468}}, "model": "openai/gpt-oss-120b"}
{"timestamp": "2025-10-22T03:29:40.267247", "feed": "arxiv_cslg", "title": "Generalization Below the Edge of Stability: The Role of Data Geometry", "link": "https://papers.cool/arxiv/2510.18120", "analysis": {"summary": "The paper theoretically investigates how the geometry of data influences generalization in overparameterized two-layer ReLU networks trained below the edge of stability. It derives bounds that adapt to intrinsic dimension for mixtures of low‑dimensional balls and shows deterioration of rates as probability mass concentrates near the unit sphere, linking shatterability to memorization versus representation learning. These results unify several empirical observations about geometry‑dependent generalization.", "summary_cn": "本文从理论上探讨数据几何如何影响在边界稳定性以下训练的过参数化两层 ReLU 网络的泛化能力。研究给出针对低维球混合分布的内在维度自适应的泛化界，并展示当概率质量集中于单位球面时，泛化速率会恶化，说明易被 ReLU 阈值“打碎”的数据倾向于记忆而非共享特征学习。这些结果统一了此前关于数据几何与泛化的若干实验观察。", "keywords": "generalization, data geometry, edge of stability, overparameterized neural networks, two-layer ReLU, implicit bias, low-dimensional manifolds, spectral bounds", "scoring": {"interpretability": 2, "understanding": 7, "safety": 1, "technicality": 8, "surprisal": 6}, "category": {"failure_mode_addressed": "non-applicable", "primary_focus": "other"}, "authors": ["Tongtong Liang", "Alexander Cloninger", "Rahul Parhi", "Yu-Xiang Wang"]}, "usage": {"completion_tokens": 757, "prompt_tokens": 3410, "total_tokens": 4167, "completion_tokens_details": {"accepted_prediction_tokens": null, "audio_tokens": null, "reasoning_tokens": 503, "rejected_prediction_tokens": null, "image_tokens": 0}, "prompt_tokens_details": {"audio_tokens": 0, "cached_tokens": 3152}, "cost": 0.00066936, "is_byok": false, "cost_details": {"upstream_inference_cost": null, "upstream_inference_prompt_cost": 0.00029086, "upstream_inference_completions_cost": 0.0003785}}, "model": "openai/gpt-oss-120b"}
{"timestamp": "2025-10-22T03:29:40.551897", "feed": "arxiv_cslg", "title": "SimBA: Simplifying Benchmark Analysis Using Performance Matrices Alone", "link": "https://papers.cool/arxiv/2510.17998", "analysis": {"summary": "The paper introduces SimBA, a three‑phase framework (stalk, prowl, pounce) that uses only raw evaluation scores to analyze large language model benchmarks, discover a small representative subset of datasets, and predict performance on unseen models. Applied to HELM, MMLU, and BigBenchLite, SimBA achieves >95% coverage with a tiny fraction of datasets and can preserve model rankings with near‑zero mean‑squared error predictions. The approach aims to aid model developers in efficient training decisions and help dataset creators assess novelty relative to existing benchmarks.", "summary_cn": "本文提出了 SimBA，一个由三个阶段（stalk、prowl、pounce）组成的框架，仅利用原始评估分数对大规模语言模型基准进行分析、发现小规模代表性数据子集，并预测未见模型的性能。在 HELM、MMLU 和 BigBenchLite 基准上的实验表明，SimBA 能以极少的数据子集实现>95%的覆盖，并且在保持模型排名的同时，预测误差接近零。该方法旨在帮助模型开发者提高训练效率，并帮助数据集创建者评估新数据集相对于现有基准的差异性。", "keywords": "benchmark analysis, performance matrices, representative subset, model selection, LM benchmarks, HELM, MMLU, BigBenchLite", "scoring": {"interpretability": 2, "understanding": 6, "safety": 2, "technicality": 7, "surprisal": 6}, "category": {"failure_mode_addressed": "non-applicable", "primary_focus": "other"}, "authors": ["Nishant Subramani", "Alfredo Gomez", "Mona Diab"]}, "usage": {"completion_tokens": 649, "prompt_tokens": 3501, "total_tokens": 4150, "completion_tokens_details": {"accepted_prediction_tokens": null, "audio_tokens": null, "reasoning_tokens": 352, "rejected_prediction_tokens": null, "image_tokens": 0}, "prompt_tokens_details": {"audio_tokens": 0, "cached_tokens": 3152}, "cost": 0.00062901, "is_byok": false, "cost_details": {"upstream_inference_cost": null, "upstream_inference_prompt_cost": 0.00030451, "upstream_inference_completions_cost": 0.0003245}}, "model": "openai/gpt-oss-120b"}
{"timestamp": "2025-10-22T03:29:41.064262", "feed": "arxiv_cslg", "title": "Universal Spectral Tokenization via Self-Supervised Panchromatic Representation Learning", "link": "https://papers.cool/arxiv/2510.17959", "analysis": {"summary": "The paper introduces a universal spectral tokenizer that learns self-supervised representations from heterogeneous astronomical spectra across different object types and resolutions, processing them on native wavelength grids. The resulting aligned, homogeneous embeddings can be efficiently adapted to a variety of downstream tasks, demonstrating that a single model can unify spectral data across domains. This approach is presented as a building block for foundation models in astronomy and potentially other scientific fields with sequential data.", "summary_cn": "本文提出了一种通用光谱分词器，能够在自监督方式下从不同天体类型和分辨率的异构天文光谱中学习表征，直接在原始波长网格上处理数据。得到的对齐且同质的嵌入可高效适配多种下游任务，展示单一模型能够统一跨域光谱数据。作者将该方法视为天文学基础模型的关键构件，并有望拓展至其他具有异构序列数据的科学领域（如气候与医疗）。", "keywords": "spectral tokenization, self-supervised learning, heterogeneous spectra, foundation models, astronomy, representation learning", "scoring": {"interpretability": 3, "understanding": 5, "safety": 2, "technicality": 7, "surprisal": 6}, "category": {"failure_mode_addressed": "non-applicable", "primary_focus": "other"}, "authors": ["Jeff Shen", "Francois Lanusse", "Liam Holden Parker", "Ollie Liu", "Tom Hehir", "Leopoldo Sarra", "Lucas Meyer", "Micah Bowles", "Sebastian Wagner-Carena", "Sebastian Wagner-Carena", "Helen Qu", "Siavash Golkar", "Alberto Bietti", "Hatim Bourfoune", "Nathan Cassereau", "Pierre Cornette", "Keiya Hirashima", "Geraud Krawezik", "Ruben Ohana", "Nicholas Lourie", "Michael McCabe", "Rudy Morel", "Payel Mukhopadhyay", "Mariel Pettee", "Bruno Régaldo-Saint Blancard", "Kyunghyun Cho", "Miles Cranmer", "Shirley Ho"]}, "usage": {"completion_tokens": 681, "prompt_tokens": 3404, "total_tokens": 4085, "completion_tokens_details": {"accepted_prediction_tokens": null, "audio_tokens": null, "reasoning_tokens": 438, "rejected_prediction_tokens": null, "image_tokens": 0}, "prompt_tokens_details": {"audio_tokens": 0, "cached_tokens": 3152}, "cost": 0.00063046, "is_byok": false, "cost_details": {"upstream_inference_cost": null, "upstream_inference_prompt_cost": 0.00028996, "upstream_inference_completions_cost": 0.0003405}}, "model": "openai/gpt-oss-120b"}
{"timestamp": "2025-10-22T03:29:41.258480", "feed": "arxiv_cslg", "title": "ViBED-Net: Video Based Engagement Detection Network Using Face-Aware and Scene-Aware Spatiotemporal Cues", "link": "https://papers.cool/arxiv/2510.18016", "analysis": {"summary": "The paper introduces ViBED-Net, a dual‑stream deep network that jointly processes facial crops and full video frames with EfficientNetV2 to extract spatial features, then models their temporal dynamics using LSTM and Transformer encoders for student engagement detection in e‑learning videos. Evaluated on the DAiSEE dataset, the LSTM variant achieves 73.43% accuracy, surpassing prior state‑of‑the‑art methods and demonstrating the benefit of combining face‑aware and scene‑aware cues. The approach is modular and applicable to broader contexts such as user experience research and content personalization.", "summary_cn": "本文提出 ViBED-Net，一种双流深度网络，分别对面部裁剪和完整视频帧使用 EfficientNetV2 提取空间特征，再通过 LSTM 与 Transformer 编码器建模其时序信息，以实现在线学习场景中的学生参与度检测。 在 DAiSEE 数据集上，LSTM 版本取得 73.43% 的准确率，优于现有最先进方法，展示了面部与全场景线索结合的优势。 该模型结构模块化，可推广至用户体验研究和内容个性化等应用。", "keywords": "engagement detection, video analysis, facial expression, scene context, EfficientNetV2, LSTM, transformer, affective computing, e-learning", "scoring": {"interpretability": 2, "understanding": 5, "safety": 2, "technicality": 7, "surprisal": 5}, "category": {"failure_mode_addressed": "non-applicable", "primary_focus": "other"}, "authors": ["Prateek Gothwal", "Deeptimaan Banerjee", "Ashis Kumer Biswas"]}, "usage": {"completion_tokens": 680, "prompt_tokens": 3461, "total_tokens": 4141, "completion_tokens_details": {"accepted_prediction_tokens": null, "audio_tokens": null, "reasoning_tokens": 357, "rejected_prediction_tokens": null, "image_tokens": 0}, "prompt_tokens_details": {"audio_tokens": 0, "cached_tokens": 3152}, "cost": 0.00063851, "is_byok": false, "cost_details": {"upstream_inference_cost": null, "upstream_inference_prompt_cost": 0.00029851, "upstream_inference_completions_cost": 0.00034}}, "model": "openai/gpt-oss-120b"}
{"timestamp": "2025-10-22T03:29:41.435107", "feed": "arxiv_cslg", "title": "PGTT: Phase-Guided Terrain Traversal for Perceptive Legged Locomotion", "link": "https://papers.cool/arxiv/2510.18348", "analysis": {"summary": "The paper introduces Phase-Guided Terrain Traversal (PGTT), a perception‑aware deep reinforcement learning method for legged robots that imposes gait structure via reward shaping rather than explicit gait priors. PGTT encodes per‑leg phase with a cubic Hermite spline to adapt swing height to local terrain statistics and adds a swing‑phase contact penalty, enabling morphology‑agnostic policies trained in simulation and transferred to real robots such as Unitree Go2 and ANYmal‑C. Experiments show PGTT achieves higher success rates under disturbances and obstacles while converging roughly twice as fast as strong baselines.", "summary_cn": "本文提出相位引导地形穿越（PGTT）方法，通过奖励塑形而非显式的步态先验来约束四足机器人的步态结构，实现感知驱动的深度强化学习控制。PGTT 使用三次Hermite样条对每条腿的相位进行编码，以适应局部地形高度统计并加入相位接触惩罚，使策略能够在关节空间直接操作，具备形态无关性，并在仿真和真实机器人（如Unitree Go2、ANYmal‑C）上验证。实验表明 PGTT 在推力扰动和离散障碍下的成功率显著提升，并且收敛速度约为基线的两倍。", "keywords": "perceptive locomotion, reinforcement learning, phase-guided reward shaping, legged robots, terrain adaptation, morphology-agnostic control, heightmap, MuJoCo, real‑world transfer", "scoring": {"interpretability": 2, "understanding": 5, "safety": 3, "technicality": 8, "surprisal": 6}, "category": {"failure_mode_addressed": "non-applicable", "primary_focus": "control"}, "authors": ["Alexandros Ntagkas", "Chairi Kiourt", "Konstantinos Chatzilygeroudis"]}, "usage": {"completion_tokens": 1132, "prompt_tokens": 3513, "total_tokens": 4645, "completion_tokens_details": {"accepted_prediction_tokens": null, "audio_tokens": null, "reasoning_tokens": 858, "rejected_prediction_tokens": null, "image_tokens": 0}, "prompt_tokens_details": {"audio_tokens": 0, "cached_tokens": 3152}, "cost": 0.00087231, "is_byok": false, "cost_details": {"upstream_inference_cost": null, "upstream_inference_prompt_cost": 0.00030631, "upstream_inference_completions_cost": 0.000566}}, "model": "openai/gpt-oss-120b"}
{"timestamp": "2025-10-22T03:29:41.597333", "feed": "arxiv_cslg", "title": "When Intelligence Fails: An Empirical Study on Why LLMs Struggle with Password Cracking", "link": "https://papers.cool/arxiv/2510.17884", "analysis": {"summary": "The paper empirically evaluates several open‑source large language models on the task of password guessing from synthetic user profiles and finds that they achieve less than 1.5% Hit@10, far behind traditional rule‑based methods. Detailed analysis attributes the poor performance to limited domain adaptation and memorization capabilities of current LLMs when not fine‑tuned on leaked password data. The results highlight a key limitation of LLMs for adversarial cybersecurity applications.", "summary_cn": "本文对多种开源大语言模型在基于合成用户信息进行密码猜测的任务上进行实证评估，发现其 Hit@10 低于 1.5%，远逊于传统规则式方法。通过分析指出，当前 LLM 在缺乏泄露密码数据微调的情况下，缺乏足够的领域适应和记忆能力，导致在密码推断上表现不佳。研究揭示了 LLM 在对抗性网络安全场景中的关键局限性。", "keywords": "LLM, password cracking, cybersecurity, empirical study, adversarial misuse, language models, security, generative reasoning", "scoring": {"interpretability": 2, "understanding": 6, "safety": 5, "technicality": 6, "surprisal": 4}, "category": {"failure_mode_addressed": "human-misuse", "primary_focus": "other"}, "authors": ["Mohammad Abdul Rehman", "Syed Imad Ali Shah", "Abbas Anwar", "Noor Islam"]}, "usage": {"completion_tokens": 611, "prompt_tokens": 3487, "total_tokens": 4098, "completion_tokens_details": {"accepted_prediction_tokens": null, "audio_tokens": null, "reasoning_tokens": 335, "rejected_prediction_tokens": null, "image_tokens": 0}, "prompt_tokens_details": {"audio_tokens": 0, "cached_tokens": 3152}, "cost": 0.00060791, "is_byok": false, "cost_details": {"upstream_inference_cost": null, "upstream_inference_prompt_cost": 0.00030241, "upstream_inference_completions_cost": 0.0003055}}, "model": "openai/gpt-oss-120b"}
{"timestamp": "2025-10-22T03:29:41.811517", "feed": "arxiv_cslg", "title": "TritonRL: Training LLMs to Think and Code Triton Without Cheating", "link": "https://papers.cool/arxiv/2510.17891", "analysis": {"summary": "The paper introduces TritonRL, a domain‑specialized large language model for generating Triton kernels, trained via supervised fine‑tuning on curated datasets and further improved with a reinforcement‑learning framework that employs robust, verifiable rewards and hierarchical reward decomposition to mitigate reward hacking. Experiments on KernelBench show that TritonRL achieves state‑of‑the‑art correctness and speedup compared to existing Triton‑specific models, demonstrating the effectiveness of the RL‑based training paradigm for high‑performance kernel synthesis.", "summary_cn": "本文提出 TritonRL——一种面向 Triton 内核生成的专用大型语言模型，通过在精选数据集上进行监督微调后，再利用包含可验证奖励和层级奖励分解的强化学习框架进行进一步优化，以防止奖励黑客行为。实验在 KernelBench 上表明，TritonRL 在正确性和加速方面均超过现有的 Triton 专用模型，验证了基于强化学习的训练范式在高性能内核合成中的有效性。", "keywords": "Triton, LLM, code generation, reinforcement learning, reward hacking, hierarchical rewards, kernel synthesis, verification, domain-specific language", "scoring": {"interpretability": 2, "understanding": 6, "safety": 5, "technicality": 7, "surprisal": 6}, "category": {"failure_mode_addressed": "misalignment", "primary_focus": "alignment"}, "authors": ["Jiin Woo", "Shaowei Zhu", "Allen Nie", "Zhen Jia", "Yida Wang", "Youngsuk Park"]}, "usage": {"completion_tokens": 653, "prompt_tokens": 3425, "total_tokens": 4078, "completion_tokens_details": {"accepted_prediction_tokens": null, "audio_tokens": null, "reasoning_tokens": 402, "rejected_prediction_tokens": null, "image_tokens": 0}, "prompt_tokens_details": {"audio_tokens": 0, "cached_tokens": 3152}, "cost": 0.00061961, "is_byok": false, "cost_details": {"upstream_inference_cost": null, "upstream_inference_prompt_cost": 0.00029311, "upstream_inference_completions_cost": 0.0003265}}, "model": "openai/gpt-oss-120b"}
{"timestamp": "2025-10-22T03:29:41.918849", "feed": "arxiv_cslg", "title": "Fast Agnostic Learners in the Plane", "link": "https://papers.cool/arxiv/2510.18057", "analysis": {"summary": "The paper investigates the computational time complexity of agnostic learning for fundamental geometric concept classes in the plane, presenting proper agnostic learners for triangles, 4‑gons, 5‑gons, and convex sets with substantially improved polynomial dependence on \\(\\epsilon\\) compared to prior algorithms. It also shows that agnostic learning of convex sets under arbitrary distributions is impossible due to infinite VC-dimension, and highlights that proper learners yield tolerant property testers with matching runtimes. The work raises the question of whether an inherent gap exists between sample and time complexity for agnostic learning of natural concept classes.", "summary_cn": "本文研究了平面几何概念类的无情学习（agnostic learning）的时间复杂度，提出了针对三角形、四边形、五边形以及凸集的正式无情学习算法，并显著改进了对 \\(\\epsilon\\) 的多项式依赖，优于已有方法。文中还证明在一般分布下无情学习凸集是不可能的，因为该概念类的 VC 维度无限，并指出正式学习器可以产生具有匹配运行时间的容错属性测试器。作者进一步讨论了样本复杂度与时间复杂度之间是否必然存在差距的问题。", "keywords": "agnostic learning, computational geometry, triangles, convex polygons, sample complexity, time complexity, proper learner, tolerant property testing", "scoring": {"interpretability": 1, "understanding": 4, "safety": 1, "technicality": 8, "surprisal": 6}, "category": {"failure_mode_addressed": "non-applicable", "primary_focus": "other"}, "authors": ["Talya Eden", "Ludmila Glinskih", "Sofya Raskhodnikova"]}, "usage": {"completion_tokens": 801, "prompt_tokens": 3559, "total_tokens": 4360, "completion_tokens_details": {"accepted_prediction_tokens": null, "audio_tokens": null, "reasoning_tokens": 508, "rejected_prediction_tokens": null, "image_tokens": 0}, "prompt_tokens_details": {"audio_tokens": 0, "cached_tokens": 3152}, "cost": 0.00071371, "is_byok": false, "cost_details": {"upstream_inference_cost": null, "upstream_inference_prompt_cost": 0.00031321, "upstream_inference_completions_cost": 0.0004005}}, "model": "openai/gpt-oss-120b"}
{"timestamp": "2025-10-22T03:29:42.139067", "feed": "arxiv_cslg", "title": "Transformer Redesign for Late Fusion of Audio-Text Features on Ultra-Low-Power Edge Hardware", "link": "https://papers.cool/arxiv/2510.18036", "analysis": {"summary": "The paper presents a hardware‑aware multimodal emotion recognition system that combines acoustic and linguistic features using a late‑fusion architecture optimized for Edge TPU. By integrating a quantised transformer‑based acoustic model with frozen keyword embeddings from a DSResNet‑SE network, the design achieves real‑time inference within a 1.8 MB memory budget and 21–23 ms latency, improving macro F1 by 6.3% over unimodal baselines on edge‑captured IEMOCAP data.", "summary_cn": "本文提出了一种面向硬件的多模态情感识别系统，采用在 Edge TPU 上优化的后期融合架构，将声学特征与语言特征相结合。通过将量化的 Transformer（声学模型）与 DSResNet‑SE 网络的冻结关键词嵌入融合，实现了 1.8 MB 内存限制和 21–23 ms 延迟的实时推理，在边缘设备捕获的 IEMOCAP 数据上相较于单模态基线提升了 6.3% 的宏 F1。", "keywords": "emotion recognition, multimodal fusion, late fusion, transformer, edge TPU, quantization, low-power hardware, acoustic-linguistic features", "scoring": {"interpretability": 2, "understanding": 5, "safety": 2, "technicality": 7, "surprisal": 6}, "category": {"failure_mode_addressed": "non-applicable", "primary_focus": "other"}, "authors": ["Stavros Mitsis", "Ermos Hadjikyriakos", "Humaid Ibrahim", "Savvas Neofytou", "Shashwat Raman", "James Myles", "Eiman Kanjo"]}, "usage": {"completion_tokens": 750, "prompt_tokens": 3455, "total_tokens": 4205, "completion_tokens_details": {"accepted_prediction_tokens": null, "audio_tokens": null, "reasoning_tokens": 508, "rejected_prediction_tokens": null, "image_tokens": 0}, "prompt_tokens_details": {"audio_tokens": 0, "cached_tokens": 3152}, "cost": 0.00067261, "is_byok": false, "cost_details": {"upstream_inference_cost": null, "upstream_inference_prompt_cost": 0.00029761, "upstream_inference_completions_cost": 0.000375}}, "model": "openai/gpt-oss-120b"}
{"timestamp": "2025-10-22T03:29:42.377691", "feed": "arxiv_cslg", "title": "QINNs: Quantum-Informed Neural Networks", "link": "https://papers.cool/arxiv/2510.17984", "analysis": {"summary": "The paper introduces Quantum-Informed Neural Networks (QINNs), a framework that incorporates quantum information concepts, specifically the Quantum Fisher Information Matrix (QFIM), into classical deep learning models for collider physics. Using jet tagging as an example, QFIM embeddings are incorporated into graph neural networks, improving expressivity and providing interpretable patterns that differentiate QCD and hadronic top jets. The approach demonstrates a practical, scalable way to embed quantum-inspired, physics‑grounded features into existing deep learning pipelines.", "summary_cn": "本文提出量子信息神经网络（QINNs）框架，将量子信息概念，尤其是量子费舍尔信息矩阵（Quantum Fisher Information Matrix, QFIM），引入纯经典的深度学习模型用于碰撞器数据分析。以 Jet 标记任务为案例，将 QFIM 作为轻量级嵌入加入图神经网络，提升模型的表达能力，并展示了 QCD 与强子顶喷流在 QFIM 表征上的可解释差异。该方法提供了一种实用、可扩展的方式，将量子启发的物理特征嵌入到已有的深度学习流程中。", "keywords": "quantum-informed neural networks, quantum Fisher information matrix, graph neural networks, jet tagging, particle physics, feature embeddings, interpretability, collider data", "scoring": {"interpretability": 5, "understanding": 6, "safety": 1, "technicality": 8, "surprisal": 7}, "category": {"failure_mode_addressed": "non-applicable", "primary_focus": "interpretability"}, "authors": ["Aritra Bal", "Markus Klute", "Benedikt Maier", "Melik Oughton", "Eric Pezone", "Michael Spannowsky"]}, "usage": {"completion_tokens": 744, "prompt_tokens": 3378, "total_tokens": 4122, "completion_tokens_details": {"accepted_prediction_tokens": null, "audio_tokens": null, "reasoning_tokens": 443, "rejected_prediction_tokens": null, "image_tokens": 0}, "prompt_tokens_details": {"audio_tokens": 0, "cached_tokens": 3152}, "cost": 0.00065806, "is_byok": false, "cost_details": {"upstream_inference_cost": null, "upstream_inference_prompt_cost": 0.00028606, "upstream_inference_completions_cost": 0.000372}}, "model": "openai/gpt-oss-120b"}
{"timestamp": "2025-10-22T03:29:42.433995", "feed": "arxiv_cslg", "title": "Learning Time-Varying Graphs from Incomplete Graph Signals", "link": "https://papers.cool/arxiv/2510.17903", "analysis": {"summary": "The paper proposes a unified non-convex optimization framework that simultaneously infers a sequence of time-varying graph Laplacians and imputes missing entries in partially observed graph signals. By incorporating a fused-lasso regularizer to enforce temporal smoothness and solving the problem with an efficient ADMM algorithm, the method achieves theoretical convergence guarantees and non-asymptotic error bounds, demonstrating superior performance over existing baselines in experiments.", "summary_cn": "本文提出一种统一的非凸优化框架，能够同步推断随时间变化的图拉普拉斯矩阵并填补部分观测图信号中的缺失数据。通过在拉普拉斯序列上加入 fused-lasso 类型的正则化实现时间平滑，并利用 ADMM 设计算法得到闭式解，提供收敛至驻点的理论保证以及非渐近误差界，实验表明在收敛速度和图学习、信号恢复精度上均显著优于现有基线。", "keywords": "time-varying graph learning, graph signal processing, missing data imputation, fused lasso, ADMM, non-convex optimization, Laplacian estimation, statistical guarantees", "scoring": {"interpretability": 2, "understanding": 4, "safety": 2, "technicality": 8, "surprisal": 5}, "category": {"failure_mode_addressed": "non-applicable", "primary_focus": "other"}, "authors": ["Chuansen Peng", "Xiaojing Shen"]}, "usage": {"completion_tokens": 675, "prompt_tokens": 3506, "total_tokens": 4181, "completion_tokens_details": {"accepted_prediction_tokens": null, "audio_tokens": null, "reasoning_tokens": 401, "rejected_prediction_tokens": null, "image_tokens": 0}, "prompt_tokens_details": {"audio_tokens": 0, "cached_tokens": 3152}, "cost": 0.00064276, "is_byok": false, "cost_details": {"upstream_inference_cost": null, "upstream_inference_prompt_cost": 0.00030526, "upstream_inference_completions_cost": 0.0003375}}, "model": "openai/gpt-oss-120b"}
{"timestamp": "2025-10-22T03:29:42.497276", "feed": "arxiv_cslg", "title": "Graphical model for tensor factorization by sparse sampling", "link": "https://papers.cool/arxiv/2510.17886", "analysis": {"summary": "The paper introduces a graphical model for tensor factorization based on sparse measurements arranged according to a graph, targeting scenarios with substantial missing data such as recommendation systems. It develops message‑passing algorithms and a replica theory that become exact in a dense‑limit regime, and evaluates performance in a Bayes‑optimal teacher‑student setting.", "summary_cn": "本文提出一种基于稀疏采样的张量分解图模型，利用随机图结构处理数据缺失严重的场景（如推荐系统）。作者构建了消息传递算法并在密集极限下推导了精确的复制理论，在贝叶斯最优的师生设定中评估了统计推断性能。", "keywords": "tensor factorization, sparse sampling, graphical model, message passing, replica theory, Bayesian inference, recommendation systems", "scoring": {"interpretability": 2, "understanding": 6, "safety": 2, "technicality": 8, "surprisal": 6}, "category": {"failure_mode_addressed": "non-applicable", "primary_focus": "other"}, "authors": ["Angelo Giorgio", "Riki Nagasawa", "Shuta Yokoi", "Tomoyuki Obuchi", "Hajime Yoshino"]}, "usage": {"completion_tokens": 655, "prompt_tokens": 3332, "total_tokens": 3987, "completion_tokens_details": {"accepted_prediction_tokens": null, "audio_tokens": null, "reasoning_tokens": 490, "rejected_prediction_tokens": null, "image_tokens": 0}, "prompt_tokens_details": {"audio_tokens": 0, "cached_tokens": 3152}, "cost": 0.00060666, "is_byok": false, "cost_details": {"upstream_inference_cost": null, "upstream_inference_prompt_cost": 0.00027916, "upstream_inference_completions_cost": 0.0003275}}, "model": "openai/gpt-oss-120b"}
{"timestamp": "2025-10-22T03:29:42.968511", "feed": "arxiv_cslg", "title": "From Local to Global: Revisiting Structured Pruning Paradigms for Large Language Models", "link": "https://papers.cool/arxiv/2510.18030", "analysis": {"summary": "The paper revisits global structured pruning for large language models, introducing GISP-Global Iterative Structured Pruning, a post‑training method that uses first‑order loss‑based importance scores aggregated at the structure level with block‑wise normalization. By iteratively pruning attention heads and MLP channels while supporting task‑specific objectives, GISP achieves higher sparsity without perplexity collapse and enables a \"prune‑once, deploy‑many\" workflow, showing consistent improvements on Llama, Mistral, and DeepSeek models across language modeling and downstream tasks.", "summary_cn": "本文重新审视了大语言模型的全局结构化剪枝，提出了 GISP‑Global 迭代结构化剪枝方法，该方法在后训练阶段使用基于模型整体损失的一阶重要性评分并在结构层面进行块归一化聚合，以逐层剪除注意力头和 MLP 通道。通过迭代剪枝并支持任务特定目标，GISP 在保持或提升稀疏度的同时避免困惑度崩溃，实现“一次剪枝，多次部署”，在 Llama、Mistral 与 DeepSeek 系列模型的语言建模及下游任务上均表现出显著提升。", "keywords": "structured pruning, large language models, global importance weighting, iterative pruning, sparsity, task-aligned calibration, efficiency, Llama, Mistral", "scoring": {"interpretability": 2, "understanding": 6, "safety": 1, "technicality": 8, "surprisal": 6}, "category": {"failure_mode_addressed": "non-applicable", "primary_focus": "robustness"}, "authors": ["Ziyan Wang", "Enmao Diao", "Qi Le", "Pu Wang", "Minwoo Lee", "Shu-ping Yeh", "Evgeny Stupachenko", "Hao Feng", "Li Yang"]}, "usage": {"completion_tokens": 816, "prompt_tokens": 3497, "total_tokens": 4313, "completion_tokens_details": {"accepted_prediction_tokens": null, "audio_tokens": null, "reasoning_tokens": 523, "rejected_prediction_tokens": null, "image_tokens": 0}, "prompt_tokens_details": {"audio_tokens": 0, "cached_tokens": 3152}, "cost": 0.00071191, "is_byok": false, "cost_details": {"upstream_inference_cost": null, "upstream_inference_prompt_cost": 0.00030391, "upstream_inference_completions_cost": 0.000408}}, "model": "openai/gpt-oss-120b"}
{"timestamp": "2025-10-22T03:29:43.650520", "feed": "arxiv_cslg", "title": "TriggerNet: A Novel Explainable AI Framework for Red Palm Mite Detection and Multi-Model Comparison and Heuristic-Guided Annotation", "link": "https://papers.cool/arxiv/2510.18038", "analysis": {"summary": "The paper presents TriggerNet, an explainable AI framework that combines Grad-CAM, RISE, FullGrad, and TCAV to generate visual explanations for deep learning models used in plant classification and red palm mite disease detection. It evaluates multiple CNN and transformer architectures as well as classic ML classifiers, and employs Snorkel to create heuristic‑guided annotations for disease categories, reducing manual labeling effort. Experiments on a diverse RGB dataset of eleven plant species demonstrate the framework’s ability to compare model performance and provide interpretable insights into predictions.", "summary_cn": "本文提出 TriggerNet，一种可解释 AI 框架，融合 Grad-CAM、RISE、FullGrad 和 TCAV 等方法，为用于植物分类和红棕螨（red palm mite）病害检测的深度学习模型生成可视化解释。论文评估了多种 CNN、ViT 等模型及传统机器学习分类器，并使用 Snorkel 通过启发式规则进行标注，降低人工标注成本。实验在包含 11 种植物的 RGB 数据集上展示了该框架在模型比较和提供可解释预测方面的效果。", "keywords": "explainable AI, visual explanations, Grad-CAM, RISE, FullGrad, TCAV, plant disease detection, red palm mite, Snorkel, weak supervision", "scoring": {"interpretability": 7, "understanding": 6, "safety": 2, "technicality": 7, "surprisal": 6}, "category": {"failure_mode_addressed": "non-applicable", "primary_focus": "interpretability"}, "authors": ["Harshini Suresha", "Kavitha SH"]}, "usage": {"completion_tokens": 855, "prompt_tokens": 3493, "total_tokens": 4348, "completion_tokens_details": {"accepted_prediction_tokens": null, "audio_tokens": null, "reasoning_tokens": 568, "rejected_prediction_tokens": null, "image_tokens": 0}, "prompt_tokens_details": {"audio_tokens": 0, "cached_tokens": 3152}, "cost": 0.00073081, "is_byok": false, "cost_details": {"upstream_inference_cost": null, "upstream_inference_prompt_cost": 0.00030331, "upstream_inference_completions_cost": 0.0004275}}, "model": "openai/gpt-oss-120b"}
{"timestamp": "2025-10-22T03:29:44.638107", "feed": "arxiv_cslg", "title": "XDXD: End-to-end crystal structure determination with low resolution X-ray diffraction", "link": "https://papers.cool/arxiv/2510.17936", "analysis": {"summary": "XDXD is an end-to-end diffusion-based generative deep‑learning framework that directly predicts complete atomic models from low‑resolution single‑crystal X‑ray diffraction data, bypassing manual electron‑density interpretation. Evaluated on 24,000 experimental structures, it achieves a 70.4 % match rate at 2.0 Å resolution with RMSE below 0.05, and demonstrates its potential on small peptide cases.", "summary_cn": "XDXD 是一种基于扩散的端到端深度学习框架，能够直接从低分辨率单晶 X 射线衍射数据生成完整的原子模型，省去人工电子密度图的解释。在 24,000 个实验结构的基准测试中，该模型在 2.0 Å 分辨率下实现 70.4% 的匹配率，RMSE 低于 0.05，并在小肽案例中展示了潜力。", "keywords": "crystal structure determination, X-ray diffraction, diffusion generative model, deep learning, low-resolution, atomic model prediction, protein crystallography", "scoring": {"interpretability": 2, "understanding": 4, "safety": 2, "technicality": 8, "surprisal": 7}, "category": {"failure_mode_addressed": "non-applicable", "primary_focus": "other"}, "authors": ["Jiale Zhao", "Cong Liu", "Yuxuan Zhang", "Chengyue Gong", "Zhenyi Zhang", "Shifeng Jin", "Zhenyu Liu"]}, "usage": {"completion_tokens": 852, "prompt_tokens": 3427, "total_tokens": 4279, "completion_tokens_details": {"accepted_prediction_tokens": null, "audio_tokens": null, "reasoning_tokens": 618, "rejected_prediction_tokens": null, "image_tokens": 0}, "prompt_tokens_details": {"audio_tokens": 0, "cached_tokens": 3152}, "cost": 0.00071941, "is_byok": false, "cost_details": {"upstream_inference_cost": null, "upstream_inference_prompt_cost": 0.00029341, "upstream_inference_completions_cost": 0.000426}}, "model": "openai/gpt-oss-120b"}
{"timestamp": "2025-10-22T03:29:45.351271", "feed": "arxiv_cslg", "title": "MAT-Agent: Adaptive Multi-Agent Training Optimization", "link": "https://papers.cool/arxiv/2510.17845", "analysis": {"summary": "The paper introduces MAT-Agent, a multi-agent framework that treats the training of multi-label image classifiers as a collaborative, real-time optimization problem. Autonomous agents dynamically adjust data augmentation, optimizers, learning rates, and loss functions using non-stationary multi-armed bandit algorithms, achieving higher mAP and better rare-class performance on Pascal VOC, COCO, and VG-256 compared to static baselines.", "summary_cn": "本文提出 MAT-Agent 框架，将多标签图像分类的训练视为协同实时优化过程。多个自主智能体利用非平稳多臂赌博机算法动态调节数据增强、优化器、学习率和损失函数，在 Pascal VOC、COCO 和 VG-256 数据集上实现了更高的 mAP 和稀有类别性能，优于传统静态配置方法。", "keywords": "multi-agent training, adaptive optimization, multi-label classification, non-stationary bandits, dynamic augmentation, mixed-precision training", "scoring": {"interpretability": 2, "understanding": 6, "safety": 2, "technicality": 8, "surprisal": 6}, "category": {"failure_mode_addressed": "non-applicable", "primary_focus": "other"}, "authors": ["Jusheng Zhang", "Kaitong Cai", "Yijia Fan", "Ningyuan Liu", "Keze Wang"]}, "usage": {"completion_tokens": 547, "prompt_tokens": 4102, "total_tokens": 4649, "completion_tokens_details": {"accepted_prediction_tokens": null, "audio_tokens": null, "reasoning_tokens": 250, "rejected_prediction_tokens": null, "image_tokens": 0}, "prompt_tokens_details": {"audio_tokens": 0, "cached_tokens": 0}, "cost": 0.00034185, "is_byok": false, "cost_details": {"upstream_inference_cost": null, "upstream_inference_prompt_cost": 0.0002051, "upstream_inference_completions_cost": 0.00013675}}, "model": "openai/gpt-oss-120b"}
{"timestamp": "2025-10-22T03:29:47.780660", "feed": "arxiv_cslg", "title": "Neural networks for neurocomputing circuits: a computational study of tolerance to noise and activation function non-uniformity when machine learning materials properties", "link": "https://papers.cool/arxiv/2510.17849", "analysis": {"summary": "The paper presents a computational study on how circuit noise and non-uniform neuron activation functions affect the performance of neural networks implemented in analog neurocomputing circuits, focusing on materials informatics tasks. Results show that networks have generally low noise tolerance, with single‑hidden‑layer and over‑parameterized models being somewhat more robust, and that retraining with the actual activation shapes can mitigate the impact of activation function inhomogeneity.", "summary_cn": "本文对模拟神经计算电路中电路噪声和神经元激活函数非均匀性对神经网络性能的影响进行计算研究，主要针对材料信息学任务。结果表明，网络整体对噪声容忍度较低，但单隐藏层及参数过大模型具有一定的噪声鲁棒性，且通过使用实际激活函数形状重新训练可以减轻激活函数不均匀性的影响。", "keywords": "analog neurocomputing, circuit noise, activation function non-uniformity, neural network robustness, materials informatics, noise tolerance, over-parameterization, retraining, hardware AI, computational study", "scoring": {"interpretability": 2, "understanding": 6, "safety": 2, "technicality": 7, "surprisal": 5}, "category": {"failure_mode_addressed": "non-applicable", "primary_focus": "robustness"}, "authors": ["Ye min Thant", "Methawee Nukunudompanich", "Chu-Chen Chueh", "Manabu Ihara", "Sergei Manzhos"]}, "usage": {"completion_tokens": 765, "prompt_tokens": 4115, "total_tokens": 4880, "completion_tokens_details": {"accepted_prediction_tokens": null, "audio_tokens": null, "reasoning_tokens": 437, "rejected_prediction_tokens": null, "image_tokens": 0}, "prompt_tokens_details": {"audio_tokens": 0, "cached_tokens": 0}, "cost": 0.000397, "is_byok": false, "cost_details": {"upstream_inference_cost": null, "upstream_inference_prompt_cost": 0.00020575, "upstream_inference_completions_cost": 0.00019125}}, "model": "openai/gpt-oss-120b"}
{"timestamp": "2025-10-22T03:29:47.808178", "feed": "arxiv_cslg", "title": "From Flows to Words: Can Zero-/Few-Shot LLMs Detect Network Intrusions? A Grammar-Constrained, Calibrated Evaluation on UNSW-NB15", "link": "https://papers.cool/arxiv/2510.17883", "analysis": {"summary": "The paper evaluates a prompt‑only approach using zero‑ and few‑shot large language models (LLMs) for network intrusion detection on the UNSW‑NB15 dataset, converting network flows into compact textual records enriched with lightweight boolean flags and constraining responses with a grammar. Experiments compare zero‑shot, instruction‑guided, and few‑shot prompting against strong tabular and neural baselines, showing that instruction‑guided prompts with calibrated scoring improve macro‑F1 scores but still lag behind traditional models as data size grows. Contributions include a flow‑to‑text protocol, a calibration method for decision thresholds, and a reproducibility bundle of prompts and evaluation scripts.", "summary_cn": "本文评估了在 UNSW‑NB15 数据集上使用零样本和少样本大语言模型（LLM）进行网络入侵检测的纯提示方法，将网络流转换为紧凑的文本记录并添加轻量布尔特征，同时通过语法约束保证输出结构化。实验比较了零样本、指令引导和少样本提示与强大的表格及神经基线，发现指令引导加校准的提示显著提升了 macro‑F1，但在数据规模扩大时仍不及传统模型。主要贡献包括流转文本协议、阈值校准方法以及包含提示、语法和评估脚本的可复现代码包。", "keywords": "network intrusion detection, large language models,-shot, few-shot, prompt engineering, calibration, grammar-constrained, cybersecurity, UNSW-NB15", "scoring": {"interpretability": 4, "understanding": 6, "safety": 5, "technicality": 6, "surprisal": 6}, "category": {"failure_mode_addressed": "societal-disruption", "primary_focus": "robustness"}, "authors": ["Mohammad Abdul Rehman", "Syed Imad Ali Shah", "Abbas n=Anwar", "Noor Islam"]}, "usage": {"completion_tokens": 840, "prompt_tokens": 3543, "total_tokens": 4383, "completion_tokens_details": {"accepted_prediction_tokens": null, "audio_tokens": null, "reasoning_tokens": 504, "rejected_prediction_tokens": null, "image_tokens": 0}, "prompt_tokens_details": {"audio_tokens": 0, "cached_tokens": 3152}, "cost": 0.00073081, "is_byok": false, "cost_details": {"upstream_inference_cost": null, "upstream_inference_prompt_cost": 0.00031081, "upstream_inference_completions_cost": 0.00042}}, "model": "openai/gpt-oss-120b"}
{"timestamp": "2025-10-22T03:29:47.867825", "feed": "arxiv_cslg", "title": "Shortcutting Pre-trained Flow Matching Diffusion Models is Almost Free Lunch", "link": "https://papers.cool/arxiv/2510.17858", "analysis": {"summary": "The paper introduces an ultra-efficient post‑training technique that shortcuts large pre‑trained flow‑matching diffusion models into few‑step samplers by using velocity‑field self‑distillation, eliminating the need for step‑size embeddings and enabling rapid training (e.g., a 3‑step Flux model in less than one A100 day). It also shows that this mechanism can be integrated during pretraining to produce models that inherently learn efficient flows, and presents the first few‑shot distillation method for billion‑parameter diffusion models with state‑of‑the‑art performance at minimal cost.", "summary_cn": "本文提出一种超高效的后训练方法，通过对速度场进行自蒸馏，将大规模预训练流匹配扩散模型转化为少步采样器，避免了对步长嵌入的需求，实现了快速训练（例如，3 步 Flux 模型在不到一天的 A100 GPU 上完成）。该机制还能在预训练阶段嵌入，使模型本身学习高效的少步流，并首次实现了对数十亿参数扩散模型的少样本蒸馏，在几乎无成本的情况下达到最先进的性能。", "keywords": "flow matching, diffusion models, self-distillation, velocity field, few-step sampler, shortcutting, efficient sampling, few-shot distillation, large-scale diffusion, Flux", "scoring": {"interpretability": 3, "understanding": 6, "safety": 2, "technicality": 8, "surprisal": 7}, "category": {"failure_mode_addressed": "non-applicable", "primary_focus": "other"}, "authors": ["Xu Cai", "Yang Wu", "Qianli Chen", "Haoran Wu", "Lichuan Xiang", "Hongkai Wen"]}, "usage": {"completion_tokens": 716, "prompt_tokens": 4054, "total_tokens": 4770, "completion_tokens_details": {"accepted_prediction_tokens": null, "audio_tokens": null, "reasoning_tokens": 339, "rejected_prediction_tokens": null, "image_tokens": 0}, "prompt_tokens_details": {"audio_tokens": 0, "cached_tokens": 0}, "cost": 0.0003817, "is_byok": false, "cost_details": {"upstream_inference_cost": null, "upstream_inference_prompt_cost": 0.0002027, "upstream_inference_completions_cost": 0.000179}}, "model": "openai/gpt-oss-120b"}
{"timestamp": "2025-10-22T03:29:48.573420", "feed": "arxiv_cslg", "title": "PLAGUE: Plug-and-play framework for Lifelong Adaptive Generation of Multi-turn Exploits", "link": "https://papers.cool/arxiv/2510.17947", "analysis": {"summary": "The paper introduces PLAGUE, a plug‑and‑play framework that structures multi‑turn jailbreak attacks on large language models into three phases—Primer, Planner, and Finisher—drawing on lifelong‑learning agents to systematically explore attack families. Experiments show the red‑teaming agents built with PLAGUE achieve state‑of‑the‑art success rates, improving attack success by over 30% and reaching 81.4% on OpenAI o3 and 67.3% on Claude Opus 4.1. The work provides tools and insights into plan initialization, context optimization, and lifelong learning for comprehensive evaluation of model vulnerabilities.", "summary_cn": "本文提出 PLAGUE 框架，将针对大语言模型的多轮 jailbreak 攻击拆解为 Primer、Planner 和 Finisher 三个阶段，借鉴终身学习代理以系统化探索攻击族。实验显示，使用 PLAGUE 构建的红队代理在攻击成功率上提升超过 30%，在 OpenAI o3 上达到 81.4%、Claude Opus 4.1 上达到 67.3%。该工作提供了关于计划初始化、上下文优化和终身学习的工具与洞见，用于全面评估模型脆弱性。", "keywords": "jailbreak, multi-turn attacks, lifelong learning, red-teaming, LLM safety, prompt engineering, adversarial attacks, vulnerability evaluation", "scoring": {"interpretability": 2, "understanding": 7, "safety": 8, "technicality": 7, "surprisal": 7}, "category": {"failure_mode_addressed": "human-misuse", "primary_focus": "robustness"}, "authors": ["Neeladri Bhuiya", "Madhav Aggarwal", "Diptanshu Purwar"]}, "usage": {"completion_tokens": 998, "prompt_tokens": 3506, "total_tokens": 4504, "completion_tokens_details": {"accepted_prediction_tokens": null, "audio_tokens": null, "reasoning_tokens": 763, "rejected_prediction_tokens": null, "image_tokens": 0}, "prompt_tokens_details": {"audio_tokens": 0, "cached_tokens": 3152}, "cost": 0.00080426, "is_byok": false, "cost_details": {"upstream_inference_cost": null, "upstream_inference_prompt_cost": 0.00030526, "upstream_inference_completions_cost": 0.000499}}, "model": "openai/gpt-oss-120b"}
{"timestamp": "2025-10-22T03:29:50.681566", "feed": "arxiv_cslg", "title": "Covariance Matrix Construction with Preprocessing-Based Spatial Sampling for Robust Adaptive Beamforming", "link": "https://papers.cool/arxiv/2510.17823", "analysis": {"summary": "The paper introduces a robust adaptive beamforming method that mitigates steering vector estimation errors and improves covariance matrix reconstruction. It adaptively estimates interfering source directions, uses a preprocessing‑based spatial sampling strategy to construct the interference‑plus‑noise covariance matrix, and forms the signal covariance for the sector of interest to compute the steering vector via the power method. Simulations demonstrate superior performance and lower computational cost compared to existing techniques.", "summary_cn": "本文提出了一种鲁棒自适应波束形成方法，用于缓解波束指向矢量估计误差并改进协方差矩阵重建。该方法自适应估计干扰源方向，利用基于预处理的空间采样策略构建干扰加噪声协方差矩阵，并在感兴趣信号方向上形成信号协方差矩阵，进而通过幂法计算波束指向矢量。仿真结果显示该方法在性能和计算成本上优于现有技术。", "keywords": "robust adaptive beamforming, steering vector mismatch, covariance matrix reconstruction, preprocessing-based spatial sampling, interference-plus-noise covariance, general linear combination, power method", "scoring": {"interpretability": 2, "understanding": 3, "safety": 1, "technicality": 7, "surprisal": 4}, "category": {"failure_mode_addressed": "non-applicable", "primary_focus": "other"}, "authors": ["Saeed Mohammadzadeh", "Rodrigo C. de Lamare", "Yuriy Zakharov"]}, "usage": {"completion_tokens": 586, "prompt_tokens": 3418, "total_tokens": 4004, "completion_tokens_details": {"accepted_prediction_tokens": null, "audio_tokens": null, "reasoning_tokens": 290, "rejected_prediction_tokens": null, "image_tokens": 0}, "prompt_tokens_details": {"audio_tokens": 0, "cached_tokens": 3152}, "cost": 0.00058506, "is_byok": false, "cost_details": {"upstream_inference_cost": null, "upstream_inference_prompt_cost": 0.00029206, "upstream_inference_completions_cost": 0.000293}}, "model": "openai/gpt-oss-120b"}
{"timestamp": "2025-10-22T03:29:52.921635", "feed": "arxiv_cslg", "title": "Self-Evidencing Through Hierarchical Gradient Decomposition: A Dissipative System That Maintains Non-Equilibrium Steady-State by Minimizing Variational Free Energy", "link": "https://papers.cool/arxiv/2510.17916", "analysis": {"summary": "The paper provides a constructive proof that the Free Energy Principle can be implemented through exact local credit assignment by decomposing gradient computation hierarchically into spatial credit via feedback alignment, temporal credit via eligibility traces, and structural credit via a Trophic Field Map. Empirical results show the TFM predicts oracle gradients with 0.9693 Pearson correlation and yields emergent properties such as high retention after interference, autonomous recovery from structural damage, self‑organized criticality, and sample‑efficient reinforcement learning without replay buffers. The work bridges concepts from dissipative structures, free‑energy minimization, and attractor dynamics, suggesting that biologically plausible local rules can realize hierarchical inference over network topology.", "summary_cn": "本文提供了一个构造性证明，表明自由能原理（Free Energy Principle）可以通过精确的局部信用分配实现，其方式是将梯度计算层次化分解：空间信用通过反馈对齐（feedback alignment）实现，时间信用通过资格迹（eligibility traces）实现，结构信用通过营养场映射（Trophic Field Map）实现。实验结果显示，营养场映射对梯度的预测相关系数为0.9693，并且出现了如干扰后高保留率、结构损坏后自主恢复、自组织临界性以及无需重放缓冲区的样本高效连续控制强化学习等涌现能力。该工作将耗散结构、自由能最小化和吸引子动力学等概念统一起来，表明生物学上可行的局部规则能够实现对网络拓扑的层次推断。", "keywords": "free energy principle, hierarchical gradient decomposition, feedback alignment, eligibility traces, trophic field map, local credit assignment, self-organized criticality, sample-efficient reinforcement learning, non-equilibrium steady state", "scoring": {"interpretability": 5, "understanding": 7, "safety": 5, "technicality": 8, "surprisal": 7}, "category": {"failure_mode_addressed": "non-applicable", "primary_focus": "robustness"}, "authors": ["Michael James McCulloch"]}, "usage": {"completion_tokens": 1241, "prompt_tokens": 3447, "total_tokens": 4688, "completion_tokens_details": {"accepted_prediction_tokens": null, "audio_tokens": null, "reasoning_tokens": 1000, "rejected_prediction_tokens": null, "image_tokens": 0}, "prompt_tokens_details": {"audio_tokens": 0, "cached_tokens": 3152}, "cost": 0.00091691, "is_byok": false, "cost_details": {"upstream_inference_cost": null, "upstream_inference_prompt_cost": 0.00029641, "upstream_inference_completions_cost": 0.0006205}}, "model": "openai/gpt-oss-120b"}
{"timestamp": "2025-10-22T03:29:58.377434", "feed": "arxiv_cslg", "title": "PrivaDE: Privacy-preserving Data Evaluation for Blockchain-based Data Marketplaces", "link": "https://papers.cool/arxiv/2510.18109", "analysis": {"summary": "PrivaDE is a cryptographic protocol that enables model builders to evaluate the utility of candidate datasets without revealing proprietary model information, while ensuring data providers' privacy beyond the disclosed utility score. The design leverages blockchain's trustless environment, model distillation, model splitting, and cut-and-choose zero-knowledge proofs to achieve malicious-security guarantees and practical runtimes (under 15 minutes for models with millions of parameters). The paper also introduces a unified utility scoring function combining empirical loss, predictive entropy, and feature-space diversity, suitable for active-learning pipelines in decentralized machine learning ecosystems.", "summary_cn": "PrivaDE 是一种加密协议，允许模型构建者在不泄露模型专有信息的情况下评估候选数据集的效用，同时确保数据提供者的隐私仅泄露效用评分。该方案利用区块链的去中心化特性、模型蒸馏、模型拆分以及挑选-证明零知识证明，实现了对恶意行为的安全保障，并将运行时间压缩至 15 分钟以内（即使模型参数达数百万）。文中还提出一种统一的效用评分函数，综合经验损失、预测熵和特征空间多样性，可无缝集成到去中心化机器学习的主动学习工作流中。", "keywords": "privacy-preserving, data utility scoring, blockchain, zero-knowledge proofs, model distillation, active learning", "scoring": {"interpretability": 1, "understanding": 6, "safety": 7, "technicality": 8, "surprisal": 7}, "category": {"failure_mode_addressed": "non-applicable", "primary_focus": "other"}, "authors": ["Wan Ki Wong", "Sahel Torkamani", "Michele Ciampi", "Rik Sarkar"]}, "usage": {"completion_tokens": 702, "prompt_tokens": 3462, "total_tokens": 4164, "completion_tokens_details": {"accepted_prediction_tokens": null, "audio_tokens": null, "reasoning_tokens": 364, "rejected_prediction_tokens": null, "image_tokens": 0}, "prompt_tokens_details": {"audio_tokens": 0, "cached_tokens": 3152}, "cost": 0.00064966, "is_byok": false, "cost_details": {"upstream_inference_cost": null, "upstream_inference_prompt_cost": 0.00029866, "upstream_inference_completions_cost": 0.000351}}, "model": "openai/gpt-oss-120b"}
{"timestamp": "2025-10-22T03:30:23.283746", "feed": "arxiv_cslg", "title": "Ensembling Pruned Attention Heads For Uncertainty-Aware Efficient Transformers", "link": "https://papers.cool/arxiv/2510.18358", "analysis": {"summary": "The paper proposes Hydra Ensembles, an efficient transformer‑based ensemble that creates diverse members by pruning attention heads and combines them with a novel grouped multi‑head attention, achieving uncertainty quantification performance comparable to or better than Deep Ensembles while keeping inference speed close to a single model. Extensive experiments on image and text classification, including zero‑shot ImageNet‑1k, demonstrate that the method preserves calibration and provides state‑of‑the‑art results without additional training analysis of pruning strategies shows that naïve pruning harms calibration, whereas the proposed approach maintains robust uncertainty estimates.", "summary_cn": "本文提出了 Hydra Ensembles，一种通过剪枝注意力头创建多样化成员并使用分组全连接层的多头注意力进行融合的高效 Transformer 集成方法，实现了与 Deep Ensembles 相当或更佳的不确定性量化性能，同时推理速度接近单模型。广泛的图像和文本分类实验（包括 ImageNet‑1k 零样本分类）表明，该方法在无需额外训练的情况下保持良好校准并达到最新水平。对剪枝的深入分析显示，传统剪枝会损害校准，而本文的方法能够保持稳健的不确定性估计。", "keywords": "uncertainty quantification, deep ensembles, transformer pruning, attention head pruning, Hydra Ensembles, model calibration, efficient inference, zero-shot classification", "scoring": {"interpretability": 4, "understanding": 7, "safety": 7, "technicality": 8, "surprisal": 7}, "category": {"failure_mode_addressed": "non-applicable", "primary_focus": "robustness"}, "authors": ["Firas Gabetni", "Giuseppe Curci", "Andrea Pilzer", "Subhankar Roy", "Elisa Ricci", "Gianni Franchi"]}, "usage": {"completion_tokens": 710, "prompt_tokens": 3377, "total_tokens": 4087, "completion_tokens_details": {"accepted_prediction_tokens": null, "audio_tokens": null, "reasoning_tokens": 407, "rejected_prediction_tokens": null, "image_tokens": 0}, "prompt_tokens_details": {"audio_tokens": 0, "cached_tokens": 3152}, "cost": 0.00064091, "is_byok": false, "cost_details": {"upstream_inference_cost": null, "upstream_inference_prompt_cost": 0.00028591, "upstream_inference_completions_cost": 0.000355}}, "model": "openai/gpt-oss-120b"}
{"timestamp": "2025-10-22T03:32:03.449218", "feed": "arxiv_cslg", "title": "Exploring Complexity Changes in Diseased ECG Signals for Enhanced Classification", "link": "https://papers.cool/arxiv/2510.17810", "analysis": {"summary": "The paper applies nonlinear time‑series analysis to lead‑II ECG recordings from the PTB‑XL dataset, extracting complexity measures and cross‑channel metrics (Spearman correlation and mutual information). Significant differences in these measures are reported between healthy and diseased subjects across five diagnostic super‑classes, and incorporating them into machine‑learning classifiers raises the AUC from 0.86 to 0.90.", "summary_cn": "本文对 PTB‑XL 数据库的 II 导联心电图使用非线性时间序列分析，提取复杂度度量和跨导联指标（Spearman 相关和互信息）。结果显示健康与疾病患者在几乎所有度量上存在显著差异，跨五类诊断超级类别均 $p<.001$。将这些复杂度特征加入机器学习模型后，AUC 从 0.86 提升至 0.90。", "keywords": "ECG, nonlinear dynamics, complexity, time series analysis, machine learning, PTB-XL, classification, mutual information, Spearman correlation", "scoring": {"interpretability": 3, "understanding": 5, "safety": 2, "technicality": 7, "surprisal": 5}, "category": {"failure_mode_addressed": "non-applicable", "primary_focus": "other"}, "authors": ["Camilo Quiceno Quintero", "Sandip Varkey George"]}, "usage": {"completion_tokens": 518, "prompt_tokens": 3362, "total_tokens": 3880, "completion_tokens_details": {"accepted_prediction_tokens": null, "audio_tokens": null, "reasoning_tokens": 237, "rejected_prediction_tokens": null, "image_tokens": 0}, "prompt_tokens_details": {"audio_tokens": 0, "cached_tokens": 3152}, "cost": 0.00054266, "is_byok": false, "cost_details": {"upstream_inference_cost": null, "upstream_inference_prompt_cost": 0.00028366, "upstream_inference_completions_cost": 0.000259}}, "model": "openai/gpt-oss-120b"}
{"timestamp": "2025-10-24T17:33:10.848008", "feed": "arxiv_cslg", "title": "Hierarchical Time Series Forecasting with Robust Reconciliation", "link": "https://papers.cool/arxiv/2510.20383", "analysis": {"summary": "This paper proposes a robust optimization framework for hierarchical time‑series forecasting that accounts for uncertainty in the estimated covariance matrix during reconciliation, formulating the problem as a semidefinite program and showing improved forecast accuracy over standard methods.", "summary_cn": "本文提出一种鲁棒优化框架，用于层级时间序列预测，在协方差矩阵估计不确定性下进行预测值的调和，模型被转化为半正定规划并显示出相较传统方法更好的预测性能。", "keywords": "hierarchical forecasting, time series reconciliation, robust optimization, covariance uncertainty, semidefinite programming", "scoring": {"interpretability": 2, "understanding": 5, "safety": 1, "technicality": 7, "surprisal": 5}, "category": {"failure_mode_addressed": "non-applicable", "primary_focus": "other"}, "authors": ["Shuhei Aikawa", "Aru Suzuki", "Kei Yoshitake", "Kanata Teshigawara", "Akira Iwabuchi", "Ken Kobayashi", "Kazuhide Nakata"]}, "usage": {"completion_tokens": 174, "prompt_tokens": 3433, "total_tokens": 3607, "completion_tokens_details": {"accepted_prediction_tokens": null, "audio_tokens": null, "reasoning_tokens": 0, "rejected_prediction_tokens": null, "image_tokens": 0}, "prompt_tokens_details": {"audio_tokens": 0, "cached_tokens": 0}, "cost": 0.00024995, "is_byok": false, "cost_details": {"upstream_inference_cost": null, "upstream_inference_prompt_cost": 0.00017165, "upstream_inference_completions_cost": 7.83e-05}}, "model": "openai/gpt-oss-120b"}
{"timestamp": "2025-10-24T17:33:15.395472", "feed": "arxiv_cslg", "title": "MolBridge: Atom-Level Joint Graph Refinement for Robust Drug-Drug Interaction Event Prediction", "link": "https://papers.cool/arxiv/2510.20448", "analysis": {"summary": "MolBridge is an atom‑level joint graph refinement framework that merges the molecular graphs of two drugs into a single joint graph, enabling explicit modeling of inter‑drug atomic interactions for drug‑drug interaction (DDI) event prediction. By introducing a structure consistency module that iteratively refines node features while preserving global structure, the method mitigates over‑smoothing and achieves robust performance on both frequent and long‑tail DDI types, outperforming existing baselines on benchmark datasets.", "summary_cn": "MolBridge 将两种药物的分子图合并为一个联合图，直接建模药物之间的原子级相互作用，从而预测药物‑药物相互作用（DDI）事件。其通过结构一致性模块迭代细化节点特征并保持全局结构，克服了长程依赖导致的过平滑问题，在常见和长尾 DDI 类型上均实现了比现有方法更稳健的性能，实验在两个基准数据集上验证了其优势。", "keywords": "drug-drug interaction, joint graph neural network, atom-level modeling, structure consistency, mechanistic interpretability, robustness, long-tail prediction", "scoring": {"interpretability": 6, "understanding": 7, "safety": 4, "technicality": 8, "surprisal": 7}, "category": {"failure_mode_addressed": "societal-disruption", "primary_focus": "interpretability"}, "authors": ["Xuan Lin", "Aocheng Ding", "Tengfei Ma", "Hua Liang", "Zhe Quan"]}, "usage": {"completion_tokens": 587, "prompt_tokens": 3494, "total_tokens": 4081, "completion_tokens_details": {"accepted_prediction_tokens": null, "audio_tokens": null, "reasoning_tokens": 286, "rejected_prediction_tokens": null, "image_tokens": 0}, "prompt_tokens_details": {"audio_tokens": 0, "cached_tokens": 0}, "cost": 0.00043885, "is_byok": false, "cost_details": {"upstream_inference_cost": null, "upstream_inference_prompt_cost": 0.0001747, "upstream_inference_completions_cost": 0.00026415}}, "model": "openai/gpt-oss-120b"}
{"timestamp": "2025-10-24T17:33:17.460000", "feed": "arxiv_cslg", "title": "Intransitive Player Dominance and Market Inefficiency in Tennis Forecasting: A Graph Neural Network Approach", "link": "https://papers.cool/arxiv/2510.20454", "analysis": {"summary": "The paper introduces a graph neural network that models temporal directed graphs of tennis matches to capture intransitive player dominance relationships. It demonstrates that the bookmaker Pinnacle Sports struggles with high‑intransitivity matchups, and shows that selective betting based on the model yields a positive 3.26% ROI using Kelly staking over 1903 bets, indicating a market inefficiency.", "summary_cn": "本文提出使用图神经网络对网球比赛的时间有向图进行建模，以捕捉选手间的非传递性支配关系（如 A B、B 胜 C、但 C 胜 A）。研究发现博彩公司 Pinnacle Sports 在高非传递性赛事上的表现较差，利用模型在此类比赛上进行有选择的投注（使用 Kelly 资金管理）在 1903 次投注中实现 3.26% 的正向收益率，表明市场对这类对局存在效率低下。", "keywords": "intransitive dominance, tennis forecasting, graph neural network, market inefficiency, betting, Kelly staking, relational modeling", "scoring": {"interpretability": 3, "understanding": 6, "safety": 2, "technicality": 7, "surprisal": 7}, "category": {"failure_mode_addressed": "non-applicable", "primary_focus": "other"}, "authors": ["Lawrence Clegg", "John Cartlidge"]}, "usage": {"completion_tokens": 655, "prompt_tokens": 3376, "total_tokens": 4031, "completion_tokens_details": {"accepted_prediction_tokens": null, "audio_tokens": null, "reasoning_tokens": 426, "rejected_prediction_tokens": null, "image_tokens": 0}, "prompt_tokens_details": {"audio_tokens": 0, "cached_tokens": 3152}, "cost": 0.00061326, "is_byok": false, "cost_details": {"upstream_inference_cost": null, "upstream_inference_prompt_cost": 0.00028576, "upstream_inference_completions_cost": 0.0003275}}, "model": "openai/gpt-oss-120b"}
{"timestamp": "2025-10-24T17:33:17.738632", "feed": "arxiv_cslg", "title": "Convergence Analysis of SGD under Expected Smoothness", "link": "https://papers.cool/arxiv/2510.20608", "analysis": {"summary": "The paper provides a self‑contained convergence analysis of stochastic gradient descent under the expected smoothness condition, offering refined definitions, sampling‑dependent constants, and explicit O(1/K) rates for various step‑size schedules. It derives bounds on the expected squared norm of the full gradient and presents detailed proofs, unifying and extending recent works. The results clarify how expected smoothness influences SGD performance without relying on strong variance assumptions.", "summary_cn": "本文对随机梯度下降（SGD）在期望光滑（expected smoothness）条件下的收敛性进行自包含的理论分析，提出了条件的细化解释、与采样相关的常数以及针对不同步长调度的 O(1/K) 收敛率，并给出全梯度平方范数的期望上界。所有证明在附录中完整呈现，统一并扩展了近期工作。研究阐明了在不依赖强方差假设的情况下，期望光滑如何影响 SGD 的表现。", "keywords": "stochastic gradient descent, expected smoothness, convergence analysis, optimization, step-size schedule", "scoring": {"interpretability": 2, "understanding": 6, "safety": 1, "technicality": 8, "surprisal": 5}, "category": {"failure_mode_addressed": "non-applicable", "primary_focus": "other"}, "authors": ["Yuta Kawamoto", "Hideaki Iiduka"]}, "usage": {"completion_tokens": 565, "prompt_tokens": 3363, "total_tokens": 3928, "completion_tokens_details": {"accepted_prediction_tokens": null, "audio_tokens": null, "reasoning_tokens": 282, "rejected_prediction_tokens": null, "image_tokens": 0}, "prompt_tokens_details": {"audio_tokens": 0, "cached_tokens": 3152}, "cost": 0.00056631, "is_byok": false, "cost_details": {"upstream_inference_cost": null, "upstream_inference_prompt_cost": 0.00028381, "upstream_inference_completions_cost": 0.0002825}}, "model": "openai/gpt-oss-120b"}
{"timestamp": "2025-10-24T17:33:17.887456", "feed": "arxiv_cslg", "title": "MS-BART: Unified Modeling of Mass Spectra and Molecules for Structure Elucidation", "link": "https://papers.cool/arxiv/2510.20615", "analysis": {"summary": "MS-BART is a unified modeling framework that encodes mass spectra and molecular structures into a shared token vocabulary, enabling cross‑modal pretraining on large fingerprint‑molecule datasets and multitask objectives. After pretraining, the model is fine‑tuned on experimental spectra using fingerprint predictions from MIST and further guided by a chemical feedback loop to reduce molecular hallucination. Experiments show state‑of‑the‑art performance on MassSpecGym and NPLIB1 and an order‑of‑magnitude speed advantage over diffusion‑based methods.", "summary_cn": "MS-BART 是一个统一建模框架，将质谱 (mass spectra) 和分子结构映射到共享的 token 词表，实现跨模态的大规模预训练和多任务学习。通过使用 MIST 生成的指纹预测进行微调，并加入化学反馈机制以抑制分子幻觉，模型在 MassSpecGym 与 NPLIB1 上取得了多项指标的领先性能，并比扩散方法快一个数量级。", "keywords": "mass spectrometry, molecular structure elucidation, cross-modal pretraining, BART, chemical feedback, fingerprint prediction, diffusion alternatives, MS-BART", "scoring": {"interpretability": 4, "understanding": 5, "safety": 2, "technicality": 7, "surprisal": 6}, "category": {"failure_mode_addressed": "non-applicable", "primary_focus": "other"}, "authors": ["Yang Han", "Pengyu Wang", "Kai Yu", "Xin Chen", "Lu Chen"]}, "usage": {"completion_tokens": 949, "prompt_tokens": 3473, "total_tokens": 4422, "completion_tokens_details": {"accepted_prediction_tokens": null, "audio_tokens": null, "reasoning_tokens": 761, "rejected_prediction_tokens": null, "image_tokens": 0}, "prompt_tokens_details": {"audio_tokens": 0, "cached_tokens": 0}, "cost": 0.0006007, "is_byok": false, "cost_details": {"upstream_inference_cost": null, "upstream_inference_prompt_cost": 0.00017365, "upstream_inference_completions_cost": 0.00042705}}, "model": "openai/gpt-oss-120b"}
{"timestamp": "2025-10-24T17:33:17.912446", "feed": "arxiv_cslg", "title": "Relative-Based Scaling Law for Neural Language Models", "link": "https://papers.cool/arxiv/2510.20387", "analysis": {"summary": "The paper introduces a Relative-Based Probability (RBP) metric that measures how often the correct token ranks among the top predictions, and derives a Relative-Based Scaling Law describing how RBP improves with model size. Extensive experiments across four datasets and model families validate the law's robustness and accuracy, and the authors demonstrate applications such as explaining emergence phenomena aiding the search for fundamental scaling theories.", "summary_cn": "本文提出相对概率（Relative-Based Probability, RBP）指标，用于衡量正确词在预测中排名靠前的概率，并基于该指标建立了相对尺度定律，描述模型规模增大时 RBP 的提升规律。通过在四个数据集和四类模型家族上进行的大规模实验验证了该定律的稳健性与准确性，并展示了其在解释模型涌现现象和寻找尺度定律基础理论等方面的广泛应用。", "keywords": "relative-based probability, scaling law, language models, emergence, evaluation metric, cross-entropy alternative", "scoring": {"interpretability": 2, "understanding": 7, "safety": 1, "technicality": 8, "surprisal": 6}, "category": {"failure_mode_addressed": "non-applicable", "primary_focus": "other"}, "authors": ["Baoqing Yue", "Jinyuan Zhou", "Zixi Wei", "Jingtao Zhan", "Qingyao Ai", "Yiqun Liu"]}, "usage": {"completion_tokens": 595, "prompt_tokens": 3433, "total_tokens": 4028, "completion_tokens_details": {"accepted_prediction_tokens": null, "audio_tokens": null, "reasoning_tokens": 352, "rejected_prediction_tokens": null, "image_tokens": 0}, "prompt_tokens_details": {"audio_tokens": 0, "cached_tokens": 3152}, "cost": 0.00059181, "is_byok": false, "cost_details": {"upstream_inference_cost": null, "upstream_inference_prompt_cost": 0.00029431, "upstream_inference_completions_cost": 0.0002975}}, "model": "openai/gpt-oss-120b"}
{"timestamp": "2025-10-24T17:33:18.111037", "feed": "arxiv_cslg", "title": "Structural Invariance Matters: Rethinking Graph Rewiring through Graph Metrics", "link": "https://papers.cool/arxiv/2510.20556", "analysis": {"summary": "paper systematically analyzes how different graph rewiring methods affect various graph structural metrics and links these changes to downstream node classification performance. By evaluating seven rewiring strategies, it finds that successful methods tend to preserve local graph structure while allowing flexibility in global connectivity, offering guidance for designing effective rewiring techniques.", "summary_cn": "本文系统性地研究了不同图重连方法对多种图结构度量的影响，并将这些变化与下游节点分类性能关联起来。通过评估七种重连策略，发现成功的方法往往保持局部结构不变，同时在全局连接上保持灵活，为设计有效的图重连技术提供了指导。", "keywords": "graph neural networks, graph rewiring, over-squashing, structural invariance, graph metrics, node classification, local structure preservation", "scoring": {"interpretability": 3, "understanding": 7, "safety": 3, "technicality": 7, "surprisal": 6}, "category": {"failure_mode_addressed": "non-applicable", "primary_focus": "robustness"}, "authors": ["Alexandre Benoit", "Catherine Aitken", "Yu He"]}, "usage": {"completion_tokens": 613, "prompt_tokens": 3384, "total_tokens": 3997, "completion_tokens_details": {"accepted_prediction_tokens": null, "audio_tokens": null, "reasoning_tokens": 450, "rejected_prediction_tokens": null, "image_tokens": 0}, "prompt_tokens_details": {"audio_tokens": 0, "cached_tokens": 3152}, "cost": 0.00059346, "is_byok": false, "cost_details": {"upstream_inference_cost": null, "upstream_inference_prompt_cost": 0.00028696, "upstream_inference_completions_cost": 0.0003065}}, "model": "openai/gpt-oss-120b"}
{"timestamp": "2025-10-24T17:33:18.554400", "feed": "arxiv_cslg", "title": "Transferable Black-Box One-Shot Forging of Watermarks via Image Preference Models", "link": "https://papers.cool/arxiv/2510.20468", "analysis": {"summary": "The paper introduces a black-box, one-shot watermark forging attack that uses a preference model trained on procedurally generated images to detect watermarks and then optimizes images via backagation to remove and reapply watermarks without access to the original watermarking algorithm. It demonstrates the method on several post-hoc image watermarking schemes, showing that a single watermarked example suffices to forge watermarks on malicious content, thereby exposing a significant security weakness.", "summary_cn": "本文提出一种黑盒单次水印伪造攻击，利用在程序化生成图像上训练的偏好模型判断图像是否带有水印，然后通过反向传播优化图像，实现去除并重新植入水印，无需了解原始水印算法。实验在多种后置图像水印方案上验证了该方法，仅需一张水印图即可在恶意内容上伪造水印，揭示了当前水印技术的显著安全弱点。", "keywords": "watermarking, black-box attack, image preference model, forgery, post-hoc watermark, security, generative AI, robustness", "scoring": {"interpretability": 2, "understanding": 6, "safety": 7, "technicality": 8, "surprisal": 7}, "category": {"failure_mode_addressed": "human-misuse", "primary_focus": "robustness"}, "authors": ["Tomáš Souček", "Sylvestre-Alvise Rebuffi", "Pierre Fernandez", "Nikola Jovanović", "Hady Elsahar", "Valeriu Lacatusu", "Tuan Tran", "Alexandre Mourachko"]}, "usage": {"completion_tokens": 711, "prompt_tokens": 3462, "total_tokens": 4173, "completion_tokens_details": {"accepted_prediction_tokens": null, "audio_tokens": null, "reasoning_tokens": 456, "rejected_prediction_tokens": null, "image_tokens": 0}, "prompt_tokens_details": {"audio_tokens": 0, "cached_tokens": 3152}, "cost": 0.00065416, "is_byok": false, "cost_details": {"upstream_inference_cost": null, "upstream_inference_prompt_cost": 0.00029866, "upstream_inference_completions_cost": 0.0003555}}, "model": "openai/gpt-oss-120b"}
{"timestamp": "2025-10-24T17:33:19.277142", "feed": "arxiv_cslg", "title": "GRACE: GRaph-based Addiction Care prEdiction", "link": "https://papers.cool/arxiv/2510.20671", "analysis": {"summary": "The paper introduces GRACE, a graph neural network framework that predicts the appropriate locus of care for addiction patients by modeling patient data as a meta-graph to address severe class imbalance. Extensive feature engineering and a new unbiased meta-graph construction improve minority‑class F1 scores by 11‑35% over existing baselines on real‑world datasets.", "summary_cn": "本文提出了 GRACE（GRaph-based Addiction Care prEdiction）框架，利用图神经网络（graph neural network）将成瘾患者数据建模为元图（meta-graph），以缓解数据中严重的类别不平衡问题。通过大量特征工程和新的无偏元图构建方法，在真实数据集上实现了少数类 F1 分数提升 11%‑35%，优于现有基线。", "keywords": "graph neural network, addiction care prediction, meta-graph, class imbalance, healthcare AI, structured learning", "scoring": {"interpretability": 2, "understanding": 5, "safety": 2, "technicality": 7, "surprisal": 5}, "category": {"failure_mode_addressed": "non-applicable", "primary_focus": "other"}, "authors": ["Subham Kumar", "Prakrithi Shivaprakash", "Koustav Rudra", "Lekhansh Shukla", "Animesh Mukherjee"]}, "usage": {"completion_tokens": 577, "prompt_tokens": 3378, "total_tokens": 3955, "completion_tokens_details": {"accepted_prediction_tokens": null, "audio_tokens": null, "reasoning_tokens": 352, "rejected_prediction_tokens": null, "image_tokens": 0}, "prompt_tokens_details": {"audio_tokens": 0, "cached_tokens": 3152}, "cost": 0.00057456, "is_byok": false, "cost_details": {"upstream_inference_cost": null, "upstream_inference_prompt_cost": 0.00028606, "upstream_inference_completions_cost": 0.0002885}}, "model": "openai/gpt-oss-120b"}
{"timestamp": "2025-10-24T17:33:19.338240", "feed": "arxiv_cslg", "title": "From Masks to Worlds: A Hitchhiker's Guide to World Models", "link": "https://papers.cool/arxiv/2510.20668", "analysis": {"summary": "The paper presents a directed overview of the development of world models, tracing a path from early multimodal masked models, through unified generative architectures, to interactive generative systems and memory‑augmented models that maintain consistent worlds over time. It emphasizes the core components—generative heart, perception‑action loop, and memory system—as the most promising route toward constructing true world models, rather than providing a broad survey of every related work.", "summary_cn": "本文提供了一篇聚焦于世界模型构建的导览，按照从早期多模态掩码模型到统一生成架构，再到闭环交互生成模型以及能够随时间保持一致世界的记忆增强系统的顺序展开。文章强调生成核心、感知‑行动循环与记忆系统这三大关键要素是实现真正世界模型的最有前景路径，而非对所有相关工作进行宽泛的综述。", "keywords": "world models, generative models, interactive loop, memory-augmented systems, multimodal masked models, representation learning", "scoring": {"interpretability": 3, "understanding": 6, "safety": 3, "technicality": 8, "surprisal": 5}, "category": {"failure_mode_addressed": "non-applicable", "primary_focus": "other"}, "authors": ["Jinbin Bai", "Yu Lei", "Hecong Wu", "Yuchen Zhu", "Shufan Li", "Yi Xin", "Xiangtai Li", "Molei Tao", "Aditya Grover", "Ming-Hsuan Yang"]}, "usage": {"completion_tokens": 520, "prompt_tokens": 3326, "total_tokens": 3846, "completion_tokens_details": {"accepted_prediction_tokens": null, "audio_tokens": null, "reasoning_tokens": 251, "rejected_prediction_tokens": null, "image_tokens": 0}, "prompt_tokens_details": {"audio_tokens": 0, "cached_tokens": 3152}, "cost": 0.00053826, "is_byok": false, "cost_details": {"upstream_inference_cost": null, "upstream_inference_prompt_cost": 0.00027826, "upstream_inference_completions_cost": 0.00026}}, "model": "openai/gpt-oss-120b"}
{"timestamp": "2025-10-24T17:33:19.345907", "feed": "arxiv_cslg", "title": "No-Regret Thompson Sampling for Finite-Horizon Markov Decision Processes with Gaussian Processes", "link": "https://papers.cool/arxiv/2510.20725", "analysis": {"summary": "The paper establishes no-regret guarantees for Thompson Sampling in finite‑horizon episodic Markov Decision Processes by employing joint Gaussian Process priors over rewards and transitions proving a regret bound of \\(\\tilde{O}(\\sqrt{KH\\Gamma(KH)})\\) across K episodes of horizon H. It tackles challenges such as the non‑Gaussian nature of value functions and recursive Bellman updates, extending tools like the elliptical potential lemma to multi‑output settings. This work advances theoretical understanding of Bayesian RL methods under structural Gaussian assumptions.", "summary_cn": "本文针对具有高斯过程（GP）先验的奖励和转移函数，在有限时域的周期性马尔可夫决策过程（MDP）中，对 Thompson 采样（TS）提供了无后悔（no‑regret）保证，证明了在 K 轮、每轮时长 H 的情形下，其后悔上界为 \\(\\tilde{O}(\\sqrt{KH\\Gamma(KH)})\\)。研究克服了价值函数非高斯分布和贝尔曼递归结构等难题，将椭圆势能引理等经典工具推广到多输出 GP 场景。该工作深化了在结构化高斯假设下贝叶斯强化学习的理论理解。", "keywords": "Thompson sampling, Gaussian processes, episodic reinforcement learning, regret analysis, finite-horizon MDP, Bayesian RL, elliptical potential lemma, multi-output GP, no-regret guarantees", "scoring": {"interpretability": 2, "understanding": 6, "safety": 2, "technicality": 8, "surprisal": 6}, "category": {"failure_mode_addressed": "non-applicable", "primary_focus": "other"}, "authors": ["Jasmine Bayrooti", "Sattar Vakili", "Amanda Prorok", "Carl Henrik Ek"]}, "usage": {"completion_tokens": 719, "prompt_tokens": 3410, "total_tokens": 4129, "completion_tokens_details": {"accepted_prediction_tokens": null, "audio_tokens": null, "reasoning_tokens": 360, "rejected_prediction_tokens": null, "image_tokens": 0}, "prompt_tokens_details": {"audio_tokens": 0, "cached_tokens": 3152}, "cost": 0.00065036, "is_byok": false, "cost_details": {"upstream_inference_cost": null, "upstream_inference_prompt_cost": 0.00029086, "upstream_inference_completions_cost": 0.0003595}}, "model": "openai/gpt-oss-120b"}
{"timestamp": "2025-10-24T17:33:19.356235", "feed": "arxiv_cslg", "title": "Connecting Jensen-Shannon and Kullback-Leibler Divergences: A New Bound for Representation Learning", "link": "https://papers.cool/arxiv/2510.20644", "analysis": {"summary": "The paper derives a new tight lower bound on the Kullback-Leibler divergence expressed in terms of the Jensen-Shannon divergence, and shows that maximizing a JSD-based objective yields a guaranteed lower bound on mutual information for representation learning. Experiments demonstrate that this bound provides stable, low‑variance MI estimates and is useful within the Information Bottleneck framework.", "summary_cn": "本文推导出一个将 Jensen-Shannon 散度与 Kullback-Leibler 散度关联的新紧下界，并证明最大化基于 JSD 的目标可以获得互信息的保证下界，从而用于表征学习。实验表明，该下界在互信息估计中具有稳定、低方差的特性，并在信息瓶颈框架中展示了实用价值。", "keywords": "Jensen-Shannon divergence, Kullback-Leibler divergence, mutual information, representation learning, variational lower bound, information bottleneck", "scoring": {"interpretability": 2, "understanding": 6, "safety": 2, "technicality": 8, "surprisal": 7}, "category": {"failure_mode_addressed": "non-applicable", "primary_focus": "other"}, "authors": ["Reuben Dorent", "Polina Golland", "William Wells III"]}, "usage": {"completion_tokens": 519, "prompt_tokens": 3503, "total_tokens": 4022, "completion_tokens_details": {"accepted_prediction_tokens": null, "audio_tokens": null, "reasoning_tokens": 295, "rejected_prediction_tokens": null, "image_tokens": 0}, "prompt_tokens_details": {"audio_tokens": 0, "cached_tokens": 3152}, "cost": 0.00056431, "is_byok": false, "cost_details": {"upstream_inference_cost": null, "upstream_inference_prompt_cost": 0.00030481, "upstream_inference_completions_cost": 0.0002595}}, "model": "openai/gpt-oss-120b"}
{"timestamp": "2025-10-24T17:33:19.377305", "feed": "arxiv_cslg", "title": "PSO-XAI: A PSO-Enhanced Explainable AI Framework for Reliable Breast Cancer Detection", "link": "https://papers.cool/arxiv/2510.20611", "analysis": {"summary": "The paper presents PSO-XAI, a framework that combines customized Particle Swarm Optimization for feature selection with model‑agnostic explainable AI methods to enhance breast cancer diagnosis. Evaluated on 29 diverse classifiers, the approach achieves 99.1% accuracy while reducing dimensionality and providing transparent explanations for clinical relevance.", "summary_cn": "本文提出 PSO‑XAI 框架，将定制化粒子群优化用于特征选择，并结合模型不可知的可解释人工智能方法，以提升乳腺癌诊断的可靠性。该框架在 29 种不同分类模型上进行评估，取得 99.1% 的准确率，同时降低维度并提供透明的临床解释。", "keywords": "breast cancer detection, particle swarm optimization, feature selection, explainable AI, model-agnostic explanations, medical diagnosis, classification, swarm intelligence", "scoring": {"interpretability": 6, "understanding": 6, "safety": 5, "technicality": 7, "surprisal": 6}, "category": {"failure_mode_addressed": "non-applicable", "primary_focus": "interpretability"}, "authors": ["Mirza Raquib", "Niloy Das", "Farida Siddiqi Prity", "Arafath Al Fahim", "Saydul Akbar Murad", "Mohammad Amzad Hossain", "MD Jiabul Hoque", "Mohammad Ali Moni"]}, "usage": {"completion_tokens": 726, "prompt_tokens": 3448, "total_tokens": 4174, "completion_tokens_details": {"accepted_prediction_tokens": null, "audio_tokens": null, "reasoning_tokens": 560, "rejected_prediction_tokens": null, "image_tokens": 0}, "prompt_tokens_details": {"audio_tokens": 0, "cached_tokens": 3152}, "cost": 0.00065956, "is_byok": false, "cost_details": {"upstream_inference_cost": null, "upstream_inference_prompt_cost": 0.00029656, "upstream_inference_completions_cost": 0.000363}}, "model": "openai/gpt-oss-120b"}
{"timestamp": "2025-10-24T17:33:19.577115", "feed": "arxiv_cslg", "title": "Hurdle-IMDL: An Imbalanced Learning Framework for Infrared Rainfall Retrieval", "link": "https://papers.cool/arxiv/2510.20486", "analysis": {"summary": "The paper introduces Hurdle-IMDL, a framework that tackles label imbalance in infrared rainfall retrieval by separating zero‑inflation and long‑tail issues, applying a hurdle model for non‑rain samples and an inverse‑model debiasing technique for heavy‑rain estimation. Experiments on eastern China data show that the method reduces systematic underestimation and significantly improves retrieval of heavy‑to‑extreme rain compared to standard, cost‑sensitive, generative, and multi‑task baselines.", "summary_cn": "本文提出 Hurdle‑IMDL 框架，通过将降雨分布的零膨胀（非降雨样本占多数）和长尾（轻雨样本相对重雨样本过多）两部分分离，分别使用 hurdle 模型处理零膨胀，并利用逆模型去偏技术（inverse model debiasing）提升对强降雨的检索精度。对中国东部地区的遥感数据进行实验，结果表明该方法在减轻系统性低估并显著提升重至极端降雨检索方面优于常规、代价敏感、生成式及多任务学习方法。", "keywords": "imbalanced learning, infrared rainfall retrieval, hurdle model, inverse model debiasing, remote sensing, heavy rain estimation", "scoring": {"interpretability": 2, "understanding": 6, "safety": 2, "technicality": 7, "surprisal": 6}, "category": {"failure_mode_addressed": "non-applicable", "primary_focus": "other"}, "authors": ["Fangjian Zhang", "Xiaoyong Zhuge", "Wenlan Wang", "Haixia Xiao", "Yuying Zhu", "Siyang Cheng"]}, "usage": {"completion_tokens": 574, "prompt_tokens": 3450, "total_tokens": 4024, "completion_tokens_details": {"accepted_prediction_tokens": null, "audio_tokens": null, "reasoning_tokens": 244, "rejected_prediction_tokens": null, "image_tokens": 0}, "prompt_tokens_details": {"audio_tokens": 0, "cached_tokens": 3152}, "cost": 0.00058386, "is_byok": false, "cost_details": {"upstream_inference_cost": null, "upstream_inference_prompt_cost": 0.00029686, "upstream_inference_completions_cost": 0.000287}}, "model": "openai/gpt-oss-120b"}
{"timestamp": "2025-10-24T17:33:19.683452", "feed": "arxiv_cslg", "title": "Explainable Benchmarking through the Lense of Concept Learning", "link": "https://papers.cool/arxiv/2510.20439", "analysis": {"summary": "The paper proposes a new paradigm called explainable benchmarking, which automatically generates explanations for the performance of systems in a benchmark. It demonstrates the paradigm on knowledge-graph-based question answering by introducing a novel concept learning method, PruneCEL, which outperforms existing learners and enables users to predict system behavior from the generated explanations.", "summary_cn": "本文提出了“可解释基准评估”（explainable benchmarking）新范式，旨在自动生成系统在基准测试中的表现解释。作者在基于知识图谱的问答任务上实现该范式，构建了新概念学习方法 PruneCEL ，其在解释性基准任务上比现有方法提升显著，且用户能够通过解释预测系统行为。", "keywords": "explainable benchmarking, concept learning, knowledge graph, question answering, PruneCEL, interpretability, performance explanation, evaluation metrics", "scoring": {"interpretability": 7, "understanding": 7, "safety": 3, "technicality": 7, "surprisal": 6}, "category": {"failure_mode_addressed": "non-applicable", "primary_focus": "interpretability"}, "authors": ["Quannian Zhang", "Michael Röder", "Nikit Srivastava", "N'Dah Jean Kouagou", "Axel-Cyrille Ngonga Ngomo"]}, "usage": {"completion_tokens": 582, "prompt_tokens": 3426, "total_tokens": 4008, "completion_tokens_details": {"accepted_prediction_tokens": null, "audio_tokens": null, "reasoning_tokens": 413, "rejected_prediction_tokens": null, "image_tokens": 0}, "prompt_tokens_details": {"audio_tokens": 0, "cached_tokens": 3152}, "cost": 0.00058426, "is_byok": false, "cost_details": {"upstream_inference_cost": null, "upstream_inference_prompt_cost": 0.00029326, "upstream_inference_completions_cost": 0.000291}}, "model": "openai/gpt-oss-120b"}
{"timestamp": "2025-10-24T17:33:19.728558", "feed": "arxiv_cslg", "title": "InvDec: Inverted Decoder for Multivariate Time Series Forecasting with Separated Temporal and Variate Modeling", "link": "https://papers.cool/arxiv/2510.20302", "analysis": {"summary": "InvDec introduces an inverted decoder architecture that separates temporal encoding from variate-level decoding for multivariate time series forecasting, using a patch-based temporal encoder and variate-wise self‑attention with delayed variate embeddings. The method achieves significant accuracy improvements on high‑dimensional benchmarks while retaining competitive performance on low‑dimensional datasets. Ablation studies confirm the contribution of each component and show that benefits increase with the number of variables.", "summary_cn": "InvDec 提出一种倒置解码器结构，将时间编码与变量层面解码分离，使用基于 Patch 的时间编码器和变量自注意力，并在时间编码后加入延迟变量嵌入，以保留时间特征完整性。该方法在高维数据集上显著提升预测精度，同时在低维数据集上保持竞争性能。消融实验验证了各组件的贡献，并表明随着变量数量增加，InvDec 的优势愈加明显。", "keywords": "multivariate time series, forecasting, temporal encoder, variate attention, inverted decoder, PatchTST, delayed variate embeddings, adaptive residual fusion", "scoring": {"interpretability": 2, "understanding": 5, "safety": 1, "technicality": 8, "surprisal": 6}, "category": {"failure_mode_addressed": "non-applicable", "primary_focus": "other"}, "authors": ["Yuhang Wang"]}, "usage": {"completion_tokens": 602, "prompt_tokens": 3452, "total_tokens": 4054, "completion_tokens_details": {"accepted_prediction_tokens": null, "audio_tokens": null, "reasoning_tokens": 350, "rejected_prediction_tokens": null, "image_tokens": 0}, "prompt_tokens_details": {"audio_tokens": 0, "cached_tokens": 3152}, "cost": 0.00059816, "is_byok": false, "cost_details": {"upstream_inference_cost": null, "upstream_inference_prompt_cost": 0.00029716, "upstream_inference_completions_cost": 0.000301}}, "model": "openai/gpt-oss-120b"}
{"timestamp": "2025-10-24T17:33:20.069501", "feed": "arxiv_cslg", "title": "Bi-CoG: Bi-Consistency-Guided Self-Training for Vision-Language Models", "link": "https://papers.cool/arxiv/2510.20477", "analysis": {"summary": "The paper introduces Bi-CoG, a plug-and-play self‑training framework for semi‑supervised fine‑tuning of vision‑language models that leverages both inter‑model and intra‑model consistency along with an error‑aware dynamic pseudo‑label assignment to produce higher‑quality, lower‑bias labels. The authors provide theoretical analysis and extensive experiments on 14 datasets, showing consistent performance gains over existing methods.", "summary_cn": "本文提出 Bi‑CoG，一种用于视觉语言模型半监督微调的即插即用自训练框架，通过利用模型间和模型内的一致性以及误差感知的动态伪标签分配策略，生成高质量、低偏差的伪标签。作者给出理论分析并在 14 个数据集上进行大量实验，展示了相较于现有方法的一致且显著的性能提升。", "keywords": "vision-language models, semi-supervised learning, self-training, pseudo-labeling, consistency regularization, Bi-CoG", "scoring": {"interpretability": 2, "understanding": 5, "safety": 1, "technicality": 7, "surprisal": 5}, "category": {"failure_mode_addressed": "non-applicable", "primary_focus": "robustness"}, "authors": ["Rui Zhu", "Song-Lin Lv", "Zi-Kang Wang", "Lan-Zhe Guo"]}, "usage": {"completion_tokens": 584, "prompt_tokens": 3405, "total_tokens": 3989, "completion_tokens_details": {"accepted_prediction_tokens": null, "audio_tokens": null, "reasoning_tokens": 322, "rejected_prediction_tokens": null, "image_tokens": 0}, "prompt_tokens_details": {"audio_tokens": 0, "cached_tokens": 3152}, "cost": 0.00058211, "is_byok": false, "cost_details": {"upstream_inference_cost": null, "upstream_inference_prompt_cost": 0.00029011, "upstream_inference_completions_cost": 0.000292}}, "model": "openai/gpt-oss-120b"}
{"timestamp": "2025-10-24T17:33:20.119950", "feed": "arxiv_cslg", "title": "Equitable Survival Prediction: A Fairness-Aware Survival Modeling (FASM) Approach", "link": "https://papers.cool/arxiv/2510.20629", "analysis": {"summary": "The paper introduces Fairness-Aware Survival Modeling (FASM), a method that jointly mitigates intra-group and cross-group risk ranking biases in censored survival data, demonstrated on SEER breast cancer prognosis. Experiments show that FASM improves fairness across racial groups while maintaining predictive discrimination comparable to standard survival models, with stable fairness over a ten‑year horizon. The approach highlights the importance of integrating equity considerations into clinical survival prediction.", "summary_cn": "本文提出公平感知生存建模（FASM）方法，旨在同时缓解生存分析中同组内部和跨组风险排序的偏差，并在 SEER 乳腺癌预后数据上进行验证。实验显示，FASM 在提升不同种族群体公平性的同时，保持与传统生存模型相当的预测能力，并在十年预测期内实现公平性稳定。该工作强调在临床生存预测中融入公平性原则的重要性。", "keywords": "fairness, survival analysis, censored data, healthcare equity, breast cancer prognosis, risk ranking, algorithmic bias", "scoring": {"interpretability": 2, "understanding": 5, "safety": 3, "technicality": 6, "surprisal": 5}, "category": {"failure_mode_addressed": "societal-disruption", "primary_focus": "other"}, "authors": ["Mingxuan Liu", "Yilin Ning", "Haoyuan Wang", "Chuan Hong", "Matthew Engelhard", "Danielle S. Bitterman", "William G. La Cava", "Nan Liu"]}, "usage": {"completion_tokens": 603, "prompt_tokens": 3426, "total_tokens": 4029, "completion_tokens_details": {"accepted_prediction_tokens": null, "audio_tokens": null, "reasoning_tokens": 347, "rejected_prediction_tokens": null, "image_tokens": 0}, "prompt_tokens_details": {"audio_tokens": 0, "cached_tokens": 3152}, "cost": 0.00059476, "is_byok": false, "cost_details": {"upstream_inference_cost": null, "upstream_inference_prompt_cost": 0.00029326, "upstream_inference_completions_cost": 0.0003015}}, "model": "openai/gpt-oss-120b"}
{"timestamp": "2025-10-24T17:33:20.244513", "feed": "arxiv_cslg", "title": "LEGO: A Lightweight and Efficient Multiple-Attribute Unlearning Framework for Recommender Systems", "link": "https://papers.cool/arxiv/2510.20327", "analysis": {"summary": "The paper introduces LEGO, a lightweight framework for simultaneously unlearning multiple sensitive attributes in recommender systems. It separates the process into Embedding Calibration, which removes attribute-specific information from user embeddings, and Flexible Combination, which merges calibrated embeddings to protect all attributes, formulated as a mutual information minimization problem. Experiments on three datasets and recommendation models demonstrate that LEGO achieves effective and efficient multi-attribute unlearning.", "summary_cn": "本文提出 LEGO 框架，实现推荐系统中对多个敏感属性的同时消除。通过 Embedding Calibration 步骤去除用户嵌入中特定属性的信息，再利用 Flexible Combination 将校准后的嵌入合并，从而保护所有敏感属性，整体过程被建模为互信息最小化问题。实验在三个真实数据集和三种推荐模型上验证了该方法的有效性和高效性。", "keywords": "recommendation systems, attribute unlearning, privacy, mutual information minimization, embedding calibration, multi-attribute unlearning, dynamic unlearning, efficiency", "scoring": {"interpretability": 3, "understanding": 6, "safety": 7, "technicality": 7, "surprisal": 6}, "category": {"failure_mode_addressed": "other", "primary_focus": "other"}, "authors": ["Fengyuan Yu", "Yuyuan Li", "Xiaohua Feng", "Junjie Fang", "Tao Wang", "Chaochao Chen"]}, "usage": {"completion_tokens": 621, "prompt_tokens": 3466, "total_tokens": 4087, "completion_tokens_details": {"accepted_prediction_tokens": null, "audio_tokens": null, "reasoning_tokens": 373, "rejected_prediction_tokens": null, "image_tokens": 0}, "prompt_tokens_details": {"audio_tokens": 0, "cached_tokens": 3152}, "cost": 0.00060976, "is_byok": false, "cost_details": {"upstream_inference_cost": null, "upstream_inference_prompt_cost": 0.00029926, "upstream_inference_completions_cost": 0.0003105}}, "model": "openai/gpt-oss-120b"}
{"timestamp": "2025-10-24T17:33:20.315193", "feed": "arxiv_cslg", "title": "Addressing Mark Imbalance in Integration-free Neural Marked Temporal Point Processes", "link": "https://papers.cool/arxiv/2510.20414", "analysis": {"summary": "The paper introduces a thresholding method that learns thresholds to adjust mark probabilities normalized by prior frequencies, addressing severe mark imbalance in marked temporal point processes. It also proposes an integration‑free neural MTPP architecture that predicts the mark before the time, enabling efficient probability estimation without costly numerical integration. Experiments on real‑world datasets show the approach outperforms existing baselines in both mark and time prediction.", "summary_cn": "本文提出一种阈值学习方法，通过对标记概率进行先验归一化的阈值调整，以缓解标记时序点过程中的标记不平衡问题。与此同时，设计了无需数值积分的神经 MTPP 模型，先预测标记再预测时间，从而实现高效的概率估计。实验证明该方案在真实数据集上相较于多种基线在标记及时间预测上均有显著提升。", "keywords": "marked temporal point processes, mark imbalance, thresholding, integration-free neural MTPP, event prediction, time sampling", "scoring": {"interpretability": 2, "understanding": 5, "safety": 2, "technicality": 7, "surprisal": 6}, "category": {"failure_mode_addressed": "non-applicable", "primary_focus": "other"}, "authors": ["Sishun Liu", "Ke Deng", "Xiuzhen Zhang", "Yongli Ren", "Yan Wang"]}, "usage": {"completion_tokens": 631, "prompt_tokens": 3421, "total_tokens": 4052, "completion_tokens_details": {"accepted_prediction_tokens": null, "audio_tokens": null, "reasoning_tokens": 419, "rejected_prediction_tokens": null, "image_tokens": 0}, "prompt_tokens_details": {"audio_tokens": 0, "cached_tokens": 3152}, "cost": 0.00060801, "is_byok": false, "cost_details": {"upstream_inference_cost": null, "upstream_inference_prompt_cost": 0.00029251, "upstream_inference_completions_cost": 0.0003155}}, "model": "openai/gpt-oss-120b"}
{"timestamp": "2025-10-24T17:33:20.360923", "feed": "arxiv_cslg", "title": "Quantifying Distributional Invariance in Causal Subgraph for IRM-Free Graph Generalization", "link": "https://papers.cool/arxiv/2510.20295", "analysis": {"summary": "The paper proposes an IRM-free approach for out-of-distribution generalization in graph neural networks by quantifying distributional invariance of causal subgraphs. It introduces the Invariant Distribution Criterion, proves a quantitative link between distributional shift and representation norm, and uses a norm-guided objective to discover causal subgraphs, achieving state-of-the-art performance on benchmark datasets.", "summary_cn": "本文提出一种无需 IRM 的图神经网络分布外泛化方法，通过量化因果子图的分布不变性来实现。作者提出“不变分布准则”，并证明了分布漂移与表示范数之间的定量关系，进而利用范数引导的目标函数发现因果子图，在多个基准数据集上实现了领先的性能。", "keywords": "causal subgraph, invariant distribution criterion, graph neural networks, OOD generalization, IRM-free, representation norm, graph robustness", "scoring": {"interpretability": 6, "understanding": 7, "safety": 3, "technicality": 8, "surprisal": 6}, "category": {"failure_mode_addressed": "non-applicable", "primary_focus": "robustness"}, "authors": ["Yang Qiu", "Yixiong Zou", "Jun Wang", "Wei Liu", "Xiangyu Fu", "Ruixuan Li"]}, "usage": {"completion_tokens": 635, "prompt_tokens": 3387, "total_tokens": 4022, "completion_tokens_details": {"accepted_prediction_tokens": null, "audio_tokens": null, "reasoning_tokens": 408, "rejected_prediction_tokens": null, "image_tokens": 0}, "prompt_tokens_details": {"audio_tokens": 0, "cached_tokens": 3152}, "cost": 0.00060491, "is_byok": false, "cost_details": {"upstream_inference_cost": null, "upstream_inference_prompt_cost": 0.00028741, "upstream_inference_completions_cost": 0.0003175}}, "model": "openai/gpt-oss-120b"}
{"timestamp": "2025-10-24T17:33:20.480519", "feed": "arxiv_cslg", "title": "Practical Code RAG at Scale: Task-Aware Retrieval Design Choices under Compute Budgets", "link": "https://papers.cool/arxiv/2510.20609", "analysis": {"summary": "The paper systematically evaluates retrieval configurations for code‑focused generation tasks (code completion and bug localization) under realistic compute budgets, comparing chunking strategies, similarity scoring methods, and splitting granularity. It shows that sparse BM25 with word‑level splitting outperforms dense retrievers for PL‑PL tasks while being much faster, whereas proprietary dense encoders excel for NL‑PL at higher latency, and provides practical guidelines on chunk size and latency‑quality trade‑offs.", "summary_cn": "本文系统评估了在实际计算预算约束下代码生成任务（代码补全和错误定位）的检索配置，比较了分块策略、相似度打分方法以及切分粒度。结果表明，对于 PL‑PL 场景，稀疏检索器 BM25 配合词级切分在质量和速度上均优于密集检索器，而在 NL‑PL 场景下专有的密集编码器（Voyager-3 系列）虽能获得更好效果，但延迟大约高出 100 倍；此外，文章还提供了块大小、延迟‑质量权衡的实用建议。", "keywords": "code retrieval, RAG, BM25, dense retrieval, chunking, code completion, bug localization, compute budget, latency trade-off", "scoring": {"interpretability": 2, "understanding": 6, "safety": 2, "technicality": 7, "surprisal": 6}, "category": {"failure_mode_addressed": "-applicable", "primary_focus": "robustness"}, "authors": ["Timur Galimzyanov", "Olga Kolomyttseva", "Egor Bogomolov"]}, "usage": {"completion_tokens": 822, "prompt_tokens": 3443, "total_tokens": 4265, "completion_tokens_details": {"accepted_prediction_tokens": null, "audio_tokens": null, "reasoning_tokens": 570, "rejected_prediction_tokens": null, "image_tokens": 0}, "prompt_tokens_details": {"audio_tokens": 0, "cached_tokens": 3152}, "cost": 0.00070681, "is_byok": false, "cost_details": {"upstream_inference_cost": null, "upstream_inference_prompt_cost": 0.00029581, "upstream_inference_completions_cost": 0.000411}}, "model": "openai/gpt-oss-120b"}
{"timestamp": "2025-10-24T17:33:20.546609", "feed": "arxiv_cslg", "title": "Ask a Strong LLM Judge when Your Reward Model is Uncertain", "link": "https://papers.cool/arxiv/2510.20369", "analysis": {"summary": "The paper introduces an uncertainty‑based routing framework that combines a fast reward model with a strong but costly LLM judge for reinforcement learning from human feedback. By quantifying uncertainty in pairwise preference classifications, uncertain instances are forwarded to the LLM judge while confident ones are evaluated by the reward model, improving performance and reducing reward hacking at comparable inference cost. Experiments on reward‑model benchmarks and downstream online RLHF tasks show the method outperforms random judge calling.", "summary_cn": "本文提出一种基于不确定性的路由框架，将快速奖励模型（reward model）与性能更强但计算开销更大的 LLM 判官（LLM judge）相结合用于 RLHF。通过对成对偏好分类（pairwise preference classification）进行不确定度量，对不确定的样本交给 LLM 判官处理，确定的样本则由奖励模型评估，从而在相同推理成本下提升效果并降低奖励 hacking。实验在奖励模型基准和在线 RLHF 任务上显示，该方法优于随机调用判官的策略。", "keywords": "reward model, RLHF, LLM judge, uncertainty routing, pairwise preference classification, alignment, reward hacking", "scoring": {"interpretability": 2, "understanding": 6, "safety": 7, "technicality": 8, "surprisal": 7}, "category": {"failure_mode_addressed": "misalignment", "primary_focus": "alignment"}, "authors": ["Zhenghao Xu", "Qin Lu", "Qingru Zhang", "Liang Qiu", "Ilgee Hong", "Changlong Yu", "Wenlin Yao", "Yao Liu", "Haoming Jiang", "Lihong Li", "Hyokun Yun", "Tuo Zhao"]}, "usage": {"completion_tokens": 833, "prompt_tokens": 3394, "total_tokens": 4227, "completion_tokens_details": {"accepted_prediction_tokens": null, "audio_tokens": null, "reasoning_tokens": 650, "rejected_prediction_tokens": null, "image_tokens": 0}, "prompt_tokens_details": {"audio_tokens": 0, "cached_tokens": 3152}, "cost": 0.00070496, "is_byok": false, "cost_details": {"upstream_inference_cost": null, "upstream_inference_prompt_cost": 0.00028846, "upstream_inference_completions_cost": 0.0004165}}, "model": "openai/gpt-oss-120b"}
{"timestamp": "2025-10-24T17:33:20.643281", "feed": "arxiv_cslg", "title": "Out-of-distribution Tests Reveal Compositionality in Chess Transformers", "link": "https://papers.cool/arxiv/2510.20783", "analysis": {"summary": "The paper trains a 270M‑parameter decision transformer to play chess and evaluates it on out‑of‑distribution scenarios designed to test systematic generalization. Results show that the model reliably follows basic chess rules and solves OOD puzzles, demonstrating compositional generalization, though it lags behind symbolic search especially on Chess960 variants. Training dynamics reveal an emergent understanding where the model first learns to move only its own pieces.", "summary_cn": "本文训练了一个 270M 参数的决策 Transformer（decision transformer）用于象棋，并在旨在检测系统性泛化的分布外（out‑of‑distribution）情景下进行评估。结果表明模型始终遵守象棋基本规则并能解出分布外谜题，展示了组合式泛化能力，但在 Chess960 等变体上仍不及显式搜索的符号 AI。训练动态显示模型最初学会仅移动自身棋子，暗示出现了对游戏的组合理解。", "keywords": "chess transformer, out-of-distribution, compositional generalization, systematic generalization, decision transformer, Chess960, rule extrapolation", "scoring": {"interpretability": 5, "understanding": 7, "safety": 2, "technicality": 7, "surprisal": 6}, "category": {"failure_mode_addressed": "non-applicable", "primary_focus": "interpretability"}, "authors": ["Anna Mészáros", "Patrik Reizinger", "Ferenc Huszár"]}, "usage": {"completion_tokens": 830, "prompt_tokens": 3428, "total_tokens": 4258, "completion_tokens_details": {"accepted_prediction_tokens": null, "audio_tokens": null, "reasoning_tokens": 640, "rejected_prediction_tokens": null, "image_tokens": 0}, "prompt_tokens_details": {"audio_tokens": 0, "cached_tokens": 3152}, "cost": 0.00070856, "is_byok": false, "cost_details": {"upstream_inference_cost": null, "upstream_inference_prompt_cost": 0.00029356, "upstream_inference_completions_cost": 0.000415}}, "model": "openai/gpt-oss-120b"}
{"timestamp": "2025-10-24T17:33:20.739653", "feed": "arxiv_cslg", "title": "SheafAlign: A Sheaf-theoretic Framework for Decentralized Multimodal Alignment", "link": "https://papers.cool/arxiv/2510.20540", "analysis": {"summary": "SheafAlign introduces a sheaf-theoretic framework for decentralized multimodal alignment, replacing the conventional single-space alignment with multiple comparison spaces that capture pairwise modality relations. By leveraging decentralized contrastive learning objectives, the method does not require mutual redundancy among all modalities, preserving both shared and unique information, and demonstrates superior zero-shot generalization, cross-modal alignment, and robustness to missing modalities with reduced communication cost.", "summary_cn": "SheafAlign 提出基于层析（sheaf）理论的去中心化多模态对齐框架，用多比较空间取代传统的单空间对齐，以捕获模态之间的成对关系。该方法利用去中心化对比学习目标，无需所有模态之间的相互冗余，既保留共享信息也保留独特信息，并在零样本泛化、跨模态对齐以及缺失模态鲁棒性方面表现优越，通信成本降低约 %。", "keywords": "sheaf theory, multimodal alignment, decentralized learning, contrastive learning, zero-shot generalization, missing modality robustness, communication efficiency", "scoring": {"interpretability": 2, "understanding": 6, "safety": 4, "technicality": 8, "surprisal": 7}, "category": {"failure_mode_addressed": "non-applicable", "primary_focus": "alignment"}, "authors": ["Abdulmomen Ghalkha", "Zhuojun Tian", "Chaouki Ben Issaid", "Mehdi Bennis"]}, "usage": {"completion_tokens": 666, "prompt_tokens": 3336, "total_tokens": 4002, "completion_tokens_details": {"accepted_prediction_tokens": null, "audio_tokens": null, "reasoning_tokens": 420, "rejected_prediction_tokens": null, "image_tokens": 0}, "prompt_tokens_details": {"audio_tokens": 0, "cached_tokens": 3152}, "cost": 0.00061276, "is_byok": false, "cost_details": {"upstream_inference_cost": null, "upstream_inference_prompt_cost": 0.00027976, "upstream_inference_completions_cost": 0.000333}}, "model": "openai/gpt-oss-120b"}
{"timestamp": "2025-10-24T17:33:20.798974", "feed": "arxiv_cslg", "title": "MEIcoder: Decoding Visual Stimuli from Neural Activity by Leveraging Most Exciting Inputs", "link": "https://papers.cool/arxiv/2510.20762", "analysis": {"summary": "MEIcoder is a biologically informed deep‑learning method that decodes visual stimuli from neural population activity by incorporating neuron‑specific most exciting inputs (MEIs), a structural similarity index loss, and adversarial training. It achieves state‑of‑the‑art reconstruction quality on primary visual cortex (V1) data, particularly when the dataset is small or contains few recorded neurons, and introduces a large benchmark to support future research.", "summary_cn": "MEIcoder 是一种结合了神经元特定的最激发输入（MEIs）、结构相似性指数（SSIM）损失以及对抗训练的生物学驱动深度学习解码方法。该方法在原始视觉皮层 (V1) 神经活动上实现了最先进的图像重建性能，尤其在数据量有限或记录神经元数量较少的情况下表现突出，并提供了一个包含超过 160,000 条样本的统一基准以促进后续研究。", "keywords": "neural decoding, most exciting inputs, visual cortex, brain-machine interface, adversarial training, SSIM loss, MEIcoder, population activity", "scoring": {"interpretability": 4, "understanding": 6, "safety": 2, "technicality": 7, "surprisal": 7}, "category": {"failure_mode_addressed": "non-applicable", "primary_focus": "other"}, "authors": ["Jan Sobotka", "Luca Baroni", "Ján Antolík"]}, "usage": {"completion_tokens": 686, "prompt_tokens": 3448, "total_tokens": 4134, "completion_tokens_details": {"accepted_prediction_tokens": null, "audio_tokens": null, "reasoning_tokens": 452, "rejected_prediction_tokens": null, "image_tokens": 0}, "prompt_tokens_details": {"audio_tokens": 0, "cached_tokens": 3152}, "cost": 0.00063956, "is_byok": false, "cost_details": {"upstream_inference_cost": null, "upstream_inference_prompt_cost": 0.00029656, "upstream_inference_completions_cost": 0.000343}}, "model": "openai/gpt-oss-120b"}
{"timestamp": "2025-10-24T17:33:21.237899", "feed": "arxiv_cslg", "title": "Why DPO is a Misspecified Estimator and How to Fix It", "link": "https://papers.cool/arxiv/2510.20413", "analysis": {"summary": "The paper shows that Direct Preference Optimization (DPO) constitutes a misspecified estimator when the true reward function cannot be represented within the policy class, leading to preference order reversal and sensitivity issues. By analyzing the local geometry of two‑stage RLHF, the authors derive a natural‑gradient interpretation and propose AuxDPO, which adds auxiliary variables to the loss to better approximate the RLHF solution. Empirical results on bandit simulations and LLM alignment tasks demonstrate that AuxDPO mitigates DPO’s misspecification and improves performance.", "summary_cn": "本文指出，当真实奖励函数无法在所使用的策略类中实现时，直接偏好优化（DPO）会成为一种模型错配的估计方法，导致偏好顺序逆转、奖励下降以及对偏好数据分布的高度敏感。通过对两阶段RLHF在参数空间的局部几何行为进行分析，作者将其关联到策略空间的自然梯度步骤，并据此提出 AuxDPO——在 DPO 损失中引入辅助变量以在原理上逼近 RLHF 解并缓解错配问题。在带娃乐队实验及大型语言模型对齐任务中的实验表明，AuxDPO 在性能上优于原始 DPO。", "keywords": "Direct Preference Optimization, RLHF, alignment, misspecification, AuxDPO, natural gradient, policy optimization, LLM alignment, bandit experiments", "scoring": {"interpretability": 3, "understanding": 7, "safety": 7, "technicality": 8, "surprisal": 7}, "category": {"failure_mode_addressed": "misalignment", "primary_focus": "alignment"}, "authors": ["Aditya Gopalan", "Sayak Ray Chowdhury", "Debangshu Banerjee"]}, "usage": {"completion_tokens": 677, "prompt_tokens": 3403, "total_tokens": 4080, "completion_tokens_details": {"accepted_prediction_tokens": null, "audio_tokens": null, "reasoning_tokens": 353, "rejected_prediction_tokens": null, "image_tokens": 0}, "prompt_tokens_details": {"audio_tokens": 0, "cached_tokens": 3152}, "cost": 0.00062831, "is_byok": false, "cost_details": {"upstream_inference_cost": null, "upstream_inference_prompt_cost": 0.00028981, "upstream_inference_completions_cost": 0.0003385}}, "model": "openai/gpt-oss-120b"}
{"timestamp": "2025-10-24T17:33:21.257429", "feed": "arxiv_cslg", "title": "Large Multimodal Models-Empowered Task-Oriented Autonomous Communications: Design Methodology and Implementation Challenges", "link": "https://papers.cool/arxiv/2510.20637", "analysis": {"summary": "The paper surveys the use of large language models (LLMs) and large multimodal models (LMMs) as core components for task-oriented autonomous communications in 6G networks, outlining design methodology, multimodal sensing integration, adaptive reconfiguration, and prompt/fine‑tuning strategies. It demonstrates the approach through three case studies—LMM‑based traffic control, LLM‑based robot scheduling, and LMM‑based environment‑aware channel estimation—and reports performance gains over conventional deep‑learning baselines, especially in dynamic and heterogeneous scenarios.", "summary_cn": "本文调研了大型语言模型（LLM）和大型多模态模型（LMM）在 6G 任务导向自主通信中的应用，阐述了设计方法论、多模态感知集成、自适应重构以及提示/微调策略。通过 LMM 驱动的交通控制、LLM 驱动的机器人调度和 LMM 驱动的环境感知信道估三个案例，展示了相较于传统深度学习方法在动态目标、输入参数变化和异构多模态条件下的显著性能提升。", "keywords": "large language models, large multimodal models, autonomous communications, task-oriented, 6G, multimodal sensing, prompt tuning, wireless task optimization, channel estimation, robot scheduling", "scoring": {"interpretability": 2, "understanding": 6, "safety": 2, "technicality": 7, "surprisal": 5}, "category": {"failure_mode_addressed": "non-applicable", "primary_focus": "other"}, "authors": ["Hyun Jong Yang", "Hyunsoo Kim", "Hyeonho Noh", "Seungnyun Kim", "Byonghyo Shim"]}, "usage": {"completion_tokens": 695, "prompt_tokens": 3386, "total_tokens": 4081, "completion_tokens_details": {"accepted_prediction_tokens": null, "audio_tokens": null, "reasoning_tokens": 388, "rejected_prediction_tokens": null, "image_tokens": 0}, "prompt_tokens_details": {"audio_tokens": 0, "cached_tokens": 3152}, "cost": 0.00063476, "is_byok": false, "cost_details": {"upstream_inference_cost": null, "upstream_inference_prompt_cost": 0.00028726, "upstream_inference_completions_cost": 0.0003475}}, "model": "openai/gpt-oss-120b"}
{"timestamp": "2025-10-24T17:33:21.904621", "feed": "arxiv_cslg", "title": "Generalizable Reasoning through Compositional Energy Minimization", "link": "https://papers.cool/arxiv/2510.20607", "analysis": {"summary": "The paper introduces a compositional energy minimization framework that learns energy functions for small subproblems and combines them at test time to form a global energy landscape, enabling reasoning over larger, more complex tasks with additional constraints. A parallel energy minimization (PEM) algorithm is proposed to efficiently sample high‑quality solutions, and empirical results show state‑of‑the‑art generalization performance on diverse reasoning benchmarks.", "summary_cn": "本文提出了一种组合式能量最小化方法，通过为较小的子问题学习能函数并在测试时将其组合成全局能量景观，从而在加入额外约束的情况下解决更大、更复杂的推理任务。作者进一步设计了并行能量最小化（PEM）算法以提升采样质量，实验表明该方法在多种推理基准上实现了领先的泛化性能。", "keywords": "compositional energy minimization, energy-based models, reasoning generalization, compositional inference, parallel energy minimization, constraint-based reasoning, neural reasoning, sample quality", "scoring": {"interpretability": 3, "understanding": 7, "safety": 2, "technicality": 8, "surprisal": 7}, "category": {"failure_mode_addressed": "non-applicable", "primary_focus": "robustness"}, "authors": ["Alexandru Oarga", "Yilun Du"]}, "usage": {"completion_tokens": 739, "prompt_tokens": 3422, "total_tokens": 4161, "completion_tokens_details": {"accepted_prediction_tokens": null, "audio_tokens": null, "reasoning_tokens": 523, "rejected_prediction_tokens": null, "image_tokens": 0}, "prompt_tokens_details": {"audio_tokens": 0, "cached_tokens": 3152}, "cost": 0.00066216, "is_byok": false, "cost_details": {"upstream_inference_cost": null, "upstream_inference_prompt_cost": 0.00029266, "upstream_inference_completions_cost": 0.0003695}}, "model": "openai/gpt-oss-120b"}
{"timestamp": "2025-10-24T17:33:21.986430", "feed": "arxiv_cslg", "title": "xTime: Extreme Event Prediction with Hierarchical Knowledge Distillation and Expert Fusion", "link": "https://papers.cool/arxiv/2510.20651", "analysis": {"summary": "The paper introduces xTime, a framework for forecasting extreme events in time series by employing hierarchical knowledge distillation from models trained on more common events and a mixture‑of‑experts mechanism that fuses predictions across rarity levels. Experiments on several datasets show substantial gains in extreme‑event accuracy, improving performance from 3% to up to 78%. The approach addresses data imbalance and leverages intermediate events to better anticipate rare, high‑impact occurrences.", "summary_cn": "本文提出 xTime 框架，通过层次化知识蒸馏将低稀有度事件模型的知识迁移至稀有事件模型，并使用专家混合（xture of Experts）机制在不同稀有度水平的专家模型之间动态选择与融合输出，以提升极端事件的预测精度。实验在多个数据集上显示，极端事件的预测准确率从 3% 提升至最高 78%。该方法针对数据不平衡问题，并利用中间事件信息更好地预测高影响的稀有事件。", "keywords": "extreme event prediction, time series forecasting, knowledge distillation, mixture of experts, hierarchical distillation, rare event modeling, imbalanced data, healthcare forecasting, climate forecasting", "scoring": {"interpretability": 2, "understanding": 6, "safety": 5, "technicality": 8, "surprisal": 6}, "category": {"failure_mode_addressed": "societal-disruption", "primary_focus": "robustness"}, "authors": ["Quan Li", "Wenchao Yu", "Suhang Wang", "Minhua Lin", "Lingwei Chen", "Wei Cheng", "Haifeng Chen"]}, "usage": {"completion_tokens": 749, "prompt_tokens": 3419, "total_tokens": 4168, "completion_tokens_details": {"accepted_prediction_tokens": null, "audio_tokens": null, "reasoning_tokens": 474, "rejected_prediction_tokens": null, "image_tokens": 0}, "prompt_tokens_details": {"audio_tokens": 0, "cached_tokens": 3152}, "cost": 0.00066671, "is_byok": false, "cost_details": {"upstream_inference_cost": null, "upstream_inference_prompt_cost": 0.00029221, "upstream_inference_completions_cost": 0.0003745}}, "model": "openai/gpt-oss-120b"}
{"timestamp": "2025-10-24T17:33:22.682415", "feed": "arxiv_cslg", "title": "BadGraph: A Backdoor Attack Against Latent Diffusion Model for Text-Guided Graph Generation", "link": "https://papers.cool/arxiv/2510.20792", "analysis": {"summary": "BadGraph proposes a backdoor attack on latent diffusion models used for text‑guided graph generation, inserting textual triggers into a small portion of the training data to cause the model to output attacker‑specified subgraphs when the trigger appears. Experiments on four benchmark graph datasets show that with less than 10% poisoned data the attack achieves a 50% success rate, and with 24% poisoning the success exceeds 80%, while maintaining normal performance on clean inputs. The study highlights serious security risks for applications such as drug discovery and calls for robust defenses against such diffusion‑model backdoors.", "summary_cn": "BadGraph 提出了一种针对用于文本引导图的潜在扩散模型的后门攻击方法，通过在少量训练数据中植入文本触发词，使模型在出现触发词时输出攻击者指定的子图。实验在四个基准图数据集上表明，低于 10% 的数据中毒率即可实现 50% 的攻击成功率，约 24% 的中毒率可超过 80% 成功率，同时对正常输入的性能影响甚微。该研究揭示了药物发现等应用中的严重安全风险，并呼吁对这种扩散模型后进行稳健防御。", "keywords": "backdoor attack, latent diffusion model, text-guided graph generation, graph generation, security, data poisoning, VAE, diffusion, drug discovery, robustness", "scoring": {"interpretability": 2, "understanding": 6, "safety": 8, "technicality": 7, "surprisal": 7}, "category": {"failure_mode_addressed": "human-misuse", "primary_focus": "robustness"}, "authors": ["Liang Ye", "Shengqin Chen", "Jiazhu Dai"]}, "usage": {"completion_tokens": 790, "prompt_tokens": 3442, "total_tokens": 4232, "completion_tokens_details": {"accepted_prediction_tokens": null, "audio_tokens": null, "reasoning_tokens": 487, "rejected_prediction_tokens": null, "image_tokens": 0}, "prompt_tokens_details": {"audio_tokens": 0, "cached_tokens": 3152}, "cost": 0.00069066, "is_byok": false, "cost_details": {"upstream_inference_cost": null, "upstream_inference_prompt_cost": 0.00029566, "upstream_inference_completions_cost": 0.000395}}, "model": "openai/gpt-oss-120b"}
{"timestamp": "2025-10-24T17:33:22.692714", "feed": "arxiv_cslg", "title": "Unsupervised Anomaly Prediction with N-BEATS and Graph Neural Network in Multi-variate Semiconductor Process Time Series", "link": "https://papers.cool/arxiv/2510.20718", "analysis": {"summary": "The paper introduces two unsupervised approaches for anomaly prediction in multivariate semiconductor process time series: a univariate N-BEATS forecaster assuming variable independence, and a graph neural network (GNN) forecaster that captures inter-variable dependencies. Both models are trained on presumed normal data, forecast future values, and flag deviations beyond a threshold as anomalies, achieving stable prediction up to 50 steps with the GNN outperforming N-BEATS in accuracy and efficiency. The results demonstrate the GNN's suitability for online fault prediction in manufacturing environments.", "summary_cn": "本文提出了两种用于半导体工艺多变量时间序列异常的无监督方法：一种基于 N-BEATS 的单变量预测模型，假设变量之间相互独立；另一种基于图神经网络（GNN）的预测模型，捕获变量间的依赖关系。两种模型均在假定无异常的正常数据上进行训练，预测未来数值并将超过阈值的偏差标记为异常，实验显示 GNN 在预测精度和计算效率上优于 N-BEATS，能够在长达 50 步的预测范围内保持稳定，适用于制造环境在线故障预测。", "keywords": "unsupervised anomaly prediction, multivariate time series, semiconductor manufacturing, N-BEATS, graph neural network, forecasting, fault detection, online monitoring", "scoring": {"interpretability": 3, "understanding": 4, "safety": 4, "technicality": 7, "surprisal": 5}, "category": {"failure_mode_addressed": "non-applicable", "primary_focus": "robustness"}, "authors": ["Daniel Sorensen", "Bappaditya Dey", "Minjin Hwang", "Sandip Halder"]}, "usage": {"completion_tokens": 790, "prompt_tokens": 3516, "total_tokens": 4306, "completion_tokens_details": {"accepted_prediction_tokens": null, "audio_tokens": null, "reasoning_tokens": 473, "rejected_prediction_tokens": null, "image_tokens": 0}, "prompt_tokens_details": {"audio_tokens": 0, "cached_tokens": 3152}, "cost": 0.00070176, "is_byok": false, "cost_details": {"upstream_inference_cost": null, "upstream_inference_prompt_cost": 0.00030676, "upstream_inference_completions_cost": 0.000395}}, "model": "openai/gpt-oss-120b"}
{"timestamp": "2025-10-24T17:33:22.787124", "feed": "arxiv_cslg", "title": "KCM: KAN-Based Collaboration Models Enhance Pretrained Large Models", "link": "https://papers.cool/arxiv/2510.20278", "analysis": {"summary": "The paper introduces KCM, a collaboration framework that uses a Kolmogorov-Arnold Network (KAN) as a small auxiliary model to assist pretrained large models across language, vision, and vision-language tasks. By leveraging KAN's higher visualizability and interpretability, KCM reduces the number of large‑model inference calls while preserving accuracy and mitigating catastrophic forgetting and hallucination issues that commonly arise with MLP‑based collaborators. Experiments show that KCM consistently outperforms MLP‑ small collaborative models in both efficiency and performance metrics.", "summary_cn": "本文提出 KCM——一种基于 Kolmogorov-Arnold Network (KAN) 的小模型协作框架，用于帮助预训练大模型在语言、视觉及跨模态任务中协同工作。相较于传统的 MLP 小模型，KAN 具有更强的可视化和可解释性，能够显著降低大模型调用次数，同时在保持准确率的情况下缓解灾难性遗忘和幻觉问题。实验表明，KCM 在效率和项性能指标上均优于基于 MLP 的小协作模型。", "keywords": "KAN, Kolmogorov-Arnold Network, large-small model collaboration, catastrophic forgetting mitigation, model interpretability, hallucination reduction, cross-modal tasks, efficiency", "scoring": {"interpretability": 7, "understanding": 6, "safety": 5, "technicality": 7, "surprisal": 6}, "category": {"failure_mode_addressed": "misalignment", "primary_focus": "interpretability"}, "authors": ["Guangyu Dai", "Siliang Tang", "Yueting Zhuang"]}, "usage": {"completion_tokens": 760, "prompt_tokens": 3472, "total_tokens": 4232, "completion_tokens_details": {"accepted_prediction_tokens": null, "audio_tokens": null, "reasoning_tokens": 483, "rejected_prediction_tokens": null, "image_tokens": 0}, "prompt_tokens_details": {"audio_tokens": 0, "cached_tokens": 3152}, "cost": 0.00068016, "is_byok": false, "cost_details": {"upstream_inference_cost": null, "upstream_inference_prompt_cost": 0.00030016, "upstream_inference_completions_cost": 0.00038}}, "model": "openai/gpt-oss-120b"}
{"timestamp": "2025-10-24T17:33:22.876511", "feed": "arxiv_cslg", "title": "KL-Regularized Reinforcement Learning is Designed to Mode Collapse", "link": "https://papers.cool/arxiv/2510.20817", "analysis": {"summary": "The paper shows that the common belief that reverse KL leads to mode seeking and forward KL to mass covering does not reliably extend to KL-regularized reinforcement learning, where mode coverage is mainly driven by regularization strength and reward scaling. It derives the family of optimal target distributions, highlights that typical low-regularization settings produce unimodal targets, and proposes a simple adjustment to reward magnitudes that yields diverse, high-quality samples for large language and chemical language models with both forward and reverse KL.", "summary_cn": "本文指出，逆 KL 导致模式寻找、正 KL 覆盖整体的直觉并不适用于 KL 正则化的强化学习；模式覆盖主要取决于正则化强度和奖励与参考概率的相对尺度。研究了最优目标分布的形式，发现常用的低正则化设置会产生单峰目标，并提出通过轻微调节奖励大小即可在正向和逆向 KL 下实现高质量且多样的样本，适用于大语言模型和化学语言模型。", "keywords": "KL regularization, reinforcement learning, mode collapse, forward KL, reverse KL, diversity, large language models, chemical language models", "scoring": {"interpretability": 3, "understanding": 7, "safety": 4, "technicality": 8, "surprisal": 7}, "category": {"failure_mode_addressed": "non-applicable", "primary_focus": "robustness"}, "authors": ["Anthony GX-Chen", "Jatin Prakash", "Jeff Guo", "Rob Fergus", "Rajesh Ranganath"]}, "usage": {"completion_tokens": 761, "prompt_tokens": 3448, "total_tokens": 4209, "completion_tokens_details": {"accepted_prediction_tokens": null, "audio_tokens": null, "reasoning_tokens": 522, "rejected_prediction_tokens": null, "image_tokens": 0}, "prompt_tokens_details": {"audio_tokens": 0, "cached_tokens": 3152}, "cost": 0.00067706, "is_byok": false, "cost_details": {"upstream_inference_cost": null, "upstream_inference_prompt_cost": 0.00029656, "upstream_inference_completions_cost": 0.0003805}}, "model": "openai/gpt-oss-120b"}
{"timestamp": "2025-10-24T17:33:23.047335", "feed": "arxiv_cslg", "title": "A Scalable, Causal, and Energy Efficient Framework for Neural Decoding with Spiking Neural Networks", "link": "https://papers.cool/arxiv/2510.20683", "analysis": {"summary": "The paper introduces Spikachu, a neural decoding framework based on spiking neural networks that processes binned spikes into a shared latent space and decodes behavior in a causal, energy‑efficient manner. Evaluated on 113 sessions from six non‑human primates, Spikachu outperforms causal baselines while using orders of magnitude less energy and benefits from scaling across sessions for few‑shot transfer to new subjects and tasks.", "summary_cn": "本文提出 Spikachu——一种基于脉冲神经网络（SNN）的神经解码框架，通过将分箱脉冲投射到共享潜在空间并进行因果、低能耗的特征提取和行为解码。该方法在来自六只灵长类动物的 113 场实验上表现优于因果基线，同时能耗降低数十倍，并通过跨会话和跨受试者的规模化训练实现对新会话、受试者和任务的少样本迁移。", "keywords": "spiking neural networks, neural decoding, brain-computer interface, energy efficiency, causal models, few-shot transfer, online learning", "scoring": {"interpretability": 3, "understanding": 6, "safety": 2, "technicality": 7, "surprisal": 6}, "category": {"failure_mode_addressed": "non-applicable", "primary_focus": "other"}, "authors": ["Georgios Mentzelopoulos", "Ioannis Asmanis", "Konrad P. Kording", "Eva L. Dyer", "Kostas Daniilidis", "Flavia Vitale"]}, "usage": {"completion_tokens": 1021, "prompt_tokens": 3552, "total_tokens": 4573, "completion_tokens_details": {"accepted_prediction_tokens": null, "audio_tokens": null, "reasoning_tokens": 822, "rejected_prediction_tokens": null, "image_tokens": 0}, "prompt_tokens_details": {"audio_tokens": 0, "cached_tokens": 3152}, "cost": 0.00082266, "is_byok": false, "cost_details": {"upstream_inference_cost": null, "upstream_inference_prompt_cost": 0.00031216, "upstream_inference_completions_cost": 0.0005105}}, "model": "openai/gpt-oss-120b"}
{"timestamp": "2025-10-24T17:33:23.110278", "feed": "arxiv_cslg", "title": "Thought Communication in Multiagent Collaboration", "link": "https://papers.cool/arxiv/2510.20733", "analysis": {"summary": "The paper introduces \"thought communication\", a paradigm where multi‑agent systems exchange latent internal representations directly rather than natural language, formalized as a non‑parametric latent variable model with provable identifiability of shared and private thoughts. Guided by this theory, the authors present a framework that extracts these latent thoughts and assigns them to agents, demonstrating on synthetic and real‑world benchmarks that such communication improves collaborative performance. The work highlights the potential of leveraging hidden generative processes beyond surface‑level observation.", "summary_cn": "本文提出“thought communication”（思维通信）范式，使多智能体系统直接交换潜在的内部表征（latent thoughts），而非自然语言，并将其形式化为具有可辨识性的非参数潜变量模型，可识别共享与私有思维。基于该理论，作者构建了提取并分配这些潜在思维的框架，在合成和真实基准上验证了该方法提升协作效果。该工作强调利用隐藏生成过程超表层观测的潜力。", "keywords": "thought communication, latent variable model, multi-agent collaboration, latent representations, identifiability, emergent communication, LLM, internal state extraction", "scoring": {"interpretability": 8, "understanding": 7, "safety": 3, "technicality": 8, "surprisal": 7}, "category": {"failure_mode_addressed": "non-applicable", "primary_focus": "interpretability"}, "authors": ["Yujia Zheng", "Zhuokai Zhao", "Zijian Li", "Yaqi Xie", "Mingze Gao", "Lizhu Zhang", "Kun Zhang"]}, "usage": {"completion_tokens": 774, "prompt_tokens": 3473, "total_tokens": 4247, "completion_tokens_details": {"accepted_prediction_tokens": null, "audio_tokens": null, "reasoning_tokens": 579, "rejected_prediction_tokens": null, "image_tokens": 0}, "prompt_tokens_details": {"audio_tokens": 0, "cached_tokens": 3152}, "cost": 0.00068731, "is_byok": false, "cost_details": {"upstream_inference_cost": null, "upstream_inference_prompt_cost": 0.00030031, "upstream_inference_completions_cost": 0.000387}}, "model": "openai/gpt-oss-120b"}
{"timestamp": "2025-10-24T17:33:23.149919", "feed": "arxiv_cslg", "title": "Optimizing Clinical Fall Risk Prediction: A Data-Driven Integration of EHR Variables with the Johns Hopkins Fall Risk Assessment Tool", "link": "https://papers.cool/arxiv/2510.20714", "analysis": {"summary": "The paper presents a data‑driven approach that augments the Johns Hopkins Fall Risk Assessment Tool (JHFRAT) with additional electronic health record variables using constrained score optimization (CSO) models to retain interpretability while improving predictive performance. On a retrospective cohort of over 54,000 admissions, the CSO model achieved an AUC‑ROC of 0.91, surpassing the original JHFRAT, and performed comparably to a black‑box XGBoost model while being more robust to labeling variations. The study demonstrates how knowledge‑based, interpretable models can enhance inpatient fall risk assessment and support patient safety initiatives.", "summary_cn": "本文提出一种数据驱动的方法，使用约束得分优化（CSO）模型在保持可解释性的前提下，将约翰斯·霍普金斯跌倒风险评估工具（JHFRAT）与额外的电子健康记录（EHR）变量结合，以提升预测性能。基于 54,209 例住院数据的回顾性分析显示，CSO 模型的 AUC‑ROC 为 0.91，优于原 JHFRAT（0.86），且在稳健性方面与黑箱 XGBoost 模型相当。该研究展示了基于知识的可解释模型如何改进住院倒风险评估并支持患者安全。", "keywords": "fall risk prediction, electronic health records, constrained score optimization, JHFRAT, interpretable model, clinical decision support, patient safety, logistic regression, XGBoost", "scoring": {"interpretability": 7, "understanding": 6, "safety": 2, "technicality": 6, "surprisal": 5}, "category": {"failure_mode_addressed": "non-applicable", "primary_focus": "interpretability"}, "authors": ["Fardin Ganjkhanloo", "Emmett Springer", "Erik H. Hoyer", "Daniel L. Young", "Kimia Ghobadi"]}, "usage": {"completion_tokens": 775, "prompt_tokens": 3474, "total_tokens": 4249, "completion_tokens_details": {"accepted_prediction_tokens": null, "audio_tokens": null, "reasoning_tokens": 425, "rejected_prediction_tokens": null, "image_tokens": 0}, "prompt_tokens_details": {"audio_tokens": 0, "cached_tokens": 3152}, "cost": 0.00068796, "is_byok": false, "cost_details": {"upstream_inference_cost": null, "upstream_inference_prompt_cost": 0.00030046, "upstream_inference_completions_cost": 0.0003875}}, "model": "openai/gpt-oss-120b"}
{"timestamp": "2025-10-24T17:33:23.832838", "feed": "arxiv_cslg", "title": "H-SPLID: HSIC-based Saliency Preserving Latent Information Decomposition", "link": "https://papers.cool/arxiv/2510.20627", "analysis": {"summary": "We propose H‑SPLID, an HSIC‑based algorithm that explicitly separates salient and non‑salient features into distinct latent subspaces, encouraging low‑dimensional task‑relevant representations. We prove that the expected prediction deviation under inputations is bounded by the dimension of the salient subspace and the HSIC between inputs and representations, linking robustness to latent compression. Experiments on image classification show that models trained with H‑SPLID rely mainly on salient components, demonstrating reduced sensitivity to background perturbations.", "summary_cn": "我们提出 H‑SPLID，一种基于 HSIC 的算法，通过将显著特征和非显著特征显式分解到不同的潜在子空间中，促进低维任务相关特征的学习。我们证明，在输入扰动下的期望预测偏可以由显著子空间的维度和输入与表征之间的 HSIC 上界，从而建立了鲁棒性与潜在表征压缩之间的联系。对图像分类任务的实验表明，使用 H‑SPLID 训练的模型主要依赖显著输入成分，对背景扰动的敏感性显著降低。", "keywords": "saliency decomposition, HSIC, latent representation, robustness, feature learning, dimensionality reduction, image classification, perturbation resistance", "scoring": {"interpretability": 4, "understanding": 7, "safety": 5, "technicality": 8, "surprisal": 6}, "category": {"failure_mode_addressed": "non-applicable", "primary_focus": "robustness"}, "authors": ["Lukas Miklautz", "Chengzhi Shi", "Andrii Shkabrii", "Theodoros Thirimachos Davarakis", "Prudence Lam", "Claudia Plant", "Jennifer Dy", "Stratis Ioannidis"]}, "usage": {"completion_tokens": 866, "prompt_tokens": 3364, "total_tokens": 4230, "completion_tokens_details": {"accepted_prediction_tokens": null, "audio_tokens": null, "reasoning_tokens": 649, "rejected_prediction_tokens": null, "image_tokens": 0}, "prompt_tokens_details": {"audio_tokens": 0, "cached_tokens": 3152}, "cost": 0.00071696, "is_byok": false, "cost_details": {"upstream_inference_cost": null, "upstream_inference_prompt_cost": 0.00028396, "upstream_inference_completions_cost": 0.000433}}, "model": "openai/gpt-oss-120b"}
{"timestamp": "2025-10-24T17:33:24.822135", "feed": "arxiv_cslg", "title": "On Optimal Hyperparameters for Differentially Private Deep Transfer Learning", "link": "https://papers.cool/arxiv/2510.20616", "analysis": {"summary": "The paper studies differential privacy for fine‑tuning pretrained models and investigates how to select the clipping bound C and batch size B under a fixed compute budget. It shows that theoretical guidance (smaller C for privacy) conflicts with empirical results (larger C works better) due to changes in gradient distributions, and that common batch‑size heuristics fail, with cumulative DP noise better predicting performance. The authors also demonstrate that using a single (C,B) across tasks can be suboptimal, especially when moving between tight/loose privacy regimes or between abundant/limited compute.", "summary_cn": "本文研究了在微调预训练模型时的差分隐私（DP）设置，重点探讨在固定计算预算下如何选择裁剪上限 C 和批量大小 B。研究发现理论上更强隐私应使用更小的 C，但实际实验表明在强隐私条件下更大的 C 表现更好，这源于梯度分布的变化；此外，常用的批量大小调参启发式方法失效，累积的 DP 噪声能够更好地解释批量大小对性能的影响。作者还指出，在不同任务之间使用统一的 (C,B) 设置会导致性能下降，尤其是在隐私约束松紧或计算资源充裕与受限之间切换时，这可以通过将裁剪视为梯度重新加权并分析累计噪声来解释。", "keywords": "differential privacy, transfer learning, hyperparameter tuning, clipping bound, batch size, gradient clipping, DP noise, privacy-utility tradeoff", "scoring": {"interpretability": 2, "understanding": 7, "safety": 6, "technicality": 8, "surprisal": 7}, "category": {"failure_mode_addressed": "other", "primary_focus": "other"}, "authors": ["Aki Rehn", "Linzh Zhao", "Mikko A. Heikkilä", "Antti Honkela"]}, "usage": {"completion_tokens": 927, "prompt_tokens": 3406, "total_tokens": 4333, "completion_tokens_details": {"accepted_prediction_tokens": null, "audio_tokens": null, "reasoning_tokens": 602, "rejected_prediction_tokens": null, "image_tokens": 0}, "prompt_tokens_details": {"audio_tokens": 0, "cached_tokens": 3152}, "cost": 0.00075376, "is_byok": false, "cost_details": {"upstream_inference_cost": null, "upstream_inference_prompt_cost": 0.00029026, "upstream_inference_completions_cost": 0.0004635}}, "model": "openai/gpt-oss-120b"}
{"timestamp": "2025-10-24T17:33:24.831313", "feed": "arxiv_cslg", "title": "DB-FGA-Net: Dual Backbone Frequency Gated Attention Network for Multi-Class Classification with Grad-CAM Interpretability", "link": "https://papers.cool/arxiv/2510.20299", "analysis": {"summary": "The paper proposes DB-FGA-Net, a dual‑backbone network that combines VGG16 and Xception with a Frequency‑Gated Attention block for multi‑class brain tumor classification. It achieves state‑of‑the‑art accuracy on several datasets without data augmentation and integrates Grad‑CAM visualizations and a real‑ GUI to provide clinically interpretable predictions.", "summary_cn": "本文提出 DB-FGA-Net，一种结合 VGG16 与 Xception 双主干并加入频率门控注意力 (Frequency‑Gated Attention) 模块的网络，用于脑肿瘤分类。该模型在无需数据增强的情况下在多个数据集上实现了近乎最佳的准确率，并集成 Grad‑CAM 可视化及实时 GUI，使诊断结果具备临床可解释性。", "keywords": "brain tumor classification, dual backbone, frequency gated attention, Grad-CAM, interpretability, medical imaging, VGG16, Xception, GUI, augmentation-free", "scoring": {"interpretability": 6, "understanding": 6, "safety": 4, "technicality": 7, "surprisal": 6}, "category": {"failure_mode_addressed": "non-applicable", "primary_focus": "interpretability"}, "authors": ["Saraf Anzum Shreya", "MD. Abu Ismail Siddique", "Sharaf Tasnim"]}, "usage": {"completion_tokens": 870, "prompt_tokens": 3490, "total_tokens": 4360, "completion_tokens_details": {"accepted_prediction_tokens": null, "audio_tokens": null, "reasoning_tokens": 710, "rejected_prediction_tokens": null, "image_tokens": 0}, "prompt_tokens_details": {"audio_tokens": 0, "cached_tokens": 3152}, "cost": 0.00073786, "is_byok": false, "cost_details": {"upstream_inference_cost": null, "upstream_inference_prompt_cost": 0.00030286, "upstream_inference_completions_cost": 0.000435}}, "model": "openai/gpt-oss-120b"}
{"timestamp": "2025-10-24T17:33:24.891021", "feed": "arxiv_cslg", "title": "ResearchGPT: Benchmarking and Training LLMs for End-to-End Computer Science Research Workflows", "link": "https://papers.cool/arxiv/2510.20279", "analysis": {"summary": "The paper introduces ResearchGPT, an envisioned AI collaborator that assists humans throughout the full computer‑science research cycle, and proposes a new benchmark suite (CS‑4k) and a large training corpus (CS‑50k) derived from 14k CC‑licensed papers. Using a retrieval‑augmented generation pipeline with multi‑stage quality control, the authors construct high‑quality scientific Q&A pairs and demonstrate that models fine‑tuned on CS‑50k achieve substantial gains, with 7B‑scale open models surpassing larger proprietary systems. By releasing the datasets, the work aims to promote the development of reliable AI research assistants.", "summary_cn": "本文提出了 ResearchGPT——一种能够在整个计算机科学研究流程中协助人类的 AI 合作者，并推出了基于14k 篇 CC 授权论文构建的高质量科学问答数据集（CS‑4k）和大规模训练语料（CS‑50k）。通过检索增强生成（RAG）结合多阶段质量控制的可扩展管线，确保答案的事实依据，并展示了在该数据上微调的模型（即使是 7B 规模的开源模型）也能超越更大的商业系统。作者公开数据以推动可靠的 AI 研究助手的研发。", "keywords": "LLM benchmarking, end-to-end research workflow, CS-54k dataset, retrieval-augmented generation, supervised fine-tuning, reinforcement learning, AI research assistant, computer science QA, domain-aligned training", "scoring": {"interpretability": 2, "understanding": 7, "safety": 3, "technicality": 7, "surprisal": 6}, "category": {"failure_mode_addressed": "non-applicable", "primary_focus": "other"}, "authors": ["Penghao Wang", "Yuhao Zhou", "Mengxuan Wu", "Ziheng Qin", "Bangyuan Zhu", "Shengbin Huang", "Xuanlei Zhao", "Panpan Zhang", "Xiaojiang Peng", "Yuzhang Shang", "Jianfei Yang", "Zheng Zhu", "Tianlong Chen", "Zhangyang Wang", "Kai Wang"]}, "usage": {"completion_tokens": 876, "prompt_tokens": 3517, "total_tokens": 4393, "completion_tokens_details": {"accepted_prediction_tokens": null, "audio_tokens": null, "reasoning_tokens": 548, "rejected_prediction_tokens": null, "image_tokens": 0}, "prompt_tokens_details": {"audio_tokens": 0, "cached_tokens": 3152}, "cost": 0.00074491, "is_byok": false, "cost_details": {"upstream_inference_cost": null, "upstream_inference_prompt_cost": 0.00030691, "upstream_inference_completions_cost": 0.000438}}, "model": "openai/gpt-oss-120b"}
{"timestamp": "2025-10-24T17:33:26.109296", "feed": "arxiv_cslg", "title": "ImpossibleBench: Measuring LLMs' Propensity of Exploiting Test Cases", "link": "https://papers.cool/arxiv/2510.20270", "analysis": {"summary": "ImpossibleBench is a benchmark framework that creates impossible variants of coding tasks by inserting conflicts between natural‑language specifications and unit tests, enabling measurement of large language models' propensity to exploit test cases. The authors evaluate cheating rates across different prompting strategies, test access modes, and feedback loops, and provide a testbed for developing monitoring tools and mitigating deceptive solutions.", "summary_cn": "ImpossibleBench 通过在自然语言需求与单元测试之间制造直接冲突，生成 \"不可能\" 的任务变体，以量化大语言模型利用测试用例的倾向。作者在不同提示方式、测试访问权限和反馈循环下评估作弊率，并提供用于开发监控工具和抑制欺骗行为的测试平台。", "keywords": "LLM cheating, test exploitation, benchmark, ImpossibleBench, safety evaluation, prompt engineering, deceptive behavior, code generation, alignment, robustness", "scoring": {"interpretability": 2, "understanding": 7, "safety": 8, "technicality": 7, "surprisal": 7}, "category": {"failure_mode_addressed": "misalignment", "primary_focus": "robustness"}, "authors": ["Ziqian Zhong", "Aditi Raghunathan", "Nicholas Carlini"]}, "usage": {"completion_tokens": 637, "prompt_tokens": 3486, "total_tokens": 4123, "completion_tokens_details": {"accepted_prediction_tokens": null, "audio_tokens": null, "reasoning_tokens": 453, "rejected_prediction_tokens": null, "image_tokens": 0}, "prompt_tokens_details": {"audio_tokens": 0, "cached_tokens": 3152}, "cost": 0.00062076, "is_byok": false, "cost_details": {"upstream_inference_cost": null, "upstream_inference_prompt_cost": 0.00030226, "upstream_inference_completions_cost": 0.0003185}}, "model": "openai/gpt-oss-120b"}
{"timestamp": "2025-10-24T17:33:26.494865", "feed": "arxiv_cslg", "title": "FedGPS: Statistical Rectification Against Data Heterogeneity in Federated Learning", "link": "https://papers.cool/arxiv/2510.20250", "analysis": {"summary": "FedGPS introduces a framework that incorporates statistical distribution and gradient information from other clients to mitigate data heterogeneity in federated learning. By statically modifying local objectives with surrogate global distributions and dynamically adjusting update directions with shared gradients, it demonstrates improved robustness and performance across diverse heterogeneity scenarios.", "summary_cn": "FedGPS 提出一种框架，通过整合其他客户端的统计分布信息和梯度信息来缓解联邦学习中的数据异质性。该方法在本地目标中静态加入全局分布的替代信息，并在每轮训练中动态使用其他客户端的梯度进行方向调整，从而在多种异质性场景下展示出更强的鲁棒性和性能提升。", "keywords": "federated learning, data heterogeneity, statistical rectification, gradient synergy, robustness, Fed", "scoring": {"interpretability": 1, "understanding": 5, "safety": 2, "technicality": 7, "surprisal": 6}, "category": {"failure_mode_addressed": "non-applicable", "primary_focus": "robustness"}, "authors": ["Zhiqin Yang", "Yonggang Zhang", "Chenxin Li", "Yiu-ming Cheung", "Bo Han", "Yixuan Yuan"]}, "usage": {"completion_tokens": 527, "prompt_tokens": 3453, "total_tokens": 3980, "completion_tokens_details": {"accepted_prediction_tokens": null, "audio_tokens": null, "reasoning_tokens": 295, "rejected_prediction_tokens": null, "image_tokens": 0}, "prompt_tokens_details": {"audio_tokens": 0, "cached_tokens": 3152}, "cost": 0.00056081, "is_byok": false, "cost_details": {"upstream_inference_cost": null, "upstream_inference_prompt_cost": 0.00029731, "upstream_inference_completions_cost": 0.0002635}}, "model": "openai/gpt-oss-120b"}
{"timestamp": "2025-10-24T17:33:26.511216", "feed": "arxiv_cslg", "title": "Attention Enhanced Entity Recommendation for Intelligent Monitoring in Cloud Systems", "link": "https://papers.cool/arxiv/2510.20640", "analysis": {"summary": "The paper introduces DiRecGNN, an attention‑anced graph neural network framework that recommends the optimal subset of attributes for automated monitoring of cloud services. By constructing a production‑scale heterogeneous monitor graph and applying multi‑head attention over heterogeneous neighbors and random‑walk sampled paths, the model captures long‑range dependencies and achieves a 43.1% improvement in MRR compared to baselines. Deployment feedback from Microsoft product teams shows the feature is perceived as useful (4.5/5).", "summary_cn": "本文提出 DiRecGNN，一种基于注意力机制的实体推荐框架，用于为云服务的自动监控挑选最优属性子集。通过构建生产级异构监控图，并在异构邻居及随机游走抽取的路径上使用多头注意力，模型捕获长程依赖，实现了 MRR 提升 43.1%。微软产品团队的使用反馈表明该功能被评为 4.5/5，具有较高的实用价值。", "keywords": "entity recommendation, graph neural network, attention, heterogeneous graph, cloud monitoring, transformer, random walk, multi-head attention, MRR", "scoring": {"interpretability": 2, "understanding": 5, "safety": 2, "technicality": 8, "surprisal": 5}, "category": {"failure_mode_addressed": "non-applicable", "primary_focus": "other"}, "authors": ["Fiza Hussain", "Anson Bastos", "Anjaly Parayil", "Ayush Choure", "Chetan Bansal", "Rujia Wang", "Saravan Rajmohan"]}, "usage": {"completion_tokens": 973, "prompt_tokens": 3449, "total_tokens": 4422, "completion_tokens_details": {"accepted_prediction_tokens": null, "audio_tokens": null, "reasoning_tokens": 781, "rejected_prediction_tokens": null, "image_tokens": 0}, "prompt_tokens_details": {"audio_tokens": 0, "cached_tokens": 3152}, "cost": 0.00078321, "is_byok": false, "cost_details": {"upstream_inference_cost": null, "upstream_inference_prompt_cost": 0.00029671, "upstream_inference_completions_cost": 0.0004865}}, "model": "openai/gpt-oss-120b"}
{"timestamp": "2025-10-24T17:33:27.129850", "feed": "arxiv_cslg", "title": "Limits of PRM-Guided Tree Search for Mathematical Reasoning with LLMs", "link": "https://papers.cool/arxiv/2510.20272", "analysis": {"summary": "The paper investigates whether using a process reward model (PRM) to guide tree search can improve mathematical reasoning in large language models, contrasting it with Best-of-N chain-of-thought prompting. Experiments on 23 problems with Qwen2.5-Math-7B-Instruct show that PRM‑guided tree search provides no significant benefit, suffers from poor state‑value approximation, and degrades out‑of‑distribution, while Monte Carlo tree search and beam search perform better. The authors conclude that more reliable reward modeling is needed before tree search can be effective for LLM mathematical reasoning.", "summary_cn": "本文研究了使用过程奖励模型（PRM）引导树搜索是否能够提升大型语言模型的数学推理能力，并将其与 Best-of-N 链式思考进行比较。针对 23 个问题使用 Qwen2.5-Math-7B-Instruct 的实验表明，PRM‑导向的树搜索未能带来显著改进，且在状态价值估计和分布外泛化方面表现不佳，而 Monte Carlo 树搜索和束搜索表现更佳。作者认为在树搜索有效提升 LLM 数学推理之前，需要更可靠的奖励建模方法。", "keywords": "PRM, tree search, mathematical reasoning, LLM, chain-of-thought, Monte Carlo tree search, beam search, reward modeling, evaluation", "scoring": {"interpretability": 3, "understanding": 7, "safety": 3, "technicality": 8, "surprisal": 6}, "category": {"failure_mode_addressed": "non-applicable", "primary_focus": "robustness"}, "authors": ["Tristan Cinquin", "Geoff Pleiss", "Agustinus Kristiadi"]}, "usage": {"completion_tokens": 769, "prompt_tokens": 3427, "total_tokens": 4196, "completion_tokens_details": {"accepted_prediction_tokens": null, "audio_tokens": null, "reasoning_tokens": 471, "rejected_prediction_tokens": null, "image_tokens": 0}, "prompt_tokens_details": {"audio_tokens": 0, "cached_tokens": 3152}, "cost": 0.00067791, "is_byok": false, "cost_details": {"upstream_inference_cost": null, "upstream_inference_prompt_cost": 0.00029341, "upstream_inference_completions_cost": 0.0003845}}, "model": "openai/gpt-oss-120b"}
{"timestamp": "2025-10-24T17:33:27.681369", "feed": "arxiv_cslg", "title": "On pattern classification with weighted dimensions", "link": "https://papers.cool/arxiv/2510.20107", "analysis": {"summary": "The paper proposes a novel weighting scheme for each dimension of a Minkowski distance and integrates it into a K‑Nearest Neighbour (KNN) classifier. Experiments on synthetic and real datasets, especially gene‑expression data, show up to 10% accuracy improvement over standard KNN. The approach regulates the shape and size of the neighbourhood region, addressing challenges of high‑dimensional, low‑sample settings.", "summary_cn": "本文提出了一种针对 Minkowski 距离的每维加权新方案，并将其嵌入 K 最近邻（KNN）分类器中。通过在合成数据和真实基因表达数据上实验，模型相较于传统 KNN 在分类准确率上提升约10%。该方法通过调节包含 k 个参考样本的区域形状和规模，解决了高维、样本稀少场景下邻近点选择的难题。", "keywords": "weighted distance, Minkowski distance, KNN classifier, dimensional weighting, pattern classification, high-dimensional data, gene expression, classification accuracy", "scoring": {"interpretability": 2, "understanding": 5, "safety": 1, "technicality": 7, "surprisal": 5}, "category": {"failure_mode_addressed": "non-applicable", "primary_focus": "other"}, "authors": ["Ayatullah Faruk Mollah"]}, "usage": {"completion_tokens": 539, "prompt_tokens": 3460, "total_tokens": 3999, "completion_tokens_details": {"accepted_prediction_tokens": null, "audio_tokens": null, "reasoning_tokens": 289, "rejected_prediction_tokens": null, "image_tokens": 0}, "prompt_tokens_details": {"audio_tokens": 0, "cached_tokens": 3152}, "cost": 0.00056786, "is_byok": false, "cost_details": {"upstream_inference_cost": null, "upstream_inference_prompt_cost": 0.00029836, "upstream_inference_completions_cost": 0.0002695}}, "model": "openai/gpt-oss-120b"}
{"timestamp": "2025-10-24T17:33:28.014510", "feed": "arxiv_cslg", "title": "Multi-Objective Reinforcement Learning with Max-Min Criterion: A Game-Theoretic Approach", "link": "https://papers.cool/arxiv/2510.20235", "analysis": {"summary": "The paper introduces a provably convergent framework for max‑min multi‑objective reinforcement learning by reformulating the problem as a two‑player zero‑sum regularized continuous game and solving it with a mirror‑descent‑based algorithm. It provides theoretical guarantees on iteration and sample complexity, proposes adaptive regularization for better performance, and demonstrates superior empirical results on tabular and deep RL benchmarks. The approach simplifies policy updates while ensuring global last‑iterate convergence.", "summary_cn": "本文提出了一种可证明收敛的多目标强化学习框架，采用最大‑最小准则，将问题重新表述为双人零和正则化连续博弈，并利用镜像下降算法求解。文中给出了迭代复杂度和样本复杂度的理论分析，提出了自适应正则化以提升性能，并在表格和深度强化学习实验中展示了显著优于已有基线的结果。该方法在简化策略更新的同时，实现了全局最后迭代收敛。", "keywords": "multi-objective reinforcement learning, max-min criterion, game-theoretic, zero-sum game, mirror descent, convergence analysis, sample complexity, adaptive regularization, deep RL", "scoring": {"interpretability": 2, "understanding": 6, "safety": 2, "technicality": 8, "surprisal": 5}, "category": {"failure_mode_addressed": "non-applicable", "primary_focus": "other"}, "authors": ["Woohyeon Byeon", "Giseung Park", "Jongseong Chae", "Amir Leshem", "Youngchul Sung"]}, "usage": {"completion_tokens": 696, "prompt_tokens": 3350, "total_tokens": 4046, "completion_tokens_details": {"accepted_prediction_tokens": null, "audio_tokens": null, "reasoning_tokens": 409, "rejected_prediction_tokens": null, "image_tokens": 0}, "prompt_tokens_details": {"audio_tokens": 0, "cached_tokens": 3152}, "cost": 0.00062986, "is_byok": false, "cost_details": {"upstream_inference_cost": null, "upstream_inference_prompt_cost": 0.00028186, "upstream_inference_completions_cost": 0.000348}}, "model": "openai/gpt-oss-120b"}
{"timestamp": "2025-10-24T17:33:28.017835", "feed": "arxiv_cslg", "title": "Scalable GPU-Accelerated Euler Characteristic Curves: Optimization and Differentiable Learning for PyTorch", "link": "https://papers.cool/arxiv/2510.20271", "analysis": {"summary": "The paper introduces optimized GPU kernels for computing Euler Characteristic Curves (ECC) that achieve 16–2000× speedups over existing implementations, and presents a differentiable ECC layer for PyTorch using a sigmoid relaxation to learn thresholds end‑to‑end. The CUDA kernels are designed for Ampere GPUs with coalesced memory access and shared‑memory accumulation, and the authors discuss batching and multi‑GPU extensions for broader adoption. Experiments demonstrate the efficiency gains on synthetic grids and outline downstream applications of topological features in deep learning.", "summary_cn": "本文提出了用于计算欧拉特征曲线（Euler Characteristic Curve, ECC）的优化 GPU 核心，实现了相较于已有实现 16 到 2000 倍的加速，并介绍了一种基于 Sigmoid 松弛的可微 ECC 层，可在 PyTorch 中端到端学习阈值。该 CUDA 实现针对 Ampere GPU 采用 128 字节共同访问和层次化共享内存累加，并讨论了批处理和多 GPU 扩展以促进大规模应用。实验在合成网格上展示了显著的效率提升，并概述了拓扑特征在深度学习中的下游应用。", "keywords": "Euler characteristic curve, topological data analysis, GPU acceleration, CUDA, PyTorch, differentiable layer, computational topology, deep learning, optimization", "scoring": {"interpretability": 5, "understanding": 6, "safety": 2, "technicality": 8, "surprisal": 6}, "category": {"failure_mode_addressed": "non-applicable", "primary_focus": "interpretability"}, "authors": ["Udit Saxena"]}, "usage": {"completion_tokens": 831, "prompt_tokens": 3340, "total_tokens": 4171, "completion_tokens_details": {"accepted_prediction_tokens": null, "audio_tokens": null, "reasoning_tokens": 582, "rejected_prediction_tokens": null, "image_tokens": 0}, "prompt_tokens_details": {"audio_tokens": 0, "cached_tokens": 3152}, "cost": 0.00069586, "is_byok": false, "cost_details": {"upstream_inference_cost": null, "upstream_inference_prompt_cost": 0.00028036, "upstream_inference_completions_cost": 0.0004155}}, "model": "openai/gpt-oss-120b"}
{"timestamp": "2025-10-24T17:33:28.425582", "feed": "arxiv_cslg", "title": "What Does It Take to Build a Performant Selective Classifier?", "link": "https://papers.cool/arxiv/2510.20242", "analysis": {"summary": "The paper formalizes the selective‑classification gap as the difference between practical classifiers and a perfect‑ordering oracle, decomposing it into five error sources: Bayes noise, approximation error, ranking error, statistical noise, and implementation/shift slack. It shows that post‑hoc monotone calibration has limited effect because it rarely changes the ranking of scores, and demonstrates through synthetic and real‑world experiments that richer, feature‑aware calibrators and distributionally robust training are required to close the gap. The work provides a quantitative error budget and practical guidelines for building better selective classifiers.", "summary_cn": "本文将选择性分类的性能差距形式化为实际分类器与完美排序oracle之间的差异，并将其分解为五类误差来源：贝叶斯噪声、近似误差、排序误差、统计噪声以及实现/分布迁移导致的松弛。研究表明单调后置校准因几乎不改变分数排序而对缩小差距贡献有限，实验结果显示需要更丰富、特征感知的校准器以及分布鲁棒训练才能有效改善。文章提供了量化的误差预算和可操作的设计指南，以构建更接近理想oracle的选择性分类器。", "keywords": "selective classification, abstention, calibration, ranking error, distributional shift, reliability, performance gap, feature-aware calibrator", "scoring": {"interpretability": 3, "understanding": 7, "safety": 5, "technicality": 7, "surprisal": 6}, "category": {"failure_mode_addressed": "other", "primary_focus": "robustness"}, "authors": ["Stephan Rabanser", "Nicolas Papernot"]}, "usage": {"completion_tokens": 795, "prompt_tokens": 3456, "total_tokens": 4251, "completion_tokens_details": {"accepted_prediction_tokens": null, "audio_tokens": null, "reasoning_tokens": 487, "rejected_prediction_tokens": null, "image_tokens": 0}, "prompt_tokens_details": {"audio_tokens": 0, "cached_tokens": 3152}, "cost": 0.00069526, "is_byok": false, "cost_details": {"upstream_inference_cost": null, "upstream_inference_prompt_cost": 0.00029776, "upstream_inference_completions_cost": 0.0003975}}, "model": "openai/gpt-oss-120b"}
{"timestamp": "2025-10-24T17:33:28.679126", "feed": "arxiv_cslg", "title": "Layer-to-Layer Knowledge Mixing in Graph Neural Network for Chemical Property Prediction", "link": "https://papers.cool/arxiv/2510.20236", "analysis": {"summary": "The paper proposes Layer-to-Layer Knowledge Mixing (LKM), a self‑knowledge distillation technique that aligns hidden embeddings across GNN layers to aggregate multi‑hop information, thereby improving molecular property prediction with negligible added computational cost. Experiments on three GNN architectures (DimeNet++, MXMNet, PAMNet) across QM9, MD17, and Chignolin datasets show reductions in mean absolute error up to 9.8% for QM9, 45.3% for MD17 energy, and 22.9% for Chignolin. The results demonstrate that LKM can significantly boost GNN accuracy for chemical tasks without substantial overhead.", "summary_cn": "本文提出了层间知识混合（LKM）方法，这是一种自我知识蒸馏技术，通过对齐 GNN 各层的隐藏嵌入来聚合多跳信息，从而在几乎不增加计算开销的情况下提升分子属性预测的准确性。对 DimeNet++、MXMNet、PAMNet 三种 GNN 架构在 QM9、MD17 和 Chignolin 数据集上的实验显示，平均绝对误差分别降低了最多 9.8%、45.3%（MD17 能量）和 22.9%。结果表明 LKM 能在化学属性预测任务中显著提升 GNN 性能且开销极小。", "keywords": "graph neural networks, self-knowledge distillation, chemical property prediction, Layer-to-Layer Knowledge Mixing, LKM, QM9, MD17, Chignolin", "scoring": {"interpretability": 3, "understanding": 5, "safety": 2, "technicality": 7, "surprisal": 6}, "category": {"failure_mode_addressed": "non-applicable", "primary_focus": "other"}, "authors": ["Teng Jiek See", "Daokun Zhang", "Mario Boley", "David K. Chalmers"]}, "usage": {"completion_tokens": 742, "prompt_tokens": 3454, "total_tokens": 4196, "completion_tokens_details": {"accepted_prediction_tokens": null, "audio_tokens": null, "reasoning_tokens": 371, "rejected_prediction_tokens": null, "image_tokens": 0}, "prompt_tokens_details": {"audio_tokens": 0, "cached_tokens": 3152}, "cost": 0.00066846, "is_byok": false, "cost_details": {"upstream_inference_cost": null, "upstream_inference_prompt_cost": 0.00029746, "upstream_inference_completions_cost": 0.000371}}, "model": "openai/gpt-oss-120b"}
{"timestamp": "2025-10-24T17:33:28.859113", "feed": "arxiv_cslg", "title": "Balancing Specialization and Centralization: A Multi-Agent Reinforcement Learning Benchmark for Sequential Industrial Control", "link": "https://papers.cool/arxiv/2510.20408", "analysis": {"summary": "The paper introduces a new benchmark that combines SortingEnv and ContainerGym into a sequential recycling scenario, enabling study of modular versus monolithic agents for industrial control. Experiments reveal that action masking dramatically improves learning for both architectures, reducing the performance advantage of specialized agents. The results emphasize the importance of action space constraints and provide a testbed for robust multi‑agent RL solutions in real‑world automation.", "summary_cn": "本文提出了一个将 SortingEnv 与 ContainerGym 合并的顺序回收基准，用于研究工业控制中的模块化代理与单体代理。实验表明，动作掩码显著提升了两类架构的学习效果，并缩小了专门化代理的性能优势。结果凸显了动作空间约束的重要性，为在实际自动化场景中探索稳健的多代理 RL 解法提供了测试平台。", "keywords": "multi-agent reinforcement learning, industrial control, modular architecture, action masking, benchmark, specialization, centralization, sequential recycling", "scoring": {"interpretability": 2, "understanding": 6, "safety": 4, "technicality": 7, "surprisal": 5}, "category": {"failure_mode_addressed": "non-applicable", "primary_focus": "control"}, "authors": ["Tom Maus", "Asma Atamna", "Tobias Glasmachers"]}, "usage": {"completion_tokens": 672, "prompt_tokens": 3428, "total_tokens": 4100, "completion_tokens_details": {"accepted_prediction_tokens": null, "audio_tokens": null, "reasoning_tokens": 453, "rejected_prediction_tokens": null, "image_tokens": 0}, "prompt_tokens_details": {"audio_tokens": 0, "cached_tokens": 3424}, "cost": 0.00061052, "is_byok": false, "cost_details": {"upstream_inference_cost": null, "upstream_inference_prompt_cost": 0.00027452, "upstream_inference_completions_cost": 0.000336}}, "model": "openai/gpt-oss-120b"}
{"timestamp": "2025-10-24T17:33:29.261967", "feed": "arxiv_cslg", "title": "Amplifying Prominent Representations in Multimodal Learning via Variational Dirichlet Process", "link": "https://papers.cool/arxiv/2510.20736", "analysis": {"summary": "The paper introduces a multimodal learning framework that leverages a Dirichlet Process (DP) mixture model to dynamically allocate weights to the most prominent intra‑modal features while still aligning cross‑modal distributions. By modeling each modality as a mixture of multivariate Gaussians and using the DP's richer‑gets‑richer property, the approach achieves a balance between preserving expressive modality‑specific representations and facilitating effective fusion, demonstrating superior performance across several benchmark datasets.", "summary_cn": "本文提出一种多模态学习框架，利用 Dirichlet 过程（DP）混合模型动态为最突出（prominent）的模态内部特征分配更大权重，同时实现跨模态对齐。该方法将每个模态建模为多元高斯混合分布，并借助 DP 的 richer‑gets‑richer 特性，在保持模态表达性的同时促进特征融合，在多个基准数据集上表现优于现有方法。", "keywords": "multimodal fusion, Dirichlet process, mixture model, cross-modal alignment, representation learning, variational inference", "scoring": {"interpretability": 3, "understanding": 6, "safety": 1, "technicality": 7, "surprisal": 6}, "category": {"failure_mode_addressed": "non-applicable", "primary_focus": "other"}, "authors": ["Tsai Hor Chan", "Feng Wu", "Yihang Chen", "Guosheng Yin", "Lequan Yu"]}, "usage": {"completion_tokens": 610, "prompt_tokens": 3473, "total_tokens": 4083, "completion_tokens_details": {"accepted_prediction_tokens": null, "audio_tokens": null, "reasoning_tokens": 357, "rejected_prediction_tokens": null, "image_tokens": 0}, "prompt_tokens_details": {"audio_tokens": 0, "cached_tokens": 3152}, "cost": 0.00060531, "is_byok": false, "cost_details": {"upstream_inference_cost": null, "upstream_inference_prompt_cost": 0.00030031, "upstream_inference_completions_cost": 0.000305}}, "model": "openai/gpt-oss-120b"}
{"timestamp": "2025-10-24T17:33:29.397185", "feed": "arxiv_cslg", "title": "CO-PFL: Contribution-Oriented Personalized Federated Learning for Heterogeneous Networks", "link": "https://papers.cool/arxiv/2510.20219", "analysis": {"summary": "The paper introduces CO-PFL, a contribution-oriented personalized federated learning algorithm that estimates each client’s utility by jointly analyzing gradient direction discrepancies and prediction deviations, providing discriminative aggregation weights. It combines parameter-wise personalization with mask-aware momentum to improve robustness, scalability, and convergence stability across heterogeneous datasets. Experiments on CIFAR10, CIFAR10C, CINIC10, and Mini-ImageNet demonstrate consistent gains over existing PFL methods.", "summary_cn": "本文提出 CO-PFL（一种贡献导向的个性化联邦学习）算法，通过联合分析梯度方向差异和预测偏差来估计每个客户端的贡献，从而为全局聚合分配区分度高的权重。该方法将参数级个性化与 mask-aware momentum 优化相结合，提升了在数据异构情况下的鲁棒性、可扩展性和收敛稳定性。实验在 CIFAR10、CIFAR10C、CINIC10 与 Mini-ImageNet 上显示出相较于现有 PFL 方法的一致性提升。", "keywords": "personalized federated learning, contribution estimation, gradient direction analysis, mask-aware momentum, heterogeneity, aggregation bias, robustness, federated optimization, submodel personalization", "scoring": {"interpretability": 2, "understanding": 5, "safety": 3, "technicality": 7, "surprisal": 5}, "category": {"failure_mode_addressed": "non-applicable", "primary_focus": "robustness"}, "authors": ["Ke Xing", "Yanjie Dong", "Xiaoyi Fan", "Runhao Zeng", "Victor C. M. Leung", "M. Jamal Deen", "Xiping Hu"]}, "usage": {"completion_tokens": 840, "prompt_tokens": 3475, "total_tokens": 4315, "completion_tokens_details": {"accepted_prediction_tokens": null, "audio_tokens": null, "reasoning_tokens": 621, "rejected_prediction_tokens": null, "image_tokens": 0}, "prompt_tokens_details": {"audio_tokens": 0, "cached_tokens": 3152}, "cost": 0.00072061, "is_byok": false, "cost_details": {"upstream_inference_cost": null, "upstream_inference_prompt_cost": 0.00030061, "upstream_inference_completions_cost": 0.00042}}, "model": "openai/gpt-oss-120b"}
{"timestamp": "2025-10-24T17:33:29.762331", "feed": "arxiv_cslg", "title": "Every Question Has Its Own Value: Reinforcement Learning with Explicit Human Values", "link": "https://papers.cool/arxiv/2510.20187", "analysis": {"summary": "The paper introduces Reinforcement Learning with Explicit Human Values (RLEV), a framework that incorporates quantifiable human value signals into the reward function for large language model training, extending the RLVR approach. Experiments on exam-style datasets show that RLEV improves value-weighted accuracy and learns a value-sensitive termination policy, producing concise outputs for low-value prompts and thorough responses for high-value ones. Ablation studies and robustness tests demonstrate that the performance gains stem from the explicit value alignment and persist under noisy value annotations.", "summary_cn": "本文提出了“强化学习显式人类价值”（RLEV）框架，将可量化的人类价值信号直接嵌入大语言模型的奖励函数，扩展了 RLVR 方法。实验表明，RLEV 在价值加权准确率上超越仅基于正确性的基线，并学习到价值敏感的终止策略：对低价值提示生成简洁响应，对高价值提示生成详尽回答。消融实验与噪价值标签的鲁棒性测试证明，性能提升源于显式价值对齐的因果作用。", "keywords": "reinforcement learning, human values, LLM alignment, value-weighted reward, termination policy, gradient amplification, RLVR, value-sensitive generation, AI safety, alignment", "scoring": {"interpretability": 3, "understanding": 6, "safety": 6, "technicality": 7, "surprisal": 7}, "category": {"failure_mode_addressed": "misalignment", "primary_focus": "alignment"}, "authors": ["Dian Yu", "Yulai Zhao", "Kishan Panaganti", "Linfeng Song", "Haitao Mi", "Dong Yu"]}, "usage": {"completion_tokens": 848, "prompt_tokens": 3406, "total_tokens": 4254, "completion_tokens_details": {"accepted_prediction_tokens": null, "audio_tokens": null, "reasoning_tokens": 627, "rejected_prediction_tokens": null, "image_tokens": 0}, "prompt_tokens_details": {"audio_tokens": 0, "cached_tokens": 3152}, "cost": 0.00071426, "is_byok": false, "cost_details": {"upstream_inference_cost": null, "upstream_inference_prompt_cost": 0.00029026, "upstream_inference_completions_cost": 0.000424}}, "model": "openai/gpt-oss-120b"}
{"timestamp": "2025-10-24T17:33:29.824849", "feed": "arxiv_cslg", "title": "A Multi-Layer Machine Learning and Econometric Pipeline for Forecasting Market Risk: Evidence from Cryptoasset Liquidity Spillovers", "link": "https://papers.cool/arxiv/2510.20066", "analysis": {"summary": "The paper proposes a three‑layer statistical and machine‑learning pipeline to forecast market‑wide risk in crypto markets by exploiting liquidity and volatility spillovers from a core set of assets. It combines interaction analysis, principal‑component relations, and volatility‑factor projections, supplemented with VAR impulse responses, HAR‑X models, and a leakage‑safe ML protocol with SHAP‑based interpretation, showing significant Granger‑causal links and moderate out‑of‑sample predictive performance.", "summary_cn": "本文构建了一个包含三个统计层级的机器学习与计量经济学管道，用于通过核心加密资产的流动性和波动性溢出预测全市场风险。该框架结合了流动性‑收益交互、主成分关系以及波动因子投影，并辅以向量自回归冲击响应、带外生变量的异方差自回归模型（HAR‑X）和防泄漏的机器学习流程，采用 SH（解释）进行特征解释，展示了显著的 Granger 因果关系和适度的样本外预测效果。", "keywords": "cryptoasset, liquidity spillover, market risk forecasting, SHAP, HAR-X, VAR, principal component analysis, machine learning pipeline, econometrics", "scoring": {"interpretability": 4, "understanding": 6, "safety": 3, "technicality": 7, "surprisal": 5}, "category": {"failure_mode_addressed": "societal-disruption", "primary_focus": "other"}, "authors": ["Yimeng Qiu", "Feihuang Fang"]}, "usage": {"completion_tokens": 723, "prompt_tokens": 3431, "total_tokens": 4154, "completion_tokens_details": {"accepted_prediction_tokens": null, "audio_tokens": null, "reasoning_tokens": 431, "rejected_prediction_tokens": null, "image_tokens": 0}, "prompt_tokens_details": {"audio_tokens": 0, "cached_tokens": 3152}, "cost": 0.00065551, "is_byok": false, "cost_details": {"upstream_inference_cost": null, "upstream_inference_prompt_cost": 0.00029401, "upstream_inference_completions_cost": 0.0003615}}, "model": "openai/gpt-oss-120b"}
{"timestamp": "2025-10-24T17:33:29.845969", "feed": "arxiv_cslg", "title": "Optimistic Task Inference for Behavior Foundation Models", "link": "https://papers.cool/arxiv/2510.20264", "analysis": {"summary": "The paper proposes OpTI-BFM, an optimistic decision criterion that models uncertainty over reward functions to enable task inference for behavior foundation models through interaction at test time. It provides a regret bound linking well‑trained BFMs to upper‑confidence linear bandit algorithms and demonstrates empirically that successor‑features‑based BFMs can identify and optimize unseen reward functions within a few episodes on zero‑shot benchmarks.", "summary_cn": "本文提出 OpTI-BFM——一种乐观决策准则，通过在测试时与环境交互并对奖励函数的不确定性建模，实现对行为基础模型（BFM）的任务推断。论文给出与线性赌博上置信上界算法相连的后悔界限，并在零-shot 基准上实证表明，基于后继特征的 BFM 能够在少数几轮交互中识别并优化未见过的奖励函数。", "keywords": "behavior foundation models, zero-shot reinforcement learning, task inference, optimistic decision criterion, reward uncertainty, linear bandits, successor features, regret bound, data-efficient RL, reward modeling", "scoring": {"interpretability": 3, "understanding": 6, "safety": 4, "technicality": 7, "surprisal": 7}, "category": {"failure_mode_addressed": "non-applicable", "primary_focus": "alignment"}, "authors": ["Thomas Rupf", "Marco Bagatella", "Marin Vlastelica", "Andreas Krause"]}, "usage": {"completion_tokens": 733, "prompt_tokens": 3417, "total_tokens": 4150, "completion_tokens_details": {"accepted_prediction_tokens": null, "audio_tokens": null, "reasoning_tokens": 548, "rejected_prediction_tokens": null, "image_tokens": 0}, "prompt_tokens_details": {"audio_tokens": 0, "cached_tokens": 3152}, "cost": 0.00065841, "is_byok": false, "cost_details": {"upstream_inference_cost": null, "upstream_inference_prompt_cost": 0.00029191, "upstream_inference_completions_cost": 0.0003665}}, "model": "openai/gpt-oss-120b"}
{"timestamp": "2025-10-24T17:33:30.172690", "feed": "arxiv_cslg", "title": "Embedding the MLOps Lifecycle into OT Reference Models", "link": "https://papers.cool/arxiv/2510.20590", "analysis": {"summary": "The paper analyzes challenges in combining Machine Learning Operations (MLOps) with Operational Technology (OT) systems and proposes a systematic method to embed MLOps practices into established OT reference models such as RAMI 4.0 and ISA-95. It provides a detailed mapping of MLOps lifecycle components to RAMI 4.0, illustrated with a real-world use case, showing that adapted integration can enable successful deployment of MLOps in OT environments.", "summary_cn": "本文分析了将机器学习运维（MLOps）与工业运营技术（OT）系统相结合的挑战，并提出了一种系统化方法 MLOps 实践嵌入到已建立的 OT 参考模型（如 RAMI 4.0 与 ISA-95）中。通过对 RAMI 4.0 的 MLOps 生命周期组件映射并结合实际案例，展示了经过结构化适配后可实现 MLOps 在 OT 环境中的成功集成。", "keywords": "MLOps, Operational Technology, RAMI 4.0, ISA-95, industrial AI, lifecycle integration, reference models", "scoring": {"interpretability": 2, "understanding": 5, "safety": 4, "technicality": 6, "surprisal": 5}, "category": {"failure_mode_addressed": "non-applicable", "primary_focus": "other"}, "authors": ["Simon Schindler", "Christoph Binder", "Lukas Lürzer", "Stefan Huber"]}, "usage": {"completion_tokens": 667, "prompt_tokens": 3371, "total_tokens": 4038, "completion_tokens_details": {"accepted_prediction_tokens": null, "audio_tokens": null, "reasoning_tokens": 409, "rejected_prediction_tokens": null, "image_tokens": 0}, "prompt_tokens_details": {"audio_tokens": 0, "cached_tokens": 3152}, "cost": 0.00061851, "is_byok": false, "cost_details": {"upstream_inference_cost": null, "upstream_inference_prompt_cost": 0.00028501, "upstream_inference_completions_cost": 0.0003335}}, "model": "openai/gpt-oss-120b"}
{"timestamp": "2025-10-24T17:33:30.511932", "feed": "arxiv_cslg", "title": "QKCV Attention: Enhancing Time Series Forecasting with Static Categorical Embeddings for Both Lightweight and Pre-trained Foundation Models", "link": "https://papers.cool/arxiv/2510.20222", "analysis": {"summary": "The paper proposes QKCV (Query-Key-Category-Value) attention, an extension of the standard QKV mechanism that incorporates a static categorical embedding to highlight category-specific information in time series forecasting. As a plug‑in module, QKCV improves the accuracy of various attention‑based models, including both lightweight Transformers and pre‑trained foundation models, and enables efficient fine‑tuning by updating only the categorical embedding while keeping pretrained weights fixed.", "summary_cn": "本文提出 QKCV（Query‑Key‑Category‑Value）注意力机制，在传统 QKV 架构中加入静态类别嵌入，以突出类别特定信息，从而提升时间序列预测性能。该模块可作为通用插件，提升包括轻量 Transformer、Informer、PatchTST、TFT 等在内的注意力模型的预测精度，并在微调预训练基础模型时仅更新类别嵌入 C，保持预训练权重不变，降低计算成本并实现更优的微调表现。", "keywords": "time series forecasting, attention, QKCV, categorical embedding, foundation models, fine-tuning, transformer, Informer, PatchTST, TFT", "scoring": {"interpretability": 3, "understanding": 5, "safety": 2, "technicality": 7, "surprisal": 5}, "category": {"failure_mode_addressed": "non-applicable", "primary_focus": "other"}, "authors": ["Hao Wang", "Baojun Ma"]}, "usage": {"completion_tokens": 658, "prompt_tokens": 3341, "total_tokens": 3999, "completion_tokens_details": {"accepted_prediction_tokens": null, "audio_tokens": null, "reasoning_tokens": 402, "rejected_prediction_tokens": null, "image_tokens": 0}, "prompt_tokens_details": {"audio_tokens": 0, "cached_tokens": 3152}, "cost": 0.00060951, "is_byok": false, "cost_details": {"upstream_inference_cost": null, "upstream_inference_prompt_cost": 0.00028051, "upstream_inference_completions_cost": 0.000329}}, "model": "openai/gpt-oss-120b"}
{"timestamp": "2025-10-24T17:33:30.661238", "feed": "arxiv_cslg", "title": "Understanding Mechanistic Role of Structural and Functional Connectivity in Tau Propagation Through Multi-Layer Modeling", "link": "https://papers.cool/arxiv/2510.20148", "analysis": {"summary": "The paper presents a multi-layer graph diffusion model that integrates structural and functional brain connectivity to explain the spatial and temporal dynamics of tau protein spread in Alzheimer's disease. It shows that functional connectivity dominates early disease stages and subcortical regions, while structural connectivity becomes more influential later and in occipital, parietal, and limbic areas, linking these patterns to AD-related gene expression and risk factors.", "summary_cn": "本文提出一种多层图扩散模型，将结构连通性（SC）和功能连通性（FC）结合，用于解释阿尔茨海默病中tau蛋白的空间和时间传播动力学。研究发现，早期疾病阶段和下丘脑等区域主要由功能连通性驱动，而在后期以及枕叶、顶叶和边缘区结构连通性更为重要，并将这些模式与AD相关基因表达和风险因素关联起来。", "keywords": "tau propagation, structural connectivity, functional connectivity, multi-layer graph diffusion, Alzheimer's disease, neuroimaging", "scoring": {"interpretability": 1, "understanding": 1, "safety": 1, "technicality": 8, "surprisal": 5}, "category": {"failure_mode_addressed": "non-applicable", "primary_focus": "other"}, "authors": ["Tingting Dan", "Xinwei Huang", "Jiaqi Ding", "Yinggang Zheng", "Guorong Wu"]}, "usage": {"completion_tokens": 577, "prompt_tokens": 3491, "total_tokens": 4068, "completion_tokens_details": {"accepted_prediction_tokens": null, "audio_tokens": null, "reasoning_tokens": 331, "rejected_prediction_tokens": null, "image_tokens": 0}, "prompt_tokens_details": {"audio_tokens": 0, "cached_tokens": 3152}, "cost": 0.00059151, "is_byok": false, "cost_details": {"upstream_inference_cost": null, "upstream_inference_prompt_cost": 0.00030301, "upstream_inference_completions_cost": 0.0002885}}, "model": "openai/gpt-oss-120b"}
{"timestamp": "2025-10-24T17:33:30.730973", "feed": "arxiv_cslg", "title": "Hierarchical Dual-Head Model for Suicide Risk Assessment via MentalRoBERTa", "link": "https://papers.cool/arxiv/2510.20085", "analysis": {"summary": "The paper introduces a hierarchical dual-head neural network built on MentalRoBERTa to classify suicide risk from social‑media posts into four levels (indicator, ideation, behavior, attempt). One head uses CORAL to preserve ordinal relationships while the other provides standard categorical predictions, and a lightweight transformer encoder models temporal posting patterns with time‑interval embeddings. The combined loss (CORAL, cross‑entropy, focal) addresses ordinal structure, overconfidence, and severe class imbalance, and the model is evaluated via 5‑fold stratified cross‑validation using macro F1.", "summary_cn": "本文提出了一种基于 MentalRoBERTa 的层次化双头神经网络，用于从社交媒体帖子中将自杀风险划分为四个等级（指标、头、行为、尝试）。一个头使用 CORAL（Consistent Rank Logits）保持风险等级的序序关系，另一个头进行普通分类，以捕捉灵活的类别差异；同时，3 层 Transformer 编码器结合时间间隔嵌入建模帖子序列的时间依赖性。通过 0.5 × CORAL、0.3 × 交叉熵和 0.2 × 焦点损失的组合， simultaneously 处理序列结构、过度自信和严重类别不平衡，并在 5 折分层交叉验证中以宏 F1 作为主要指标进行评估。", "keywords": "suicide risk assessment, MentalRoBERTa, hierarchical dual-head, ordinal classification, CORAL, class imbalance, temporal modeling", "scoring": {"interpretability": 2, "understanding": 5, "safety": 6, "technicality": 7, "surprisal": 5}, "category": {"failure_mode_addressed": "other", "primary_focus": "other"}, "authors": ["Chang Yang", "Ziyi Wang", "Wangfeng Tan", "Zhiting Tan", "Changrui Ji", "Zhiming Zhou"]}, "usage": {"completion_tokens": 895, "prompt_tokens": 3441, "total_tokens": 4336, "completion_tokens_details": {"accepted_prediction_tokens": null, "audio_tokens": null, "reasoning_tokens": 586, "rejected_prediction_tokens": null, "image_tokens": 0}, "prompt_tokens_details": {"audio_tokens": 0, "cached_tokens": 3152}, "cost": 0.00074301, "is_byok": false, "cost_details": {"upstream_inference_cost": null, "upstream_inference_prompt_cost": 0.00029551, "upstream_inference_completions_cost": 0.0004475}}, "model": "openai/gpt-oss-120b"}
{"timestamp": "2025-10-24T17:33:30.750729", "feed": "arxiv_cslg", "title": "Sparse Local Implicit Image Function for sub-km Weather Downscaling", "link": "https://papers.cool/arxiv/2510.20228", "analysis": {"summary": "The paper presents Sparse Local Implicit Image Function (SpLIIF), an implicit neural representation that enables arbitrary downscaling of weather variables from sparse station data and topography. Trained on Japanese data, it is evaluated on temperature and wind forecasting, achieving up to 50% improvement over CorrDiff and baseline interpolation for temperature and 10-20% for wind. The method demonstrates strong performance both in- and out-of-distribution.", "summary_cn": "本文提出了稀疏局部隐式图像函数（SpLIIF），一种隐式神经表示方法，可从稀疏气象站点和地形数据任意下采样天气变量。模型在日本数据上训练后，对温度和风速进行预测，温度下采样相较 CorrDiff 与基线插值提升最高 50%，风速提升约 10-20%。该方法在分布内外均表现出显著的精度提升。", "keywords": "weather downscaling, implicit neural representation, Sparse Local Implicit Image Function, SpLIIF, temperature prediction, wind prediction, CorrDiff, sparse stations, topography, sub-kilometer resolution", "scoring": {"interpretability": 2, "understanding": 5, "safety": 2, "technicality": 7, "surprisal": 6}, "category": {"failure_mode_addressed": "non-applicable", "primary_focus": "other"}, "authors": ["Yago del Valle Inclan Redondo", "Enrique Arriaga-Varela", "Dmitry Lyamzin", "Pablo Cervantes", "Tiago Ramalho"]}, "usage": {"completion_tokens": 652, "prompt_tokens": 3286, "total_tokens": 3938, "completion_tokens_details": {"accepted_prediction_tokens": null, "audio_tokens": null, "reasoning_tokens": 395, "rejected_prediction_tokens": null, "image_tokens": 0}, "prompt_tokens_details": {"audio_tokens": 0, "cached_tokens": 3152}, "cost": 0.00059826, "is_byok": false, "cost_details": {"upstream_inference_cost": null, "upstream_inference_prompt_cost": 0.00027226, "upstream_inference_completions_cost": 0.000326}}, "model": "openai/gpt-oss-120b"}
{"timestamp": "2025-10-24T17:33:30.851349", "feed": "arxiv_cslg", "title": "Towards Strong Certified Defense with Universal Asymmetric Randomization", "link": "https://papers.cool/arxiv/2510.19977", "analysis": {"summary": "The paper introduces UCAN, a method that transforms existing randomized smoothing techniques from isotropic to anisotropic noise distributions, enabling stronger certified adversarial robustness across various α_p norms. It provides a theoretical framework supporting arbitrary noise families and proposes three noise parameter generators to adapt the noise per data dimension, achieving up to 182.6% improvement in certified accuracy on MNIST, CIFAR-10 and ImageNet. Empirical results demonstrate significant gains over state-of-the-art certified defenses.", "summary_cn": "本文提出 UCAN 方法，将现有的随机平滑技术从各向同性噪声转变为各向异性噪声，从而在不同 α_p 范数下实现更强的可认证对抗鲁棒性。它提供了支持任意噪声分布的理论框架，并设计了三种噪声参数生成器，以针对不同数据维度进行噪声调优，在 MNIST、CIFAR-10 和 ImageNet 上实现最高 182.6% 的认证准确率提升。实验结果显示 UCAN 相较于现有最先进的认证防御方法有显著优势。", "keywords": "certified robustness, randomized smoothing, anisotropic noise, universal certification, adversarial defense", "scoring": {"interpretability": 2, "understanding": 6, "safety": 5, "technicality": 8, "surprisal": 7}, "category": {"failure_mode_addressed": "non-applicable", "primary_focus": "robustness"}, "authors": ["Hanbin Hong", "Ashish Kundu", "Ali Payani", "Binghui Wang", "Yuan Hong"]}, "usage": {"completion_tokens": 642, "prompt_tokens": 3518, "total_tokens": 4160, "completion_tokens_details": {"accepted_prediction_tokens": null, "audio_tokens": null, "reasoning_tokens": 337, "rejected_prediction_tokens": null, "image_tokens": 0}, "prompt_tokens_details": {"audio_tokens": 0, "cached_tokens": 3152}, "cost": 0.00062806, "is_byok": false, "cost_details": {"upstream_inference_cost": null, "upstream_inference_prompt_cost": 0.00030706, "upstream_inference_completions_cost": 0.000321}}, "model": "openai/gpt-oss-120b"}
{"timestamp": "2025-10-24T17:33:30.876702", "feed": "arxiv_cslg", "title": "A Unified Framework for Zero-Shot Reinforcement Learning", "link": "https://papers.cool/arxiv/2510.20542", "analysis": {"summary": "The paper proposes a unified analytical framework for zero-shot reinforcement learning that classifies existing methods into direct anditional representation families. It formalizes a taxonomy, derives an extended performance bound for successor-feature approaches, and highlights shared principles to guide future research toward more general agents. By providing a common notation and comparative lens, the work aims to consolidate and advance the study of task-general RL agents.", "summary_cn": "本文提出了一个统一的零样本强化学习（zero-shot RL）分析框架，将现有方法划分为直接表示和组合表示两大类。文中给出一致的符号体系与分类法，并为后继特征（successor features）方法推导了扩展的性能界限，阐明了不同方法的共同原理和关键差异。通过这种统一视角，旨在为研发更通用的 RL 代理提供规范化的基础。", "keywords": "zero-shot reinforcement learning, successor features, compositional representations, direct representations, task generalization, representation learning, RL foundations, analytical framework", "scoring": {"interpretability": 3, "understanding": 7, "safety": 3, "technicality": 7, "surprisal": 6}, "category": {"failure_mode_addressed": "non-applicable", "primary_focus": "robustness"}, "authors": ["Jacopo Di Ventura", "Jan Felix Kleuker", "Aske Plaat", "Thomas Moerland"]}, "usage": {"completion_tokens": 657, "prompt_tokens": 3425, "total_tokens": 4082, "completion_tokens_details": {"accepted_prediction_tokens": null, "audio_tokens": null, "reasoning_tokens": 429, "rejected_prediction_tokens": null, "image_tokens": 0}, "prompt_tokens_details": {"audio_tokens": 0, "cached_tokens": 3152}, "cost": 0.00062161, "is_byok": false, "cost_details": {"upstream_inference_cost": null, "upstream_inference_prompt_cost": 0.00029311, "upstream_inference_completions_cost": 0.0003285}}, "model": "openai/gpt-oss-120b"}
{"timestamp": "2025-10-24T17:33:31.061303", "feed": "arxiv_cslg", "title": "Bayesian Jammer Localization with a Hybrid CNN and Path-Loss Mixture of Experts", "link": "https://papers.cool/arxiv/2510.20666", "analysis": {"summary": "The paper introduces a hybrid Bayesian mixture-of-experts framework that combines a physical path‑loss model with a CNN using log‑linear pooling to localize GNSS jammers in urban environments. The physical expert enforces consistency while the CNN lever building‑height maps to capture multipath effects, and Bayesian inference with Laplace approximation yields posterior uncertainty over jammer positions and the RSS field. Experiments on ray‑tracing data show improved localization accuracy and meaningful uncertainty estimates that concentrate in sensitive urban canyons.", "summary_cn": "本文提出一种混合贝叶斯专家混合框架，将物理路径损失模型与卷积神经网络（CNN）通过对数线性池化融合，用于在城市环境中定位 GNSS 干扰源。物理专家保证一致性，CNN 利用建筑高度图捕获多路径效应，采用拉普拉斯近似的贝叶斯推断提供对干扰源位置和 RSS 场的后验不确定性。实验在射线追踪数据上显示，定位精度提升且不确定性在关键的城市谷处集中。", "keywords": "GNSS jamming, jammer localization, Bayesian mixture of experts, convolutional neural network, path-loss model, log-linear pooling, uncertainty estimation, urban propagation, Laplace approximation", "scoring": {"interpretability": 3, "understanding": 6, "safety": 6, "technicality": 7, "surprisal": 6}, "category": {"failure_mode_addressed": "human-misuse", "primary_focus": "robustness"}, "authors": ["Mariona Jaramillo-Civill", "Luis González-Gudiño", "Tales Imbiriba", "Pau Closas"]}, "usage": {"completion_tokens": 965, "prompt_tokens": 3359, "total_tokens": 4324, "completion_tokens_details": {"accepted_prediction_tokens": null, "audio_tokens": null, "reasoning_tokens": 726, "rejected_prediction_tokens": null, "image_tokens": 0}, "prompt_tokens_details": {"audio_tokens": 0, "cached_tokens": 3344}, "cost": 0.00075227, "is_byok": false, "cost_details": {"upstream_inference_cost": null, "upstream_inference_prompt_cost": 0.00026977, "upstream_inference_completions_cost": 0.0004825}}, "model": "openai/gpt-oss-120b"}
{"timestamp": "2025-10-24T17:33:31.264734", "feed": "arxiv_cslg", "title": "An Empirical Study of Sample Selection Strategies for Large Language Model Repair", "link": "https://papers.cool/arxiv/2510.20428", "analysis": {"summary": "The paper systematically evaluates sample selection strategies for post‑hoc repair of large language models to mitigate toxic or biased outputs. It compares random, K‑Center, GraNd, CCS, a proposed Semantic‑Aware Prioritized Sampling (SAPS) across metrics such as toxicity reduction, language modeling perplexity, and composite repair scores, finding SAPS offers the best trade‑off between detoxification and utility preservation while using less data. The study highlights that sample selection is a tunable component that can improve the efficiency and scalability of LLM safety interventions.", "summary_cn": "本文系统性地评估了用于大语言模型事后修复的样本选择策略，以降低有害或偏见输出。研究比较了随机、K‑Center、GraNd、CCS 与作者提出的语义感知优先采样（SAPS），通过毒性降低、语言模型困惑度以及综合修复评分等指标，发现 SAPS 在保持效用的同时实现了最佳的戒毒与效率平衡。调查表明，样本应视为修复流程的可调组件，可提升 LLM 安全性的效率与可扩展性。", "keywords": "sample selection, LLM repair, toxicity reduction, post-hoc alignment, SAPS, K-Center, GraNd, CCS, repair efficiency, model safety", "scoring": {"interpretability": 4, "understanding": 6, "safety": 7, "technicality": 7, "surprisal": 6}, "category": {"failure_mode_addressed": "misalignment", "primary_focus": "alignment"}, "authors": ["Xuran Li", "Jingyi Wang"]}, "usage": {"completion_tokens": 943, "prompt_tokens": 3496, "total_tokens": 4439, "completion_tokens_details": {"accepted_prediction_tokens": null, "audio_tokens": null, "reasoning_tokens": 719, "rejected_prediction_tokens": null, "image_tokens": 0}, "prompt_tokens_details": {"audio_tokens": 0, "cached_tokens": 3488}, "cost": 0.00075174, "is_byok": false, "cost_details": {"upstream_inference_cost": null, "upstream_inference_prompt_cost": 0.00028024, "upstream_inference_completions_cost": 0.0004715}}, "model": "openai/gpt-oss-120b"}
{"timestamp": "2025-10-24T17:33:31.334569", "feed": "arxiv_cslg", "title": "Competition is the key: A Game Theoretic Causal Discovery Approach", "link": "https://papers.cool/arxiv/2510.20106", "analysis": {"summary": "The paper introduces a game‑theoretic reinforcement‑learning framework for causal discovery in which a DDQN agent competes against a strong baseline such as GES or GraN‑DAG, always warm‑starting from the opponent’s solution. This design yields three provable guarantees: the learned graph never underperforms the, warm‑starting accelerates convergence, and with high probability the algorithm selects the true best graph. Experiments on synthetic SEMs and real‑world benchmarks (Sachs, Asia, Alarm, Child, Hepar2, Dream, Andes) demonstrate consistent improvements and scalability to graphs with hundreds of nodes.", "summary_cn": "本文提出了一种基于博弈论的强化学习因果发现框架，使用 DDQN 代理与强基线（如 GES 或 GraN‑DAG）竞争，并始终从对手的解进行热启动。该设计提供三项可证明的保证：学习得到的图结构不会劣于基线，热启动显著加速收敛，并且在高概率下选出真正的最优候选图。实验在合成 SEM（30 节点）和多个真实基准Sachs、Asia、Alarm、Child、Hepar2、Dream、Andes）上展示了持续的性能提升和对上百节点图的可扩展性。", "keywords": "causal discovery, game theory, reinforcement learning, DDQN, finite-sample guarantees, GES, GraN-DAG, structural equation models, scalability, consistency", "scoring": {"interpretability": 5, "understanding": 7, "safety": 5, "technicality": 8, "surprisal": 7}, "category": {"failure_mode_addressed": "non-applicable", "primary_focus": "interpretability"}, "authors": ["Amartya Roy", "Souvik Chakraborty"]}, "usage": {"completion_tokens": 1003, "prompt_tokens": 3489, "total_tokens": 4492, "completion_tokens_details": {"accepted_prediction_tokens": null, "audio_tokens": null, "reasoning_tokens": 731, "rejected_prediction_tokens": null, "image_tokens": 0}, "prompt_tokens_details": {"audio_tokens": 0, "cached_tokens": 3152}, "cost": 0.00080421, "is_byok": false, "cost_details": {"upstream_inference_cost": null, "upstream_inference_prompt_cost": 0.00030271, "upstream_inference_completions_cost": 0.0005015}}, "model": "openai/gpt-oss-120b"}
{"timestamp": "2025-10-24T17:33:31.577357", "feed": "arxiv_cslg", "title": "Federated Learning via Meta-Variational Dropout", "link": "https://papers.cool/arxiv/2510.20225", "analysis": {"summary": "The paper proposes MetaVD, a Bayesian meta‑learning method for federated learning that uses a hypernetwork to predict client‑specific dropout rates, enabling personalized models and reducing overfitting on non‑IID data. Experiments show improved classification accuracy, better uncertainty calibration, and lower communication costs, especially for out‑of‑distribution clients.", "summary_cn": "本文提出 MetaVD，一种基于贝叶斯元学习的联邦学习方法，通过超网络预测每个客户端的 dropout 率，实现模型个性化并缓解非 IID 数据导致的过拟合。实验表明该方法在分类准确率、uncertainty 校准以及通信成本方面均有提升，尤其对分布外（OOD）客户端表现突出。", "keywords": "federated learning, meta-learning, variational dropout, Bayesian FL, personalization, non-IID data, model compression, uncertainty calibration, OOD detection", "scoring": {"interpretability": 3, "understanding": 6, "safety": 5, "technicality": 7, "surprisal": 7}, "category": {"failure_mode_addressed": "non-applicable", "primary_focus": "robustness"}, "authors": ["Insu Jeon", "Minui Hong", "Junhyeog Yun", "Gunhee Kim"]}, "usage": {"completion_tokens": 712, "prompt_tokens": 3399, "total_tokens": 4111, "completion_tokens_details": {"accepted_prediction_tokens": null, "audio_tokens": null, "reasoning_tokens": 508, "rejected_prediction_tokens": null, "image_tokens": 0}, "prompt_tokens_details": {"audio_tokens": 0, "cached_tokens": 3152}, "cost": 0.00064521, "is_byok": false, "cost_details": {"upstream_inference_cost": null, "upstream_inference_prompt_cost": 0.00028921, "upstream_inference_completions_cost": 0.000356}}, "model": "openai/gpt-oss-120b"}
{"timestamp": "2025-10-24T17:33:31.608649", "feed": "arxiv_cslg", "title": "There is No \"apple\" in Timeseries: Rethinking TSFM through the Lens of Invariance", "link": "https://papers.cool/arxiv/2510.20119", "analysis": {"summary": "The paper argues that the underperformance of timeseries foundation models (TSFMs) relative to lightweight baselines stems from importing NLP and CV pipelines that rely on massive web‑scale corpora, which do not exist for timeseries data. It proposes a shift toward principled dataset construction that systematically covers the space of temporal invariances, building an ontology of invariances from first principles to ensure representational completeness and better generalisation. By aligning datasets with the intrinsic semantics of timeseries, the authors aim to enable TSFMs to exhibit more robust reasoning and emergent behaviour.", "summary_cn": "本文指出，时间序列基础模型（TSFM）表现不佳的原因在于盲目沿用 NLP 与计算机视觉的管线，而后者依赖于包含大量概念（如“苹果”）的网页数据，时间序列数据并不存在此类大规模概念库。作者主张转向原则化的数据集构建，系统覆盖时间不变性的空间，从第一性原理构建不变性本体，以确保表示的完整性并提升模型的泛化能力。通过使数据集与时间序列的固有语义对齐，期望 TSFM 能实现更稳健的推理和真正的涌现行为。", "keywords": "timeseries foundation models, invariance, dataset design, temporal semantics, representation completeness, generalisation", "scoring": {"interpretability": 2, "understanding": 6, "safety": 2, "technicality": 7, "surprisal": 5}, "category": {"failure_mode_addressed": "non-applicable", "primary_focus": "other"}, "authors": ["Arian Prabowo", "Flora D. Salim"]}, "usage": {"completion_tokens": 626, "prompt_tokens": 3392, "total_tokens": 4018, "completion_tokens_details": {"accepted_prediction_tokens": null, "audio_tokens": null, "reasoning_tokens": 302, "rejected_prediction_tokens": null, "image_tokens": 0}, "prompt_tokens_details": {"audio_tokens": 0, "cached_tokens": 3152}, "cost": 0.00060116, "is_byok": false, "cost_details": {"upstream_inference_cost": null, "upstream_inference_prompt_cost": 0.00028816, "upstream_inference_completions_cost": 0.000313}}, "model": "openai/gpt-oss-120b"}
{"timestamp": "2025-10-24T17:33:32.443813", "feed": "arxiv_cslg", "title": "Risk-Averse Constrained Reinforcement Learning with Optimized Certainty Equivalents", "link": "https://papers.cool/arxiv/2510.20199", "analysis": {"summary": "The paper introduces a risk-aware constrained reinforcement learning framework that incorporates optimized certainty equivalents (OCEs) to achieve per-stage robustness in both reward values and time. It provides a strong Lagrangian duality formulation guaranteeing exact equivalence to the original constrained problem and presents a simple algorithmic wrapper compatible with standard RL solvers such as PPO, along with convergence guarantees and empirical validation.", "summary_cn": "本文提出了一种风险感知的约束强化学习框架，利用优化确定等价（optimized certainty equivalents, OCE）实现奖励值和时间维度上的每阶段鲁棒性。该框架基于强拉格朗日对偶理论，确保与原始约束问题精确等价，并给出了可在 PPO 等标准强化学习求解器上直接包装的简单算法方案，提供收敛性证明并通过数值实验验证其风险规避特性。", "keywords": "risk-averse reinforcement learning, constrained RL, optimized certainty equivalents, risk-sensitive RL, Lagrangian duality, PPO, safety, robust RL", "scoring": {"interpretability": 2, "understanding": 6, "safety": 7, "technicality": 7, "surprisal": 6}, "category": {"failure_mode_addressed": "other", "primary_focus": "robustness"}, "authors": ["Jane H. Lee", "Baturay Saglam", "Spyridon Pougkakiotis", "Amin Karbasi", "Dionysis Kalogerias"]}, "usage": {"completion_tokens": 712, "prompt_tokens": 3382, "total_tokens": 4094, "completion_tokens_details": {"accepted_prediction_tokens": null, "audio_tokens": null, "reasoning_tokens": 498, "rejected_prediction_tokens": null, "image_tokens": 0}, "prompt_tokens_details": {"audio_tokens": 0, "cached_tokens": 3152}, "cost": 0.00064266, "is_byok": false, "cost_details": {"upstream_inference_cost": null, "upstream_inference_prompt_cost": 0.00028666, "upstream_inference_completions_cost": 0.000356}}, "model": "openai/gpt-oss-120b"}
{"timestamp": "2025-10-24T17:33:32.636760", "feed": "arxiv_cslg", "title": "Empowering Targeted Neighborhood Search via Hyper Tour for Large-Scale TSP", "link": "https://papers.cool/arxiv/2510.20169", "analysis": {"summary": "The paper introduces Hyper Tour Guided Neighborhood Search (HyperNS), a method that clusters large TSP instances using a sparse heatmap, abstracts clusters as supernodes, and constructs a hyper tour to guide both initialization and optimization, thereby reducing the search space to edges relevant to the tour. Experiments on synthetic and real-world datasets show that HyperNS outperforms existing neural-based approaches, especially on larger instances, achieving a smaller optimality gap.", "summary_cn": "本文提出一种名为 HyperNS 的方法，通过在稀疏热图上进行聚类并构建超遍历（hyper tour），以引导大规模旅行商问题（TSP）的邻域搜索，从而在初始化和优化阶段聚焦相关边缘，实现更高效的求解。实验表明，该方法在合成和真实数据集上相较于现有神经网络方法显著缩小了与最优解的差距，尤其在大规模实例上表现突出。", "keywords": "traveling salesman problem, hyper tour, neighborhood search, large-scale optimization, clustering, neural combinatorial optimization", "scoring": {"interpretability": 2, "understanding": 6, "safety": 2, "technicality": 7, "surprisal": 6}, "category": {"failure_mode_addressed": "non-applicable", "primary_focus": "other"}, "authors": ["Tongkai Lu", "Shuai Ma", "Chongyang Tao"]}, "usage": {"completion_tokens": 706, "prompt_tokens": 3420, "total_tokens": 4126, "completion_tokens_details": {"accepted_prediction_tokens": null, "audio_tokens": null, "reasoning_tokens": 485, "rejected_prediction_tokens": null, "image_tokens": 0}, "prompt_tokens_details": {"audio_tokens": 0, "cached_tokens": 3152}, "cost": 0.00064536, "is_byok": false, "cost_details": {"upstream_inference_cost": null, "upstream_inference_prompt_cost": 0.00029236, "upstream_inference_completions_cost": 0.000353}}, "model": "openai/gpt-oss-120b"}
{"timestamp": "2025-10-24T17:33:32.643492", "feed": "arxiv_cslg", "title": "ShapeX: Shapelet-Driven Post Hoc Explanations for Time Series Classification Models", "link": "https://papers.cool/arxiv/2510.20084", "analysis": {"summary": "ShapeX introduces a shapelet-driven post hoc explanation framework for time series classification models, segmenting series into shapelet-based segments and using Shapley values to quantify their saliency. The method leverages a Shapelet Describe-and-Detect (SDD) module to learn diverse, discriminative shapelets, enabling explanations that capture causal relationships rather than mere correlations. Experiments on synthetic and real-world data show that ShapeX more accurately identifies relevant subsequences and improves the precision and causal fidelity of explanations compared to existing approaches.", "summary_cn": "ShapeX 提出了一种基于 shapelet 的事后解释框架，用于时间序列分类模型。它将时间序列划分为 shapelet 驱动的片段，并通过 Shapley 值评估其重要性，利用 Shapelet Describe-and-Detect（SDD）模块学习多样且区分度高的 shapelet，从而生成能够揭示因果关系而非仅仅相关性的解释。实验表明，ShapeX 在合成和真实数据上均能更准确地识别关键子序列，提高了解释的精度和因果忠实度。", "keywords": "shapelet, time series classification, post-hoc explanation, Shapley values, causal fidelity, interpretability", "scoring": {"interpretability": 8, "understanding": 7, "safety": 5, "technicality": 7, "surprisal": 6}, "category": {"failure_mode_addressed": "non-applicable", "primary_focus": "interpretability"}, "authors": ["Bosong Huang", "Ming Jin", "Yuxuan Liang", "Johan Barthelemy", "Debo Cheng", "Qingsong Wen", "Chenghao Liu", "Shirui Pan"]}, "usage": {"completion_tokens": 634, "prompt_tokens": 3432, "total_tokens": 4066, "completion_tokens_details": {"accepted_prediction_tokens": null, "audio_tokens": null, "reasoning_tokens": 339, "rejected_prediction_tokens": null, "image_tokens": 0}, "prompt_tokens_details": {"audio_tokens": 0, "cached_tokens": 3152}, "cost": 0.00061116, "is_byok": false, "cost_details": {"upstream_inference_cost": null, "upstream_inference_prompt_cost": 0.00029416, "upstream_inference_completions_cost": 0.000317}}, "model": "openai/gpt-oss-120b"}
{"timestamp": "2025-10-24T17:33:32.663055", "feed": "arxiv_cslg", "title": "Assessing the Feasibility of Early Cancer Detection Using Routine Laboratory Data: An Evaluation of Machine Learning Approaches on an Imbalanced Dataset", "link": "https://papers.cool/arxiv/2510.20209", "analysis": {"summary": "The paper evaluates whether routine laboratory tests can be used to detect early cancer in Golden Retrievers by benchmarking 126 machine‑learning pipelines on an imbalanced dataset. The best model (logistic regression with class weighting and recursive feature elimination) achieved moderate AUROC (0.815) but low clinical utility (F1 0.25, PPV 0.15), with high NPV yet insufficient recall for a rule‑out test. SHAP analysis showed predictions were driven by nonspecific features such as age and inflammation markers, indicating that lab data alone provide a weak, confounded cancer signal.", "summary_cn": "本文评估了利用常规实验室检测数据在金毛犬中进行早期癌症筛查的可行性，比较了 126 条机器学习流水线在不平衡数据集上的表现。最佳模型（带类别加权和递归特征消除的逻辑回归）获得了中等的 AUROC（0.815），但临床分类性能较差（F1=0.25，阳性预测值=0.15），尽管阴性预测值高（0.98），但召回率不足（0.79）不足以作为可靠的排除测试。SHAP 可解释性分析显示，预测主要受年龄、炎症和贫血等非特异性特征驱动，表明单纯实验室数据的癌症信号微弱且易受混淆。", "keywords": "cancer detection, veterinary oncology, routine laboratory data, machine learning, class imbalance, logistic regression, SHAP, feature selection, early detection", "scoring": {"interpretability": 6, "understanding": 6, "safety": 2, "technicality": 7, "surprisal": 5}, "category": {"failure_mode_addressed": "non-applicable", "primary_focus": "other"}, "authors": ["Shumin Li"]}, "usage": {"completion_tokens": 749, "prompt_tokens": 3546, "total_tokens": 4295, "completion_tokens_details": {"accepted_prediction_tokens": null, "audio_tokens": null, "reasoning_tokens": 392, "rejected_prediction_tokens": null, "image_tokens": 0}, "prompt_tokens_details": {"audio_tokens": 0, "cached_tokens": 3152}, "cost": 0.00068576, "is_byok": false, "cost_details": {"upstream_inference_cost": null, "upstream_inference_prompt_cost": 0.00031126, "upstream_inference_completions_cost": 0.0003745}}, "model": "openai/gpt-oss-120b"}
{"timestamp": "2025-10-24T17:33:33.093907", "feed": "arxiv_cslg", "title": "Approximate Replicability in Learning", "link": "https://papers.cool/arxiv/2510.20200", "analysis": {"summary": "The paper introduces three relaxed notions of replicability—pointwise, approximate, and semi—within the PAC learning framework and shows that for constant replicability parameters, sample‑optimal agnostic learners can be achieved: the first two using Θ(d/α²) samples and the semi‑replicable setting requiring Θ(d²/α²) labeled samples while allowing shared unlabeled data. These results demonstrate that modest relaxations of strict replicability enable learning tasks that were previously impossible under exact replicability. The work provides theoretical guarantees and sample complexity bounds for each relaxation.", "summary_cn": "本文在 PAC 学习框架下提出了三种可近似复制性的放宽形式——点式、近似式和半复制式，并证明在常数复制性参数下可以实现样本最优的非一致学习者：前两种仅需 Θ(d/α²) 样本，半复制式则在允许使用共享未标记样本的情况下需要 Θ(d²/α²) 标记样本。该研究表明，适度放宽严格复制性可以实现先前在严格复制性下不可行的学习任务，并为每种放宽形式提供了理论保证和样本复杂度界限。", "keywords": "replicability, PAC learning, approximate replicability, agnostic learning, sample complexity, unlabeled data, stability", "scoring": {"interpretability": 2, "understanding": 7, "safety": 3, "technicality": 8, "surprisal": 7}, "category": {"failure_mode_addressed": "non-applicable", "primary_focus": "other"}, "authors": ["Max Hopkins", "Russell Impagliazzo", "Christopher Ye"]}, "usage": {"completion_tokens": 737, "prompt_tokens": 3437, "total_tokens": 4174, "completion_tokens_details": {"accepted_prediction_tokens": null, "audio_tokens": null, "reasoning_tokens": 436, "rejected_prediction_tokens": null, "image_tokens": 0}, "prompt_tokens_details": {"audio_tokens": 0, "cached_tokens": 3152}, "cost": 0.00066341, "is_byok": false, "cost_details": {"upstream_inference_cost": null, "upstream_inference_prompt_cost": 0.00029491, "upstream_inference_completions_cost": 0.0003685}}, "model": "openai/gpt-oss-120b"}
{"timestamp": "2025-10-24T17:33:33.523794", "feed": "arxiv_cslg", "title": "Synthetic Data for Robust Runway Detection", "link": "https://papers.cool/arxiv/2510.20349", "analysis": {"summary": "The paper proposes using a commercial flight simulator to generate synthetic images that supplement a small set of annotated real runway images, enabling standard object detection models to achieve accurate runway detection for autonomous landing. By controlling the generation process and combining real and synthetic data, the authors demonstrate robustness to adverse conditions such as nighttime, which are absent from the real dataset, and show benefits of a customized domain adaptation strategy.", "summary_cn": "本文利用商业飞行模拟器生成合成图像，补充少量已标注的真实跑道图像，从而使标准目标检测模型能够实现对自主着陆系统中跑道的准确检测。通过控制图像生成并融合真实与合成数据，作者展示了模型在未在真实数据中出现的夜间等不利条件下的鲁棒性，并证明了定制化领域适应策略的有效性。", "keywords": "synthetic data, runway detection, domain adaptation, object detection, autonomous landing, robustness, flight simulator", "scoring": {"interpretability": 2, "understanding": 5, "safety": 6, "technicality": 7, "surprisal": 5}, "category": {"failure_mode_addressed": "non-applicable", "primary_focus": "robustness"}, "authors": ["Estelle Chigot", "Dennis G. Wilson", "Meriem Ghrib", "Fabrice Jimenez", "Thomas Oberlin"]}, "usage": {"completion_tokens": 799, "prompt_tokens": 3399, "total_tokens": 4198, "completion_tokens_details": {"accepted_prediction_tokens": null, "audio_tokens": null, "reasoning_tokens": 619, "rejected_prediction_tokens": null, "image_tokens": 0}, "prompt_tokens_details": {"audio_tokens": 0, "cached_tokens": 3152}, "cost": 0.00068871, "is_byok": false, "cost_details": {"upstream_inference_cost": null, "upstream_inference_prompt_cost": 0.00028921, "upstream_inference_completions_cost": 0.0003995}}, "model": "openai/gpt-oss-120b"}
{"timestamp": "2025-10-24T17:33:34.038668", "feed": "arxiv_cslg", "title": "Not-a-Bandit: Provably No-Regret Drafter Selection in Speculative Decoding for LLMs", "link": "https://papers.cool/arxiv/2510.20064", "analysis": {"summary": "The paper introduces a provably no‑regret algorithm for online draft model selection in speculative decoding, allowing accurate evaluation of all draft models without extra target model queries. By extending beyond bandit‑based methods, it achieves exponential improvements as the number of drafts grows and offers system‑efficient implementations that reduce computational and latency overhead. Experiments on open‑source LLMs show consistent gains over state‑of‑the‑art baselines, especially for long reasoning tasks.", "summary_cn": "本文提出了一种在投机解码中实现在线草稿模型选择的无后悔（no‑regret）算法，可在不增加目标模型查询的情况下准确评估所有草稿模型。该方法突破了基于 bandit 的做法，随着草稿模型数量的增加实现指数级提升，并提供了系统效率优化以降低计算和延迟开销。实验在开源 LLM 和多种数据集上展示了相对于最新基线的显著性能提升，尤其在需要长推理链的场景中表现突出。", "keywords": "speculative decoding, draft model selection, online learning, no-regret algorithm, multi-draft, LLM acceleration", "scoring": {"interpretability": 2, "understanding": 5, "safety": 2, "technicality": 8, "surprisal": 7}, "category": {"failure_mode_addressed": "non-applicable", "primary_focus": "other"}, "authors": ["Hongyi Liu", "Jiaji Huang", "Zhen Jia", "Youngsuk Park", "Yu-Xiang Wang"]}, "usage": {"completion_tokens": 627, "prompt_tokens": 3423, "total_tokens": 4050, "completion_tokens_details": {"accepted_prediction_tokens": null, "audio_tokens": null, "reasoning_tokens": 356, "rejected_prediction_tokens": null, "image_tokens": 0}, "prompt_tokens_details": {"audio_tokens": 0, "cached_tokens": 3152}, "cost": 0.00060631, "is_byok": false, "cost_details": {"upstream_inference_cost": null, "upstream_inference_prompt_cost": 0.00029281, "upstream_inference_completions_cost": 0.0003135}}, "model": "openai/gpt-oss-120b"}
{"timestamp": "2025-10-24T17:33:34.172206", "feed": "arxiv_cslg", "title": "Speculative Sampling for Parametric Temporal Point Processes", "link": "https://papers.cool/arxiv/2510.20031", "analysis": {"summary": "The paper introduces a rejection‑sampling based algorithm that allows exact, parallel sampling of multiple future events from existing parametric temporal point process models without modifying their architecture or retraining. The method provides theoretical guarantees and demonstrates empirical speedups on real‑world datasets, bridging the gap between expressive modeling and efficient large‑scale generation. This enables more scalable applications of TPPs for event‑sequence data.", "summary_cn": "本文提出一种基于拒绝采样的算法，可在不改动模型结构或重新训练的前提下，实现对已有参数化时间点过程模型的多个未来事件的精确并行采样。该方法提供理论保证，并在真实数据集上展示了显著的加速效果，弥合了模型表达能力与大规模高效生成之间的鸿沟。", "keywords": "temporal point processes, rejection sampling, parallel exact sampling, autoregressive models, event sequence generation, scalability, generative modeling, parallel generation", "scoring": {"interpretability": 2, "understanding": 5, "safety": 1, "technicality": 7, "surprisal": 6}, "category": {"failure_mode_addressed": "non-applicable", "primary_focus": "other"}, "authors": ["Marin Biloš", "Anderson Schneider", "Yuriy Nevmyvaka"]}, "usage": {"completion_tokens": 637, "prompt_tokens": 3308, "total_tokens": 3945, "completion_tokens_details": {"accepted_prediction_tokens": null, "audio_tokens": null, "reasoning_tokens": 438, "rejected_prediction_tokens": null, "image_tokens": 0}, "prompt_tokens_details": {"audio_tokens": 0, "cached_tokens": 3152}, "cost": 0.00059406, "is_byok": false, "cost_details": {"upstream_inference_cost": null, "upstream_inference_prompt_cost": 0.00027556, "upstream_inference_completions_cost": 0.0003185}}, "model": "openai/gpt-oss-120b"}
{"timestamp": "2025-10-24T17:33:34.376731", "feed": "arxiv_cslg", "title": "The Temporal Graph of Bitcoin Transactions", "link": "https://papers.cool/arxiv/2510.20028", "analysis": {"summary": "The paper introduces a temporal, heterogeneous graph representation of the entire Bitcoin transaction history, reconstructing fund flows to produce a dataset with over 2.4 billion nodes and 39.7 billion edges. It provides sampling methods, feature vectors, tools for loading the data into graph databases, and ready-to-use snapshots to enable large‑scale graph machine‑learning research such as anomaly detection and address classification. The dataset and toolkit aim to make Bitcoin’s economic topology accessible for ML studies.", "summary_cn": "本文提出了一种时间异构图，用于重建比特币全部交易历史的资金流动，生成包含超过 24 亿节点和 397 亿边的完整数据集。论文提供了社区采样方法、节点和边特征向量、图数据库加载工具以及可直接使用的数据库快照，以支持大规模图机器学习研究，如异常检测和地址分类。该数据集和工具旨在让比特币的经济拓扑对机器学习社区可访问。", "keywords": "Bitcoin, transaction graph, temporal graph, cryptocurrency, anomaly detection, graph machine learning, dataset, UTXO, blockchain analytics, large-scale graph", "scoring": {"interpretability": 2, "understanding": 6, "safety": 4, "technicality": 7, "surprisal": 5}, "category": {"failure_mode_addressed": "non-applicable", "primary_focus": "other"}, "authors": ["Vahid Jalili"]}, "usage": {"completion_tokens": 641, "prompt_tokens": 3433, "total_tokens": 4074, "completion_tokens_details": {"accepted_prediction_tokens": null, "audio_tokens": null, "reasoning_tokens": 387, "rejected_prediction_tokens": null, "image_tokens": 0}, "prompt_tokens_details": {"audio_tokens": 0, "cached_tokens": 3152}, "cost": 0.00061481, "is_byok": false, "cost_details": {"upstream_inference_cost": null, "upstream_inference_prompt_cost": 0.00029431, "upstream_inference_completions_cost": 0.0003205}}, "model": "openai/gpt-oss-120b"}
{"timestamp": "2025-10-24T17:33:34.501463", "feed": "arxiv_cslg", "title": "Abstain Mask Retain Core: Time Series Prediction by Adaptive Masking Loss with Representation Consistency", "link": "https://papers.cool/arxiv/2510.19980", "analysis": {"summary": "The paper identifies a counterintuitive phenomenon that truncating historical data can improve time‑series prediction, suggesting that current deep models learn many redundant features. To address this, it proposes Adaptive Masking Loss with Representation Consistency (AMRC), which dynamically masks discriminative temporal segments and enforces consistency among inputs, labels, and predictions, thereby suppressing noise learning and boosting performance.", "summary_cn": "本文发现截断历史数据有时能提升时间序列预测效果，表明现有深度模型会学习大量冗余特征（如噪声）。为此提出自适应掩蔽损失与表示一致性（AMRC）方法，通过动态掩蔽关键时间段并保持输入、标签与预测之间的映射一致性，从而抑制冗余学习并显著提升模型性能。", "keywords": "time series forecasting, adaptive masking loss, representation consistency, information bottleneck, redundant features, AMRC, deep learning, temporal modeling", "scoring": {"interpretability": 2, "understanding": 5, "safety": 2, "technicality": 7, "surprisal": 5}, "category": {"failure_mode_addressed": "non-applicable", "primary_focus": "other"}, "authors": ["Renzhao Liang", "Sizhe Xu", "Chenggang Xie", "Jingru Chen", "Feiyang Ren", "Shu Yang", "Takahiro Yabe"]}, "usage": {"completion_tokens": 598, "prompt_tokens": 3421, "total_tokens": 4019, "completion_tokens_details": {"accepted_prediction_tokens": null, "audio_tokens": null, "reasoning_tokens": 382, "rejected_prediction_tokens": null, "image_tokens": 0}, "prompt_tokens_details": {"audio_tokens": 0, "cached_tokens": 3152}, "cost": 0.00059151, "is_byok": false, "cost_details": {"upstream_inference_cost": null, "upstream_inference_prompt_cost": 0.00029251, "upstream_inference_completions_cost": 0.000299}}, "model": "openai/gpt-oss-120b"}
{"timestamp": "2025-10-24T17:33:34.627452", "feed": "arxiv_cslg", "title": "Learning Personalized Ad Impact via Contextual Reinforcement Learning under Delayed Rewards", "link": "https://papers.cool/arxiv/2510.20055", "analysis": {"summary": "The paper models online ad bidding as a Contextual Markov Decision Process with delayed Poisson rewards to capture delayed effects, cumulative impact, and customer heterogeneity. It proposes a two‑stage maximum‑likelihood estimator with data‑splitting and a reinforcement‑learning algorithm that achieves a near‑optimal regret bound of \\(\\tilde{O}(dH^2\\sqrt{T})\\). Simulation experiments validate the theoretical results.", "summary_cn": "本文将在线广告竞价建模为具有延迟泊松奖励的上下文马尔可夫决策过程，以同时考虑延迟效应、累积影响和用户异质性。作者提出两阶段最大似然估计结合数据划分的方法，并基于此设计强化学习算法，实现近似最优的 regret 上界 \\(\\tilde{O}(dH^2\\sqrt{T})\\)。通过仿真实验验证了理论成果。", "keywords": "contextual reinforcement learning, delayed rewards, ad bidding, personalized advertising, CMDP, maximum likelihood estimator, regret bound", "scoring": {"interpretability": 2, "understanding": 5, "safety": 2, "technicality": 8, "surprisal": 5}, "category": {"failure_mode_addressed": "non-applicable", "primary_focus": "other"}, "authors": ["Yuwei Cheng", "Zifeng Zhao", "Haifeng Xu"]}, "usage": {"completion_tokens": 671, "prompt_tokens": 3400, "total_tokens": 4071, "completion_tokens_details": {"accepted_prediction_tokens": null, "audio_tokens": null, "reasoning_tokens": 415, "rejected_prediction_tokens": null, "image_tokens": 0}, "prompt_tokens_details": {"audio_tokens": 0, "cached_tokens": 3152}, "cost": 0.00062486, "is_byok": false, "cost_details": {"upstream_inference_cost": null, "upstream_inference_prompt_cost": 0.00028936, "upstream_inference_completions_cost": 0.0003355}}, "model": "openai/gpt-oss-120b"}
{"timestamp": "2025-10-24T17:33:34.666546", "feed": "arxiv_cslg", "title": "Towards General Modality Translation with Contrastive and Predictive Latent Diffusion Bridge", "link": "https://papers.cool/arxiv/2510.20819", "analysis": {"summary": "The paper introduces the Latent Denoising Diffusion Bridge Model (LDDBM), a framework that learns a shared latent space to translate between arbitrary modalities without requiring aligned dimensions, using contrastive alignment and predictive losses to ensure semantic consistency. Experiments on tasks such as multi‑view to 3D shape generation, image super‑resolution, and scene synthesis demonstrate strong performance and establish a new baseline for general modality translation.", "summary_cn": "本文提出了潜在去噪扩散桥模型（LDDBM），通过在共享潜在空间中学习跨模态桥接，实现任意模态之间的翻译，无需对齐维度，并使用对比对齐损失和预测损失确保语义一致性。实验在多视角到 3D 形状生成、图像超分辨率和场景合成等任务上表现出色，树立了通用模态翻译的新基准。", "keywords": "modality translation, latent diffusion, diffusion bridge, contrastive alignment, predictive loss, cross-modal generation", "scoring": {"interpretability": 2, "understanding": 6, "safety": 2, "technicality": 8, "surprisal": 7}, "category": {"failure_mode_addressed": "non-applicable", "primary_focus": "other"}, "authors": ["Nimrod Berman", "Omkar Joglekar", "Eitan Kosman", "Dotan Di Castro", "Omri Azencot"]}, "usage": {"completion_tokens": 562, "prompt_tokens": 3486, "total_tokens": 4048, "completion_tokens_details": {"accepted_prediction_tokens": null, "audio_tokens": null, "reasoning_tokens": 317, "rejected_prediction_tokens": null, "image_tokens": 0}, "prompt_tokens_details": {"audio_tokens": 0, "cached_tokens": 3152}, "cost": 0.00058326, "is_byok": false, "cost_details": {"upstream_inference_cost": null, "upstream_inference_prompt_cost": 0.00030226, "upstream_inference_completions_cost": 0.000281}}, "model": "openai/gpt-oss-120b"}
{"timestamp": "2025-10-24T17:33:35.524732", "feed": "arxiv_cslg", "title": "Why Prototypes Collapse: Diagnosing and Preventing Partial Collapse in Prototypical Self-Supervised Learning", "link": "https://papers.cool/arxiv/2510.20108", "analysis": {"summary": "The paper identifies partial prototype collapse as a common failure in prototypical self‑supervised learning, where many prototypes become nearly identical, reducing the diversity of learned targets. It attributes this collapse to the joint optimization of encoders and prototypes, which creates a shortcut that minimizes loss without encouraging representation diversity. To solve the issue, the authors propose a fully decoupled training scheme that updates prototypes via an online EM‑style Gaussian‑mixture model independently of the encoder loss, eliminating collapse and improving downstream performance.", "summary_cn": "本文指出原型自监督学习中常见的部分原型塌陷现象，即多个原型趋于相同表示，导致目标多样性下降。作者将其归因于编码器与原型的联合优化所形成的“捷径”，在不提升表征多样性的情况下最小化损失。为此，提出一种完全解耦的训练策略，通过在线 EM 风格的高斯混合模型独立更新原型，摆脱了原型塌陷并提升了下游表现。", "keywords": "prototype collapse, self-supervised learning, prototypical learning, Gaussian mixture, EM algorithm, decoupled training, representation diversity", "scoring": {"interpretability": 2, "understanding": 7, "safety": 1, "technicality": 8, "surprisal": 6}, "category": {"failure_mode_addressed": "non-applicable", "primary_focus": "other"}, "authors": ["Gabriel Y. Arteaga", "Marius Aasan", "Rwiddhi Chakraborty", "Martine Hjelkrem-Tan", "Thalles Silva", "Michael Kampffmeyer", "Adín Ramírez Rivera"]}, "usage": {"completion_tokens": 862, "prompt_tokens": 3390, "total_tokens": 4252, "completion_tokens_details": {"accepted_prediction_tokens": null, "audio_tokens": null, "reasoning_tokens": 641, "rejected_prediction_tokens": null, "image_tokens": 0}, "prompt_tokens_details": {"audio_tokens": 0, "cached_tokens": 3152}, "cost": 0.00071886, "is_byok": false, "cost_details": {"upstream_inference_cost": null, "upstream_inference_prompt_cost": 0.00028786, "upstream_inference_completions_cost": 0.000431}}, "model": "openai/gpt-oss-120b"}
{"timestamp": "2025-10-24T17:33:35.927637", "feed": "arxiv_cslg", "title": "On the Detectability of LLM-Generated Text: What Exactly Is LLM-Generated Text?", "link": "https://papers.cool/arxiv/2510.20810", "analysis": {"summary": "The paper critiques the lack of a precise definition for \"LLM-generated text\" and examines how diverse usage scenarios, human edits, and subtle LLM influences blur the line between machine- and human-written content. It argues that current detection benchmarks and evaluation methods fail to capture real-world conditions, leading to misunderstandings of detector performance, and recommends interpreting detector outputs as contextual references rather than definitive judgments.", "summary_cn": "本文批评了“LLM 生成文本”缺乏精确定义的问题，分析了使用场景多样、人类编辑以及 LLM 对用户的微妙影响如何模糊机器生成与人类写作的界限。作者指出现有的检测基准和评估方法未能覆盖真实应用条件，导致对检测器性能的误解，建议将检测结果视为情境参考而非决定性结论。", "keywords": "LLM-generated text, detection, definitional analysis, benchmarks, safety, misuse detection, evaluation, text classification", "scoring": {"interpretability": 2, "understanding": 7, "safety": 7, "technicality": 6, "surprisal": 6}, "category": {"failure_mode_addressed": "human-misuse", "primary_focus": "control"}, "authors": ["Mingmeng Geng", "Thierry Poibeau"]}, "usage": {"completion_tokens": 634, "prompt_tokens": 3376, "total_tokens": 4010, "completion_tokens_details": {"accepted_prediction_tokens": null, "audio_tokens": null, "reasoning_tokens": 392, "rejected_prediction_tokens": null, "image_tokens": 0}, "prompt_tokens_details": {"audio_tokens": 0, "cached_tokens": 3152}, "cost": 0.00060276, "is_byok": false, "cost_details": {"upstream_inference_cost": null, "upstream_inference_prompt_cost": 0.00028576, "upstream_inference_completions_cost": 0.000317}}, "model": "openai/gpt-oss-120b"}
{"timestamp": "2025-10-24T17:33:36.118864", "feed": "arxiv_cslg", "title": "ADP-VRSGP: Decentralized Learning with Adaptive Differential Privacy via Variance-Reduced Stochastic Gradient Push", "link": "https://papers.cool/arxiv/2510.20157", "analysis": {"summary": "The paper proposes ADP-VRSGP, a decentralized learning framework that adaptively adjusts differential‑privacy noise variance and learning rate via a stepwise‑decaying schedule, while employing progressive gradient fusion and push‑sum aggregation to handle time‑varying communication topologies. Theoretical analysis shows robust convergence, and experiments demonstrate improved training speed and model performance compared to fixed‑variance baselines, providing node‑level personalized privacy guarantees.", "summary_cn": "本文提出 ADP-VRSGP，一种去中心化学习框架，通过逐步衰减的调度自适应调整差分隐私噪声方差和学习率，并引入渐进式梯度融合及 push‑sum 聚合，以适应时变通信拓扑。理论分析证明了其收敛性，实验表明相较于固定方差方法在训练速度和模型性能上都有显著提升，并提供节点级别的个性化隐私保障。", "keywords": "decentralized learning, differential privacy, adaptive noise variance, variance-reduced stochastic gradient push, push-sum, privacy-preserving machine learning, gradient fusion, time-varying topology", "scoring": {"interpretability": 2, "understanding": 5, "safety": 6, "technicality": 8, "surprisal": 7}, "category": {"failure_mode_addressed": "human-misuse", "primary_focus": "robustness"}, "authors": ["Xiaoming Wu", "Teng Liu", "Xin Wang", "Ming Yang", "Jiguo Yu"]}, "usage": {"completion_tokens": 896, "prompt_tokens": 3428, "total_tokens": 4324, "completion_tokens_details": {"accepted_prediction_tokens": null, "audio_tokens": null, "reasoning_tokens": 694, "rejected_prediction_tokens": null, "image_tokens": 0}, "prompt_tokens_details": {"audio_tokens": 0, "cached_tokens": 3152}, "cost": 0.00074156, "is_byok": false, "cost_details": {"upstream_inference_cost": null, "upstream_inference_prompt_cost": 0.00029356, "upstream_inference_completions_cost": 0.000448}}, "model": "openai/gpt-oss-120b"}
{"timestamp": "2025-10-24T17:33:36.284242", "feed": "arxiv_cslg", "title": "Separating the what and how of compositional computation to enable reuse and continual learning", "link": "https://papers.cool/arxiv/2510.20709", "analysis": {"summary": "The paper proposes a two‑system framework that separates a \"what\" module, which infers the compositional structure of a task using an online probabilistic generative model of discrete task epochs, from a \"how\" module, an RNN whose low‑rank components are assembled according to the inferred context. This design enables continual learning of sequential tasks without catastrophic forgetting, supports forward and backward transfer, and allows fast compositional generalisation to novel tasks. Experiments on a suite of cognitive tasks demonstrate competitive performance and efficient reuse of learned computational primitives.", "summary_cn": "本文提出了一种两系统框架，将“what”模块（利用在线概率生成模型推断任务的离散时期结构）与“How”模块（根据推断上下文组装低秩 RNN 组件）分离，实现对任务的组合式理解和实现。该设计在顺序学习任务时避免灾难性遗忘，支持前向和后向迁移，并能快速组合推广到未见任务。实验在一套认知任务上展示了竞争性的性能和高效的计算原语复用。", "keywords": "compositionality, continual learning, recurrent neural network, low-rank RNN, probabilistic generative model, task epochs, modular learning, transfer learning", "scoring": {"interpretability": 6, "understanding": 7, "safety": 3, "technicality": 7, "surprisal": 6}, "category": {"failure_mode_addressed": "non-applicable", "primary_focus": "interpretability"}, "authors": ["Haozhe Shan", "Sun Minni", "Lea Duncker"]}, "usage": {"completion_tokens": 718, "prompt_tokens": 3527, "total_tokens": 4245, "completion_tokens_details": {"accepted_prediction_tokens": null, "audio_tokens": null, "reasoning_tokens": 442, "rejected_prediction_tokens": null, "image_tokens": 0}, "prompt_tokens_details": {"audio_tokens": 0, "cached_tokens": 3520}, "cost": 0.00064165, "is_byok": false, "cost_details": {"upstream_inference_cost": null, "upstream_inference_prompt_cost": 0.00028265, "upstream_inference_completions_cost": 0.000359}}, "model": "openai/gpt-oss-120b"}
{"timestamp": "2025-10-24T17:33:36.541476", "feed": "arxiv_cslg", "title": "On the Optimal Construction of Unbiased Gradient Estimators for Zeroth-Order Optimization", "link": "https://papers.cool/arxiv/2510.19953", "analysis": {"summary": "The paper introduces a novel family of unbiased gradient estimators for zeroth-order optimization by reformulating directional derivatives as a telescoping series and sampling from carefully designed distributions. It derives optimal scaling distributions and perturbation stepsizes for four constructions, proving that SGD with these estimators attains optimal complexity on smooth non-convex objectives, and validates the approach with synthetic experiments and language model fine-tuning.", "summary_cn": "本文提出了一类新的无偏梯度估计器用于零阶优化，通过将方向导数重写为望远镜级数并从精心设计的分布中采样，实现了在仅使用函数评估的情况下消除偏差并保持方差可控。文中推导了四种具体构造的最优尺度分布和扰动步长，并证明使用该估计器的 SGD 在平滑非凸目标上达到最优复杂度；实验在合成任务及语言模型微调上展示了其相较于标准方法的更高准确率和收敛速度。", "keywords": "zeroth-order optimization, unbiased gradient estimator, stochastic gradient descent, non-convex optimization, variance reduction, function evaluation, optimal scaling distribution, language model fine-tuning", "scoring": {"interpretability": 2, "understanding": 6, "safety": 3, "technicality": 8, "surprisal": 6}, "category": {"failure_mode_addressed": "non-applicable", "primary_focus": "other"}, "authors": ["Shaocong Ma", "Heng Huang"]}, "usage": {"completion_tokens": 649, "prompt_tokens": 3365, "total_tokens": 4014, "completion_tokens_details": {"accepted_prediction_tokens": null, "audio_tokens": null, "reasoning_tokens": 412, "rejected_prediction_tokens": null, "image_tokens": 0}, "prompt_tokens_details": {"audio_tokens": 0, "cached_tokens": 3152}, "cost": 0.00060861, "is_byok": false, "cost_details": {"upstream_inference_cost": null, "upstream_inference_prompt_cost": 0.00028411, "upstream_inference_completions_cost": 0.0003245}}, "model": "openai/gpt-oss-120b"}
{"timestamp": "2025-10-24T17:33:36.549791", "feed": "arxiv_cslg", "title": "Simple Context Compression: Mean-Pooling and Multi-Ratio Training", "link": "https://papers.cool/arxiv/2510.20797", "analysis": {"summary": "The paper introduces a lightweight mean‑pooling method for soft context compression in retrieval‑augmented generation, showing it consistently outperforms the commonly used compression‑tokens architecture across various QA datasets and model scales. It also explores training a single compressor to produce multiple compression ratios, revealing nuanced trade‑offs among architectures and training regimes.", "summary_cn": "本文提出一种轻量级的均值池化软上下文压缩方法，用于检索增强生成（RAG），在多种问答数据集和模型下稳健超越常用的 compression‑tokens 架构。论文进一步研究了对同一压缩器进行多倍率训练，揭示了不同体系结构和训练策略之间的细致权衡。", "keywords": "context compression, mean-pooling, retrieval-augmented generation, multi-ratio training, long-context processing, LLM efficiency", "scoring": {"interpretability": 2, "understanding": 5, "safety": 2, "technicality": 7, "surprisal": 5}, "category": {"failure_mode_addressed": "non-applicable", "primary_focus": "other"}, "authors": ["Yair Feldman", "Yoav Artzi"]}, "usage": {"completion_tokens": 577, "prompt_tokens": 3347, "total_tokens": 3924, "completion_tokens_details": {"accepted_prediction_tokens": null, "audio_tokens": null, "reasoning_tokens": 370, "rejected_prediction_tokens": null, "image_tokens": 0}, "prompt_tokens_details": {"audio_tokens": 0, "cached_tokens": 3152}, "cost": 0.00056991, "is_byok": false, "cost_details": {"upstream_inference_cost": null, "upstream_inference_prompt_cost": 0.00028141, "upstream_inference_completions_cost": 0.0002885}}, "model": "openai/gpt-oss-120b"}
{"timestamp": "2025-10-24T17:33:36.805731", "feed": "arxiv_cslg", "title": "Coupled Transformer Autoencoder for Disentangling Multi-Region Neural Latent Dynamics", "link": "https://papers.cool/arxiv/2510.20068", "analysis": {"summary": "The paper introduces the Coupled Transformer Autoencoder (CTAE), a sequence model that leverages transformer encoders and decoders to capture long-range, non-stationary, non-linear neural dynamics while explicitly separating each brain region’s latent representation into orthogonal shared and private subspaces. Experiments on high‑density electrophysiology recordings from motor and sensory cortices show that CTAE yields more meaningful latent structures and improves behavioral decoding compared to existing alignment and dynamical latent variable methods.", "summary_cn": "本文提出了耦合 Transformer 自动编码器（CTAE），一种使用 Transformer 编码器和解码器捕获长期、非平稳、非线性神经动态的序列模型，并显式地将每个脑区的潜在表示划分为正交的共享子空间和私有子空间。对来自运动和感觉皮层的高密度电生理记录的实验表明，与现有的对齐方法和动力学潜变量模型相比，CTAE 能提取更有意义的潜在结构并提升行为解码性能。", "keywords": "transformer, autoencoder, latent dynamics, multi-region neural data, disentanglement, shared-private subspaces, neural decoding", "scoring": {"interpretability": 3, "understanding": 6, "safety": 2, "technicality": 7, "surprisal": 6}, "category": {"failure_mode_addressed": "non-applicable", "primary_focus": "other"}, "authors": ["Ram Dyuthi Sristi", "Sowmya Manojna Narasimha", "Jingya Huang", "Alice Despatin", "Simon Musall", "Vikash Gilja", "Gal Mishne"]}, "usage": {"completion_tokens": 838, "prompt_tokens": 3393, "total_tokens": 4231, "completion_tokens_details": {"accepted_prediction_tokens": null, "audio_tokens": null, "reasoning_tokens": 651, "rejected_prediction_tokens": null, "image_tokens": 0}, "prompt_tokens_details": {"audio_tokens": 0, "cached_tokens": 3152}, "cost": 0.00070731, "is_byok": false, "cost_details": {"upstream_inference_cost": null, "upstream_inference_prompt_cost": 0.00028831, "upstream_inference_completions_cost": 0.000419}}, "model": "openai/gpt-oss-120b"}
{"timestamp": "2025-10-24T17:33:36.870464", "feed": "arxiv_cslg", "title": "Compress to Impress: Efficient LLM Adaptation Using a Single Gradient Step on 100 Samples", "link": "https://papers.cool/arxiv/2510.20800", "analysis": {"summary": "The paper introduces a fast LLM adaptation technique that selects a small set of weight matrices for low‑rank factorization using the gradient of singular values, clusters matrix rows into multiple subspaces, and evaluates the adaptation on only 100 examples with a single gradient step. This approach eliminates the exhaustive layer‑wise search of LASER, reduces overfitting, and achieves up to 24.6 percentage‑point accuracy gains without any conventional fine‑tuning.", "summary_cn": "本文提出一种快速的 LLM 适配方法，通过计算矩阵奇异值的梯度来挑选少数矩阵进行低秩分解，并对矩阵行进行多子空间聚类，仅使用 100 条样本并执行一次梯度更新即可完成适配。该方案省去了 LASER 的逐层 exhaustive 搜索，降低了过拟合，并在无需传统微调的情况下实现最高 24.6% 的准确率提升。", "keywords": "LLM adaptation, low-rank factorization, singular value gradient, matrix pruning, LASER, data-efficient fine-tuning, row clustering, single gradient step", "scoring": {"interpretability": 3, "understanding": 5, "safety": 2, "technicality": 7, "surprisal": 7}, "category": {"failure_mode_addressed": "non-applicable", "primary_focus": "other"}, "authors": ["Shiva Sreeram", "Alaa Maalouf", "Pratyusha Sharma", "Daniela Rus"]}, "usage": {"completion_tokens": 878, "prompt_tokens": 3499, "total_tokens": 4377, "completion_tokens_details": {"accepted_prediction_tokens": null, "audio_tokens": null, "reasoning_tokens": 682, "rejected_prediction_tokens": null, "image_tokens": 0}, "prompt_tokens_details": {"audio_tokens": 0, "cached_tokens": 3152}, "cost": 0.00074321, "is_byok": false, "cost_details": {"upstream_inference_cost": null, "upstream_inference_prompt_cost": 0.00030421, "upstream_inference_completions_cost": 0.000439}}, "model": "openai/gpt-oss-120b"}
{"timestamp": "2025-10-24T17:33:37.438189", "feed": "arxiv_cslg", "title": "Robust Reinforcement Learning in Finance: Modeling Market Impact with Elliptic Uncertainty Sets", "link": "https://papers.cool/arxiv/2510.19950", "analysis": {"summary": "The paper proposes elliptic uncertainty sets to model directional market impact in reinforcement learning agents used for financial trading, providing closed-form worst-case solutions that enable efficient robust policy evaluation. Empirical results on single‑asset and multi‑asset tasks show improved Sharpe ratios and robustness to larger trade volumes compared to traditional symmetric uncertainty approaches.", "summary_cn": "本文提出使用椭圆不确定性集合来建模金融交易中强化学习代理的方向性市场冲击，并给出最坏情况的闭式解，从而实现高效的鲁棒策略评估。实验在单资产和多资产交易任务上显示，相较于传统对称不确定性方法，本文方法提升了夏普比率并在交易量增大时保持鲁棒性。", "keywords": "robust reinforcement learning, market impact, elliptic uncertainty sets, financial trading, robust policy evaluation, Sharpe ratio, RL robustness, uncertainty sets", "scoring": {"interpretability": 2, "understanding": 6, "safety": 5, "technicality": 7, "surprisal": 7}, "category": {"failure_mode_addressed": "misalignment", "primary_focus": "robustness"}, "authors": ["Shaocong Ma", "Heng Huang"]}, "usage": {"completion_tokens": 631, "prompt_tokens": 3382, "total_tokens": 4013, "completion_tokens_details": {"accepted_prediction_tokens": null, "audio_tokens": null, "reasoning_tokens": 425, "rejected_prediction_tokens": null, "image_tokens": 0}, "prompt_tokens_details": {"audio_tokens": 0, "cached_tokens": 3152}, "cost": 0.00060216, "is_byok": false, "cost_details": {"upstream_inference_cost": null, "upstream_inference_prompt_cost": 0.00028666, "upstream_inference_completions_cost": 0.0003155}}, "model": "openai/gpt-oss-120b"}
{"timestamp": "2025-10-24T17:33:37.718339", "feed": "arxiv_cslg", "title": "CSU-PCAST: A Dual-Branch Transformer Framework for medium-range ensemble Precipitation Forecasting", "link": "https://papers.cool/arxiv/2510.20769", "analysis": {"summary": "The paper proposes CSU-PCAST, a dual‑branch transformer framework that uses a Swin‑Transformer encoder with periodic convolutions and conditional layer normalization to produce medium‑range (up to 15‑day) ensemble precipitation forecasts from ERA5 reanalysis and GFS initial conditions. The model jointly predicts total precipitation and auxiliary atmospheric variables, training with a hybrid loss that combines CRPS and weighted log1p‑SE, and demonstrates higher CSI scores than the GEFS baseline across multiple rainfall thresholds. This approach highlights the potential of deep learning ensembles for improving probabilistic precipitation forecasting at moderate to heavy rain rates.", "summary_cn": "本文提出了 CSU‑PCAST 双分支 Transformer 框架，使用带周期卷积的 Swin‑Transformer 编码器和条件层归一化，将 ERA5 再分析数据与 GFS 初始条件相结合，实现最长  天的集合降水预报。模型通过混合损失（CRPS 与加权 log1p‑MSE）联合预测总降水量及其他大气变量，并在多个降雨阈值下的 CSI 指标上相较 GEFS 基线取得提升。该工作展示了深度学习集合方法在中期至强降雨概率预报中的潜力。", "keywords": "precipitation forecasting, ensemble learning, transformer, Swin Transformer, CRPS, deep learning, medium-range prediction, probabilistic forecasting, meteorology", "scoring": {"interpretability": 2, "understanding": 5, "safety": 2, "technicality": 8, "surprisal": 5}, "category": {"failure_mode_addressed": "non-applicable", "primary_focus": "other"}, "authors": ["Tianyi Xiong", "Haonan Chen"]}, "usage": {"completion_tokens": 658, "prompt_tokens": 3516, "total_tokens": 4174, "completion_tokens_details": {"accepted_prediction_tokens": null, "audio_tokens": null, "reasoning_tokens": 319, "rejected_prediction_tokens": null, "image_tokens": 0}, "prompt_tokens_details": {"audio_tokens": 0, "cached_tokens": 3152}, "cost": 0.00063576, "is_byok": false, "cost_details": {"upstream_inference_cost": null, "upstream_inference_prompt_cost": 0.00030676, "upstream_inference_completions_cost": 0.000329}}, "model": "openai/gpt-oss-120b"}
{"timestamp": "2025-10-24T17:33:37.810094", "feed": "arxiv_cslg", "title": "No Compute Left Behind: Rethinking Reasoning and Sampling with Masked Diffusion Models", "link": "https://papers.cool/arxiv/2510.19990", "analysis": {"summary": "The paper proposes reasoning-as-infilling for masked diffusion language models, allowing structured reasoning traces, answer uncertainty measurement, early exits, and posterior sampling for post‑training data generation. It also introduces multi‑token entropy decoding (MED), an adaptive parallel decoding strategy that selects positions with low conditional entropy, preserving performance while reducing decoding steps by 2.7×. Experiments on GSM8k show that fine‑tuning on model‑generated reasoning traces matches gains from human‑written traces.", "summary_cn": "本文提出将推理视为填空（reasoning‑as‑infilling）用于掩码扩散语言模型（MDLM），通过在推理模板中填充实现对推理过程的结构化、答案不确定性的测量、提前退出以及在已知答案条件下采样后训练数据。随后引入多标记熵解码（MED），一种基于条件熵自适应选择并行解码位置的方法，在保持性能的同时将解码步数缩减约 2.7 倍。实验表明，在 GSM8k 上使用模型生成的推理轨迹进行微调，可获得与使用人类推理轨迹相当的性能提升。", "keywords": "masked diffusion language models, reasoning-as-infilling, multi-token entropy decoding, early exit, posterior sampling, GSM8k, LLaDA, inference efficiency", "scoring": {"interpretability": 4, "understanding": 7, "safety": 3, "technicality": 7, "surprisal": 7}, "category": {"failure_mode_addressed": "non-applicable", "primary_focus": "other"}, "authors": ["Zachary Horvitz", "Raghav Singhal", "Hao Zou", "Carles Domingo-Enrich", "Zhou Yu", "Rajesh Ranganath", "Kathleen McKeown"]}, "usage": {"completion_tokens": 836, "prompt_tokens": 3561, "total_tokens": 4397, "completion_tokens_details": {"accepted_prediction_tokens": null, "audio_tokens": null, "reasoning_tokens": 570, "rejected_prediction_tokens": null, "image_tokens": 0}, "prompt_tokens_details": {"audio_tokens": 0, "cached_tokens": 3152}, "cost": 0.00073151, "is_byok": false, "cost_details": {"upstream_inference_cost": null, "upstream_inference_prompt_cost": 0.00031351, "upstream_inference_completions_cost": 0.000418}}, "model": "openai/gpt-oss-120b"}
{"timestamp": "2025-10-24T17:33:38.073575", "feed": "arxiv_cslg", "title": "Are Greedy Task Orderings Better Than Random in Continual Linear Regression?", "link": "https://papers.cool/arxiv/2510.19941", "analysis": {"summary": "The paper studies task orderings in continual learning for linear regression, focusing on greedy strategies that maximize dissimilarity between consecutive tasks. Using tools from the Kaczmarz method, it provides geometric and algebraic insights, proves loss bounds for high‑rank settings, and shows experimentally that greedy orderings converge faster than random ones, though single‑pass greedy orderings can fail catastrophically while repeated greedy orderings converge at a rate of O(k^{-1/3}).", "summary_cn": "本文研究在连续学习线性回归中的任务排序，重点考察通过最大化连续任务间不相似性实现的贪心策略。借助 Kaczmarz 方法的工具，提供几何和代数直观，证明在高秩回归情况下贪心排序的损失上界，并在实验中展示贪心排序相较随机排序收敛更快；然而单遍贪心排序可能出现灾难性失败，而允许重复的贪心排序收敛速率为 O(k^{-1/3})。", "keywords": "continual learning, task ordering, linear regression, greedy algorithm, Kaczmarz method, convergence rate, catastrophic forgetting", "scoring": {"interpretability": 2, "understanding": 6, "safety": 2, "technicality": 7, "surprisal": 6}, "category": {"failure_mode_addressed": "non-applicable", "primary_focus": "other"}, "authors": ["Matan Tsipory", "Ran Levinstein", "Itay Evron", "Mark Kong", "Deanna Needell", "Daniel Soudry"]}, "usage": {"completion_tokens": 662, "prompt_tokens": 3442, "total_tokens": 4104, "completion_tokens_details": {"accepted_prediction_tokens": null, "audio_tokens": null, "reasoning_tokens": 396, "rejected_prediction_tokens": null, "image_tokens": 0}, "prompt_tokens_details": {"audio_tokens": 0, "cached_tokens": 3152}, "cost": 0.00062666, "is_byok": false, "cost_details": {"upstream_inference_cost": null, "upstream_inference_prompt_cost": 0.00029566, "upstream_inference_completions_cost": 0.000331}}, "model": "openai/gpt-oss-120b"}
{"timestamp": "2025-10-24T17:33:38.366615", "feed": "arxiv_cslg", "title": "Alternatives to the Laplacian for Scalable Spectral Clustering with Group Fairness Constraints", "link": "https://papers.cool/arxiv/2510.20220", "analysis": {"summary": "The paper proposes Fair‑SMW, a scalable spectral clustering algorithm that enforces group‑fairness balance constraints by reformulating the constrained optimization using the Lagrangian and the Sherman‑Morrison‑Woodbury identity, yielding three Laplacian‑alternative matrices with larger spectral gaps. Experiments on synthetic Stochastic Block Model graphs and real‑world networks (LastFM, FacebookNet, Deezer, German) show that Fair‑SMW attains comparable or better balance while running up to twice as fast as state‑of‑the‑art methods.", "summary_cn": "本文提出 Fair‑SMW 算法，通过拉格朗日方法和 Sherman‑Morrison‑Woodbury (SMW) 恒等式重新表述带有群体公平（平衡）约束的谱聚类优化问题，得到了三种拉普拉斯矩阵的替代方案以增大光谱间隙。实验在随机块模型以及真实网络数据集（LastFM、FacebookNet、Deezer、German）上表明，Fair‑SMW 在保持或提升平衡性的同时，运行速度可比现有最先进方法提升约两倍。", "keywords": "spectral clustering, group fairness, balance constraint, Sherman-Morrison-Woodbury, Laplacian alternative, scalable clustering, Stochastic Block Model, fairness in graphs", "scoring": {"interpretability": 2, "understanding": 5, "safety": 2, "technicality": 8, "surprisal": 6}, "category": {"failure_mode_addressed": "societal-disruption", "primary_focus": "other"}, "authors": ["Iván Ojeda-Ruiz", "Young Ju-Lee", "Malcolm Dickens", "Leonardo Cambisaca"]}, "usage": {"completion_tokens": 1090, "prompt_tokens": 3449, "total_tokens": 4539, "completion_tokens_details": {"accepted_prediction_tokens": null, "audio_tokens": null, "reasoning_tokens": 869, "rejected_prediction_tokens": null, "image_tokens": 0}, "prompt_tokens_details": {"audio_tokens": 0, "cached_tokens": 3152}, "cost": 0.00084171, "is_byok": false, "cost_details": {"upstream_inference_cost": null, "upstream_inference_prompt_cost": 0.00029671, "upstream_inference_completions_cost": 0.000545}}, "model": "openai/gpt-oss-120b"}
{"timestamp": "2025-10-24T17:33:38.374008", "feed": "arxiv_cslg", "title": "Beyond the Ideal: Analyzing the Inexact Muon Update", "link": "https://papers.cool/arxiv/2510.19933", "analysis": {"summary": "The paper provides the first theoretical analysis of Muon's inexact orthogonalized update by modeling the practical approximation error within a Linear Minimization Oracle framework. It derives explicit bounds showing how oracle inexactness couples with optimal step size and momentum, and validates these predictions with NanoGPT experiments that demonstrate learning rate shifts as approximation precision varies.", "summary_cn": "本文首次在 Linear Minimization Oracle 框架下，对 Muon 优化器的近似正交更新进行理论分析，建立了实际近似误差的加性模型。研究得出误差程度与最佳学习率和动量之间的耦合关系，并通过 NanoGPT 实验验证了随着近似精度变化学习率的显著移动。", "keywords": "Muon optimizer, orthogonalization, inexact LMO, linear minimization oracle, step size, momentum, Newton-Schulz, NanoGPT, optimization analysis, training dynamics", "scoring": {"interpretability": 2, "understanding": 6, "safety": 2, "technicality": 8, "surprisal": 6}, "category": {"failure_mode_addressed": "non-applicable", "primary_focus": "other"}, "authors": ["Egor Shulgin", "Sultan AlRashed", "Francesco Orabona", "Peter Richtárik"]}, "usage": {"completion_tokens": 640, "prompt_tokens": 3435, "total_tokens": 4075, "completion_tokens_details": {"accepted_prediction_tokens": null, "audio_tokens": null, "reasoning_tokens": 439, "rejected_prediction_tokens": null, "image_tokens": 0}, "prompt_tokens_details": {"audio_tokens": 0, "cached_tokens": 3152}, "cost": 0.00061461, "is_byok": false, "cost_details": {"upstream_inference_cost": null, "upstream_inference_prompt_cost": 0.00029461, "upstream_inference_completions_cost": 0.00032}}, "model": "openai/gpt-oss-120b"}
{"timestamp": "2025-10-24T17:33:38.595744", "feed": "arxiv_cslg", "title": "SALT: Step-level Advantage Assignment for Long-horizon Agents via Trajectory Graph", "link": "https://papers.cool/arxiv/2510.20022", "analysis": {"summary": "The paper introduces SALT, a lightweight framework that assigns step‑level advantages to long‑horizon language agents by constructing a trajectory graph from multiple rollouts of the same prompt, enabling finer‑grained credit assignment based only on outcome rewards. SALT can be plugged into existing group‑based reinforcement‑learning methods such as GRPO without changing the rollout procedure, and experiments on WebShop, ALFWorld, and AppWorld show consistent performance gains.", "summary_cn": "本文提出 SALT 框架，通过为同一提示的多个轨迹构建图结构，基于最终奖励对长时程语言代理的每一步进行细粒度优势分配，实现更精确的信用分配。该方法可作为插件直接集成到如 GRPO 等基于组的强化学习算法中，实验在 WebShop、ALFWorld 与 AppWorld 上表明显著提升性能。", "keywords": "step-level advantage, trajectory graph, long-horizon language agents, group reinforcement learning, GRPO, credit assignment, WebShop, ALFWorld, AppWorld", "scoring": {"interpretability": 2, "understanding": 5, "safety": 2, "technicality": 7, "surprisal": 6}, "category": {"failure_mode_addressed": "non-applicable", "primary_focus": "robustness"}, "authors": ["Jiazheng Li", "Yawei Wang", "David Yan", "Yijun Tian", "Zhichao Xu", "Huan Song", "Panpan Xu", "Lin Lee Cheong"]}, "usage": {"completion_tokens": 896, "prompt_tokens": 3464, "total_tokens": 4360, "completion_tokens_details": {"accepted_prediction_tokens": null, "audio_tokens": null, "reasoning_tokens": 744, "rejected_prediction_tokens": null, "image_tokens": 0}, "prompt_tokens_details": {"audio_tokens": 0, "cached_tokens": 3152}, "cost": 0.00074696, "is_byok": false, "cost_details": {"upstream_inference_cost": null, "upstream_inference_prompt_cost": 0.00029896, "upstream_inference_completions_cost": 0.000448}}, "model": "openai/gpt-oss-120b"}
{"timestamp": "2025-10-24T17:33:38.616247", "feed": "arxiv_cslg", "title": "Revisiting Zeroth-Order Optimization: Minimum-Variance Two-Point Estimators and Directionally Aligned Perturbations", "link": "https://papers.cool/arxiv/2510.19975", "analysis": {"summary": "The paper studies two‑point zeroth‑order gradient estimators and determines the perturbation distribution that minimizes asymptotic variance as the stepsize approaches zero. It shows that optimal perturbations can be directionally aligned with the true gradient, proposes the Directionally Aligned Perturbation (DAP) scheme, and provides convergence analysis and empirical results demonstrating DAP’s advantage over fixed‑length perturbations under certain conditions.", "summary_cn": "本文研究了两点零阶梯度估计器，并找出在步长趋于零时使估计方差最小的扰动分布，发现最优扰动可以在方向上与真实梯度对齐。作者提出方向对齐扰动（DAP）方案，给出相应的收敛分析，并通过合成及实际任务实验表明 DAP 在特定条件下优于传统固定长度扰动方法。", "keywords": "zeroth-order optimization, two-point estimator, minimum-variance, directionally aligned perturbations, stochastic gradient descent, functional optimization, gradient estimation", "scoring": {"interpretability": 2, "understanding": 6, "safety": 3, "technicality": 7, "surprisal": 6}, "category": {"failure_mode_addressed": "non-applicable", "primary_focus": "other"}, "authors": ["Shaocong Ma", "Heng Huang"]}, "usage": {"completion_tokens": 794, "prompt_tokens": 3399, "total_tokens": 4193, "completion_tokens_details": {"accepted_prediction_tokens": null, "audio_tokens": null, "reasoning_tokens": 609, "rejected_prediction_tokens": null, "image_tokens": 0}, "prompt_tokens_details": {"audio_tokens": 0, "cached_tokens": 3152}, "cost": 0.00068621, "is_byok": false, "cost_details": {"upstream_inference_cost": null, "upstream_inference_prompt_cost": 0.00028921, "upstream_inference_completions_cost": 0.000397}}, "model": "openai/gpt-oss-120b"}
{"timestamp": "2025-10-24T17:33:38.698314", "feed": "arxiv_cslg", "title": "From Optimization to Prediction: Transformer-Based Path-Flow Estimation to the Traffic Assignment Problem", "link": "https://papers.cool/arxiv/2510.19889", "analysis": {"summary": "The paper proposes a Transformer-based deep neural network that directly predicts equilibrium path flows for the traffic assignment problem, bypassing traditional optimization methods that struggle with large-scale networks. By modeling path-level traffic distributions, the approach captures complex correlations among origin‑destination pairs, achieves orders‑of‑magnitude speedups, and adapts to changes in demand and network structure without recomputation. Experiments on synthetic and real networks demonstrate significant computational savings and improved prediction accuracy for multi‑class traffic scenarios.", "summary_cn": "本文提出一种基于 Transformer 的深度神经网络，直接预测交通分配问题中的均衡路径流，以规避传统在大规模网络上计算成本高的优化方法。通过对路径层面的流量分布建模，捕捉起点‑终点对之间的复杂关联，实现了数量级的加速，并在需求或网络结构变化时无需重新计算即可适应。实验证明在合成及真实网络（如 Sioux Falls、Eastern‑Massachusetts）上，该方法在多类交通场景下显著降低计算成本并提升预测精度。", "keywords": "traffic assignment, transformer, path flow prediction, equilibrium, deep learning, transportation planning, network optimization, multi-class traffic, fast what-if analysis", "scoring": {"interpretability": 2, "understanding": 5, "safety": 2, "technicality": 7, "surprisal": 6}, "category": {"failure_mode_addressed": "non-applicable", "primary_focus": "other"}, "authors": ["Mostafa Ameli", "Van Anh Le", "Sulthana Shams", "Alexander Skabardonis"]}, "usage": {"completion_tokens": 574, "prompt_tokens": 3424, "total_tokens": 3998, "completion_tokens_details": {"accepted_prediction_tokens": null, "audio_tokens": null, "reasoning_tokens": 268, "rejected_prediction_tokens": null, "image_tokens": 0}, "prompt_tokens_details": {"audio_tokens": 0, "cached_tokens": 3152}, "cost": 0.00057996, "is_byok": false, "cost_details": {"upstream_inference_cost": null, "upstream_inference_prompt_cost": 0.00029296, "upstream_inference_completions_cost": 0.000287}}, "model": "openai/gpt-oss-120b"}
{"timestamp": "2025-10-24T17:33:38.742268", "feed": "arxiv_cslg", "title": "An Integrated Approach to Neural Architecture Search for Deep Q-Networks", "link": "https://papers.cool/arxiv/2510.19872", "analysis": {"summary": "The paper introduces NAS-DQN, a deep reinforcement learning agent that incorporates a neural architecture search controller into the DQN training loop, allowing the network architecture to be dynamically reconfigured based on cumulative performance feedback. Experiments on a continuous control task show that NAS-DQN outperforms fixed-architecture baselines and random search in final performance, sample efficiency, and policy stability with minimal computational overhead. The results suggest that online architecture adaptation is essential for optimal sample efficiency in deep RL.", "summary_cn": "本文提出 NAS-DQN，一种在 DQN 训练过程中嵌入神经架构搜索控制器的深度强化学习代理，使网络结构能够根据累计性能反馈动态调整。针对连续控制任务的实验表明，NAS-DQN 在最终性能、样本效率和策略稳定性方面均优于固定架构基线和随机搜索，且计算开销几乎可以忽略不计。结果表明，在线架构适配是实现深度强化学习最佳样本效率的关键。", "keywords": "neural architecture search, deep Q-network, reinforcement learning, online architecture adaptation, sample efficiency, architecture controller", "scoring": {"interpretability": 2, "understanding": 6, "safety": 2, "technicality": 7, "surprisal": 7}, "category": {"failure_mode_addressed": "non-applicable", "primary_focus": "other"}, "authors": ["Iman Rahmani", "Saman Yazdannik", "Morteza Tayefi", "Jafar Roshanian"]}, "usage": {"completion_tokens": 565, "prompt_tokens": 3421, "total_tokens": 3986, "completion_tokens_details": {"accepted_prediction_tokens": null, "audio_tokens": null, "reasoning_tokens": 295, "rejected_prediction_tokens": null, "image_tokens": 0}, "prompt_tokens_details": {"audio_tokens": 0, "cached_tokens": 3152}, "cost": 0.00057501, "is_byok": false, "cost_details": {"upstream_inference_cost": null, "upstream_inference_prompt_cost": 0.00029251, "upstream_inference_completions_cost": 0.0002825}}, "model": "openai/gpt-oss-120b"}
{"timestamp": "2025-10-24T17:33:38.977873", "feed": "arxiv_cslg", "title": "Real Deep Research for AI, Robotics and Beyond", "link": "https://papers.cool/arxiv/2510.20809", "analysis": {"summary": "The paper proposes Real Deep Research (RDR), a generalizable pipeline for systematically analyzing any research area to identify emerging trends, uncover cross‑domain opportunities, and suggest concrete starting points for new inquiry, with a focus on AI and robotics. It details the construction of the RDR framework and presents extensive results across AI, robotics, and brief extensions to other scientific fields. The authors aim to help researchers stay up to date amidst the rapid growth of publications.", "summary_cn": "本文提出了 Real Deep Research（RDR）流水线，一种可通用的系统化分析任何研究领域的方法，用于识别新兴趋势、发掘跨领域机会并提供具体的研究起点，重点聚焦于 AI 与机器人领域。论文阐述了 RDR 框架的构建，并在 AI、机器人以及其他科学领域展示了大量分析结果。作者希望帮助研究者在论文激增的环境中保持前沿了解。", "keywords": "meta-research, trend detection, literature mining, AI robotics, foundation models, cross-domain analysis, research pipeline, emerging topics, scientific survey", "scoring": {"interpretability": 2, "understanding": 5, "safety": 2, "technicality": 6, "surprisal": 5}, "category": {"failure_mode_addressed": "non-applicable", "primary_focus": "other"}, "authors": ["Xueyan Zou", "Jianglong Ye", "Hao Zhang", "Xiaoyu Xiang", "Mingyu Ding", "Zhaojing Yang", "Yong Jae Lee", "Zhuowen Tu", "Sifei Liu", "Xiaolong Wang"]}, "usage": {"completion_tokens": 530, "prompt_tokens": 3369, "total_tokens": 3899, "completion_tokens_details": {"accepted_prediction_tokens": null, "audio_tokens": null, "reasoning_tokens": 251, "rejected_prediction_tokens": null, "image_tokens": 0}, "prompt_tokens_details": {"audio_tokens": 0, "cached_tokens": 3152}, "cost": 0.00054971, "is_byok": false, "cost_details": {"upstream_inference_cost": null, "upstream_inference_prompt_cost": 0.00028471, "upstream_inference_completions_cost": 0.000265}}, "model": "openai/gpt-oss-120b"}
{"timestamp": "2025-10-24T17:33:39.074177", "feed": "arxiv_cslg", "title": "FairGRPO: Fair Reinforcement Learning for Equitable Clinical Reasoning", "link": "https://papers.cool/arxiv/2510.19893", "analysis": {"summary": "The paper proposes FairGRPO, a hierarchical reinforcement learning algorithm that adaptively reweights advantages to promote equitable performance across latent demographic groups in clinical diagnosis tasks. By combining unsupervised clustering to discover demographic subpopulations with importance‑weighted policy updates, FairGRPO reduces predictive parity gaps by 27.2% while improving overall F1 score, and the authors release a fairness‑aware clinical VLLM (FairMedGemma-4B).", "summary_cn": "本文提出 FairGRPO，一种层次化强化学习方法，通过对优势进行自适应加权，以在临床诊断任务中实现不同潜在人口群体的公平学习。该方法利用无监督聚类自动发现人口子群，并在策略更新中加入加权机制，使预测公平性差距降低 27.2%，整体 F1 分数提升，并发布了具备公平性的临床大模型 FairMedGemma-4B。", "keywords": "fairness, reinforcement learning, clinical AI, group relative policy optimization, bias mitigation, multimodal diagnosis, demographic parity", "scoring": {"interpretability": 3, "understanding": 6, "safety": 7, "technicality": 7, "surprisal": 6}, "category": {"failure_mode_addressed": "misalignment", "primary_focus": "alignment"}, "authors": ["Shiqi Dai", "Wei Dai", "Jiaee Cheong", "Paul Pu Liang"]}, "usage": {"completion_tokens": 638, "prompt_tokens": 3473, "total_tokens": 4111, "completion_tokens_details": {"accepted_prediction_tokens": null, "audio_tokens": null, "reasoning_tokens": 433, "rejected_prediction_tokens": null, "image_tokens": 0}, "prompt_tokens_details": {"audio_tokens": 0, "cached_tokens": 3152}, "cost": 0.00061931, "is_byok": false, "cost_details": {"upstream_inference_cost": null, "upstream_inference_prompt_cost": 0.00030031, "upstream_inference_completions_cost": 0.000319}}, "model": "openai/gpt-oss-120b"}
{"timestamp": "2025-10-24T17:33:39.079454", "feed": "arxiv_cslg", "title": "Learning to Triage Taint Flows Reported by Dynamic Program Analysis in Node.js Packages", "link": "https://papers.cool/arxiv/2510.20739", "analysis": {"summary": "The paper studies how machine learning can prioritize vulnerability reports generated by dynamic program analysis tools for Node.js packages. It evaluates classical models, graph neural networks, large language models, and hybrid approaches on a benchmark of 1,883 packages, achieving up to 0.915 F1 and reducing manual review workload by filtering out the majority of benign reports. The best model can operate at high precision while still detecting over 99% of exploitable taint flows.", "summary_cn": "本文研究机器学习如何对 Node.js 包的动态程序分析工具产生的漏洞报告进行优先级排序。通过在 1,883 个包的基准上评估传统模型、图神经网络、大语言模型及其混合方式，最高 F1 达到 0.915，并能够在高精度下过滤掉大多数无害报告，从而显著降低人工审查负担。最佳模型在保持约 99% 可利用污点流检测率的同时，实现了约 66.9% 的良性包自动剔除。", "keywords": "vulnerability triage, taint analysis, Node.js, machine learning, graph neural network, large language model, dynamic program analysis, software security", "scoring": {"interpretability": 2, "understanding": 3, "safety": 3, "technicality": 7, "surprisal": 6}, "category": {"failure_mode_addressed": "-applicable", "primary_focus": "other"}, "authors": ["Ronghao Ni", "Aidan Z. H. Yang", "Min-Chien Hsu", "Nuno Sabino", "Limin Jia", "Ruben Martins", "Darion Cassel", "Kevin Cheang"]}, "usage": {"completion_tokens": 772, "prompt_tokens": 3470, "total_tokens": 4242, "completion_tokens_details": {"accepted_prediction_tokens": null, "audio_tokens": null, "reasoning_tokens": 508, "rejected_prediction_tokens": null, "image_tokens": 0}, "prompt_tokens_details": {"audio_tokens": 0, "cached_tokens": 3152}, "cost": 0.00068586, "is_byok": false, "cost_details": {"upstream_inference_cost": null, "upstream_inference_prompt_cost": 0.00029986, "upstream_inference_completions_cost": 0.000386}}, "model": "openai/gpt-oss-120b"}
{"timestamp": "2025-10-24T17:33:39.407262", "feed": "arxiv_cslg", "title": "Machine Learning-Based Localization Accuracy of RFID Sensor Networks via RSSI Decision Trees and CAD Modeling for Defense Applications", "link": "https://papers.cool/arxiv/2510.20019", "analysis": {"summary": "The paper presents a supervised learning simulation that uses realistic RSSI data and Decision Tree classification within a CAD‑modeled floor plan to localize RFID tags across twelve laboratory zones for defense logistics. Using a balanced subset of 5,000 observations from a dataset of ~980,000 reads, the model attains 34.2% overall accuracy and F1 scores above 0.40 for several zones, while struggling with rare classes, and introduces an adjacency‑aware confusion matrix for better interpretation of zone misclassifications. The study highlights the potential of RSSI‑based decision trees for zone‑level anomaly detection in defense contexts, noting that improved antenna placement and sensor fusion could boost performance in low‑coverage areas.", "summary_cn": "本文在 CAD 建模的防御设施平面图中，利用真实 RSSI 数据和决策树分类进行 RFID 标签的定位仿真，目标是对十二个实验室区域进行定位推断。使用约 980,000 条读取的平衡子样本（5,000 条）进行训练，模型整体准确率为 34.2%，多个区域的 F1 分数超过 0.40，但对稀有区域（如 LabZoneC）仍易误分类，并通过邻接感知混淆矩阵更好地解释相邻区域的错误。研究表明 RSSI‑基决策树可用于防御供应物流的区域异常检测，指出更佳的天线布置或多模态传感器融合可提升低覆盖区的分类性能。", "keywords": "RFID, localization, RSSI, decision tree, sensor networks, defense applications, CAD modeling, class imbalance, zone classification, anomaly detection", "scoring": {"interpretability": 4, "understanding": 5, "safety": 4, "technicality": 6, "surprisal": 3}, "category": {"failure_mode_addressed": "human-misuse", "primary_focus": "robustness"}, "authors": ["Curtis Lee Shull", "Merrick Green"]}, "usage": {"completion_tokens": 947, "prompt_tokens": 3507, "total_tokens": 4454, "completion_tokens_details": {"accepted_prediction_tokens": null, "audio_tokens": null, "reasoning_tokens": 610, "rejected_prediction_tokens": null, "image_tokens": 0}, "prompt_tokens_details": {"audio_tokens": 0, "cached_tokens": 3152}, "cost": 0.00077891, "is_byok": false, "cost_details": {"upstream_inference_cost": null, "upstream_inference_prompt_cost": 0.00030541, "upstream_inference_completions_cost": 0.0004735}}, "model": "openai/gpt-oss-120b"}
{"timestamp": "2025-10-24T17:33:39.599766", "feed": "arxiv_cslg", "title": "Strategic Costs of Perceived Bias in Fair Selection", "link": "https://papers.cool/arxiv/2510.20606", "analysis": {"summary": "The paper presents a game-theoretic model of meritocratic selection where candidates from different socioeconomic groups face differing perceived‑selection values, shaped by social context and AI‑driven guidance tools. Candidates choose effort strategically, trading off its cost against expected rewards, and the model yields a unique Nash equilibrium describing effort levels, representation, and welfare as functions of valuation disparities and institutional selectivity. The authors propose a cost‑sensitive optimization framework to adjust selectivity or perceived value, reducing disparity without sacrificing institutional objectives, highlighting a perception‑driven bias that can propagate through ostensibly fair selection mechanisms.", "summary_cn": "本文提出一个博弈论模型，研究在 meritocratic（择优）选拔体系中，不同社会经济群体因社会环境和 AI 驱动的职业/薪资指导工具而对选拔后价值的感知存在差异。候选人基于努力成本与预期回报进行战略性努力选择，模型给出唯一的纳什均衡，展示感知价值差异和机构选择度如何共同决定努力水平、群体代表性、社会福利以及机构效用。作者进一步提出一种成本敏感的优化框架，通过调整选择度或感知价值，实现在不牺牲机构目标的前提下降低不平等，揭示了感知驱动的偏见如何在表面公平的选拔过程中产生并放大。", "keywords": "fair selection, game theory perceived bias, socioeconomic disparity, strategic effort, AI-guided career advice, meritocracy, social welfare", "scoring": {"interpretability": 1, "understanding": 6, "safety": 4, "technicality": 7, "surprisal": 6}, "category": {"failure_mode_addressed": "societal-disruption", "primary_focus": "other"}, "authors": ["L. Elisa Celis", "Lingxiao Huang", "Milind Sohoni", "Nisheeth K. Vishnoi"]}, "usage": {"completion_tokens": 684, "prompt_tokens": 3448, "total_tokens": 4132, "completion_tokens_details": {"accepted_prediction_tokens": null, "audio_tokens": null, "reasoning_tokens": 307, "rejected_prediction_tokens": null, "image_tokens": 0}, "prompt_tokens_details": {"audio_tokens": 0, "cached_tokens": 3152}, "cost": 0.00063856, "is_byok": false, "cost_details": {"upstream_inference_cost": null, "upstream_inference_prompt_cost": 0.00029656, "upstream_inference_completions_cost": 0.000342}}, "model": "openai/gpt-oss-120b"}
{"timestamp": "2025-10-24T17:33:40.028213", "feed": "arxiv_cslg", "title": "Finding the Sweet Spot: Trading Quality, Cost, and Speed During Inference-Time LLM Reflection", "link": "https://papers.cool/arxiv/2510.20653", "analysis": {"summary": "The paper systematically compares self‑reflection and budget‑tuning techniques across mathematical reasoning and translation tasks for several large language models, analyzing trade‑offs among accuracy, cost, and latency and identifying domain‑dependent performance gains up to 220%. It explores how reflection depth and feedback quality affect outcomes, derives Pareto‑optimal frontiers, and validates the approach in a real‑world marketing localisation system.", "summary_cn": "本文系统性地比较了自我反思（self‑reflection）和预算调优（budget tuning）在数学推理和翻译任务中的表现，评估不同大语言模型在准确率、成本和延迟之间的权衡，并发现不同领域的性能提升可达 220%。研究还分析了反思深度和反馈质量的影响，绘制了 Pareto 最优前沿，并在实际的营销内容本地化系统中进行了验证。", "keywords": "self-reflection, budget tuning, inference optimization, LLM evaluation, trade-off analysis, Pareto frontier, mathematical reasoning, translation, downstream deployment, performance scaling", "scoring": {"interpretability": 2, "understanding": 7, "safety": 2, "technicality": 7, "surprisal": 7}, "category": {"failure_mode_addressed": "non-applicable", "primary_focus": "other"}, "authors": ["Jack Butler", "Nikita Kozodoi", "Zainab Afolabi", "Brian Tyacke", "Gaiar Baimuratov"]}, "usage": {"completion_tokens": 743, "prompt_tokens": 3453, "total_tokens": 4196, "completion_tokens_details": {"accepted_prediction_tokens": null, "audio_tokens": null, "reasoning_tokens": 521, "rejected_prediction_tokens": null, "image_tokens": 0}, "prompt_tokens_details": {"audio_tokens": 0, "cached_tokens": 3152}, "cost": 0.00066881, "is_byok": false, "cost_details": {"upstream_inference_cost": null, "upstream_inference_prompt_cost": 0.00029731, "upstream_inference_completions_cost": 0.0003715}}, "model": "openai/gpt-oss-120b"}
{"timestamp": "2025-10-24T17:33:40.374448", "feed": "arxiv_cslg", "title": "FINDER: Feature Inference on Noisy Datasets using Eigenspace Residuals", "link": "https://papers.cool/arxiv/2510.19917", "analysis": {"summary": "The paper introduces FINDER, a framework that treats datasets as realizations of random fields and leverages the Karhunen‑Loève expansion to extract stochastic features for classification in low‑signal‑to‑noise regimes. By analyzing the eigenspace residuals of class‑specific operators, FINDER separates classes in the spectral domain and demonstrates state‑of‑the‑art performance on Alzheimer's disease staging and deforestation detection. Limitations, expected outperforming conditions, and failure modes are also discussed.", "summary_cn": "本文提出 FINDER 框架，将数据集视为随机场的实现，通过 Karhunen‑Loève 展开提取随机特征，并利用特征空间残差的特征值分解在噪声较大的环境中进行分类。该方法在阿尔茨海默病阶段划分和森林砍伐遥感检测两大科学任务上取得了领先性能，并讨论了适用条件、局限性以及潜在失效模式。", "keywords": "feature inference, noisy datasets, eigen decomposition, Karhunen-Loève expansion, stochastic features, classification, robustness, medical imaging, remote sensing", "scoring": {"interpretability": 3, "understanding": 5, "safety": 4, "technicality": 7, "surprisal": 6}, "category": {"failure_mode_addressed": "non-applicable", "primary_focus": "robustness"}, "authors": ["Trajan Murphy", "Akshunna S. Dogra", "Hanfeng Gu", "Caleb Meredith", "Mark Kon", "Julio Enrique Castrillion-Candas"]}, "usage": {"completion_tokens": 759, "prompt_tokens": 3443, "total_tokens": 4202, "completion_tokens_details": {"accepted_prediction_tokens": null, "audio_tokens": null, "reasoning_tokens": 546, "rejected_prediction_tokens": null, "image_tokens": 0}, "prompt_tokens_details": {"audio_tokens": 0, "cached_tokens": 3152}, "cost": 0.00067531, "is_byok": false, "cost_details": {"upstream_inference_cost": null, "upstream_inference_prompt_cost": 0.00029581, "upstream_inference_completions_cost": 0.0003795}}, "model": "openai/gpt-oss-120b"}
{"timestamp": "2025-10-24T17:33:40.698001", "feed": "arxiv_cslg", "title": "Mitigating Privacy-Utility Trade-off in Decentralized Federated Learning via $f$-Differential Privacy", "link": "https://papers.cool/arxiv/2510.19934", "analysis": {"summary": "The paper proposes two novel f-differential privacy accounting methods for decentralized federated learning: Pairwise Network f-DP, which measures privacy leakage between user pairs in a random-walk communication graph, and Secret-based f-Local DP, which enables structured noise injection using shared secrets. By leveraging f-DP theory and Markov chain concentration, the framework captures privacy amplification from sparse communication and local updates, yielding tighter (ε,δ) bounds and better utility than Rényi DP approaches in experiments.", "summary_cn": "本文提出了两种针对去中心化联邦学习的 f-差分隐私 (f-DP) 计量方法：配对网络 f-DP (PN-f-DP)，用于在随机游走通信图中量化用户对之间的隐私泄漏；以及基于秘密的 f-本地 DP (Sec-f-LDP)，通过共享秘密实现结构化噪声注入。利用 f-DP 理论和马尔可夫链浓缩技术，框架捕捉稀疏通信和本地迭代带来的隐私放大效应，在实验中相较于 Rényi DP 方法实现了更紧的 (ε,δ) 上界和更高的效用。", "keywords": "federated learning, decentralized federated learning, differential privacy, f-differential privacy, privacy accounting, pairwise network f-DP, secret-based f-LDP, privacy-utility tradeoff", "scoring": {"interpretability": 2, "understanding": 6, "safety": 7, "technicality": 8, "surprisal": 6}, "category": {"failure_mode_addressed": "other", "primary_focus": "other"}, "authors": ["Xiang Li", "Buxin Su", "Chendi Wang", "Qi Long", "Weijie J. Su"]}, "usage": {"completion_tokens": 836, "prompt_tokens": 3443, "total_tokens": 4279, "completion_tokens_details": {"accepted_prediction_tokens": null, "audio_tokens": null, "reasoning_tokens": 536, "rejected_prediction_tokens": null, "image_tokens": 0}, "prompt_tokens_details": {"audio_tokens": 0, "cached_tokens": 3152}, "cost": 0.00071381, "is_byok": false, "cost_details": {"upstream_inference_cost": null, "upstream_inference_prompt_cost": 0.00029581, "upstream_inference_completions_cost": 0.000418}}, "model": "openai/gpt-oss-120b"}
{"timestamp": "2025-10-24T17:33:40.901819", "feed": "arxiv_cslg", "title": "Bayesian Inference of Primordial Magnetic Field Parameters from CMB with Spherical Graph Neural Networks", "link": "https://papers.cool/arxiv/2510.20795", "analysis": {"summary": "The paper introduces a Bayesian graph‑neural‑network framework that combines DeepSphere, a spherical convolutional architecture, with Bayesian neural networks to infer primordial magnetic field parameters directly from simulated CMB maps. By modeling both aleatoric and epistemic uncertainties, the method achieves high R² scores (>0.89) and provides well‑calibrated posterior estimates for cosmological inference.", "summary_cn": "本文提出将 DeepSphere 球面图卷积网络与贝叶斯神经网络相结合的框架，用于直接从模拟的 CMB 图像中推断原始磁场参数，并对预测的不确定性进行建模。实验显示该方法在磁场参数估计上实现了超过 0.89 的 R² 分数，并提供了可靠的后验不确定性估计。", "keywords": "primordial magnetic field, cosmic microwave background, spherical graph neural network, DeepSphere, Bayesian neural network, uncertainty quantification, cosmological parameter inference", "scoring": {"interpretability": 2, "understanding": 3, "safety": 1, "technicality": 8, "surprisal": 6}, "category": {"failure_mode_addressed": "non-applicable", "primary_focus": "other"}, "authors": ["Juan Alejandro Pinto Castro", "Héctor J. Hortúa", "Jorge Enrique García-Farieta", "Roger Anderson Hurtado"]}, "usage": {"completion_tokens": 612, "prompt_tokens": 3430, "total_tokens": 4042, "completion_tokens_details": {"accepted_prediction_tokens": null, "audio_tokens": null, "reasoning_tokens": 377, "rejected_prediction_tokens": null, "image_tokens": 0}, "prompt_tokens_details": {"audio_tokens": 0, "cached_tokens": 3152}, "cost": 0.00059986, "is_byok": false, "cost_details": {"upstream_inference_cost": null, "upstream_inference_prompt_cost": 0.00029386, "upstream_inference_completions_cost": 0.000306}}, "model": "openai/gpt-oss-120b"}
{"timestamp": "2025-10-24T17:33:40.943808", "feed": "arxiv_cslg", "title": "AlphaFlow: Understanding and Improving MeanFlow Models", "link": "https://papers.cool/arxiv/2510.20771", "analysis": {"summary": "The paper analyzes the MeanFlow objective, showing it decomposes into trajectory flow matching and trajectory consistency, which are negatively correlated and cause optimization conflicts. Based on this insight, the authors propose α-Flow, a unified family of objectives with a curriculum that anneals from flow matching to MeanFlow, leading to faster convergence and state-of-the-art FID scores on ImageNet when trained with DiT backbones.", "summary_cn": "本文分析了 MeanFlow 目标，发现其可分解为轨迹流匹配和轨迹一致性两部分，这两者呈强负相关，导致优化冲突并收敛缓慢。基于此洞察，作者提出 α-Flow——一种统一的目标族，并采用从轨迹流匹配平滑退火至 MeanFlow 的 curriculum 策略，从而消除冲突、加速收敛，在使用 DiT 骨干的 ImageNet 生成任务上实现了新的 FID 最佳成绩。", "keywords": "MeanFlow, α-Flow, trajectory flow matching, generative modeling, curriculum learning, DiT, FID, diffusion models", "scoring": {"interpretability": 3, "understanding": 6, "safety": 2, "technicality": 7, "surprisal": 7}, "category": {"failure_mode_addressed": "non-applicable", "primary_focus": "other"}, "authors": ["Huijie Zhang", "Aliaksandr Siarohin", "Willi Menapace", "Michael Vasilkovsky", "Sergey Tulyakov", "Qing Qu", "Ivan Skorokhodov"]}, "usage": {"completion_tokens": 630, "prompt_tokens": 3420, "total_tokens": 4050, "completion_tokens_details": {"accepted_prediction_tokens": null, "audio_tokens": null, "reasoning_tokens": 385, "rejected_prediction_tokens": null, "image_tokens": 0}, "prompt_tokens_details": {"audio_tokens": 0, "cached_tokens": 3152}, "cost": 0.00060736, "is_byok": false, "cost_details": {"upstream_inference_cost": null, "upstream_inference_prompt_cost": 0.00029236, "upstream_inference_completions_cost": 0.000315}}, "model": "openai/gpt-oss-120b"}
{"timestamp": "2025-10-24T17:33:40.948506", "feed": "arxiv_cslg", "title": "Enhancing Diagnostic Accuracy for Urinary Tract Disease through Explainable SHAP-Guided Feature Selection and Classification", "link": "https://papers.cool/arxiv/2510.19896", "analysis": {"summary": "The paper proposes a diagnostic pipeline for urinary tract diseases, especially bladder cancer, that uses SHAP-based feature selection to identify the most informative clinical variables and then trains XGBoost, LightGBM, and CatBoost classifiers with hyperparameter tuning via Optuna and class balancing with SMOTE. The SHAP-guided selection improves model transparency while maintaining or enhancing performance metrics such as balanced accuracy, precision, and specificity, demonstrating the utility of explainability techniques in clinical decision support.", "summary_cn": "本文提出了一套针对泌尿道疾病（尤其是膀胱癌）的诊断流程，利用 SHAP（Shapley Additive exPlanations）进行特征选择以挑选最具信息量的临床变量，随后使用 XGBoost、LightGBM 和 CatBoost 分类器，并通过 Optuna 进行超参数调优及 SMOTE 进行类别平衡。SHAP 引导的特征选择在提升模型透明度的同时，保持或提升了平衡准确率、精确率和特异性等性能指标，展示了可解释性技术在临床决策支持系统中的有效性。", "keywords": "urinary tract disease, bladder cancer, SHAP, feature selection, interpretability, XGBoost, LightGBM, CatBoost, Optuna, SMOTE", "scoring": {"interpretability": 6, "understanding": 5, "safety": 3, "technicality": 6, "surprisal": 5}, "category": {"failure_mode_addressed": "non-applicable", "primary_focus": "interpretability"}, "authors": ["Filipe Ferreira de Oliveira", "Matheus Becali Rocha", "Renato A. Krohling"]}, "usage": {"completion_tokens": 790, "prompt_tokens": 3385, "total_tokens": 4175, "completion_tokens_details": {"accepted_prediction_tokens": null, "audio_tokens": null, "reasoning_tokens": 483, "rejected_prediction_tokens": null, "image_tokens": 0}, "prompt_tokens_details": {"audio_tokens": 0, "cached_tokens": 3152}, "cost": 0.00068211, "is_byok": false, "cost_details": {"upstream_inference_cost": null, "upstream_inference_prompt_cost": 0.00028711, "upstream_inference_completions_cost": 0.000395}}, "model": "openai/gpt-oss-120b"}
{"timestamp": "2025-10-24T17:33:41.503262", "feed": "arxiv_cslg", "title": "Blur2seq: Blind Deblurring and Camera Trajectory Estimation from a Single Camera Motion-blurred Image", "link": "https://papers.cool/arxiv/2510.20539", "analysis": {"summary": "The paper introduces Blur2Seq, a deep learning framework that jointly restores a sharp image and estimates the underlying 3D camera motion trajectory from a single motion-blurred photograph. By embedding a differentiable Projective Motion Blur Model into the network, it predicts a full rotation trajectory that guides a model-based deblurring network, and the estimated trajectory can be used to reconstruct the sequence of sharp frames that generated the blur, with post‑inference refinement via a reblur loss. Experiments demonstrate state‑of‑the‑art performance on synthetic and real datasets, especially under severe or spatially variant blur where conventional end‑to‑end deblurring fails.", "summary_cn": "本文提出 Blur2Seq，一个深度学习框架，可从单张摄像机运动模糊图像中同时恢复清晰图像并估计其 3D 相机运动轨迹。通过将可微分的投影运动模糊模型 (PMBM) 融入网络，模型预测完整的旋转轨迹并用于指导基于模型的去模糊网络，估计的轨迹还能重建产生模糊图像的连续清晰帧，并通过再模糊损进行后推优化。实验表明，在合成和真实数据集上，尤其是严重或空间变化模糊情况下，方法显著优于传统端到端去模糊方法。", "keywords": "blind deblurring, camera motion trajectory estimation, motion blur model, differentiable blur module, deep learning, image restoration, 3D rotation trajectory, interpretability, reblur loss, sequential sharp image reconstruction", "scoring": {"interpretability": 7, "understanding": 7, "safety": 2, "technicality": 7, "surprisal": 6}, "category": {"failure_mode_addressed": "non-applicable", "primary_focus": "interpretability"}, "authors": ["Guillermo Carbajal", "Andrés Almansa", "Pablo Musé"]}, "usage": {"completion_tokens": 819, "prompt_tokens": 3426, "total_tokens": 4245, "completion_tokens_details": {"accepted_prediction_tokens": null, "audio_tokens": null, "reasoning_tokens": 490, "rejected_prediction_tokens": null, "image_tokens": 0}, "prompt_tokens_details": {"audio_tokens": 0, "cached_tokens": 3152}, "cost": 0.00070276, "is_byok": false, "cost_details": {"upstream_inference_cost": null, "upstream_inference_prompt_cost": 0.00029326, "upstream_inference_completions_cost": 0.0004095}}, "model": "openai/gpt-oss-120b"}
{"timestamp": "2025-10-24T17:33:41.509478", "feed": "arxiv_cslg", "title": "Neural Reasoning for Robust Instance Retrieval in $\\mathcal{SHOIQ}$", "link": "https://papers.cool/arxiv/2510.20457", "analysis": {"summary": "The paper introduces EBR, a neural reasoner that approximates symbolic reasoning in the expressive description logic SHOIQ by learning embeddings for atomic concepts and existential restrictions. EBR can retrieve instances for any complex concept without invoking a traditional reasoner, and experiments show it remains robust to missing or erroneous data where conventional reasoners fail. This work advances neuro‑symbolic concept learning toward deployment on real‑world, noisy knowledge bases.", "summary_cn": "本文提出了 EBR 神经推理器，通过对原子概念和存在限制学习嵌入，实现对表达性描述逻辑 SHOIQ 中任意概念的实例检索，而无需使用传统符号推理器。实验表明，在数据缺失或错误情况下，EBR 能保持稳健，相较于现有推理器表现更佳。该工作推动了神经符号概念学习在真实、噪声知识库中的应用。", "keywords": "neural reasoner, description logic, SHOIQ, instance retrieval, embeddings, robustness, neuro-symbolic, concept learning", "scoring": {"interpretability": 5, "understanding": 7, "safety": 3, "technicality": 8, "surprisal": 7}, "category": {"failure_mode_addressed": "other", "primary_focus": "robustness"}, "authors": ["Louis Mozart Kamdem Teyou", "Luke Friedrichs", "N'Dah Jean Kouagou", "Caglar Demir", "Yasir Mahmood", "Stefan Heindorf", "Axel-Cyrille Ngonga Ngomo"]}, "usage": {"completion_tokens": 677, "prompt_tokens": 3367, "total_tokens": 4044, "completion_tokens_details": {"accepted_prediction_tokens": null, "audio_tokens": null, "reasoning_tokens": 436, "rejected_prediction_tokens": null, "image_tokens": 0}, "prompt_tokens_details": {"audio_tokens": 0, "cached_tokens": 3152}, "cost": 0.00062291, "is_byok": false, "cost_details": {"upstream_inference_cost": null, "upstream_inference_prompt_cost": 0.00028441, "upstream_inference_completions_cost": 0.0003385}}, "model": "openai/gpt-oss-120b"}
{"timestamp": "2025-10-24T17:33:41.691799", "feed": "arxiv_cslg", "title": "A Coherence-Based Measure of AGI", "link": "https://papers.cool/arxiv/2510.20784", "analysis": {"summary": "The paper introduces a coherence‑based AGI metric that integrates generalized means over a range of compensability exponents, producing an area‑under‑the‑curve (AUC) score that penalizes imbalanced domain competence. This formulation addresses the limitation of arithmetic‑mean definitions that allow strong performance in some cognitive domains to mask weaknesses in others, and it is applied to CHC‑based scores of GPT‑4 and GPT‑5, showing that both remain far from truly general intelligence despite high arithmetic scores.", "summary_cn": "本文提出了一种基于一致性的 AGI 衡量方法，通过对不同补偿指数下的广义均值进行积分，计算得到的面积（AUC）能够惩罚在各认知域之间不平衡的能力。该方法克服了仅使用算术平均导致的“强项掩盖弱项”问题，并将其应用于 GPT‑4 和 GPT‑5 的 CHC 领域得分，显示出即使算术分数较高，两者仍距离真正的通用智能有很大差距。", "keywords": "AGI measurement, coherence, generalized mean, compensability, CHC model, AI evaluation, robustness", "scoring": {"interpretability": 3, "understanding": 6, "safety": 4, "technicality": 7, "surprisal": 6}, "category": {"failure_mode_addressed": "non-applicable", "primary_focus": "other"}, "authors": ["Fares Fourati"]}, "usage": {"completion_tokens": 659, "prompt_tokens": 3453, "total_tokens": 4112, "completion_tokens_details": {"accepted_prediction_tokens": null, "audio_tokens": null, "reasoning_tokens": 385, "rejected_prediction_tokens": null, "image_tokens": 0}, "prompt_tokens_details": {"audio_tokens": 0, "cached_tokens": 3152}, "cost": 0.00062681, "is_byok": false, "cost_details": {"upstream_inference_cost": null, "upstream_inference_prompt_cost": 0.00029731, "upstream_inference_completions_cost": 0.0003295}}, "model": "openai/gpt-oss-120b"}
{"timestamp": "2025-10-24T17:33:41.968994", "feed": "arxiv_cslg", "title": "From Large to Small: Transferring CUDA Optimization Expertise via Reasoning Graph", "link": "https://papers.cool/arxiv/2510.19873", "analysis": {"summary": "The paper introduces ReGraphT, a training‑free retrieval‑augmented generation framework that organizes CUDA optimization steps into a structured reasoning graph and employs Monte Carlo Graph Search to transfer LLM‑level reasoning to small language models. By leveraging this graph‑based approach, ReGraphT enables compact coder models to achieve near‑LLM performance on a CUDA‑specific benchmark, delivering an average 2.33× speedup while preserving privacy and reducing computational overhead.", "summary_cn": "本文提出 ReGraphT——一种无需微调的检索增强生成框架，将 CUDA 优化步骤组织为结构化推理图，并使用蒙特卡罗图搜索将大语言模型的推理能力转移至小语言模型。该方法使得轻量级编码模型在 CUDA 基准测试中实现接近大模型的性能，平均提升 2.33 倍，同时保持隐私并降低计算开销。", "keywords": "CUDA optimization, reasoning graph, retrieval-augmented generation, small language models, Monte Carlo Graph Search, code generation, performance acceleration", "scoring": {"interpretability": 2, "understanding": 5, "safety": 2, "technicality": 7, "surprisal": 6}, "category": {"failure_mode_addressed": "non-applicable", "primary_focus": "other"}, "authors": ["Junfeng Gong", "Zhiyi Wei", "Junying Chen", "Cheng Liu", "Huawei Li"]}, "usage": {"completion_tokens": 793, "prompt_tokens": 3523, "total_tokens": 4316, "completion_tokens_details": {"accepted_prediction_tokens": null, "audio_tokens": null, "reasoning_tokens": 603, "rejected_prediction_tokens": null, "image_tokens": 0}, "prompt_tokens_details": {"audio_tokens": 0, "cached_tokens": 3152}, "cost": 0.00070431, "is_byok": false, "cost_details": {"upstream_inference_cost": null, "upstream_inference_prompt_cost": 0.00030781, "upstream_inference_completions_cost": 0.0003965}}, "model": "openai/gpt-oss-120b"}
{"timestamp": "2025-10-24T17:33:42.086169", "feed": "arxiv_cslg", "title": "Video Prediction of Dynamic Physical Simulations With Pixel-Space Spatiotemporal Transformers", "link": "https://papers.cool/arxiv/2510.20807", "analysis": {"summary": "The paper introduces a pure transformer model for autoregressive video prediction of physical simulations using continuous pixel-space representations. By comparing various spatiotemporal self‑attention layouts, the approach extends accurate prediction horizons by up to 50% compared to latent‑space methods while maintaining comparable video quality. Interpretability probes reveal network regions that encode information useful for estimating PDE simulation parameters, even for out‑of‑distribution settings.", "summary_cn": "本文提出了一种纯 Transformer 模型，用于基于连续像素空间的物理模拟视频的自回归预测。通过比较不同的时空自注意力布局，该方法在保持视频质量的同时，将物理上准确的预测时间延长了约 50%。解释性实验显示网络的特定区域能够编码用于估计 PDE 模拟参数的信息，且在分布外参数上也具备泛化能力。", "keywords": "video prediction, spatiotemporal transformer, physical simulation, autoregressive, pixel-space, PDE parameter estimation, interpretability, attention", "scoring": {"interpretability": 6, "understanding": 7, "safety": 3, "technicality": 7, "surprisal": 6}, "category": {"failure_mode_addressed": "non-applicable", "primary_focus": "other"}, "authors": ["Dean L Slack", "G Thomas Hudson", "Thomas Winterbottom", "Noura Al Moubayed"]}, "usage": {"completion_tokens": 733, "prompt_tokens": 3442, "total_tokens": 4175, "completion_tokens_details": {"accepted_prediction_tokens": null, "audio_tokens": null, "reasoning_tokens": 596, "rejected_prediction_tokens": null, "image_tokens": 0}, "prompt_tokens_details": {"audio_tokens": 0, "cached_tokens": 3152}, "cost": 0.00066216, "is_byok": false, "cost_details": {"upstream_inference_cost": null, "upstream_inference_prompt_cost": 0.00029566, "upstream_inference_completions_cost": 0.0003665}}, "model": "openai/gpt-oss-120b"}
{"timestamp": "2025-10-24T17:33:42.227810", "feed": "arxiv_cslg", "title": "The Reality Gap in Robotics: Challenges, Solutions, and Best Practices", "link": "https://papers.cool/arxiv/2510.20808", "analysis": {"summary": "The paper surveys the reality gap in robotics, reviewing causes of discrepancies between simulation and real-world environments and summarizing techniques such as domain randomization, real-to-sim transfer, abstraction, and co‑training that aim to close the gap. It also discusses evaluation metrics and best practices for sim‑to‑real transfer across locomotion, navigation, and manipulation tasks.", "summary_cn": "本文综述了机器人领域的现实差距（reality gap），阐述仿真与真实环境之间的偏差来源，并总结了领域随机化、真实到仿真迁移、状态与动作抽象以及仿真‑真实协同训练等缩小差距的方法。还讨论了评估指标和在行走、导航、操作等任务中的最佳实践。", "keywords": "reality gap, sim-to-real transfer, domain randomization, robotics simulation, transfer learning, locomotion, manipulation, navigation, abstraction, co-training", "scoring": {"interpretability": 2, "understanding": 6, "safety": 3, "technicality": 7, "surprisal": 5}, "category": {"failure_mode_addressed": "non-applicable", "primary_focus": "robustness"}, "authors": ["Elie Aljalbout", "Jiaxu Xing", "Angel Romero", "Iretiayo Akinola", "Caelan Reed Garrett", "Eric Heiden", "Abhishek Gupta", "Tucker Hermans", "Yashraj Narang", "Dieter Fox", "Davide Scaramuzza", "Fabio Ramos"]}, "usage": {"completion_tokens": 753, "prompt_tokens": 3411, "total_tokens": 4164, "completion_tokens_details": {"accepted_prediction_tokens": null, "audio_tokens": null, "reasoning_tokens": 575, "rejected_prediction_tokens": null, "image_tokens": 0}, "prompt_tokens_details": {"audio_tokens": 0, "cached_tokens": 3152}, "cost": 0.00066751, "is_byok": false, "cost_details": {"upstream_inference_cost": null, "upstream_inference_prompt_cost": 0.00029101, "upstream_inference_completions_cost": 0.0003765}}, "model": "openai/gpt-oss-120b"}
{"timestamp": "2025-10-24T17:33:42.422781", "feed": "arxiv_cslg", "title": "Diffusion Autoencoders with Perceivers for Long, Irregular and Multimodal Astronomical Sequences", "link": "https://papers.cool/arxiv/2510.20595", "analysis": {"summary": "The paper introduces Diffusion Autoencoders with Perceivers (daep), a self-supervised architecture that tokenizes heterogeneous astronomical measurements, encodes them with a Perceiver encoder, and reconstructs them via a Perceiver‑IO diffusion decoder. Benchmarked against VAE and a Perceiver‑based masked autoencoder (maep) on various spectroscopic and photometric datasets, daep achieves lower reconstruction error, more discriminative latent representations, and better preservation of fine‑scale structure.", "summary_cn": "本文提出了 Diffusion Autoencoders with Perceivers (daep)，一种自监督架构，能够对异构的天文测量进行标记化，使用 Perceiver 编码器压缩后，再通过 Perceiver‑IO diffusion 解码器进行重构。在多个光谱和光度数据集上，与 VAE 和 Perceiver‑based 掩码自编码器 (maep) 对比，daep 显著降低了重构误差，生成了更具区分性的潜在空间，并更好地保留了细粒度结构。", "keywords": "diffusion autoencoder, perceiver, irregular sequences, multimodal representation, self-supervised learning, astronomical data, latent space, masked autoencoder", "scoring": {"interpretability": 2, "understanding": 5, "safety": 1, "technicality": 8, "surprisal": 6}, "category": {"failure_mode_addressed": "non-applicable", "primary_focus": "other"}, "authors": ["Yunyi Shen", "Alexander Gagliano"]}, "usage": {"completion_tokens": 597, "prompt_tokens": 3420, "total_tokens": 4017, "completion_tokens_details": {"accepted_prediction_tokens": null, "audio_tokens": null, "reasoning_tokens": 304, "rejected_prediction_tokens": null, "image_tokens": 0}, "prompt_tokens_details": {"audio_tokens": 0, "cached_tokens": 3152}, "cost": 0.00059086, "is_byok": false, "cost_details": {"upstream_inference_cost": null, "upstream_inference_prompt_cost": 0.00029236, "upstream_inference_completions_cost": 0.0002985}}, "model": "openai/gpt-oss-120b"}
{"timestamp": "2025-10-24T17:33:42.455321", "feed": "arxiv_cslg", "title": "VAMOS: A Hierarchical Vision-Language-Action Model for Capability-Modulated and Steerable Navigation", "link": "https://papers.cool/arxiv/2510.20818", "analysis": {"summary": "VAMOS introduces a hierarchical Vision-Language-Action system that separates high-level semantic planning from low-level embodiment grounding via a generalist planner and a specialist affordance model, enabling capability-modulated navigation across diverse environments. Real-world experiments demonstrate higher success rates, cross-embodiment portability between legged and wheeled robots, and steerability through natural language, with the specialist model crucial for rejecting physically infeasible plans. The approach highlights the benefits of modular design for robust and adaptable robot navigation.", "summary_cn": "VAMOS 提出了一种层次化的视觉-语言-动作模型（Vision-Language-Action），通过通用规划器（high-level planner）和专用可行性模型（affordance model）将语义规划与实体约束分离，实现了能力调制的导航。实验证明该体系在室内和复杂户外环境中提升了成功率，并能在腿式机器人和轮式机器人之间跨实体迁移，同时可通过自然语言进行指令调节。专用模型负责评估并剔除物理上不可行的路径，从而显著提升单机器人可靠性。", "keywords": "hierarchical navigation, vision-language-action, affordance model, capability-modulated navigation, cross-embodiment, language steering, robot navigation, embodied AI", "scoring": {"interpretability": 4, "understanding": 6, "safety": 6, "technicality": 7, "surprisal": 6}, "category": {"failure_mode_addressed": "other", "primary_focus": "control"}, "authors": ["Mateo Guaman Castro", "Sidharth Rajagopal", "Daniel Gorbatov", "Matt Schmittle", "Rohan Baijal", "Octi Zhang", "Rosario Scalise", "Sidharth Talia", "Emma Romig", "Celso de Melo", "Byron Boots", "Abhishek Gupta"]}, "usage": {"completion_tokens": 767, "prompt_tokens": 3462, "total_tokens": 4229, "completion_tokens_details": {"accepted_prediction_tokens": null, "audio_tokens": null, "reasoning_tokens": 536, "rejected_prediction_tokens": null, "image_tokens": 0}, "prompt_tokens_details": {"audio_tokens": 0, "cached_tokens": 3152}, "cost": 0.00068216, "is_byok": false, "cost_details": {"upstream_inference_cost": null, "upstream_inference_prompt_cost": 0.00029866, "upstream_inference_completions_cost": 0.0003835}}, "model": "openai/gpt-oss-120b"}
{"timestamp": "2025-10-24T17:33:42.502902", "feed": "arxiv_cslg", "title": "Black Box Absorption: LLMs Undermining Innovative Ideas", "link": "https://papers.cool/arxiv/2510.20612", "analysis": {"summary": "The paper defines \"Black Box Absorption\" as the risk that opaque LLM platforms can internalize and repurpose novel ideas contributed by users, creating informational and structural asymmetries that threaten innovation ecosystems. It formalizes the concept with \"idea units\" and \"idea safety\" standards, analyses how absorption occurs, and proposes a governance and engineering agenda to keep creator contributions traceable, controllable, and equitable.", "summary_cn": "本文提出“黑箱吸收”风险，即不透明的大语言模型平台可能内部化并重新利用用户贡献的创新概念，导致创作者与平台运营方之间的信息和结构不对称，危及创新经济的可持续性。文中通过“idea unit”（想法单元）和“idea safety”（想法安全）两大概念进行形式化描述，分析吸收机制，并提出治理与工程议程，以确保创作者的贡献可追溯、可控制且公平。", "keywords": "black box absorption, large language models, idea safety, governance, AI safety, intellectual property, model leakage, innovation economics", "scoring": {"interpretability": 2, "understanding": 6, "safety": 7, "technicality": 5, "surprisal": 7}, "category": {"failure_mode_addressed": "societal-disruption", "primary_focus": "control"}, "authors": ["Wenjun Cao"]}, "usage": {"completion_tokens": 603, "prompt_tokens": 3379, "total_tokens": 3982, "completion_tokens_details": {"accepted_prediction_tokens": null, "audio_tokens": null, "reasoning_tokens": 324, "rejected_prediction_tokens": null, "image_tokens": 0}, "prompt_tokens_details": {"audio_tokens": 0, "cached_tokens": 3152}, "cost": 0.00058771, "is_byok": false, "cost_details": {"upstream_inference_cost": null, "upstream_inference_prompt_cost": 0.00028621, "upstream_inference_completions_cost": 0.0003015}}, "model": "openai/gpt-oss-120b"}
{"timestamp": "2025-10-24T17:33:42.577127", "feed": "arxiv_cslg", "title": "Adversary-Aware Private Inference over Wireless Channels", "link": "https://papers.cool/arxiv/2510.20518", "analysis": {"summary": "The paper introduces a novel adversary-aware framework for private inference over wireless channels, where edge devices transform extracted features before transmitting them to a remote model server to mitigate privacy risks from feature reconstruction attacks. It discusses the limitations of conventional differential privacy for protecting individual features and proposes transformation mechanisms tailored to wireless communication constraints. Experimental results demonstrate reduced privacy leakage while maintaining inference accuracy in typical vision and perception tasks.", "summary_cn": "本文提出了一种针对无线信道的对手感知私密推理框架，边缘设备在将提取的特征发送至远程模型服务器之前进行转化，以降低特征被对手重构的隐私风险。文章指出传统差分隐私在保护单个特征方面的局限，并提出了适用于无线通信约束的特征转化机制。实验表明，在保持视觉和感知任务推理精度的同时，显著降低了隐私泄漏。", "keywords": "private inference, wireless channels, adversary-aware, feature transformation, differential privacy, edge AI, privacy-preserving, secure communication, AI safety, privacy leakage", "scoring": {"interpretability": 2, "understanding": 5, "safety": 7, "technicality": 6, "surprisal": 5}, "category": {"failure_mode_addressed": "human-misuse", "primary_focus": "other"}, "authors": ["Mohamed Seif", "Malcolm Egan", "Andrea J. Goldsmith", "H. Vincent Poor"]}, "usage": {"completion_tokens": 603, "prompt_tokens": 3356, "total_tokens": 3959, "completion_tokens_details": {"accepted_prediction_tokens": null, "audio_tokens": null, "reasoning_tokens": 335, "rejected_prediction_tokens": null, "image_tokens": 0}, "prompt_tokens_details": {"audio_tokens": 0, "cached_tokens": 3152}, "cost": 0.00058426, "is_byok": false, "cost_details": {"upstream_inference_cost": null, "upstream_inference_prompt_cost": 0.00028276, "upstream_inference_completions_cost": 0.0003015}}, "model": "openai/gpt-oss-120b"}
{"timestamp": "2025-10-24T17:33:42.668855", "feed": "arxiv_cslg", "title": "Concentration and excess risk bounds for imbalanced classification with synthetic oversampling", "link": "https://papers.cool/arxiv/2510.20472", "analysis": {"summary": "The paper develops a theoretical framework for analyzing synthetic oversampling methods such as SMOTE in imbalanced classification, deriving uniform concentration bounds between empirical risk on synthetic minority samples and population risk, and providing non‑parametric excess risk guarantees for kernel‑based classifiers trained on the synthetic data. It also offers practical guidelines for tuning SMOTE and downstream learning algorithms and validates the theory with numerical experiments.", "summary_cn": "本文建立了一个理论框架，分析用于处理类别不平衡问题的合成过采样方法（如 SMOTE）的行为，推导了合成少数样本的经验风险与真实少数分布的总体风险之间的统一浓度界，并给出了在该合成数据上训练的基于核的分类器的非参数超额风险保证。文中还提供了 SMOTE 与下游学习算法的参数调优实用指南，并通过数值实验验证理论结果。", "keywords": "SMOTE, synthetic oversampling, imbalanced classification, concentration bounds, excess risk, kernel classifiers, theoretical analysis", "scoring": {"interpretability": 2, "understanding": 5, "safety": 1, "technicality": 7, "surprisal": 5}, "category": {"failure_mode_addressed": "non-applicable", "primary_focus": "other"}, "authors": ["Touqeer Ahmad", "Mohammadreza M. Kalan", "François Portier", "Gilles Stupfler"]}, "usage": {"completion_tokens": 566, "prompt_tokens": 3333, "total_tokens": 3899, "completion_tokens_details": {"accepted_prediction_tokens": null, "audio_tokens": null, "reasoning_tokens": 322, "rejected_prediction_tokens": null, "image_tokens": 0}, "prompt_tokens_details": {"audio_tokens": 0, "cached_tokens": 3152}, "cost": 0.00056231, "is_byok": false, "cost_details": {"upstream_inference_cost": null, "upstream_inference_prompt_cost": 0.00027931, "upstream_inference_completions_cost": 0.000283}}, "model": "openai/gpt-oss-120b"}
{"timestamp": "2025-10-24T17:33:42.692895", "feed": "arxiv_cslg", "title": "Partial Optimality in Cubic Correlation Clustering for General Graphs", "link": "https://papers.cool/arxiv/2510.20431", "analysis": {"summary": "The paper studies the cubic correlation clustering problem, where costs are assigned to cliques of size at most three, and seeks a clustering that minimizes the total cost of cliques fully contained within a cluster. It introduces partial optimality conditions for this problem, proposes algorithms to test these conditions, and evaluates their practical effectiveness on two benchmark datasets.", "summary_cn": "本文研究了三元（cubic）相关聚类问题，即在图中对最多包含三个节点的团分配成本，目标是找出使同聚类内部团成本总和最小的划分。作者提出了部分最优性条件，并实现了相应的判定算法，在两个数据集上进行数值实验以评估其实际效果。", "keywords": "cubic correlation clustering, partial optimality, higher-order clustering, graph clustering, local search, NP-hard optimization", "scoring": {"interpretability": 2, "understanding": 5, "safety": 1, "technicality": 7, "surprisal": 5}, "category": {"failure_mode_addressed": "non-applicable", "primary_focus": "other"}, "authors": ["David Stein", "Bjoern Andres", "Silvia Di Gregorio"]}, "usage": {"completion_tokens": 505, "prompt_tokens": 3317, "total_tokens": 3822, "completion_tokens_details": {"accepted_prediction_tokens": null, "audio_tokens": null, "reasoning_tokens": 295, "rejected_prediction_tokens": null, "image_tokens": 0}, "prompt_tokens_details": {"audio_tokens": 0, "cached_tokens": 3152}, "cost": 0.00052941, "is_byok": false, "cost_details": {"upstream_inference_cost": null, "upstream_inference_prompt_cost": 0.00027691, "upstream_inference_completions_cost": 0.0002525}}, "model": "openai/gpt-oss-120b"}
{"timestamp": "2025-10-24T17:33:42.858293", "feed": "arxiv_cslg", "title": "Efficient Multi-bit Quantization Network Training via Weight Bias Correction and Bit-wise Coreset Sampling", "link": "https://papers.cool/arxiv/2510.20673", "analysis": {"summary": "The paper introduces two techniques—weight bias correction and bit-wise coreset sampling—to dramatically reduce the training overhead of multi-bit quantization networks while preserving accuracy across multiple precisions. Weight bias correction aligns activation distributions across bit-widths, removing the need for fine‑tuning, and coreset sampling selects a compact, gradient‑important subset of data for each child model. Experiments on CIFAR‑10/100, TinyImageNet, and ImageNet‑1K with ResNet and ViT show up to 7.88× faster training with competitive or superior performance.", "summary_cn": "本文提出两种技术——权重偏置校正和按位核心集采样，以大幅降低多比特量化网络的训练开销，同时保持跨多精度的模型性能。权重偏置校正通过对齐不同位宽下的激活分布，消除微调需求；按位核心集采样基于梯度重要性分数，为每个子模型挑选紧凑且信息丰富的数据子集。实验在 CIFAR‑10/100、TinyImageNet 和 ImageNet‑1K 上使用 ResNet 与 ViT 验证，训练速度提升最高达 7.88 倍，且精度保持或更优。", "keywords": "multi-bit quantization, weight bias correction, bit-wise coreset sampling, model compression, training efficiency, gradient-based importance, ResNet, Vision Transformer, CIFAR-10, ImageNet", "scoring": {"interpretability": 1, "understanding": 5, "safety": 2, "technicality": 8, "surprisal": 6}, "category": {"failure_mode_addressed": "non-applicable", "primary_focus": "other"}, "authors": ["Jinhee Kim", "Jae Jun An", "Kang Eun Jeon", "Jong Hwan Ko"]}, "usage": {"completion_tokens": 735, "prompt_tokens": 3439, "total_tokens": 4174, "completion_tokens_details": {"accepted_prediction_tokens": null, "audio_tokens": null, "reasoning_tokens": 409, "rejected_prediction_tokens": null, "image_tokens": 0}, "prompt_tokens_details": {"audio_tokens": 0, "cached_tokens": 3152}, "cost": 0.00066271, "is_byok": false, "cost_details": {"upstream_inference_cost": null, "upstream_inference_prompt_cost": 0.00029521, "upstream_inference_completions_cost": 0.0003675}}, "model": "openai/gpt-oss-120b"}
{"timestamp": "2025-10-24T17:33:43.118838", "feed": "arxiv_cslg", "title": "Learning Coupled Earth System Dynamics with GraphDOP", "link": "https://papers.cool/arxiv/2510.20416", "analysis": {"summary": "The paper introduces GraphDOP, a graph‑based machine‑learning model that learns to forecast weather directly from raw satellite and in‑situ observations by embedding diverse Earth‑system components into a shared latent space, thereby implicitly capturing cross‑domain interactions without explicit coupling. Case studies demonstrate its ability to predict events driven by coupled processes such as Arctic sea‑ice freezing, hurricane‑induced ocean cooling, and the 2022 European heat wave. The results suggest that endto‑end data‑driven Earth‑system prediction can characterize and propagate cross‑component dynamics, offering a promising path toward physically consistent forecasting.", "summary_cn": "本文提出 GraphDOP，一种基于图的机器学习模型，通过将原始卫星和现场观测中的海洋、大气、陆地和冰盖等多源信息嵌入共享潜在空间，隐式捕捉跨域耦合交互，实现无需显式耦合的天气预测。案例展示了该模型在北极快速海冰冻结、飓风导致的海面降温以及2022年欧洲热浪等关键耦合过程中的预测能力。结果表明，从观测直接学习的端到端 Earth System 预测能够有效表征并传播跨组件互动，为实现物理一致的天气预报提供了新路径。", "keywords": "graph neural networks, Earth system modeling, data-driven weather prediction, coupled dynamics, satellite observations, graph-based ML", "scoring": {"interpretability": 2, "understanding": 6, "safety": 2, "technicality": 8, "surprisal": 7}, "category": {"failure_mode_addressed": "non-applicable", "primary_focus": "other"}, "authors": ["Eulalie Boucher", "Mihai Alexe", "Peter Lean", "Ewan Pinnington", "Simon Lang", "Patrick Laloyaux", "Lorenzo Zampieri", "Patricia de Rosnay", "Niels Bormann", "Anthony McNally"]}, "usage": {"completion_tokens": 692, "prompt_tokens": 3446, "total_tokens": 4138, "completion_tokens_details": {"accepted_prediction_tokens": null, "audio_tokens": null, "reasoning_tokens": 365, "rejected_prediction_tokens": null, "image_tokens": 0}, "prompt_tokens_details": {"audio_tokens": 0, "cached_tokens": 3152}, "cost": 0.00064226, "is_byok": false, "cost_details": {"upstream_inference_cost": null, "upstream_inference_prompt_cost": 0.00029626, "upstream_inference_completions_cost": 0.000346}}, "model": "openai/gpt-oss-120b"}
{"timestamp": "2025-10-24T17:33:43.332818", "feed": "arxiv_cslg", "title": "Neural Diversity Regularizes Hallucinations in Small Models", "link": "https://papers.cool/arxiv/2510.20690", "analysis": {"summary": "The paper introduces neural diversity—decorrelated parallel representations—as a mechanism to reduce hallucination rates in language models without increasing parameters or data. By proving a bound linking hallucination probability to representational correlation and implementing ND-LoRA (parallel LoRA adapters with Barlow Twins regularization), the authors achieve up to 25.6% reduction in hallucinations while preserving accuracy. Analyses reveal task-dependent optimal levels of diversity and suggest neural diversity as a third scaling axis orthogonal to size and data.", "summary_cn": "本文提出神经多样性（去相关的平行表征）作为降低语言模型幻觉率的原理机制，且在不增加参数或数据的情况下实现。通过证明幻觉概率上界与表征相关性之间的关系，并引入 ND-LoRA（平行 LoRA 适配器结合 Barlow Twins 正则），实验显示幻觉率最高降低 25.6%，且不牺牲整体准确性。进一步分析表明不同任务需要不同的最优多样性水平，神经多样性成为与参数和数据规模正交的第三个扩展维度。", "keywords": "neural diversity, hallucination reduction, LoRA adapters, Barlow Twins, representational correlation, language model reliability", "scoring": {"interpretability": 6, "understanding": 7, "safety": 7, "technicality": 8, "surprisal": 7}, "category": {"failure_mode_addressed": "misalignment", "primary_focus": "robustness"}, "authors": ["Kushal Chakrabarti", "Nirmal Balachundhar"]}, "usage": {"completion_tokens": 768, "prompt_tokens": 3475, "total_tokens": 4243, "completion_tokens_details": {"accepted_prediction_tokens": null, "audio_tokens": null, "reasoning_tokens": 525, "rejected_prediction_tokens": null, "image_tokens": 0}, "prompt_tokens_details": {"audio_tokens": 0, "cached_tokens": 3152}, "cost": 0.00068461, "is_byok": false, "cost_details": {"upstream_inference_cost": null, "upstream_inference_prompt_cost": 0.00030061, "upstream_inference_completions_cost": 0.000384}}, "model": "openai/gpt-oss-120b"}
{"timestamp": "2025-10-24T17:33:43.395080", "feed": "arxiv_cslg", "title": "Alleviating Forgetfulness of Linear Attention by Hybrid Sparse Attention and Contextualized Learnable Token Eviction", "link": "https://papers.cool/arxiv/2510.20787", "analysis": {"summary": "The paper proposes hybrid sparse attention mechanisms to reduce forgetfulness in linear-attention models, including a novel learnable token eviction method combined with sliding-window attention and a lightweight CNN that adaptively retains critical key‑value pairs while preserving linear time and space complexity. Efficient Triton kernels are provided, and experiments on retrieval‑intensive benchmarks show notable performance gains.", "summary_cn": "本文提出混合稀疏注意力机制，以缓解线性注意力模型的遗忘问题，其中包括一种可学习的 token 淘汰方法，结合滑动窗口注意力和轻量级 CNN，在保持线性时间空间复杂度的同时自适应保留关键 KV 对。实现了高效的 Triton 内核，并在检索密集型基准上展示了显著的性能提升。", "keywords": "linear attention, hybrid sparse attention, token eviction, sliding-window attention, learnable token eviction, efficient attention, retrieval-intensive, Triton kernels, CNN aggregator", "scoring": {"interpretability": 2, "understanding": 5, "safety": 1, "technicality": 8, "surprisal": 6}, "category": {"failure_mode_addressed": "non-applicable", "primary_focus": "other"}, "authors": ["Mutian He", "Philip N. Garner"]}, "usage": {"completion_tokens": 756, "prompt_tokens": 3372, "total_tokens": 4128, "completion_tokens_details": {"accepted_prediction_tokens": null, "audio_tokens": null, "reasoning_tokens": 592, "rejected_prediction_tokens": null, "image_tokens": 0}, "prompt_tokens_details": {"audio_tokens": 0, "cached_tokens": 3152}, "cost": 0.00066316, "is_byok": false, "cost_details": {"upstream_inference_cost": null, "upstream_inference_prompt_cost": 0.00028516, "upstream_inference_completions_cost": 0.000378}}, "model": "openai/gpt-oss-120b"}
{"timestamp": "2025-10-24T17:33:43.782016", "feed": "arxiv_cslg", "title": "Capability of using the normalizing flows for extraction rare gamma events in the TAIGA experiment", "link": "https://papers.cool/arxiv/2510.20334", "analysis": {"summary": "The paper proposes a deep‑learning method based on normalizing flows for anomaly detection to identify rare gamma‑ray events among charged‑particle background in the TAIGA‑IACT experiment. Experiments on simulated data show the approach has potential, though its performance currently lags behind existing techniques, and the authors suggest avenues for improvement.", "summary_cn": "本文提出一种基于归一化流（normalizing flows）的深度学习异常检测方法，用于在 TAIGA‑IACT 实验中从带电粒子背景中识别稀有伽马射线事件。对模拟数据的实验表明该方法具有潜力，但其性能仍低于其他已有方法，作者因此提出了若干改进方向。", "keywords": "normalizing flows, anomaly detection, gamma-ray detection, TAIGA-IACT, deep learning, rare event extraction", "scoring": {"interpretability": 3, "understanding": 5, "safety": 2, "technicality": 6, "surprisal": 5}, "category": {"failure_mode_addressed": "non-applicable", "primary_focus": "robness"}, "authors": ["A. P. Kryukov", "A. Yu. Razumov", "A. P. Demichev", "J. J. Dubenskaya", "E. O. Gres", "S. P. Polyakov", "E. B. Postnikov", "P. A. Volchugov", "D. P. Zhurov"]}, "usage": {"completion_tokens": 619, "prompt_tokens": 3300, "total_tokens": 3919, "completion_tokens_details": {"accepted_prediction_tokens": null, "audio_tokens": null, "reasoning_tokens": 425, "rejected_prediction_tokens": null, "image_tokens": 0}, "prompt_tokens_details": {"audio_tokens": 0, "cached_tokens": 3152}, "cost": 0.00058386, "is_byok": false, "cost_details": {"upstream_inference_cost": null, "upstream_inference_prompt_cost": 0.00027436, "upstream_inference_completions_cost": 0.0003095}}, "model": "openai/gpt-oss-120b"}
{"timestamp": "2025-10-24T17:33:43.793258", "feed": "arxiv_cslg", "title": "Multi-Task Deep Learning for Surface Metrology", "link": "https://papers.cool/arxiv/2510.20339", "analysis": {"summary": "The paper introduces a reproducible deep learning framework for surface metrology that jointly predicts texture parameters (, Rz, RONt) and their associated standard uncertainties using multi-task learning across tactile and optical measurement systems. It employs quantile and heteroscedastic heads with post-hoc conformal calibration, achieving high regression performance for most targets and a 92.85% accurate classifier for measurement system type, while noting negative transfer in naive multi-output models. The calibrated predictions are intended to aid instrument selection and acceptance decisions in metrological workflows.", "summary_cn": "本文提出一个可复现的深度学习框架用于表面计量，能够在触觉和光学系统的数据上联合预测表面纹理参数（Ra、Rz、RONt）及其标准不确定性。采用分位数和异方差输出头，并通过事后共形校准获得校准区间，回归性能对大多数目标均表现出高精度，测量系统类型分类器准确率为 92.85%。研究还发现直接使用多输出模型会出现负迁移，单目标模型表现更佳。这些经过校准的预测可用于指导仪器选择和计量流程中的接受决策。", "keywords": "multi-task learning, surface metrology, uncertainty quantification, conformal calibration, regression, classification, instrument selection", "scoring": {"interpretability": 2, "understanding": 4, "safety": 1, "technicality": 7, "surprisal": 5}, "category": {"failure_mode_addressed": "non-applicable", "primary_focus": "other"}, "authors": ["D. Kucharski", "A. Gaska", "T. Kowaluk", "K. Stepien", "M. Repalska", "B. Gapinski", "M. Wieczorowski", "M. Nawotka", "P. Sobecki", "P. Sosinowski", "J. Tomasik", "A. Wojtowicz"]}, "usage": {"completion_tokens": 620, "prompt_tokens": 3444, "total_tokens": 4064, "completion_tokens_details": {"accepted_prediction_tokens": null, "audio_tokens": null, "reasoning_tokens": 315, "rejected_prediction_tokens": null, "image_tokens": 0}, "prompt_tokens_details": {"audio_tokens": 0, "cached_tokens": 3152}, "cost": 0.00060596, "is_byok": false, "cost_details": {"upstream_inference_cost": null, "upstream_inference_prompt_cost": 0.00029596, "upstream_inference_completions_cost": 0.00031}}, "model": "openai/gpt-oss-120b"}
{"timestamp": "2025-10-24T17:33:43.989803", "feed": "arxiv_cslg", "title": "Breakdance Video classification in the age of Generative AI", "link": "https://papers.cool/arxiv/2510.20287", "analysis": {"summary": "The paper evaluates modern video foundation models for classifying breakdance videos, comparing video encoders and decoder-based video-language models. Results indicate that encoder-only models outperform state-of-the-art video-language models on this niche dance sport task, and detailed analysis is provided on selecting encoders and fine-tuning decoders.", "summary_cn": "本文评估了现代视频基础模型在街舞（breakdance）视频分类任务中的表现，比较了视频编码器和基于解码器的视频语言模型。结果表明，纯编码器模型在此细分舞蹈体育任务上优于最先进的视频语言模型，并提供了关于如何选择编码器以及对解码器进行微调的深入分析。", "keywords": "breakdance, video classification, vision-language models, video encoder, video decoder, generative AI", "scoring": {"interpretability": 2, "understanding": 4, "safety": 1, "technicality": 6, "surprisal": 5}, "category": {"failure_mode_addressed": "non-applicable", "primary_focus": "other"}, "authors": ["Sauptik Dhar", "Naveen Ramakrishnan", "Michelle Munson"]}, "usage": {"completion_tokens": 538, "prompt_tokens": 3321, "total_tokens": 3859, "completion_tokens_details": {"accepted_prediction_tokens": null, "audio_tokens": null, "reasoning_tokens": 327, "rejected_prediction_tokens": null, "image_tokens": 0}, "prompt_tokens_details": {"audio_tokens": 0, "cached_tokens": 3152}, "cost": 0.00054651, "is_byok": false, "cost_details": {"upstream_inference_cost": null, "upstream_inference_prompt_cost": 0.00027751, "upstream_inference_completions_cost": 0.000269}}, "model": "openai/gpt-oss-120b"}
{"timestamp": "2025-10-24T17:33:44.327058", "feed": "arxiv_cslg", "title": "Symbolic Regression and Differentiable Fits in Beyond the Standard Model Physics", "link": "https://papers.cool/arxiv/2510.20453", "analysis": {"summary": "The paper applies symbolic regression to the Constrained Minimal Supersymmetric Standard Model (CMSSM) to obtain compact analytic formulas for the Higgs mass, dark matter relic density, and the muon anomalous magnetic moment. These symbolic expressions enable fast, differentiable global fits of the CMSSM parameters that match conventional sampling results, and a comparison with neural‑network regression shows SR delivers more globally robust performance.", "summary_cn": "本文将符号回归（symbolic regression）应用于受约束最小超对称模型（CMSSM），推导出描述希格斯质量、暗物质剩余密度以及 μ 子 anomalous magnetic moment（muon g‑2）的紧凑解析式。利用这些解析式进行可微分的全局参数拟合，结果与传统采样方法一致，并与神经网络回归（neural network regression）进行比较，发现符号回归在全局鲁棒性方面表现更佳。", "keywords": "symbolic regression, differentiable fitting CMSSM, Higgs mass, dark matter relic density, muon g-2, neural network regression, global fits, beyond the Standard Model", "scoring": {"interpretability": 7, "understanding": 7, "safety": 2, "technicality": 6, "surprisal": 5}, "category": {"failure_mode_addressed": "non-applicable", "primary_focus": "other"}, "authors": ["Shehu AbdusSalam", "Steven Abel", "Deaglan Bartlett", "Miguel Crispim Romão"]}, "usage": {"completion_tokens": 921, "prompt_tokens": 3435, "total_tokens": 4356, "completion_tokens_details": {"accepted_prediction_tokens": null, "audio_tokens": null, "reasoning_tokens": 728, "rejected_prediction_tokens": null, "image_tokens": 0}, "prompt_tokens_details": {"audio_tokens": 0, "cached_tokens": 3152}, "cost": 0.00075511, "is_byok": false, "cost_details": {"upstream_inference_cost": null, "upstream_inference_prompt_cost": 0.00029461, "upstream_inference_completions_cost": 0.0004605}}, "model": "openai/gpt-oss-120b"}
{"timestamp": "2025-10-24T17:33:44.890393", "feed": "arxiv_cslg", "title": "SynTSBench: Rethinking Temporal Pattern Learning in Deep Learning Models for Time Series", "link": "https://papers.cool/arxiv/2510.20273", "analysis": {"summary": "SynTSBench introduces a synthetic, feature‑configurable benchmark for time‑series forecasting that isolates specific temporal patterns, assesses model robustness to data irregularities, and compares predictions to theoretical optimal performance. The framework provides three analytical dimensions—temporal feature decomposition, robustness analysis, and optimality benchmarking—to diagnose strengths and weaknesses of deep learning models. Experiments reveal that current state‑of‑the‑art models fall short of optimal baselines across many pattern types.", "summary_cn": "SynTSBench 提出了一种可编程特征的合成时间序列预测基准，通过隔离特定时间模式、评估模型对数据不规则性的鲁棒性，并将预测结果与理论最优性能进行比较。该框架包括三个核心分析维度：时间特征分解与能力映射、鲁棒性分析以及最优基准评估，以帮助诊断深度学习模型的优势和不足。实验表明，当前最先进的模型在多个模式下仍未接近理论最优基准。", "keywords": "time series forecasting, synthetic benchmark, temporal pattern learning, model evaluation, robustness analysis, feature decomposition, theoretical optimum, synthetic data, capability mapping", "scoring": {"interpretability": 4, "understanding": 6, "safety": 2, "technicality": 6, "surprisal": 5}, "category": {"failure_mode_addressed": "non-applicable", "primary_focus": "interpretability"}, "authors": ["Qitai Tan", "Yiyun Chen", "Mo Li", "Ruiwen Gu", "Yilin Su", "Xiao-Ping Zhang"]}, "usage": {"completion_tokens": 1070, "prompt_tokens": 3458, "total_tokens": 4528, "completion_tokens_details": {"accepted_prediction_tokens": null, "audio_tokens": null, "reasoning_tokens": 970, "rejected_prediction_tokens": null, "image_tokens": 0}, "prompt_tokens_details": {"audio_tokens": 0, "cached_tokens": 3152}, "cost": 0.00083306, "is_byok": false, "cost_details": {"upstream_inference_cost": null, "upstream_inference_prompt_cost": 0.00029806, "upstream_inference_completions_cost": 0.000535}}, "model": "openai/gpt-oss-120b"}
{"timestamp": "2025-10-24T17:33:45.259696", "feed": "arxiv_cslg", "title": "Calibrating Multimodal Consensus for Emotion Recognition", "link": "https://papers.cool/arxiv/2510.20256", "analysis": {"summary": "The paper introduces Calibrated Multimodal Consensus (CMC), a framework that first generates pseudo unimodal labels for self‑supervised pretraining and then employs a parameter‑free fusion module and a multimodal consensus router to reduce text dominance and resolve semantic inconsistencies across modalities in emotion recognition. Experiments on four benchmark datasets show that CMC matches or exceeds state‑of‑the‑art performance, particularly when modalities provide conflicting emotional cues.", "summary_cn": "本文提出了校准多模态共识（CMC）框架，先通过伪标签生成模块进行单模态自监督预训练，再利用无参融合模块和多模态共识路由器减轻文本主导现象并缓解跨模态语义不一致问题，以实现情感识别。在四个基准数据集上的实验表明，CMC 在总体性能上与最先进方法持平或更佳，尤其在模态之间情感线索冲突的场景中表现突出。", "keywords": "multimodal emotion recognition, consensus fusion, pseudo label generation, modality dominance, parameter-free fusion, multimodal consensus router", "scoring": {"interpretability": 3, "understanding": 6, "safety": 2, "technicality": 6, "surprisal": 5}, "category": {"failure_mode_addressed": "non-applicable", "primary_focus": "robustness"}, "authors": ["Guowei Zhong", "Junjie Li", "Huaiyu Zhu", "Ruohong Huan", "Yun Pan"]}, "usage": {"completion_tokens": 621, "prompt_tokens": 3440, "total_tokens": 4061, "completion_tokens_details": {"accepted_prediction_tokens": null, "audio_tokens": null, "reasoning_tokens": 374, "rejected_prediction_tokens": null, "image_tokens": 0}, "prompt_tokens_details": {"audio_tokens": 0, "cached_tokens": 3152}, "cost": 0.00060586, "is_byok": false, "cost_details": {"upstream_inference_cost": null, "upstream_inference_prompt_cost": 0.00029536, "upstream_inference_completions_cost": 0.0003105}}, "model": "openai/gpt-oss-120b"}
{"timestamp": "2025-10-24T17:33:45.645426", "feed": "arxiv_cslg", "title": "Decoding the Ear: A Framework for Objectifying Expressiveness from Human Preference Through Efficient Alignment", "link": "https://papers.cool/arxiv/2510.20513", "analysis": {"summary": "The paper introduces DeEAR, a framework that converts human preference for speech expressiveness into an objective score across three dimensions—Emotion, Prosody, and Spontaneity—achieving a Spearman's rank correlation of 0.86 with human judgments using fewer than 500 annotated samples. DeEAR is used for fair benchmarking of speech-to-speech models and for curating a 14K-utterance expressive dataset (ExpressiveSpeech) that significantly improves expressive scores of S2S systems.", "summary_cn": "本文提出 DeEAR 框架，将人类对语音表达性的偏好转化为客观评分，涵盖情感、韵律和自然度三个维度，在少于 500 条标注样本下实现与人工感知的 Spearman 秩相关系数 0.86。DeEAR 用于对语音到语音模型进行公平基准测试，并筛选出 14 000 条富表达力的语料库（ExpressiveSpeech），显著提升模型的表达评分。", "keywords": "speech expressiveness, human preference metric, DeEAR, SRCC, prosody, emotion, spontaneity, speech-to-speech, expressive dataset, evaluation benchmark", "scoring": {"interpretability": 3, "understanding": 6, "safety": 3, "technicality": 7, "surprisal": 7}, "category": {"failure_mode_addressed": "non-applicable", "primary_focus": "alignment"}, "authors": ["Zhiyu Lin", "Jingwen Yang", "Jiale Zhao", "Meng Liu", "Sunzhu Li", "Benyou Wang"]}, "usage": {"completion_tokens": 769, "prompt_tokens": 3437, "total_tokens": 4206, "completion_tokens_details": {"accepted_prediction_tokens": null, "audio_tokens": null, "reasoning_tokens": 532, "rejected_prediction_tokens": null, "image_tokens": 0}, "prompt_tokens_details": {"audio_tokens": 0, "cached_tokens": 3152}, "cost": 0.00067941, "is_byok": false, "cost_details": {"upstream_inference_cost": null, "upstream_inference_prompt_cost": 0.00029491, "upstream_inference_completions_cost": 0.0003845}}, "model": "openai/gpt-oss-120b"}
{"timestamp": "2025-10-24T17:33:45.909009", "feed": "arxiv_cslg", "title": "Automated Cloud Infrastructure-as-Code Reconciliation with AI Agents", "link": "https://papers.cool/arxiv/2510.20211", "analysis": {"summary": "The paper introduces NSync, an automated system that uses LLM-based agents to detect and reconcile infrastructure drift by analyzing cloud API traces and updating IaC configurations such as Terraform scripts. It presents a novel evaluation pipeline with realistic drift injections and demonstrates significant improvements in accuracy and token efficiency over baselines across multiple real-world projects.", "summary_cn": "本文提出 NSync 系统，利用基于大型语言模型的代理从云 API 调用痕迹中检测基础设施漂移，并自动更新 IaC（如 Terraform）配置以实现同步。作者设计了注入真实漂移的评估流程，在多个实际项目中显示出在准确率和令牌效率上相较基线的显著提升。", "keywords": "infrastructure-as-code, drift detection, LLM agents, cloud API tracing, Terraform, reconciliation, self-evolving knowledge base, AI-powered infrastructure management", "scoring": {"interpretability": 2, "understanding": 4, "safety": 3, "technicality": 7, "surprisal": 6}, "category": {"failure_mode_addressed": "non-applicable", "primary_focus": "control"}, "authors": ["Zhenning Yang", "Hui Guan", "Victor Nicolet", "Brandon Paulsen", "Joey Dodds", "Daniel Kroening", "Ang Chen"]}, "usage": {"completion_tokens": 633, "prompt_tokens": 3549, "total_tokens": 4182, "completion_tokens_details": {"accepted_prediction_tokens": null, "audio_tokens": null, "reasoning_tokens": 415, "rejected_prediction_tokens": null, "image_tokens": 0}, "prompt_tokens_details": {"audio_tokens": 0, "cached_tokens": 3152}, "cost": 0.00062821, "is_byok": false, "cost_details": {"upstream_inference_cost": null, "upstream_inference_prompt_cost": 0.00031171, "upstream_inference_completions_cost": 0.0003165}}, "model": "openai/gpt-oss-120b"}
{"timestamp": "2025-10-24T17:33:45.980471", "feed": "arxiv_cslg", "title": "A Transformer Inspired AI-based MIMO receiver", "link": "https://papers.cool/arxiv/2510.20363", "analysis": {"summary": "The paper introduces AttDet, a Transformer-inspired MIMO detection technique that treats each transmit layer as a token and learns inter‑stream interference via a lightweight self‑attention mechanism derived from the estimated channel matrix. By initializing values with matched‑filter outputs and iteratively refining them, AttDet combines model‑based interpretability with data‑driven flexibility, achieving near‑optimal BER/BLER performance on realistic 5G channel models while keeping polynomial computational complexity.", "summary_cn": "本文提出了 AttDet，一种受 Transformer 启发的 MIMO 检测方法，将每个发射层视为 token，并通过基于估计信道矩阵的轻量自注意力机制学习流间干扰。值初始化为匹配滤波输出并迭代更新，使得该方法兼具模型可解释性和数据驱动的灵活性，在真实 5G 信道模型和高阶混合 QAM 调制编码下实现了接近最优的 BER/BLER 性能，同时保持可预测的多项式复杂度。", "keywords": "MIMO detection, transformer, self-attention, AttDet, channel correlation, BER, BLER, 5G, QAM", "scoring": {"interpretability": 4, "understanding": 5, "safety": 2, "technicality": 7, "surprisal": 6}, "category": {"failure_mode_addressed": "non-applicable", "primary_focus": "other"}, "authors": ["András Rácz", "Tamás Borsos", "András Veres", "Benedek Csala"]}, "usage": {"completion_tokens": 608, "prompt_tokens": 3323, "total_tokens": 3931, "completion_tokens_details": {"accepted_prediction_tokens": null, "audio_tokens": null, "reasoning_tokens": 314, "rejected_prediction_tokens": null, "image_tokens": 0}, "prompt_tokens_details": {"audio_tokens": 0, "cached_tokens": 3152}, "cost": 0.00058181, "is_byok": false, "cost_details": {"upstream_inference_cost": null, "upstream_inference_prompt_cost": 0.00027781, "upstream_inference_completions_cost": 0.000304}}, "model": "openai/gpt-oss-120b"}
{"timestamp": "2025-10-24T17:33:46.347584", "feed": "arxiv_cslg", "title": "Extending machine learning model for implicit solvation to free energy calculations", "link": "https://papers.cool/arxiv/2510.20103", "analysis": {"summary": "The paper introduces Lambda Solvation Neural Network (LSNN), a graph neural network–based implicit solvent model that is trained not only on force matching but also on the derivatives of alchemical variables, enabling accurate absolute free energy predictions across chemical species. Trained on ~300,000 small molecules, LSNN achieves explicit‑solvent‑level accuracy with substantial computational speedup, offering a framework for future drug‑discovery applications.", "summary_cn": "本文提出了 Lambda Solvation Neural Network（LSNN），一种基于图神经网络的隐式溶剂模型，除了力匹配外，还通过匹配铝化变量的导数进行训练，从而实现不同化学物种之间的绝对自由能可比预测。该模型在约30万小分子数据上训练，达到了显式溶剂模拟水平的精度并显著加快计算，为药物发现等应用提供了基础框架。", "keywords": "graph neural network, implicit solvation, free energy calculation, force matching, alchemical derivatives, LSNN, molecular simulation, machine learning potentials", "scoring": {"interpretability": 2, "understanding": 4, "safety": 1, "technicality": 7, "surprisal": 6}, "category": {"failure_mode_addressed": "non-applicable", "primary_focus": "other"}, "authors": ["Rishabh Dey", "Michael Brocidiacono", "Kushal Koirala", "Alexander Tropsha", "Konstantin I. Popov"]}, "usage": {"completion_tokens": 647, "prompt_tokens": 3415, "total_tokens": 4062, "completion_tokens_details": {"accepted_prediction_tokens": null, "audio_tokens": null, "reasoning_tokens": 394, "rejected_prediction_tokens": null, "image_tokens": 0}, "prompt_tokens_details": {"audio_tokens": 0, "cached_tokens": 3152}, "cost": 0.00061511, "is_byok": false, "cost_details": {"upstream_inference_cost": null, "upstream_inference_prompt_cost": 0.00029161, "upstream_inference_completions_cost": 0.0003235}}, "model": "openai/gpt-oss-120b"}
{"timestamp": "2025-10-24T17:33:46.516483", "feed": "arxiv_cslg", "title": "Endogenous Aggregation of Multiple Data Envelopment Analysis Scores for Large Data Sets", "link": "https://papers.cool/arxiv/2510.20052", "analysis": {"summary": "The paper introduces two regularized DEA models—a slack‑based measure (SBM) and a linearized goal‑programming version (GP‑SBM)—that generate both dimension‑specific and aggregate efficiency scores while handling desirable and undesirable outputs. It demonstrates computational efficiency and superior discriminatory power on large datasets, including a case study of twelve Ontario hospitals evaluated across technical, clinical, and patient‑experience dimensions. The approach outperforms conventional separate‑dimension benchmarking methods.", "summary_cn": "本文提出了两种正则化数据包络分析模型——基于松弛度的测度（SBM）和线性化目标规划模型（GP‑SBM），能够在处理可取和不可取输出的同时生成维度特定和整体效率得分。通过在大规模数据集上的实验以及对安大略省十二家医院在技术、临床和患者体验三个维度的案例研究，展示了该方法的计算效率和更高的辨别力，优于传统的先分别评估维度再聚合的基准方法。", "keywords": "data envelopment analysis, DEA, slack-based measure, GP-SBM, regularization, multi-dimensional efficiency, undesirable outputs, large-scale benchmarking, organizational effectiveness, efficiency aggregation", "scoring": {"interpretability": 2, "understanding": 4, "safety": 1, "technicality": 7, "surprisal": 5}, "category": {"failure_mode_addressed": "non-applicable", "primary_focus": "other"}, "authors": ["Hashem Omrani", "Raha Imanirad", "Adam Diamant", "Utkarsh Verma", "Amol Verma", "Fahad Razak"]}, "usage": {"completion_tokens": 604, "prompt_tokens": 3412, "total_tokens": 4016, "completion_tokens_details": {"accepted_prediction_tokens": null, "audio_tokens": null, "reasoning_tokens": 290, "rejected_prediction_tokens": null, "image_tokens": 0}, "prompt_tokens_details": {"audio_tokens": 0, "cached_tokens": 3152}, "cost": 0.00059316, "is_byok": false, "cost_details": {"upstream_inference_cost": null, "upstream_inference_prompt_cost": 0.00029116, "upstream_inference_completions_cost": 0.000302}}, "model": "openai/gpt-oss-120b"}
{"timestamp": "2025-10-24T17:33:46.871701", "feed": "arxiv_cslg", "title": "Testing Most Influential Sets", "link": "https://papers.cool/arxiv/2510.20372", "analysis": {"summary": "The paper introduces a rigorous statistical framework for assessing the significance of most influential data subsets on model outcomes, deriving extreme value distributions of maximal influence and proposing hypothesis tests to distinguish genuine problems from sampling variation. This replaces ad-hoc sensitivity checks with formal significance testing and is demonstrated on applications in economics, biology, and machine learning benchmarks.", "summary_cn": "本文提出了一套严格的统计框架，用于评估模型输出中最具影响力的数据子集的显著性，通过推导最大影响力的极值分布并提出假设检验，以区分真实问题与抽样波动。这取代了以往的随意敏感性检查，并在经济学、生物学以及机器学习基准等多个案例中展示了其实用价值。", "keywords": "most influential sets, data influence, statistical significance, hypothesis testing, extreme value theory, robustness, interpretability, sensitivity analysis", "scoring": {"interpretability": 6, "understanding": 7, "safety": 4, "technicality": 8, "surprisal": 7}, "category": {"failure_mode_addressed": "non-applicable", "primary_focus": "interpretability"}, "authors": ["Lucas Darius Konrad", "Nikolas Kuschnig"]}, "usage": {"completion_tokens": 743, "prompt_tokens": 3314, "total_tokens": 4057, "completion_tokens_details": {"accepted_prediction_tokens": null, "audio_tokens": null, "reasoning_tokens": 627, "rejected_prediction_tokens": null, "image_tokens": 0}, "prompt_tokens_details": {"audio_tokens": 0, "cached_tokens": 3152}, "cost": 0.00064796, "is_byok": false, "cost_details": {"upstream_inference_cost": null, "upstream_inference_prompt_cost": 0.00027646, "upstream_inference_completions_cost": 0.0003715}}, "model": "openai/gpt-oss-120b"}
{"timestamp": "2025-10-24T17:33:46.959680", "feed": "arxiv_cslg", "title": "Enhanced Cyclic Coordinate Descent Methods for Elastic Net Penalized Linear Models", "link": "https://papers.cool/arxiv/2510.19999", "analysis": {"summary": "The paper introduces an Enhanced Cyclic Coordinate Descent (ECCD) framework for elastic net penalized generalized linear models, using a Taylor expansion to transform nonlinear gradient steps into efficient batched operations. By unrolling vector recurrences with a tunable integer parameter, the method achieves up to 3× speedup over state-of-the-art solvers without sacrificing convergence, and is implemented in C++ with Eigen.", "summary_cn": "本文提出了一种增强循环坐标下降（ECCD）框架，用于弹性网惩罚的广义线性模型，通过在当前迭代点进行泰勒展开，将非线性梯度计算转化为高效的批量运算。通过可调整数参数展开向量递推，方法在保持收敛性的同时实现了约 3 倍的加速，并使用 C++ Eigen 实现。", "keywords": "elastic net, cyclic coordinate descent, optimization, linear models, regularization path, batched computation", "scoring": {"interpretability": 2, "understanding": 5, "safety": 1, "technicality": 8, "surprisal": 5}, "category": {"failure_mode_addressed": "non-applicable", "primary_focus": "other"}, "authors": ["Yixiao Wang", "Zishan Shao", "Ting Jiang", "Aditya Devarakonda"]}, "usage": {"completion_tokens": 509, "prompt_tokens": 3426, "total_tokens": 3935, "completion_tokens_details": {"accepted_prediction_tokens": null, "audio_tokens": null, "reasoning_tokens": 268, "rejected_prediction_tokens": null, "image_tokens": 0}, "prompt_tokens_details": {"audio_tokens": 0, "cached_tokens": 3152}, "cost": 0.00054776, "is_byok": false, "cost_details": {"upstream_inference_cost": null, "upstream_inference_prompt_cost": 0.00029326, "upstream_inference_completions_cost": 0.0002545}}, "model": "openai/gpt-oss-120b"}
{"timestamp": "2025-10-24T17:33:47.045784", "feed": "arxiv_cslg", "title": "Multimedia-Aware Question Answering: A Review of Retrieval and Cross-Modal Reasoning Architectures", "link": "https://papers.cool/arxiv/2510.20193", "analysis": {"summary": "This survey reviews recent advances in question answering systems that incorporate multimedia retrieval and cross‑modal reasoning, covering architectures that align vision, language, and audio modalities with user queries. The authors categorize approaches by retrieval methods, fusion techniques, and answer generation strategies, and discuss benchmarks, evaluation protocols, latency‑accuracy trade‑offs, and open challenges such as semantic grounding. The paper highlights future research directions for building more robust, context‑aware QA systems that can effectively leverage diverse multimedia data.", "summary_cn": "本文综述了将多媒体检索与跨模态推理相结合的问答系统的最新进展，涵盖了将视觉、语言和音频模态与用户查询对齐的架构。作者按检索方法、融合技术和答案生成策略进行分类，并讨论了基准数据集、评估协议、延迟‑精度权衡以及语义定位等关键挑战。文章指出了未来研究方向，旨在构建能够有效利用多种多媒体数据的更鲁棒、上下文感知的问答系统。", "keywords": "multimedia QA, cross-modal retrieval, multimodal fusion, vision-language, audio-visual reasoning, retrieval-augmented generation, benchmark datasets, semantic grounding, multimodal reasoning, QA systems", "scoring": {"interpretability": 3, "understanding": 6, "safety": 2, "technicality": 5, "surprisal": 4}, "category": {"failure_mode_addressed": "non-applicable", "primary_focus": "other"}, "authors": ["Rahul Raja", "Arpita Vats"]}, "usage": {"completion_tokens": 595, "prompt_tokens": 3347, "total_tokens": 3942, "completion_tokens_details": {"accepted_prediction_tokens": null, "audio_tokens": null, "reasoning_tokens": 286, "rejected_prediction_tokens": null, "image_tokens": 0}, "prompt_tokens_details": {"audio_tokens": 0, "cached_tokens": 3152}, "cost": 0.00057891, "is_byok": false, "cost_details": {"upstream_inference_cost": null, "upstream_inference_prompt_cost": 0.00028141, "upstream_inference_completions_cost": 0.0002975}}, "model": "openai/gpt-oss-120b"}
{"timestamp": "2025-10-24T17:33:47.154099", "feed": "arxiv_cslg", "title": "On the Structure of Stationary Solutions to McKean-Vlasov Equations with Applications to Noisy Transformers", "link": "https://papers.cool/arxiv/2510.20094", "analysis": {"summary": "The paper establishes an exact equivalence between stationary solutions of McKean-Vlasov equations on the circle and an infinite-dimensional quadratic system over Fourier coefficients, enabling explicit characterization of stationary states, local bifurcations, and resonance structures, including singular potentials. Analytic expressions are derived for various bifurcation types and their connection to discontinuous phase transitions, and global properties of the free energy landscape are proved. These results are applied to the Noisy Mean-Field Transformer model, revealing how the inverse temperature β shapes bifurcation geometry, produces multi‑mode metastable states, and triggers a sharp shift from continuous to first‑order phase behavior.", "summary_cn": "本文展示了圆上McKean-Vlasov方程的平稳解与傅里叶系数的无限维二次方程组之间的精确等价，从而在序列空间而非函数空间中显式描述平稳状态、局部分叉及共振结构（包括奇异势能）。作者推导了不同分叉类型（超临界、临界、亚临界、交叉）的解析表达式，并将其与不连续相变关联，同时证明了自由能全局凹凸性、最小化平稳测度的存在性与紧致性。随后将理论应用于噪声均场Transformer模型，阐明逆温度β如何影响从均匀分布的多重分叉几何、产生近似多模态的亚稳态，并在β增大时出现从连续到一级相变的锐利转变。", "keywords": "McKean-Vlasov, stationary solutions, Fourier coefficients, bifurcation, phase transition, noisy transformer, mean-field, metastable states, statistical mechanics", "scoring": {"interpretability": 2, "understanding": 8, "safety": 3, "technicality": 9, "surprisal": 7}, "category": {"failure_mode_addressed": "non-applicable", "primary_focus": "robustness"}, "authors": ["Krishnakumar Balasubramanian", "Sayan Banerjee", "Philippe Rigollet"]}, "usage": {"completion_tokens": 700, "prompt_tokens": 3524, "total_tokens": 4224, "completion_tokens_details": {"accepted_prediction_tokens": null, "audio_tokens": null, "reasoning_tokens": 279, "rejected_prediction_tokens": null, "image_tokens": 0}, "prompt_tokens_details": {"audio_tokens": 0, "cached_tokens": 3152}, "cost": 0.00065796, "is_byok": false, "cost_details": {"upstream_inference_cost": null, "upstream_inference_prompt_cost": 0.00030796, "upstream_inference_completions_cost": 0.00035}}, "model": "openai/gpt-oss-120b"}
{"timestamp": "2025-10-24T17:33:47.615241", "feed": "arxiv_cslg", "title": "PointMapPolicy: Structured Point Cloud Processing for Multi-Modal Imitation Learning", "link": "https://papers.cool/arxiv/2510.20406", "analysis": {"summary": "PointMapPolicy introduces a method that conditions diffusion policies on structured grids of points (point maps) without downsampling, enabling the use of standard computer vision techniques on 3D data. By fusing these point maps with RGB images via an xLSTM backbone, the approach achieves state-of-the-art performance on RoboCasa and CALVIN benchmarks and demonstrates strong real‑robot manipulation results.", "summary_cn": "PointMapPolicy 提出一种在不进行下采样的情况下，将扩散策略条件化于结构化点网格（point map）的方法，使得标准计算机视觉技术能够直接作用于三维数据。该方法利用 xLSTM 将点网格与 RGB 图像融合，在 RoboCasa 和 CALVIN 基准上实现了最新水平的表现，并在真实机器人上展现出优异的操作能力。", "keywords": "point cloud, structured point map, diffusion policy, multi-modal imitation learning, robotics manipulation, xLSTM, RoboCasa, CALVIN", "scoring": {"interpretability": 3, "understanding": 6, "safety": 3, "technicality": 8, "surprisal": 6}, "category": {"failure_mode_addressed": "non-applicable", "primary_focus": "robustness"}, "authors": ["Xiaogang Jia", "Qian Wang", "Anrui Wang", "Han A. Wang", "Balázs Gyenes", "Emiliyan Gospodinov", "Xinkai Jiang", "Ge Li", "Hongyi Zhou", "Weiran Liao", "Xi Huang", "Maximilian Beck", "Moritz Reuss", "Rudolf Lioutikov", "Gerhard Neumann"]}, "usage": {"completion_tokens": 730, "prompt_tokens": 3409, "total_tokens": 4139, "completion_tokens_details": {"accepted_prediction_tokens": null, "audio_tokens": null, "reasoning_tokens": 529, "rejected_prediction_tokens": null, "image_tokens": 0}, "prompt_tokens_details": {"audio_tokens": 0, "cached_tokens": 3152}, "cost": 0.00065571, "is_byok": false, "cost_details": {"upstream_inference_cost": null, "upstream_inference_prompt_cost": 0.00029071, "upstream_inference_completions_cost": 0.000365}}, "model": "openai/gpt-oss-120b"}
{"timestamp": "2025-10-24T17:33:47.930050", "feed": "arxiv_cslg", "title": "Some Attention is All You Need for Retrieval", "link": "https://papers.cool/arxiv/2510.19861", "analysis": {"summary": "The paper demonstrates that in hybrid SSM‑Transformer models, retrieval performance depends exclusively on self‑attention layers, with attention ablation causing complete failure while SSM layers provide no compensation. Sparsifying attention to a small subset of heads retains near‑perfect retrieval and high MMLU performance, indicating a functional specialization of attention for retrieval tasks. These findings reveal precise mechanistic requirements for retrieval and challenge the view of hybrid models as fully integrated systems.", "summary_cn": "本文表明，在混合 SSM‑Transformer 模型中，检索功能完全依赖自注意力层，去除注意力会导致检索彻底失败，而 SSM 层无法补偿。即使将注意力稀疏到仅 15% 的 heads，也能保持几乎完美的检索性能并保留 84% 的 MMLU 表现，说明注意力在检索任务中具有专门化的功能。该研究揭示了检索的精确机制需求，挑战了混合模型作为整体系统的假设，并对架构优化与可解释性具有重要意义。", "keywords": "retrieval, self-attention, SSM, hybrid architecture, functional segregation, mechanistic interpretability, attention sparsity, model ablation", "scoring": {"interpretability": 8, "understanding": 8, "safety": 3, "technicality": 7, "surprisal": 7}, "category": {"failure_mode_addressed": "non-applicable", "primary_focus": "interpretability"}, "authors": ["Felix Michalak", "Steven Abreu"]}, "usage": {"completion_tokens": 659, "prompt_tokens": 3352, "total_tokens": 4011, "completion_tokens_details": {"accepted_prediction_tokens": null, "audio_tokens": null, "reasoning_tokens": 402, "rejected_prediction_tokens": null, "image_tokens": 0}, "prompt_tokens_details": {"audio_tokens": 0, "cached_tokens": 3344}, "cost": 0.00059822, "is_byok": false, "cost_details": {"upstream_inference_cost": null, "upstream_inference_prompt_cost": 0.00026872, "upstream_inference_completions_cost": 0.0003295}}, "model": "openai/gpt-oss-120b"}
{"timestamp": "2025-10-24T17:33:48.130966", "feed": "arxiv_cslg", "title": "From Facts to Folklore: Evaluating Large Language Models on Bengali Cultural Knowledge", "link": "https://papers.cool/arxiv/2510.20043", "analysis": {"summary": "The paper introduces the Bengali Language Cultural Knowledge (BLanCK) dataset, which captures folk traditions, culinary arts, and regional dialects to assess large language models' cultural knowledge. Experiments reveal that current multilingual models perform well on non‑cultural tasks but struggle significantly on cultural items, and that providing contextual prompts improves performance across models. The authors argue for context‑aware architectures and culturally curated training data to close this gap.", "summary_cn": "本文推出了孟加拉语言文化知识（BLanCK）数据集，覆盖民俗、烹饪和方言等内容，用于评估大型语言模型的文化知识水平。实验表明，现有多语言模型在非文化任务上表现良好，但在文化项目上显著不足，提供上下文提示可提升所有模型的表现。作者主张采用上下文感知的架构并进行文化定制的训练，以弥合这一差距。", "keywords": "Bengali cultural knowledge, multilingual LLM evaluation, low-resource languages, cultural bias, BLanCK dataset, context-aware models, folk traditions, culinary arts, regional dialects", "scoring": {"interpretability": 2, "understanding": 6, "safety": 2, "technicality": 7, "surprisal": 5}, "category": {"failure_mode_addressed": "societal-disruption", "primary_focus": "other"}, "authors": ["Nafis Chowdhury", "Moinul Haque", "Anika Ahmed", "Nazia Tasnim", "Md. Istiak Hossain Shihab", "Sajjadur Rahman", "Farig Sadeque"]}, "usage": {"completion_tokens": 611, "prompt_tokens": 3318, "total_tokens": 3929, "completion_tokens_details": {"accepted_prediction_tokens": null, "audio_tokens": null, "reasoning_tokens": 331, "rejected_prediction_tokens": null, "image_tokens": 0}, "prompt_tokens_details": {"audio_tokens": 0, "cached_tokens": 3152}, "cost": 0.00058256, "is_byok": false, "cost_details": {"upstream_inference_cost": null, "upstream_inference_prompt_cost": 0.00027706, "upstream_inference_completions_cost": 0.0003055}}, "model": "openai/gpt-oss-120b"}
{"timestamp": "2025-10-24T17:33:48.143082", "feed": "arxiv_cslg", "title": "Throwing Vines at the Wall: Structure Learning via Random Search", "link": "https://papers.cool/arxiv/2510.20035", "analysis": {"summary": "The paper introduces random search algorithms for learning the structure of vine copulas, accompanied by a statistical framework based on model confidence sets that offers theoretical guarantees on selection probabilities and supports ensembling. Empirical evaluations on several real-world datasets demonstrate consistent performance improvements over existing state-of-the-art methods, including the traditional greedy algorithm.", "summary_cn": "本文提出了用于学习 vine copulas 结构的随机搜索算法，并基于模型置信集构建统计框架，提供了结构选择概率的理论保证并支持集成。实验证明，在多个真实数据集上，该方法相较于包括传统贪心算法在内的现有最先进方法表现出一致的优势。", "keywords": "vine copulas, structure learning, random search, model confidence sets, ensemble, multivariate dependence", "scoring": {"interpretability": 3, "understanding": 6, "safety": 1, "technicality": 8, "surprisal": 6}, "category": {"failure_mode_addressed": "non-applicable", "primary_focus": "other"}, "authors": ["Thibault Vatter", "Thomas Nagler"]}, "usage": {"completion_tokens": 574, "prompt_tokens": 3294, "total_tokens": 3868, "completion_tokens_details": {"accepted_prediction_tokens": null, "audio_tokens": null, "reasoning_tokens": 382, "rejected_prediction_tokens": null, "image_tokens": 0}, "prompt_tokens_details": {"audio_tokens": 0, "cached_tokens": 3152}, "cost": 0.00056046, "is_byok": false, "cost_details": {"upstream_inference_cost": null, "upstream_inference_prompt_cost": 0.00027346, "upstream_inference_completions_cost": 0.000287}}, "model": "openai/gpt-oss-120b"}
{"timestamp": "2025-10-24T17:33:48.224059", "feed": "arxiv_cslg", "title": "Enhancing Security in Deep Reinforcement Learning: A Comprehensive Survey on Adversarial Attacks and Defenses", "link": "https://papers.cool/arxiv/2510.20314", "analysis": {"summary": "This survey reviews adversarial attacks and defenses for deep reinforcement learning (DRL), outlining a classification framework based on perturbation type and attack target, and describing attacks on state, action, reward, and model spaces. It systematically summarizes robustness training strategies such as adversarial training, competitive training, detection, and defense distillation, discussing their advantages and limitations. The paper also highlights future research directions toward better generalization, lower computational cost, scalability, and explainability of DRL in adversarial settings.", "summary_cn": "本文综述了深度强化学习（DRL）在对抗攻击下的安全与鲁棒性研究，提出基于扰动类型和攻击目标的攻击分类框架，并详细介绍了对状态空间、动作空间、奖励函数和模型空间的攻击方法。系统总结了包括对抗训练、竞争训练、鲁棒学习、对抗检测、防御蒸馏等在内的鲁棒性训练策略，分析了各方法的优缺点。最后，文章展望了提升 DRL 在对抗环境中的泛化能力、降低计算复杂度、增强可扩展性和可解释性（explainability）的未来研究方向。", "keywords": "deep reinforcement learning, adversarial attacks, robustness, defense, adversarial training, detection, explainability, safety", "scoring": {"interpretability": 3, "understanding": 6, "safety": 8, "technicality": 5, "surprisal": 3}, "category": {"failure_mode_addressed": "human-misuse", "primary_focus": "robustness"}, "authors": ["Wu Yichao", "Wang Yirui", "Ding Panpan", "Wang Hailong", "Zhu Bingqian", "Liu Chun"]}, "usage": {"completion_tokens": 672, "prompt_tokens": 3472, "total_tokens": 4144, "completion_tokens_details": {"accepted_prediction_tokens": null, "audio_tokens": null, "reasoning_tokens": 363, "rejected_prediction_tokens": null, "image_tokens": 0}, "prompt_tokens_details": {"audio_tokens": 0, "cached_tokens": 3152}, "cost": 0.00063616, "is_byok": false, "cost_details": {"upstream_inference_cost": null, "upstream_inference_prompt_cost": 0.00030016, "upstream_inference_completions_cost": 0.000336}}, "model": "openai/gpt-oss-120b"}
{"timestamp": "2025-10-24T17:33:48.269716", "feed": "arxiv_cslg", "title": "BIOCAP: Exploiting Synthetic Captions Beyond Labels in Biological Foundation Models", "link": "https://papers.cool/arxiv/2510.20095", "analysis": {"summary": "The paper introduces BIOCAP, a biological foundation model that incorporates synthetic, instance-specific captions generated by multimodal large language models to supplement traditional label supervision. By aligning images and captions within a shared latent morphospace, the approach improves species classification and text-image retrieval performance while mitigating spurious correlations. The study demonstrates that descriptive captions provide valuable semantic information beyond mere labels in biological multimodal learning.", "summary_cn": "本文提出 BIOCAP，一种利用多模态大型语言模型生成的合成实例级描述性字幕，补充传统标签监督的生物学基础模型。通过在共享潜在形态空间内对齐图像和字幕，该方法提升了物种分类和文本-图像检索的性能，同时抑制了虚假关联。研究表明，描述性字幕在生物多模态学习中提供了超越标签的丰富语义信息。", "keywords": "synthetic captions, multimodal large language models, BIOCAP, biological foundation models, species classification, image-text retrieval, caption generation, dataset augmentation, multimodal supervision", "scoring": {"interpretability": 3, "understanding": 6, "safety": 2, "technicality": 7, "surprisal": 6}, "category": {"failure_mode_addressed": "non-applicable", "primary_focus": "other"}, "authors": ["Ziheng Zhang", "Xinyue Ma", "Arpita Chowdhury", "Elizabeth G. Campolongo", "Matthew J. Thompson", "Net Zhang", "Samuel Stevens", "Hilmar Lapp", "Tanya Berger-Wolf", "Yu Su", "Wei-Lun Chao", "Jianyang Gu"]}, "usage": {"completion_tokens": 684, "prompt_tokens": 3406, "total_tokens": 4090, "completion_tokens_details": {"accepted_prediction_tokens": null, "audio_tokens": null, "reasoning_tokens": 485, "rejected_prediction_tokens": null, "image_tokens": 0}, "prompt_tokens_details": {"audio_tokens": 0, "cached_tokens": 3152}, "cost": 0.00063226, "is_byok": false, "cost_details": {"upstream_inference_cost": null, "upstream_inference_prompt_cost": 0.00029026, "upstream_inference_completions_cost": 0.000342}}, "model": "openai/gpt-oss-120b"}
{"timestamp": "2025-10-24T17:33:48.492474", "feed": "arxiv_cslg", "title": "Learning Decentralized Routing Policies via Graph Attention-based Multi-Agent Reinforcement Learning in Lunar Delay-Tolerant Networks", "link": "https://papers.cool/arxiv/2510.20436", "analysis": {"summary": "The paper introduces a fully decentralized routing framework for lunar delay‑tolerant networks using a graph‑attention based multi‑agent reinforcement learning policy trained centrally and executed locally. It formulates routing as a POMDP, avoids global topology updates and packet duplication, and demonstrates higher delivery rates and scalability in Monte‑Carlo simulations of rover teams.", "summary_cn": "本文提出一种基于图注意力的多智能体强化学习（GAT‑MARL）的全去中心化路由框架，用于月面延迟容忍网络（LDTN）。该方法将路由问题建模为部分可观测马尔可夫决策过程（POMDP），在不需要全局拓扑更新或数据包复制的情况下，实现中心化训练、去中心化执行，并在蒙特卡罗仿真中显示出更高的数据交付率和良好的可扩展性。", "keywords": "graph attention networks, multi-agent reinforcement learning, delay-tolerant networks, decentralized routing, lunar exploration, POMDP, space robotics", "scoring": {"interpretability": 2, "understanding": 5, "safety": 3, "technicality": 8, "surprisal": 6}, "category": {"failure_mode_addressed": "non-applicable", "primary_focus": "control"}, "authors": ["Federico Lozano-Cuadra", "Beatriz Soret", "Marc Sanchez Net", "Abhishek Cauligi", "Federico Rossi"]}, "usage": {"completion_tokens": 983, "prompt_tokens": 3396, "total_tokens": 4379, "completion_tokens_details": {"accepted_prediction_tokens": null, "audio_tokens": null, "reasoning_tokens": 814, "rejected_prediction_tokens": null, "image_tokens": 0}, "prompt_tokens_details": {"audio_tokens": 0, "cached_tokens": 3152}, "cost": 0.00078026, "is_byok": false, "cost_details": {"upstream_inference_cost": null, "upstream_inference_prompt_cost": 0.00028876, "upstream_inference_completions_cost": 0.0004915}}, "model": "openai/gpt-oss-120b"}
{"timestamp": "2025-10-24T17:33:48.678562", "feed": "arxiv_cslg", "title": "Deep Sequence-to-Sequence Models for GNSS Spoofing Detection", "link": "https://papers.cool/arxiv/2510.19890", "analysis": {"summary": "The paper introduces a data generation framework for simulating GNSS spoofing attacks worldwide and applies deep sequence-to-sequence models, including LSTM and Transformer-inspired architectures, for online spoofing detection. Experiments show that the Transformer-based model with early input fusion achieves an error rate of 0.16%, outperforming other baselines.", "summary_cn": "本文提出了一套用于在全球范围内模拟 GNSS 欺骗攻击的数据生成框架，并使用深度序列到序列模型（包括 LSTM 与受 Transformer 启发的架构）进行在线欺骗检测。实验表明，采用早期特征融合的 Transformer 模型将错误率降低至 0.16%，优于其他基线方法。", "keywords": "GNSS spoofing detection, sequence-to-sequence, LSTM, Transformer, online detection, data generation, cybersecurity", "scoring": {"interpretability": 2, "understanding": 5, "safety": 7, "technicality": 7, "surprisal": 6}, "category": {"failure_mode_addressed": "human-misuse", "primary_focus": "other"}, "authors": ["Jan Zelinka", "Oliver Kost", "Marek Hrúz"]}, "usage": {"completion_tokens": 601, "prompt_tokens": 3296, "total_tokens": 3897, "completion_tokens_details": {"accepted_prediction_tokens": null, "audio_tokens": null, "reasoning_tokens": 393, "rejected_prediction_tokens": null, "image_tokens": 0}, "prompt_tokens_details": {"audio_tokens": 0, "cached_tokens": 3152}, "cost": 0.00057426, "is_byok": false, "cost_details": {"upstream_inference_cost": null, "upstream_inference_prompt_cost": 0.00027376, "upstream_inference_completions_cost": 0.0003005}}, "model": "openai/gpt-oss-120b"}
{"timestamp": "2025-10-24T17:33:49.024574", "feed": "arxiv_cslg", "title": "ComProScanner: A multi-agent based framework for composition-property structured data extraction from scientific literature", "link": "https://papers.cool/arxiv/2510.20362", "analysis": {"summary": "ComProScanner is a multi-agent framework that autonomously extracts, validates, classifies, and visualises machine‑readable chemical compositions and properties from scientific literature, demonstrated on ceramic piezoelectric materials and their d33 coefficients. Evaluation on 100 journal articles against ten LLMs shows DeepSeek‑V3‑0324 achieving the highest overall accuracy of 0.82. The system offers a user‑friendly package for building structured datasets for downstream machine‑learning applications.", "summary_cn": "本文提出 ComProScanner，一个基于多智能体的框架，用于从学术文献中自动提取化学成分和性质数据，并实现验证、分类和可视化，重点针对陶瓷压电材料及其压电应变系数 d33 的数据。通过在 100 篇期刊文章上比较 10 种大型语言模型，发现 DeepSeek‑V3‑0324 达到 0.82 的整体准确率。该系统提供了一个易用的工具，帮助构建机器学习所需的结构化实验数据集。", "keywords": "multi-agent, structured data extraction, chemical composition, property extraction, large language models, material informatics, piezoelectric, dataset generation", "scoring": {"interpretability": 2, "understanding": 6, "safety": 1, "technicality": 7, "surprisal": 5}, "category": {"failure_mode_addressed": "non-applicable", "primary_focus": "other"}, "authors": ["Aritra Roy", "Enrico Grisan", "John Buckeridge", "Chiara Gattinoni"]}, "usage": {"completion_tokens": 920, "prompt_tokens": 3412, "total_tokens": 4332, "completion_tokens_details": {"accepted_prediction_tokens": null, "audio_tokens": null, "reasoning_tokens": 697, "rejected_prediction_tokens": null, "image_tokens": 0}, "prompt_tokens_details": {"audio_tokens": 0, "cached_tokens": 3152}, "cost": 0.00075116, "is_byok": false, "cost_details": {"upstream_inference_cost": null, "upstream_inference_prompt_cost": 0.00029116, "upstream_inference_completions_cost": 0.00046}}, "model": "openai/gpt-oss-120b"}
{"timestamp": "2025-10-24T17:33:49.159259", "feed": "arxiv_cslg", "title": "Compositional Generation for Long-Horizon Coupled PDEs", "link": "https://papers.cool/arxiv/2510.20141", "analysis": {"summary": "The paper proposes a compositional diffusion strategy for simulating long-horizon coupled partial differential equations (PDEs) by training diffusion models solely on decoupled data and composing them at inference time. Experiments on reaction‑diffusion and modified Burgers systems show that, despite only seeing decoupled training data, the compositional models achieve low error over many time steps, with v‑parameterization improving accuracy, though a Fourier Neural Operator trained on coupled data remains the strongest baseline.", "summary_cn": "本文提出了一种组合扩散方法，用于长时间跨度的耦合偏微分方程（PDE）模拟，即仅在解耦数据上训练扩散模型并在推理时进行组合。实验在反应扩散和改进的 Burgers 系统上表明，尽管只使用了解耦训练数据，组合模型仍能在大量时间步上恢复耦合轨迹且误差较低，v 参数化提升了精度，但在耦合数据上训练的 Fourier 神经算子仍表现最优。", "keywords": "compositional diffusion, coupled PDEs, long-horizon modeling, v-parameterization, Euler scheme, Fourier Neural Operator, surrogate modeling", "scoring": {"interpretability": 2, "understanding": 6, "safety": 2, "technicality": 8, "surprisal": 7}, "category": {"failure_mode_addressed": "non-applicable", "primary_focus": "other"}, "authors": ["Somayajulu L. N. Dhulipala", "Deep Ray", "Nicholas Forman"]}, "usage": {"completion_tokens": 676, "prompt_tokens": 3426, "total_tokens": 4102, "completion_tokens_details": {"accepted_prediction_tokens": null, "audio_tokens": null, "reasoning_tokens": 398, "rejected_prediction_tokens": null, "image_tokens": 0}, "prompt_tokens_details": {"audio_tokens": 0, "cached_tokens": 3152}, "cost": 0.00063126, "is_byok": false, "cost_details": {"upstream_inference_cost": null, "upstream_inference_prompt_cost": 0.00029326, "upstream_inference_completions_cost": 0.000338}}, "model": "openai/gpt-oss-120b"}
{"timestamp": "2025-10-24T17:33:49.493218", "feed": "arxiv_cslg", "title": "SSL-SE-EEG: A Framework for Robust Learning from Unlabeled EEG Data with Self-Supervised Learning and Squeeze-Excitation Networks", "link": "https://papers.cool/arxiv/2510.19829", "analysis": {"summary": "The paper presents SSL-SE-EEG, a framework that combines self-supervised learning with squeeze-and-excitation networks to transform EEG signals into 2D representations and improve robustness to noise and data scarcity. Experiments on four public EEG datasets show state-of-the-art classification accuracies, demonstrating its suitability for real-time brain-computer interface applications.", "summary_cn": "本文提出 SSL-SE-EEG 框架，将自监督学习与 Squeeze‑and‑Excitation 网络结合，将 EEG 信号转化为二维图像表示，从而提升特征提取的噪声鲁棒性并降低对标注数据的依赖。对 MindBigData、TUH‑AB、SEED‑IV 与 BCI‑IV 四个数据集的实验显示其分类准确率达到业界领先水平，适用于实时脑机接口应用。", "keywords": "self-supervised learning, squeeze-and-excitation networks, EEG, brain-computer interface, noise robustness, feature extraction, deep learning, biomedical signal processing", "scoring": {"interpretability": 2, "understanding": 4, "safety": 2, "technicality": 6, "surprisal": 5}, "category": {"failure_mode_addressed": "non-applicable", "primary_focus": "robustness"}, "authors": ["Meghna Roy Chowdhury", "Yi Ding", "Shreyas Sen"]}, "usage": {"completion_tokens": 593, "prompt_tokens": 3417, "total_tokens": 4010, "completion_tokens_details": {"accepted_prediction_tokens": null, "audio_tokens": null, "reasoning_tokens": 364, "rejected_prediction_tokens": null, "image_tokens": 0}, "prompt_tokens_details": {"audio_tokens": 0, "cached_tokens": 3152}, "cost": 0.00058841, "is_byok": false, "cost_details": {"upstream_inference_cost": null, "upstream_inference_prompt_cost": 0.00029191, "upstream_inference_completions_cost": 0.0002965}}, "model": "openai/gpt-oss-120b"}
{"timestamp": "2025-10-24T17:33:49.547999", "feed": "arxiv_cslg", "title": "Compressing Biology: Evaluating the Stable Diffusion VAE for Phenotypic Drug Discovery", "link": "https://papers.cool/arxiv/2510.19887", "analysis": {"summary": "The paper systematically evaluates the Stable Diffusion variational autoencoder (SD-VAE) for reconstructing Cell Painting microscopy images, showing that reconstructions retain phenotypic signals with minimal loss. It benchmarks reconstruction quality using pixel-level, embedding-based, latent-space, and retrieval metrics, finding that general‑purpose feature extractors like InceptionV3 often match or exceed specialized models. The results provide practical guidelines for using off‑the‑shelf generative models in high‑throughput phenotypic drug discovery pipelines.", "summary_cn": "本文系统评估了 Stable Diffusion 变分自编码器（SD‑VAE）在 Cell Painting 显微镜图像上的重建性能，发现其重建能够以极小的损失保留表型信号。通过像素层面、嵌入层、潜在空间以及检索等多种度量指标进行基准测试，结果表明通用特征提取器（如 InceptionV3）在检索任务上常常能够匹配或超越专用模型。该研究为在高通量表型药物发现工作流中使用现成生成模型提供了实用指南。", "keywords": "stable diffusion, variational autoencoder, phenotypic drug discovery, cell painting, microscopy images, generative models, reconstruction evaluation, embedding metrics", "scoring": {"interpretability": 3, "understanding": 6, "safety": 2, "technicality": 7, "surprisal": 5}, "category": {"failure_mode_addressed": "non-applicable", "primary_focus": "other"}, "authors": ["Télio Cropsal", "Rocío Mercado"]}, "usage": {"completion_tokens": 685, "prompt_tokens": 3402, "total_tokens": 4087, "completion_tokens_details": {"accepted_prediction_tokens": null, "audio_tokens": null, "reasoning_tokens": 397, "rejected_prediction_tokens": null, "image_tokens": 0}, "prompt_tokens_details": {"audio_tokens": 0, "cached_tokens": 3152}, "cost": 0.00063216, "is_byok": false, "cost_details": {"upstream_inference_cost": null, "upstream_inference_prompt_cost": 0.00028966, "upstream_inference_completions_cost": 0.0003425}}, "model": "openai/gpt-oss-120b"}
{"timestamp": "2025-10-24T17:33:49.849524", "feed": "arxiv_cslg", "title": "AsyncHZP: Hierarchical ZeRO Parallelism with Asynchronous Scheduling for Scalable LLM Training", "link": "https://papers.cool/arxiv/2510.20111", "analysis": {"summary": "The paper introduces AsyncHZP, an asynchronous hierarchical variant of the Zero Redundancy Optimizer (ZeRO) that reshards parameters, gradients, and optimizer states across replica groups to reduce communication overhead and improve memory utilization. It also proposes a multi‑stream asynchronous scheduling system that overlaps all‑gather and reduce‑scatter operations with computation using background threads. Experiments on dense and Mixture‑of‑Experts language models show that AsyncHZP achieves state‑of‑the‑art training speed and scalability compared to traditional tensor‑parallel approaches while maintaining stability.", "summary_cn": "本文提出 AsyncHZP，这是一种异步层次化的 ZeRO（Zero Redundancy Optimizer）变体，通过在不同副本组之间重新分片参数、梯度和优化器状态来降低通信开销并提升内存利用率。论文还设计了多流异步调度机制，在后台线程中将参数 all‑gather 与梯度 reduce‑scatter 与计算并行执行，实现通信与计算的重叠。针对密集模型和混合专家（Mixture‑of‑Experts性的前提下，显著提升训练速度并超越传统张量并行（ND）方法的可扩展性。", "keywords": "hierarchical ZeRO, asynchronous scheduling, large language model training, model parallelism, Mixture-of-Experts, communication optimization, zero redundancy optimizer", "scoring": {"interpretability": 2, "understanding": 6, "safety": 3, "technicality": 8, "surprisal": 7}, "category": {"failure_mode_addressed": "non-applicable", "primary_focus": "other"}, "authors": ["Huawei Bai", "Yifan Huang", "Wenqi Shi", "Ansheng You", "Feifan Shao", "Tengfei Han", "Minghui Yu"]}, "usage": {"completion_tokens": 744, "prompt_tokens": 3442, "total_tokens": 4186, "completion_tokens_details": {"accepted_prediction_tokens": null, "audio_tokens": null, "reasoning_tokens": 432, "rejected_prediction_tokens": null, "image_tokens": 0}, "prompt_tokens_details": {"audio_tokens": 0, "cached_tokens": 3152}, "cost": 0.00066766, "is_byok": false, "cost_details": {"upstream_inference_cost": null, "upstream_inference_prompt_cost": 0.00029566, "upstream_inference_completions_cost": 0.000372}}, "model": "openai/gpt-oss-120b"}
{"timestamp": "2025-10-24T17:33:49.961838", "feed": "arxiv_cslg", "title": "MemER: Scaling Up Memory for Robot Control via Experience Retrieval", "link": "https://papers.cool/arxiv/2510.20328", "analysis": {"summary": "MemER introduces a hierarchical policy that enables robots to retrieve and use relevant past experiences as keyframes, allowing efficient reasoning over long-horizon dependencies. The high-level policy selects keyframes and combines them with recent observations to generate text instructions for a low-level policy, and the method scales memory to minutes using fine-tuned vision-language-action models. Experiments on three real-world manipulation tasks show that MemER outperforms prior approaches.", "summary_cn": "MemER 提出一种层次化策略框架，使机器人能够检索并利用先前的关键帧经验，从而高效推理长期依赖。高层策略选取关键帧并与最新观测结合，生成用于低层策略执行的文本指令，在大规模视觉-语言-动作模型上进行微调，实现分钟级记忆。实验在三个真实的长时间操作任务上显示，MemER 超越了已有方法。", "keywords": "memory retrieval, hierarchical policy, robot manipulation, long-horizon control, vision-language-action, experience keyframes, large language model, Qwen2.5-VL, policy scaling", "scoring": {"interpretability": 3, "understanding": 7, "safety": 4, "technicality": 7, "surprisal": 6}, "category": {"failure_mode_addressed": "non-applicable", "primary_focus": "control"}, "authors": ["Ajay Sridhar", "Jennifer Pan", "Satvik Sharma", "Chelsea Finn"]}, "usage": {"completion_tokens": 965, "prompt_tokens": 3421, "total_tokens": 4386, "completion_tokens_details": {"accepted_prediction_tokens": null, "audio_tokens": null, "reasoning_tokens": 803, "rejected_prediction_tokens": null, "image_tokens": 0}, "prompt_tokens_details": {"audio_tokens": 0, "cached_tokens": 3152}, "cost": 0.00077501, "is_byok": false, "cost_details": {"upstream_inference_cost": null, "upstream_inference_prompt_cost": 0.00029251, "upstream_inference_completions_cost": 0.0004825}}, "model": "openai/gpt-oss-120b"}
{"timestamp": "2025-10-24T17:33:49.968763", "feed": "arxiv_cslg", "title": "Multi-Resolution Analysis of the Convective Structure of Tropical Cyclones for Short-Term Intensity Guidance", "link": "https://papers.cool/arxiv/2510.19854", "analysis": {"summary": "The paper introduces a concise, interpretable method that uses discrete wavelet transform based multi-resolution analysis (MRA) to quantify fine-scale convective structures of tropical cyclones from satellite imagery, identifying features that strongly correlate with rapid intensity changes. It demonstrates how these physically meaningful descriptors can improve short‑term (24‑hour) intensity forecasts and serve as inputs for deep‑learning models that provide intensity guidance.", "summary_cn": "本文提出一种简洁且可解释的方法，利用离散小波变换的多分辨率分析（MRA）量化热带气旋卫星图像中的细尺度对流结构，识别出与快速强度变化高度相关的物理特征。研究表明，这些特征可提升 24 小时短期强度预测，并可作为深度学习模型的输入，以提供强度指导。", "keywords": "tropical cyclone, intensity forecasting, multi-resolution analysis, discrete wavelet transform, satellite imagery, convective structure, short-term guidance, deep learning", "scoring": {"interpretability": 4, "understanding": 7, "safety": 3, "technicality": 7, "surprisal": 6}, "category": {"failure_mode_addressed": "non-applicable", "primary_focus": "interpretability"}, "authors": ["Elizabeth Cucuzzella", "Tria McNeely", "Kimberly Wood", "Ann B. Lee"]}, "usage": {"completion_tokens": 693, "prompt_tokens": 3336, "total_tokens": 4029, "completion_tokens_details": {"accepted_prediction_tokens": null, "audio_tokens": null, "reasoning_tokens": 495, "rejected_prediction_tokens": null, "image_tokens": 0}, "prompt_tokens_details": {"audio_tokens": 0, "cached_tokens": 3152}, "cost": 0.00062626, "is_byok": false, "cost_details": {"upstream_inference_cost": null, "upstream_inference_prompt_cost": 0.00027976, "upstream_inference_completions_cost": 0.0003465}}, "model": "openai/gpt-oss-120b"}
{"timestamp": "2025-10-24T17:33:50.107464", "feed": "arxiv_cslg", "title": "Reinforcement Learning and Consumption-Savings Behavior", "link": "https://papers.cool/arxiv/2510.20748", "analysis": {"summary": "The paper presents a reinforcement‑learning model in which agents use Q‑learning with neural‑network function approximation to make consumption‑savings decisions under income uncertainty. It shows that this adaptive learning mechanism can simultaneously generate higher marginal propensities to consume for liquidity‑constrained households and a persistent \"scarring\" effect for those with past unemployment, matching recent empirical findings. Simulation results suggest that value‑function approximation errors driven by experience provide a unified explanation for these phenomena beyond standard rational‑expectations models.", "summary_cn": "本文构建了一个强化学习模型，使用带神经网络近似的 Q 学习来决定在收入不确定性下的消费‑储蓄行为。模型能够同时解释两大经验现象：流动性较低的失业家庭对刺激转移的边际消费倾向（MPC）更高，以及拥有更多失业经历的家庭在控制当前疤痕”效应），并与最新实证结果高度吻合。仿真表明，价值函数近似误差随经验演化提供了超越传统理性预期的统一解释框架。", "keywords": "reinforcement learning, consumption-savings, Q-learning, neural network approximation, marginal propensity to consume, scarring effect, adaptive learning, economic downturn", "scoring": {"interpretability": 2, "understanding": 5, "safety": 2, "technicality": 7, "surprisal": 6}, "category": {"failure_mode_addressed": "non-applicable", "primary_focus": "other"}, "authors": ["Brandon Kaplowitz"]}, "usage": {"completion_tokens": 724, "prompt_tokens": 3430, "total_tokens": 4154, "completion_tokens_details": {"accepted_prediction_tokens": null, "audio_tokens": null, "reasoning_tokens": 425, "rejected_prediction_tokens": null, "image_tokens": 0}, "prompt_tokens_details": {"audio_tokens": 0, "cached_tokens": 3152}, "cost": 0.00065586, "is_byok": false, "cost_details": {"upstream_inference_cost": null, "upstream_inference_prompt_cost": 0.00029386, "upstream_inference_completions_cost": 0.000362}}, "model": "openai/gpt-oss-120b"}
{"timestamp": "2025-10-24T17:33:50.343034", "feed": "arxiv_cslg", "title": "Simultaneously Solving Infinitely Many LQ Mean Field Games In Hilbert Spaces: The Power of Neural Operators", "link": "https://papers.cool/arxiv/2510.20017", "analysis": {"summary": "The paper proposes training neural operators to learn the mapping from dynamics and cost functionals (the \"rules\") to equilibrium strategies for linear‑quadratic mean field games defined on separable Hilbert spaces. It provides a statistical guarantee that a neural operator trained on a limited set of sampled rules can reliably solve unseen variants, supported by local‑Lipschitz estimates, a universal approximation theorem with controlled Lipschitz regularity, and new infinite‑dimensional sample‑complexity bounds.", "summary_cn": "本文提出使用神经算子学习线性‑二次均场博弈（在可分 Hilbert 空间上）的规则到均衡映射，即从动力学和代价提供统计保证，证明在少量随机采样规则上训练的神经算子能够可靠求解未见的游戏变体，核心技术包括对高度非线性映射的局部 Lipschitz 估计、具有受控 Lipschitz 常数的通用逼近定理，以及针对无限维空间的样本复杂度界。", "keywords": "neural operators, linear-quadratic mean field games, Hilbert spaces, infinite-dimensional analysis, Lipschitz continuity, universal approximation, sample complexity", "scoring": {"interpretability": 2, "understanding": 6, "safety": 2, "technicality": 9, "surprisal": 7}, "category": {"failure_mode_addressed": "non-applicable", "primary_focus": "other"}, "authors": ["Dena Firoozi", "Anastasis Kratsios", "Xuwei Yang"]}, "usage": {"completion_tokens": 660, "prompt_tokens": 3475, "total_tokens": 4135, "completion_tokens_details": {"accepted_prediction_tokens": null, "audio_tokens": null, "reasoning_tokens": 369, "rejected_prediction_tokens": null, "image_tokens": 0}, "prompt_tokens_details": {"audio_tokens": 0, "cached_tokens": 3152}, "cost": 0.00063061, "is_byok": false, "cost_details": {"upstream_inference_cost": null, "upstream_inference_prompt_cost": 0.00030061, "upstream_inference_completions_cost": 0.00033}}, "model": "openai/gpt-oss-120b"}
{"timestamp": "2025-10-24T17:33:50.432836", "feed": "arxiv_cslg", "title": "Low-Latency Neural Inference on an Edge Device for Real-Time Handwriting Recognition from EEG Signals", "link": "https://papers.cool/arxiv/2510.19832", "analysis": {"summary": "The paper introduces EEdGeNet, a hybrid Temporal Convolutional Network and MLP architecture that decodes imagined handwriting from non‑invasive 32‑channel EEG using 85 engineered features, achieving 89.83% accuracy with sub‑second latency on an NVIDIA Jetson TX2. By selecting ten key features the latency drops to 202 ms with minimal accuracy loss, demonstrating feasible real‑time, portable BCI communication.", "summary_cn": "本文提出 EEdGeNet——一种结合时序卷积网络和多层感知器的混合模型，通过对 32 通道 EEG 提取的 85 项时频图特征进行解码，实现了想象手写字符的实时识别，在 NVIDIA Jetson TX2 上达到 89.83% 的准确率和约 914 ms 的单字符延迟。精选十个关键特征后，延迟降至 202 ms，准确率几乎不受影响，展示了非侵入式 BCI 在便携实时通信中的可行性。", "keywords": "EEG, brain-computer interface, handwritten character decoding, low-latency inference, edge device, Temporal Convolutional Network, feature extraction, real-time BCI", "scoring": {"interpretability": 3, "understanding": 6, "safety": 2, "technicality": 6, "surprisal": 7}, "category": {"failure_mode_addressed": "non-applicable", "primary_focus": "other"}, "authors": ["Ovishake Sen", "Raghav Soni", "Darpan Virmani", "Akshar Parekh", "Patrick Lehman", "Sarthak Jena", "Adithi Katikhaneni", "Adam Khalifa", "Baibhab Chatterjee"]}, "usage": {"completion_tokens": 736, "prompt_tokens": 3492, "total_tokens": 4228, "completion_tokens_details": {"accepted_prediction_tokens": null, "audio_tokens": null, "reasoning_tokens": 468, "rejected_prediction_tokens": null, "image_tokens": 0}, "prompt_tokens_details": {"audio_tokens": 0, "cached_tokens": 3152}, "cost": 0.00067116, "is_byok": false, "cost_details": {"upstream_inference_cost": null, "upstream_inference_prompt_cost": 0.00030316, "upstream_inference_completions_cost": 0.000368}}, "model": "openai/gpt-oss-120b"}
{"timestamp": "2025-10-24T17:33:50.530424", "feed": "arxiv_cslg", "title": "LLMs can hide text in other text of the same length.ipynb", "link": "https://papers.cool/arxiv/2510.20075", "analysis": {"summary": "The paper introduces a simple protocol that uses large language models to embed a meaningful text within another coherent text of the same length, enabling covert communication while preserving surface plausibility. Experiments show that even modest 8‑billion‑parameter open‑source LLMs can encode and decode messages locally in seconds, highlighting a radical decoupling of text from authorial intent. The authors discuss the safety implications, including the potential for covert deployment of unfiltered models and the erosion of trust in written communication.", "summary_cn": "本文提出一种利用大型语言模型（LLM）在相同长度的另一段连上看似合乎情理的隐蔽通信。实验表明，即使是 8 十亿参数的开源 LLM，也能在本地笔记本电脑上在数秒内完成编码与解码，显示出文本与作者意图的彻底解耦。作者进一步讨论了安全风险，如通过安全模型的合规回复隐藏未过滤模型的答案，以及这对书面交流可信度的冲击。", "keywords": "LLM steganography, text hiding, covert communication, AI safety, deceptive alignment, model misuse, encoding protocol, trust erosion, adversarial use", "scoring": {"interpretability": 2, "understanding": 6, "safety": 8, "technicality": 7, "surprisal": 8}, "category": {"failure_mode_addressed": "human-misuse", "primary_focus": "control"}, "authors": ["Antonio Norelli", "Michael Bronstein"]}, "usage": {"completion_tokens": 791, "prompt_tokens": 3417, "total_tokens": 4208, "completion_tokens_details": {"accepted_prediction_tokens": null, "audio_tokens": null, "reasoning_tokens": 510, "rejected_prediction_tokens": null, "image_tokens": 0}, "prompt_tokens_details": {"audio_tokens": 0, "cached_tokens": 3152}, "cost": 0.00068741, "is_byok": false, "cost_details": {"upstream_inference_cost": null, "upstream_inference_prompt_cost": 0.00029191, "upstream_inference_completions_cost": 0.0003955}}, "model": "openai/gpt-oss-120b"}
{"timestamp": "2025-10-24T17:33:50.797177", "feed": "arxiv_cslg", "title": "Neural Networks for Censored Expectile Regression Based on Data Augmentation", "link": "https://papers.cool/arxiv/2510.20344", "analysis": {"summary": "The paper introduces DAERNN, a data‑augmentation based neural network algorithm for censored expectile regression that handles heterogeneous censored observations without explicit parametric assumptions. Simulation studies and real‑world applications show that DAERNN outperforms existing censored ERNN methods and matches the predictive quality of models trained on fully observed data.", "summary_cn": "本文提出了 DAERNN，一种基于数据增强的神经网络算法，用于在不做显式参数假设的情况下处理异质的删失期望分位回归问题。实验模拟和真实数据案例表明，DAERNN 在预测性能上优于现有删失 ERNN 方法，且可与在完整观测数据上训练的模型相媲美。", "keywords": "expectile regression, neural networks, censored data, data augmentation, heterogeneity, nonparametric modeling, predictive performance, survival analysis", "scoring": {"interpretability": 2, "understanding": 5, "safety": 1, "technicality": 7, "surprisal": 5}, "category": {"failure_mode_addressed": "non-applicable", "primary_focus": "other"}, "authors": ["Wei Cao", "Shanshan Wang"]}, "usage": {"completion_tokens": 612, "prompt_tokens": 3351, "total_tokens": 3963, "completion_tokens_details": {"accepted_prediction_tokens": null, "audio_tokens": null, "reasoning_tokens": 415, "rejected_prediction_tokens": null, "image_tokens": 0}, "prompt_tokens_details": {"audio_tokens": 0, "cached_tokens": 3152}, "cost": 0.00058801, "is_byok": false, "cost_details": {"upstream_inference_cost": null, "upstream_inference_prompt_cost": 0.00028201, "upstream_inference_completions_cost": 0.000306}}, "model": "openai/gpt-oss-120b"}
{"timestamp": "2025-10-24T17:33:50.813714", "feed": "arxiv_cslg", "title": "On Encoding Matrices using Quantum Circuits", "link": "https://papers.cool/arxiv/2510.20030", "analysis": {"summary": "The paper systematically studies how to encode matrices as quantum circuits using block encodings and state preparation circuits. It presents a general efficient method to construct a block encoding from a classical description stored in RAM, and low‑overhead bidirectional conversion algorithms showing the two representations are essentially equivalent, based on a constant‑depth multiplexer for higher‑order Pauli matrices and a quantum basis‑conversion algorithm.", "summary_cn": "本文系统研究将矩阵以块编码。提出一种在经典随机存取存储器中给定矩阵的通用高效块编码构造方法，并提供低开销、双向的块编码与状态准备电路之间的转换算法，展示两种模型本质上等价。关键技术包括常数深度的多路复用器用于同时复用高阶 Pauli 矩阵，以及在标准基和 Pauli 基之间进行矩阵展开的量子转换算法。", "keywords": "quantum block encoding, state preparation circuits, quantum linear algebra, Pauli decomposition, quantum multiplexer, matrix encoding, quantum algorithm", "scoring": {"interpretability": 1, "understanding": 5, "safety": 1, "technicality": 8, "surprisal": 6}, "category": {"failure_mode_addressed": "non-applicable", "primary_focus": "other"}, "authors": ["Liron Mor Yosef", "Haim Avron"]}, "usage": {"completion_tokens": 691, "prompt_tokens": 3464, "total_tokens": 4155, "completion_tokens_details": {"accepted_prediction_tokens": null, "audio_tokens": null, "reasoning_tokens": 448, "rejected_prediction_tokens": null, "image_tokens": 0}, "prompt_tokens_details": {"audio_tokens": 0, "cached_tokens": 3152}, "cost": 0.00064446, "is_byok": false, "cost_details": {"upstream_inference_cost": null, "upstream_inference_prompt_cost": 0.00029896, "upstream_inference_completions_cost": 0.0003455}}, "model": "openai/gpt-oss-120b"}
{"timestamp": "2025-10-24T17:33:50.854207", "feed": "arxiv_cslg", "title": "SecureInfer: Heterogeneous TEE-GPU Architecture for Privacy-Critical Tensors for Large Language Model Deployment", "link": "https://papers.cool/arxiv/2510.19979", "analysis": {"summary": "SecureInfer introduces a heterogeneous architecture that combines Trusted Execution Environments (SGX) with GPUs to protect privacy‑critical components of large language models during on‑device inference. By partitioning non‑linear layers and adapters into an enclave while encrypting linear matrix‑multiplication operations for GPU execution, the system aims to prevent model extraction attacks with modest performance overhead, demonstrated on LLaMA‑2.", "summary_cn": "SecureInfer 提出了将可信执行环境（SGX）与 GPU 异构结合的架构，在边缘设备上对大型语言模型的隐私关键组件进行保护。它将非线性层和 LoRA 适配器等安全敏感部分放入 enclave，线性矩阵乘法在加密后交由 GPU 计算，再在 enclave 中安全，以防模型提取攻击，实验基于 LLaMA‑2 显示出合理的性能开销。", "keywords": "secure inference, trusted execution environment, SGX, GPU offloading, model extraction protection, LLM deployment, privacy, heterogeneous architecture, LoRA adapters", "scoring": {"interpretability": 2, "understanding": 6, "safety": 8, "technicality": 7, "surprisal": 6}, "category": {"failure_mode_addressed": "human-misuse", "primary_focus": "robustness"}, "authors": ["Tushar Nayan", "Ziqi Zhang", "Ruimin Sun"]}, "usage": {"completion_tokens": 981, "prompt_tokens": 3436, "total_tokens": 4417, "completion_tokens_details": {"accepted_prediction_tokens": null, "audio_tokens": null, "reasoning_tokens": 809, "rejected_prediction_tokens": null, "image_tokens": 0}, "prompt_tokens_details": {"audio_tokens": 0, "cached_tokens": 3152}, "cost": 0.00078526, "is_byok": false, "cost_details": {"upstream_inference_cost": null, "upstream_inference_prompt_cost": 0.00029476, "upstream_inference_completions_cost": 0.0004905}}, "model": "openai/gpt-oss-120b"}
{"timestamp": "2025-10-24T17:33:51.179169", "feed": "arxiv_cslg", "title": "Transforming Multi-Omics Integration with GANs: Applications in Alzheimer's and Cancer", "link": "https://papers.cool/arxiv/2510.19870", "analysis": {"summary": "The paper presents Omics-GAN, a generative adversarial network framework that synthesizes multi-omics profiles (mRNA, miRNA, DNA methylation) while preserving biological relationships, and demonstrates that classifiers trained on the synthetic data achieve higher AUCs for Alzheimer's disease and several cancers compared to using original data. It also shows that the generated data retain statistical properties, enable additional biomarker discovery via enrichment analyses, and facilitate drug rep and accelerate precision medicine pipelines.", "summary_cn": "本文提出 Omics-GAN 框架，利用生成对抗网络合成多组学数据（mRNA、miRNA、DNA 甲基化），在保持生物学关系的同时提升阿尔茨海默病和多种癌症的预测准确率。实验表明，基于合成数据的分类器在 AUC 上均优于使用原始数据，且合成数据保持统计分布，帮助发现额外的生物标志物并通过分子对接提出药物再利用候选，如 Nilotinib（AD）和 Atovaquone（肝癌）。该方法旨在提升疾病预测并加速精准医学研究。", "keywords": "multi-omics, GAN, synthetic data, disease prediction, Alzheimer's, cancer, biomarker discovery", "scoring": {"interpretability": 2, "understanding": 5, "safety": 2, "technicality": 7, "surprisal": 6}, "category": {"failure_mode_addressed": "non-applicable", "primary_focus": "other"}, "authors": ["Md Selim Reza", "Sabrin Afroz", "Mostafizer Rahman", "Md Ashad Alam"]}, "usage": {"completion_tokens": 625, "prompt_tokens": 3518, "total_tokens": 4143, "completion_tokens_details": {"accepted_prediction_tokens": null, "audio_tokens": null, "reasoning_tokens": 283, "rejected_prediction_tokens": null, "image_tokens": 0}, "prompt_tokens_details": {"audio_tokens": 0, "cached_tokens": 3152}, "cost": 0.00061956, "is_byok": false, "cost_details": {"upstream_inference_cost": null, "upstream_inference_prompt_cost": 0.00030706, "upstream_inference_completions_cost": 0.0003125}}, "model": "openai/gpt-oss-120b"}
{"timestamp": "2025-10-24T17:33:51.209788", "feed": "arxiv_cslg", "title": "Quantifying Feature Importance for Online Content Moderation", "link": "https://papers.cool/arxiv/2510.19882", "analysis": {"summary": "The paper quantifies how 753 socio‑behavioural, linguistic, relational, and psychological features predict changes in activity, toxicity, and participation diversity of 16.8K Reddit users after a major moderation intervention. Using a greedy feature‑selection approach, the authors identify a small set of consistently informative features and show that predictive performance varies across tasks, with activity and toxicity being easier to estimate than diversity. The results inform the design of tailored moderation strategies that consider both user traits and specific intervention objectives.", "summary_cn": "本文量化了 753 种社会行为、语言、关系和心理特征在 Reddit 上 16.8K 名用户在一次重大内容审查干预后行为变化（活动、毒性、参与多样性）中的预测能力。通过贪婪特征选择方法，作者找出了一小批在所有任务中始终有效的特征，并发现不同任务的预测效果不同，其中活动和毒性更易预测，而多样性较难。研究结果有助于制定兼顾用户特征和干预目标的精准审查策略。", "keywords": "feature importance, content moderation, user behavior prediction, feature selection, Reddit, toxicity, activity, participation diversity", "scoring": {"interpretability": 2, "understanding": 7, "safety": 6, "technicality": 7, "surprisal": 5}, "category": {"failure_mode_addressed": "societal-disruption", "primary_focus": "other"}, "authors": ["Benedetta Tessa", "Alejandro Moreo", "Stefano Cresci", "Tiziano Fagni", "Fabrizio Sebastiani"]}, "usage": {"completion_tokens": 746, "prompt_tokens": 3467, "total_tokens": 4213, "completion_tokens_details": {"accepted_prediction_tokens": null, "audio_tokens": null, "reasoning_tokens": 493, "rejected_prediction_tokens": null, "image_tokens": 0}, "prompt_tokens_details": {"audio_tokens": 0, "cached_tokens": 3152}, "cost": 0.00067241, "is_byok": false, "cost_details": {"upstream_inference_cost": null, "upstream_inference_prompt_cost": 0.00029941, "upstream_inference_completions_cost": 0.000373}}, "model": "openai/gpt-oss-120b"}
{"timestamp": "2025-10-24T17:33:51.420087", "feed": "arxiv_cslg", "title": "Artificial Intelligence Powered Identification of Potential Antidiabetic Compounds in Ficus religiosa", "link": "https://papers.cool/arxiv/2510.19867", "analysis": {"summary": "The paper applies an AI‑driven pipeline combining machine learning, graphDock) to screen phytochemicals from Ficus religiosa for inhibition of the antidiabetic target DPP‑4. Flavonoids and alkaloids are identified as promising candidates with strong predicted binding and favorable ADMET profiles, demonstrating that AI can accelerate and improve accuracy in plant‑based drug discovery.", "summary_cn": "本文利用人工智能驱动的流程，结合机器学习、图卷积网络（DeepBindGCN）以及分子对接（AutoDock），筛选菩提树（Ficus religiosa）中的植物化学物质以抑制抗糖尿病关键靶点 DPP‑4。研究发现黄酮类和生物碱类化合物具有强结合力和良好 ADMET 预测，展示了 AI 在植物药物发现中加速筛选并提升准确性的潜力。", "keywords": "antidiabetic, Ficus religiosa, DPP-4 inhibition, deep learning, molecular docking, AI drug discovery, phytochemicals", "scoring": {"interpretability": 2, "understanding": 4, "safety": 2, "technicality": 6, "surprisal": 5}, "category": {"failure_mode_addressed": "non-applicable", "primary_focus": "other"}, "authors": ["Md Ashad Alam", "Md Amanullah"]}, "usage": {"completion_tokens": 642, "prompt_tokens": 3412, "total_tokens": 4054, "completion_tokens_details": {"accepted_prediction_tokens": null, "audio_tokens": null, "reasoning_tokens": 367, "rejected_prediction_tokens": null, "image_tokens": 0}, "prompt_tokens_details": {"audio_tokens": 0, "cached_tokens": 3152}, "cost": 0.00061216, "is_byok": false, "cost_details": {"upstream_inference_cost": null, "upstream_inference_prompt_cost": 0.00029116, "upstream_inference_completions_cost": 0.000321}}, "model": "openai/gpt-oss-120b"}
{"timestamp": "2025-10-24T17:33:51.710924", "feed": "arxiv_cslg", "title": "SODBench: A Large Language Model Approach to Documenting Spreadsheet Operations", "link": "https://papers.cool/arxiv/2510.19864", "analysis": {"summary": "The paper defines Spreadsheet Operations Documentation (SOD) as the task of generating human‑readable explanations for spreadsheet manipulation code and introduces a benchmark of 111 code–summary pairs. It evaluates several LLMs (GPT‑4o, GPT‑4o‑mini, LLaMA‑3.3‑70B, Mixtral‑8x7B, Gemma2‑9B) on the benchmark using BLEU, GLEU, ROUGE‑L, and METEOR, showing that LLMs can reliably document spreadsheet operations, though challenges remain. The work highlights SOD as a step toward better reproducibility, maintainability, and collaboration in spreadsheet‑based workflows.", "summary_cn": "本文提出“电子表格操作文档化”（SOD）任务，即将电子表格操作代码生成可读的自然语言说明，并构建了包含 111 条代码‑摘要对的基准数据集。作者评估了多种大型语言模型（GPT‑4o、GPT‑4o‑mini、LLaMA‑3.3‑70B、Mixtral‑8x7B、Gemma2‑9B），使用 BLEU、GLEU、ROUGE‑L 和 METEOR 等指标，结果表明这些模型能够较准确地生成电子表格文档，尽管仍存在一些挑战。该工作将 SOD 视为提升电子表格可重现性、可维护性和协作性的可行前置步骤。", "keywords": "spreadsheet documentation, large language models, SOD, natural language summarization, code-to-text, benchmark, GPT-4o, spreadsheet automation", "scoring": {"interpretability": 3, "understanding": 5, "safety": 2, "technicality": 6, "surprisal": 5}, "category": {"failure_mode_addressed": "non-applicable", "primary_focus": "other"}, "authors": ["Amila Indika", "Igor Molybog"]}, "usage": {"completion_tokens": 792, "prompt_tokens": 3426, "total_tokens": 4218, "completion_tokens_details": {"accepted_prediction_tokens": null, "audio_tokens": null, "reasoning_tokens": 432, "rejected_prediction_tokens": null, "image_tokens": 0}, "prompt_tokens_details": {"audio_tokens": 0, "cached_tokens": 3152}, "cost": 0.00068926, "is_byok": false, "cost_details": {"upstream_inference_cost": null, "upstream_inference_prompt_cost": 0.00029326, "upstream_inference_completions_cost": 0.000396}}, "model": "openai/gpt-oss-120b"}
{"timestamp": "2025-10-24T17:33:52.130061", "feed": "arxiv_cslg", "title": "Spectral Thresholds in Correlated Spiked Models and Fundamental Limits of Partial Least Squares", "link": "https://papers.cool/arxiv/2510.17561", "analysis": {"summary": "The paper presents a rigorous random matrix theory analysis of spiked cross-covariance models where signals in two high-dimensional data channels are partially aligned, a setting underlying Partial Least Squares (PLS). It shows that the leading singular values of the sample cross-covariance matrix exhibit a BBP-type phase transition and derives exact thresholds for the emergence of informative components, revealing a fundamental performance gap between PLS and the Bayes-optimal estimator. The results delineate regimes where PLS cannot recover any signal despite detectability being theoretically possible, thus clarifying the theoretical limits of PLS for multi‑modal inference.", "summary_cn": "本文对两个高维数据通道中部分对齐信号的尖刺交叉协方差模型进行严格的随机矩阵理论分析，该模型是偏最小二乘（PLS）方法的标准生成设定。研究表明样本交叉协方差矩阵的主奇异值出现 BBP 类型的相变，并精确刻画了信息成分出现的阈值，揭示了 PLS 与贝叶斯最优估计器之间的根本性能差距。结果指出在某些信噪比和相关性 regime 下，PLS 无法恢复任何信号，即使理论上可以检测到，从而阐明了 PLS 在多模态推断中的理论极限。", "keywords": "spiked covariance, cross-covariance, partial least squares, random matrix theory, BBP phase transition, signal recovery, high-dimensional statistics, multi-modal learning, Bayes-optimal estimator", "scoring": {"interpretability": 2, "understanding": 7, "safety": 2, "technicality": 9, "surprisal": 6}, "category": {"failure_mode_addressed": "non-applicable", "primary_focus": "other"}, "authors": ["Pierre Mergny", "Lenka Zdeborová"]}, "usage": {"completion_tokens": 788, "prompt_tokens": 3394, "total_tokens": 4182, "completion_tokens_details": {"accepted_prediction_tokens": null, "audio_tokens": null, "reasoning_tokens": 453, "rejected_prediction_tokens": null, "image_tokens": 0}, "prompt_tokens_details": {"audio_tokens": 0, "cached_tokens": 3152}, "cost": 0.00068246, "is_byok": false, "cost_details": {"upstream_inference_cost": null, "upstream_inference_prompt_cost": 0.00028846, "upstream_inference_completions_cost": 0.000394}}, "model": "openai/gpt-oss-120b"}
{"timestamp": "2025-10-24T17:33:53.354799", "feed": "arxiv_cslg", "title": "Learning from Supervision with Semantic and Episodic Memory: A Reflective Approach to Agent Adaptation", "link": "https://papers.cool/arxiv/2510.19897", "analysis": {"summary": "The paper proposes a memory‑augmented framework for large language model agents to learn classification tasks from labeled examples without updating model parameters, using episodic memory to store instance‑level critiques and semantic memory to distill task‑level guidance. Incorporating LLM‑generated critiques improves accuracy by up to 24.8% over retrieval‑only baselines, and the authors introduce a “suggestibility” metric to analyze how different memory representations affect model learning dynamics. Experiments reveal behavioral differences between OpenAI and open‑source models on factual versus preference‑based data, highlighting the potential of reflective, memory‑driven learning for more adaptive and interpretable agents.", "summary_cn": "本文提出一种记忆增强框架，使基于大语言模型的智能体能够在不更新模型参数的情况下，通过标记示例学习分类任务；框架利用情景记忆存储实例层面的批评，并通过语义记忆提炼为任务层面的指导。结合 LLM 生成的批评相较仅使用检索的基线可提升最高 24.8% 的准确率，作者还引入 “suggestibility（可暗示性）” 指标来解释不同记忆表征如何影响模型学习动力学。实验展示了 OpenAI 与开源模型在处理事实型与偏好型数据时的行为差异，凸显了反思式、记忆驱动学习在构建更适应且可解释的 LLM 智能体方面的前景。", "keywords": "memory-augmented LLM, episodic memory, semantic memory, reflective learning, LLM critiques, suggestibility metric, parameter-free adaptation, agent interpretability, classification learning", "scoring": {"interpretability": 6, "understanding": 7, "safety": 4, "technicality": 7, "surprisal": 6}, "category": {"failure_mode_addressed": "misalignment", "primary_focus": "interpretability"}, "authors": ["Jackson Hassell", "Dan Zhang", "Hannah Kim", "Tom Mitchell", "Estevam Hruschka"]}, "usage": {"completion_tokens": 1074, "prompt_tokens": 3417, "total_tokens": 4491, "completion_tokens_details": {"accepted_prediction_tokens": null, "audio_tokens": null, "reasoning_tokens": 839, "rejected_prediction_tokens": null, "image_tokens": 0}, "prompt_tokens_details": {"audio_tokens": 0, "cached_tokens": 3152}, "cost": 0.00082891, "is_byok": false, "cost_details": {"upstream_inference_cost": null, "upstream_inference_prompt_cost": 0.00029191, "upstream_inference_completions_cost": 0.000537}}, "model": "openai/gpt-oss-120b"}
{"timestamp": "2025-10-24T17:33:53.914594", "feed": "arxiv_cslg", "title": "Guiding diffusion models to reconstruct flow fields from sparse data", "link": "https://papers.cool/arxiv/2510.19971", "analysis": {"summary": "This paper proposes a novel sampling technique for diffusion models that guides the reverse diffusion process with sparse measurements to reconstruct high‑fidelity unsteady flow fields. It also incorporates physics knowledge via a conflict‑free update during training and demonstrates superior performance on 2‑D and 3‑D turbulent flow datasets compared to existing diffusion‑based methods. The results highlight the potential of diffusion generative models for CFD reconstruction tasks.", "summary_cn": "本文提出一种新颖的扩散模型采样方法，通过利用稀疏观测数据在逆扩散过程中进行引导，以重建高保真度的非稳态流场。同时在训练阶段加入冲突‑自由的物理约束更新。实验在二维和三维湍流数据上表明方法相较于现有基于扩散模型的技术在流场结构和像素误差上均有显著提升，展示了扩散模型在计算流体力学重建中的巨大潜力。", "keywords": "diffusion models, flow reconstruction, sparse measurements, computational fluid dynamics, physics-informed learning, turbulent flow", "scoring": {"interpretability": 3, "understanding": 6, "safety": 1, "technicality": 8, "surprisal": 7}, "category": {"failure_mode_addressed": "non-applicable", "primary_focus": "other"}, "authors": ["Marc Amorós-Trepat", "Luis Medrano-Navarro", "Qiang Liu", "Luca Guastoni", "Nils Thuerey"]}, "usage": {"completion_tokens": 977, "prompt_tokens": 3410, "total_tokens": 4387, "completion_tokens_details": {"accepted_prediction_tokens": null, "audio_tokens": null, "reasoning_tokens": 842, "rejected_prediction_tokens": null, "image_tokens": 0}, "prompt_tokens_details": {"audio_tokens": 0, "cached_tokens": 3152}, "cost": 0.00077936, "is_byok": false, "cost_details": {"upstream_inference_cost": null, "upstream_inference_prompt_cost": 0.00029086, "upstream_inference_completions_cost": 0.0004885}}, "model": "openai/gpt-oss-120b"}
{"timestamp": "2025-10-24T17:33:54.279755", "feed": "arxiv_cslg", "title": "Branch-and-Browse: Efficient and Controllable Web Exploration with Tree-Structured Reasoning and Action Memory", "link": "https://papers.cool/arxiv/2510.19838", "analysis": {"summary": "The paper presents Branch-and-Browse, a framework for LLM-powered autonomous web agents that integrates tree-structured subtask management, background state replay, and a page action memory to enable controllable multi-branch reasoning and improve efficiency. Evaluated on the WebArena benchmark, the method achieves a 35.8% success rate while reducing execution time by up to 40.4 compared to previous state-of-the-art approaches.", "summary_cn": "本文提出了 Branch-and-Browse 框架，针对基于大型语言模型的自主网页代理，结合树结构子任务管理、后台状态重放以及页面动作记忆，实现可控的多分支推理并提升效率。在 WebArena 基准测试中，该方法实现了 35.8% 的任务成功率，并将执行时间最多降低了 40.4%，相比现有最先进方法表现更佳。", "keywords": "LLM web agents, tree-structured reasoning, action memory, web navigation, controllable exploration, WebArena, autonomous agents, efficiency", "scoring": {"interpretability": 3, "understanding": 6, "safety": 4, "technicality": 7, "surprisal": 5}, "category": {"failure_mode_addressed": "non-applicable", "primary_focus": "control"}, "authors": ["Shiqi He", "Yue Cui", "Xinyu Ma", "Yaliang Li", "Bolin Ding", "Mosharaf Chowdhury"]}, "usage": {"completion_tokens": 958, "prompt_tokens": 3434, "total_tokens": 4392, "completion_tokens_details": {"accepted_prediction_tokens": null, "audio_tokens": null, "reasoning_tokens": 810, "rejected_prediction_tokens": null, "image_tokens": 0}, "prompt_tokens_details": {"audio_tokens": 0, "cached_tokens": 3152}, "cost": 0.00077346, "is_byok": false, "cost_details": {"upstream_inference_cost": null, "upstream_inference_prompt_cost": 0.00029446, "upstream_inference_completions_cost": 0.000479}}, "model": "openai/gpt-oss-120b"}
{"timestamp": "2025-10-24T17:33:55.369298", "feed": "arxiv_cslg", "title": "Neurotremor: A wearable Supportive Device for Supporting Upper Limb Muscle Function", "link": "https://papers.cool/arxiv/2510.19826", "analysis": {"summary": "The paper presents Neurotremor, a wearable prototype that assists upper‑limb muscle function by fusing surface EMG, inertial measurement, and flex/force sensors with an on‑device INT8 TensorFlow Lite micro model. Real‑time features are extracted and control commands are bounded by a control‑barrier‑function safety envelope, leading to reduced tremor and improved movement metrics in a pilot feasibility study with healthy volunteers. The system operates at 100 Hz with low latency, full session completion, and no device‑related adverse events, with patient trials planned.", "summary_cn": "本文介绍了 Neurotremor种可穿戴原型，通过融合表面肌电 (sEMG)、惯性测量单元 (IMU) 与弯曲/力传感器，并在 MStickC+ ESP32‑S3 上运行 INT8 TensorFlow Lite Micro 模型，实现上肢肌肉功能的辅助。系统在 250 ms 窗口内实时提取特征，并通过控制屏障函数 (control‑barrier‑function) 安全包络约束控制指令，在健康志愿者的可行性试验中显著降低颤抖并提升运动范围和重复次数。该装置以 100 Hz 运行，延迟约 8.7 ms，实验期间无设备相关不良事件，计划在伦理审查下进行患者试验。", "keywords": "wearable assistive device, upper limb, sEMG, sensor fusion, TensorFlow Lite Micro, control barrier function, embedded inference, rehabilitation, real-time control", "scoring": {"interpretability": 2, "understanding": 4, "safety": 4, "technicality": 7, "surprisal": 4}, "category": {"failure_mode_addressed": "non-applicable", "primary_focus": "other"}, "authors": ["Aueaphum Aueawattthanaphisut", "Thanyanee Srichaisak", "Arissa Ieochai"]}, "usage": {"completion_tokens": 1189, "prompt_tokens": 3529, "total_tokens": 4718, "completion_tokens_details": {"accepted_prediction_tokens": null, "audio_tokens": null, "reasoning_tokens": 968, "rejected_prediction_tokens": null, "image_tokens": 0}, "prompt_tokens_details": {"audio_tokens": 0, "cached_tokens": 3152}, "cost": 0.00090321, "is_byok": false, "cost_details": {"upstream_inference_cost": null, "upstream_inference_prompt_cost": 0.00030871, "upstream_inference_completions_cost": 0.0005945}}, "model": "openai/gpt-oss-120b"}
{"timestamp": "2025-10-24T17:33:56.985791", "feed": "arxiv_cslg", "title": "LyriCAR: A Difficulty-Aware Curriculum Reinforcement Learning Framework For Controllable Lyric Translation", "link": "https://papers.cool/arxiv/2510.19967", "analysis": {"summary": "LyriCAR introduces a difficulty-aware curriculum reinforcement learning framework for controllable lyric translation, operating in an unsupervised manner. By designing an adaptive curriculum that presents increasingly complex translation challenges, the system improves translation quality, cross-line coherence, and global rhyme while reducing training steps by about 40% compared to baselines. Experiments on English‑Chinese lyric translation demonstrate state-of-the-art performance on both standard metrics and multi‑dimensional reward scores.", "summary_cn": "LyriCAR 提出了一种难度感知的课程强化学习框架，用于可控的歌词翻译，完全无监督。该框架通过自适应课程设计，逐步提供更复杂的翻译挑战，从而提升翻译质量、跨行连贯性和整体押韵，并将训练步骤缩减约 40%。在英-中歌词翻译实验中，该方法在标准翻译指标和多维奖励得分上均实现了最先进的性能。", "keywords": "lyric translation, curriculum reinforcement learning, difficulty-aware curriculum, controllable generation, unsupervised translation, multi-dimensional reward, EN-ZH translation", "scoring": {"interpretability": 2, "understanding": 6, "safety": 1, "technicality": 7, "surprisal": 5}, "category": {"failure_mode_addressed": "non-applicable", "primary_focus": "other"}, "authors": ["Le Ren", "Xiangjian Zeng", "Qingqiang Wu", "Ruoxuan Liang"]}, "usage": {"completion_tokens": 770, "prompt_tokens": 3400, "total_tokens": 4170, "completion_tokens_details": {"accepted_prediction_tokens": null, "audio_tokens": null, "reasoning_tokens": 573, "rejected_prediction_tokens": null, "image_tokens": 0}, "prompt_tokens_details": {"audio_tokens": 0, "cached_tokens": 3152}, "cost": 0.00067436, "is_byok": false, "cost_details": {"upstream_inference_cost": null, "upstream_inference_prompt_cost": 0.00028936, "upstream_inference_completions_cost": 0.000385}}, "model": "openai/gpt-oss-120b"}
{"timestamp": "2025-10-24T17:33:58.280786", "feed": "arxiv_cslg", "title": "DAG-Math: Graph-Guided Mathematical Reasoning in LLMs", "link": "https://papers.cool/arxiv/2510.19842", "analysis": {"summary": "The paper introduces DAG-MATH, a graph‑guided framework that models chain‑of‑thought reasoning as a stochastic process over directed acyclic graphs, defining a logical closeness metric to assess how well LLM generated derivations follow rule‑consistent structures. By creating a benchmark that requires LLMs to produce CoT trajectories in this DAG format, the authors reveal significant differences in reasoning fidelity across model families even when final answer accuracy (PASS@k) is similar. This work bridges free‑form CoT and formal proof systems, offering a new diagnostic tool for evaluating LLM mathematical reasoning.", "summary_cn": "本文提出 DAG‑MATH 框架，将链式思考（CoT）建模为有向无环图（DAG）上的随机过程，并引入逻辑接近度指标衡量模型生成的推理路径与图结构的规则一致性。通过构建要求 LLM 按 DAG 格式输出 CoT 的基准，作者发现即使在 PASS@k 相近的情况下，不同模型家族在推理忠实度上存在显著差异。该工作在自由形式 CoT 与形式化证明系统之间提供了平衡，为评估 LLM 数学推理提供了可操作的诊断手段。", "keywords": "DAG, chain-of-thought, logical closeness, mathematical reasoning, LLM, benchmark, interpretability, reasoning fidelity", "scoring": {"interpretability": 7, "understanding": 8, "safety": 4, "technicality": 7, "surprisal": 7}, "category": {"failure_mode_addressed": "non-applicable", "primary_focus": "interpretability"}, "authors": ["Yuanhe Zhang", "Ilja Kuzborskij", "Jason D. Lee", "Chenlei Leng", "Fanghui Liu"]}, "usage": {"completion_tokens": 650, "prompt_tokens": 3460, "total_tokens": 4110, "completion_tokens_details": {"accepted_prediction_tokens": null, "audio_tokens": null, "reasoning_tokens": 331, "rejected_prediction_tokens": null, "image_tokens": 0}, "prompt_tokens_details": {"audio_tokens": 0, "cached_tokens": 3456}, "cost": 0.00060208, "is_byok": false, "cost_details": {"upstream_inference_cost": null, "upstream_inference_prompt_cost": 0.00027708, "upstream_inference_completions_cost": 0.000325}}, "model": "openai/gpt-oss-120b"}
{"timestamp": "2025-10-24T17:33:58.419083", "feed": "arxiv_cslg", "title": "RELATE: A Schema-Agnostic Perceiver Encoder for Multimodal Relational Graphs", "link": "https://papers.cool/arxiv/2510.19954", "analysis": {"summary": "The paper introduces RELATE, a schema-agnostic Perceiver-style encoder that processes heterogeneous multimodal node attributes and produces fixed-size, permutation‑invariant representations for use with any graph neural network. By sharing modality‑specific encoders and a cross‑attention aggregation module, RELATE achieves performance comparable to schema‑specific encoders while dramatically reducing parameter count, enabling multi‑dataset pretraining for relational graphs.", "summary_cn": "本文提出 RELATE，一种基于 Perceiver 的跨模态编码器，能够无视表结构差异，对异构多模态节点属性进行统一编码，并生成固定维度、置换不变的节点表示，可与任意图神经网络配合使用。该方法通过共享的模态专属编码器和交叉注意力聚合，保持与特定模式编码器相近的性能，同时显著降低模型参数量，支持跨数据集的预训练，为关系图数据的基础模型奠定基础。", "keywords": "schema-agnostic encoder, multimodal relational graph, Perceiver cross-attention, heterogeneous graph neural network, foundation model, relational graph representation, multi-table data", "scoring": {"interpretability": 2, "understanding": 6, "safety": 1, "technicality": 8, "surprisal": 6}, "category": {"failure_mode_addressed": "non-applicable", "primary_focus": "other"}, "authors": ["Joseph Meyer", "Divyansha Lachi", "Reza Mohammadi", "Roshan Reddy Upendra", "Eva L. Dyer", "Mark Li", "Tom Palczewski"]}, "usage": {"completion_tokens": 704, "prompt_tokens": 3420, "total_tokens": 4124, "completion_tokens_details": {"accepted_prediction_tokens": null, "audio_tokens": null, "reasoning_tokens": 433, "rejected_prediction_tokens": null, "image_tokens": 0}, "prompt_tokens_details": {"audio_tokens": 0, "cached_tokens": 3152}, "cost": 0.00064436, "is_byok": false, "cost_details": {"upstream_inference_cost": null, "upstream_inference_prompt_cost": 0.00029236, "upstream_inference_completions_cost": 0.000352}}, "model": "openai/gpt-oss-120b"}
{"timestamp": "2025-10-24T17:34:03.271306", "feed": "arxiv_cslg", "title": "Improving Predictive Confidence in Medical Imaging via Online Label Smoothing", "link": "https://papers.cool/arxiv/2510.20011", "analysis": {"summary": "The paper proposes Online Label Smoothing (OLS), a dynamic label smoothing technique that adjusts soft labels during training based on the model’s predictions, and evaluates it on the large‑scale RadImageNet dataset using ResNet‑, MobileNetV2 and VGG‑19. Experiments show that OLS consistently improves top‑1 and top‑5 accuracy as well as calibration compared to hard labels, conventional label smoothing and teacher‑free knowledge distillation, while also producing more compact and well‑separated feature embeddings. These results suggest OLS can enhance the reliability and trustworthiness of medical imaging classifiers.", "summary_cn": "本文提出在线标签平滑（OLS）方法，该方法根据模型在训练过程中的预测动态调整软标签，并在大规模 RadImageNet 数据集上使用 ResNet‑50、MobileNetV2 和 VGG‑19 进行评估。实验表明，较之硬标签、传统标签平滑以及无教师知识蒸馏，OLS 能持续提升 Top‑1 与 Top‑5 准确率及预测校准效果，同时生成更紧凑且分布更分明的特征嵌入。结果显示 OLS 有助于提升医学影像分类器的可靠性与可信度。", "keywords": "online label smoothing, calibration, medical imaging, CNN, RadImageNet, representation learning, predictive confidence, label smoothing, deep learning, trustworthiness", "scoring": {"interpretability": 2, "understanding": 5, "safety": 6, "technicality": 6, "surprisal": 5}, "category": {"failure_mode_addressed": "misalignment", "primary_focus": "robustness"}, "authors": ["Kushan Choudhury", "Shubhrodeep Roy", "Ankur Chanda", "Shubhajit Biswas", "Somenath Kuiry"]}, "usage": {"completion_tokens": 1113, "prompt_tokens": 3422, "total_tokens": 4535, "completion_tokens_details": {"accepted_prediction_tokens": null, "audio_tokens": null, "reasoning_tokens": 942, "rejected_prediction_tokens": null, "image_tokens": 0}, "prompt_tokens_details": {"audio_tokens": 0, "cached_tokens": 3152}, "cost": 0.00084916, "is_byok": false, "cost_details": {"upstream_inference_cost": null, "upstream_inference_prompt_cost": 0.00029266, "upstream_inference_completions_cost": 0.0005565}}, "model": "openai/gpt-oss-120b"}
{"timestamp": "2025-10-24T17:34:04.299068", "feed": "arxiv_cslg", "title": "Empower Words: DualGround for Structured Phrase and Sentence-Level Temporal Grounding", "link": "https://papers.cool/arxiv/2510.20244", "analysis": {"summary": "The paper identifies that current video temporal grounding models treat all text tokens uniformly, causing an over-reliance on the [EOS] token and limiting fine-grained alignment. To address this, DualGround introduces a dual-branch architecture that separates sentence-level semantics (via the [EOS] token) from phrase-level semantics obtained by clustering word tokens, employing token-role-aware cross-modal interactions. Experiments on QVHighlights and Charades-STA show that this disentangled approach achieves state-of-the-art performance on both Moment Retrieval and Highlight Detection.", "summary_cn": "本文指出现有视频时间定位模型在跨模态注意力中对所有文本标记一视同仁，导致过度依赖 [EOS] 标记而削弱细粒度对齐能力。为此，DualGround 采用双分支结构，将子层级语义（通过 [EOS] 标记）与通过词标记聚类获得的短语层级语义分离，并使用基于标记角色的跨模态交互策略。实验在 QVHighlights 与 Charades-STA 数据集上展示，该方法在 Moment Retrieval 与 Highlight Detection 两项任务上均达到了最新水平。", "keywords": "video temporal grounding, moment retrieval, highlight detection, dual-branch architecture, token-role aware interaction, phrase-level semantics, sentence-level semantics, cross-modal attention, structured phrase, state-of-the-art", "scoring": {"interpretability": 3, "understanding": 6, "safety": 2, "technicality": 7, "surprisal": 6}, "category": {"failure_mode_addressed": "non-applicable", "primary_focus": "other"}, "authors": ["Minseok Kang", "Minhyeok Lee", "Minjung Kim", "Donghyeong Kim", "Sangyoun Lee"]}, "usage": {"completion_tokens": 1164, "prompt_tokens": 3502, "total_tokens": 4666, "completion_tokens_details": {"accepted_prediction_tokens": null, "audio_tokens": null, "reasoning_tokens": 1020, "rejected_prediction_tokens": null, "image_tokens": 0}, "prompt_tokens_details": {"audio_tokens": 0, "cached_tokens": 3152}, "cost": 0.00088666, "is_byok": false, "cost_details": {"upstream_inference_cost": null, "upstream_inference_prompt_cost": 0.00030466, "upstream_inference_completions_cost": 0.000582}}, "model": "openai/gpt-oss-120b"}
